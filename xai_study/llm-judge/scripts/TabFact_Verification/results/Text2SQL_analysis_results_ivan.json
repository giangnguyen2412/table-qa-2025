{
    "TP/test-343.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the game at the target center took place after the game at the fedexforum\nInput Table: 2008 - 09 phoenix suns season\n\n\ngamedateteamlocation_attendancerecord759999-04-01houstonus airways center 1842241 - 34769999-04-03sacramentous airways center 1842242 - 3477'9999-04-05'dallasamerican airlines center 2030142 - 35789999-04-08new orleansnew orleans arena 1778143 - 3579'9999-04-10'memphisfedexforum 1590843 - 36809999-04-11minnesotatarget center 1847844 - 36819999-04-13memphisus airways center 1842245 - 3682'9999-04-15'golden stateus airways center46 - 36\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT date FROM table_sql WHERE game = 80) > \n             (SELECT date FROM table_sql WHERE game = 79) \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1661.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: three of the people tied for ninth place are from the united states\nInput Table: 1989 u.s. open (golf)\n\n\nplaceplayercountryscoreto_parmoney1curtis strangeunited states71 + 64 + 73 + 70 = 278- 2200000t2chip beckunited states71 + 69 + 71 + 68 = 279- 167823t2mark mccumberunited states70 + 68 + 72 + 69 = 279- 167823t2ian woosnamwales70 + 68 + 73 + 68 = 279- 1678235brian claarunited states71 + 72 + 68 + 69 = 280e34345t6masashi ozakijapan70 + 71 + 68 + 72 = 281+ 128220t6scott simpsonunited states67 + 70 + 69 + 75 = 281+ 1282208peter jacobsenunited states71 + 70 + 71 + 70 = 282+ 224307t9paul azingerunited states71 + 72 + 70 + 70 = 283+ 319968t9hubert greenunited states69 + 72 + 74 + 68 = 283+ 319968t9tom kiteunited states67 + 69 + 69 + 78 = 283+ 319968t9jos\u00e9 mar\u00eda olaz\u00e1balspain69 + 72 + 70 + 72 = 283+ 319968\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 3 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE place = 't9' \nAND country = 'united states';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1751.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the 49ers first opponent of the season was the brooklyn dodgers\nInput Table: 1947 san francisco 49ers season\n\n\nweekdateopponentresultscorerecord11947-08-31brooklyn dodgersw23 - 71 - 021947-09-07los angeles donsw17 - 142 - 031947-09-14baltimore coltsw14 - 73 - 041947-09-21new york yankeesl21 - 163 - 151947-09-28buffalo billsw41 - 244 - 161947-10-05baltimore coltst28 - 284 - 1 - 171947-10-12chicago rocketsw42 - 285 - 1 - 181947-10-26cleveland brownsl14 - 75 - 2 - 191947-11-02los angeles donsw26 - 166 - 2 - 1101947-11-09new york yankeesl24 - 166 - 3 - 1111947-11-16cleveland brownsl37 - 146 - 4 - 1121947-11-21chicago rocketsw41 - 167 - 4 - 1131947-11-27brooklyn dodgersw21 - 78 - 4 - 1141947-12-07buffalo billst21 - 218 - 4 - 2\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN opponent = 'brooklyn dodgers' AND week = 1 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1109.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the lead was denni neufeld with a skip of mike mcewen\nInput Table: 2009 canadian olympic curling trials\n\n\nskipthird_/_vice_skipsecondleadcitykerry burtnykdon walchukrichard daneaultgarth smithwinnipegpat simmonsgerry adamjeff sharpsteve laycockdavidsonjeff stoughtonkevin parkrob fowlersteve gouldwinnipegwayne middaughjon meadjohn eppingscott baileyislingtonbrad gushuemark nicholsryan fryjamie korabst john 'smike mcewenb j neufeldmatt wozniakdenni neufeldwinnipegjoel jordisonscott bitzaryn schmidtdean hickemoose jawbob urseljim cotterkevin folkrick sawatskykelownajean - michel m\u00e9nardmartin cr\u00eate\u00e9ric sylvainjean gagnonl\u00e9visted appelmantom appelmanbradon klassenbrendan melnykedmontongreg mcaulayken maskiewichdeane horningaaron watsonrichmondjason gunnlaugsonjustin richterbraden zawadatyler forrestbeausejour\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT lead FROM table_sql WHERE skip = 'mike mcewen') = 'denni neufeld' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1316.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: robert bauman was the incumbent for maryland district 1\nInput Table: united states house of representatives elections , 1974\n\n\ndistrictincumbentpartyfirst_electedresultcandidatesmaryland 1robert baumanrepublican1973-01-01re - electedrobert bauman (r) 53.0% thomas j hatem (d) 47.0%maryland 2clarence longdemocratic1962-01-01re - electedclarence long (d) 77.1% john m seney (r) 22.9%maryland 4marjorie holtrepublican1972-01-01re - electedmarjorie holt (r) 58.1% fred l wineland (d) 41.9%maryland 6goodloe byrondemocratic1970-01-01re - electedgoodloe byron (d) 73.7% elton r wampler (r) 26.3%maryland 7parren mitchelldemocratic1970-01-01re - electedparren mitchell (d) unopposed\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE district = 'maryland 1' \nAND incumbent = 'robert bauman';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1037.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there are only two highest ranks listed in the table\nInput Table: list of sumo record holders\n\n\nnametotalfirstlasthighest_rankkotonishiki341990-09-011999-09-01sekiwakekai\u014d321994-05-012000-07-01\u014dzekimus\u014dyama311994-03-012000-09-01\u014dzekihasegawa301965-11-011974-09-01sekiwakekotomitsuki302001-01-012007-07-01\u014dzekiakinoshima271988-11-012000-09-01sekiwaketakamiyama271969-11-011982-09-01sekiwaketakat\u014driki261991-05-012000-05-01sekiwakewakanosato262000-11-012005-09-01sekiwakedaikirin221966-11-011970-09-01\u014dzekitochiazuma ii221997-07-012005-01-01\u014dzekikisenosato222006-07-012011-09-01\u014dzeki\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(DISTINCT highest_rank) = 2 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-369.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: on october 11th , the black knights lost to duke\nInput Table: 1975 army cadets football team\n\n\ngamedateopponentresultblack_knights_pointsopponentsrecord19999-09-13holy crosswin4471 - 029999-09-20lehighwin54322 - 039999-09-27villanovaloss0102 - 149999-10-04stanfordloss14672 - 259999-10-11dukeloss10212 - 369999-10-18pittsburghloss20522 - 479999-10-25penn stateloss0312 - 589999-11-01air forceloss3332 - 699999-11-08boston collegeloss0312 - 7109999-11-15vanderbiltloss14232 - 8\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE date = '9999-10-11' \nAND opponent = 'duke' \nAND result = 'loss';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1139.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: richmond hosted fitzroy at punt road oval\nInput Table: 1946 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddategeelong15.7 (97)melbourne21.14 (140)kardinia park115001946-07-13essendon16.24 (120)footscray14.8 (92)windy hill290001946-07-13collingwood15.23 (113)hawthorn11.14 (80)victoria park110001946-07-13carlton12.13 (85)south melbourne11.18 (84)princes park260001946-07-13st kilda10.14 (74)north melbourne12.11 (83)junction oval70001946-07-13richmond14.14 (98)fitzroy10.12 (72)punt road oval190001946-07-13\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE home_team = 'richmond' \nAND venue = 'punt road oval' \nAND away_team = 'fitzroy';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-275.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the toronto blue jays played the rangers three times in may during the 1991 season\nInput Table: 1991 toronto blue jays season\n\n\ndateopponentscorelossattendancerecord9999-05-01rangers3 - 0key (4 - 1)3343912 - 109999-05-02royals3 - 1appier (1 - 4)2289613 - 109999-05-03royals5 - 1davis (2 - 2)2080914 - 109999-05-04royals6 - 5boucher (0 - 2)2262814 - 119999-05-05royals3 - 0gordon (1 - 2)2258815 - 119999-05-07rangers3 - 2key (4 - 2)4462215 - 129999-05-08rangers4 - 2ryan (3 - 3)4321116 - 129999-05-09white sox2 - 0p\u00e3rez (1 - 2)4723617 - 129999-05-10white sox5 - 3 (12)fraser (0 - 1)5019817 - 139999-05-11white sox5 - 2hough (0 - 2)5020618 - 139999-05-12white sox4 - 2hibbard (2 - 1)5010819 - 139999-05-13royals4 - 2davis (2 - 4)4427520 - 139999-05-14royals4 - 1gubicza (0 - 1)4335721 - 139999-05-15royals6 - 4boucher (0 - 3)5011321 - 149999-05-17white sox5 - 3timlin (3 - 1)3009521 - 159999-05-18white sox9 - 2hibbard (2 - 2)3486122 - 159999-05-19white sox5 - 4timlin (3 - 2)4101522 - 169999-05-20athletics1 - 0welch (4 - 3)2463123 - 169999-05-21athletics11 - 7dressendorfer (3 - 3)2273824 - 169999-05-22athletics2 - 1stieb (4 - 3)3402824 - 179999-05-24angels3 - 2finley (7 - 2)2640825 - 179999-05-25angels5 - 0stottlemyre (5 - 1)3673225 - 189999-05-26angels6 - 2wells (5 - 4)4530725 - 199999-05-28athletics8 - 4acker (1 - 2)5029925 - 209999-05-29athletics8 - 3slusarski (1 - 2)5026226 - 209999-05-30athletics8 - 6ward (0 - 2)5027126 - 219999-05-31angels5 - 1langston (6 - 2)5025227 - 21\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 3 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE opponent = 'rangers' \nAND date LIKE '9999-05%' \nAND record LIKE '% - %';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-377.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: coherence has partial windows\nInput Table: comparison of upnp av media servers\n\n\nnamelicenseos_xunix_-_likewindowsweb_interface360 media servergplnoyesyesyesavia media playerpropnonononobrisamitpartialpartialnoyescoherencemitpartialpartialpartialyesdivxpropyesnoyesnoelgato eyeconnectpropyesnononofoobar2000propnonoyesnofuppesgplyesyesyesyesgeexbox usharegplnoyesnoyesgmediaservergplnoyesnonohome media centergplv2nonoyesyesisedora media serverpropyesnoyesyesjriver media centerpropnonoyesyeskooraroo mediapropyesyesyesyeslximediagplyesyesyesnomajestic media serverpropyesnononomediatombgplpartialyesnoyesminidlnagpl / bsdpartialyesyespartialmezzmopropnonoyesnomyihomepropyesyesyesnomythtv with upnpgplyesyesnoyesnullriver medialinkpropyesnononoplayonpropnonoyesyesplexpropyesyesyesyesps3 media servergplyesyesyesyespymedsmitpartialpartialnonorygellgplv2noyesnonorivetpropyesnononoserviiopropyesyesyesyessimplecenter premiumpropnonoyesyesskiftapropyesyesyesnosongbirdgplv2yesnoyesnotvblepropnonoyesnotversitypropnonoyesyestvmobilipropyesyesyesyestvsharepropnonoyesnotwonkyserverpropyesyesyesyesuniversal media servergplyesyesyesyeswindows media connectpropnonoyesnowild media serverpropyesyesyesyesxbmc media centergplyesyesyesyesxupnpdgplv2noyesnoyesyazsoft playbackpropyesnonononamelicenseos xunix - likewindowsweb interface\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT windows FROM table_sql WHERE name = 'coherence') = 'partial' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-893.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: bridgenorth has the highest number of wins in the ntfa div with 15 wins and only 3 losses\nInput Table: none\n\n\nntfa_div_1winsbyeslossesdrawsagainstbridgenorth150301247rocherlea130501661bracknell120511589george town90811431scottsdale801001607deloraine601021639longford501211607hillwood101612071\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT wins FROM table_sql WHERE ntfa_div_1 = 'bridgenorth') = 15 \n             AND (SELECT losses FROM table_sql WHERE ntfa_div_1 = 'bridgenorth') = 3 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-771.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: at the game versus the dallas cowboys , the attendance was 62170\nInput Table: 2000 cincinnati bengals season\n\n\nweekdateopponentresultattendance22000-09-10cleveland brownsl 24 - 76400632000-09-17jacksonville jaguarsl 13 - 04565342000-09-24baltimore ravensl 37 - 06848152000-10-01miami dolphinsl 31 - 166153562000-10-08tennessee titansl 23 - 146340672000-10-15pittsburgh steelersl 15 - 05432882000-10-22denver broncosw 31 - 216160392000-10-29cleveland brownsw 12 - 373118102000-11-05baltimore ravensl 27 - 754759112000-11-12dallas cowboysl 23 - 662170122000-11-19new england patriotsl 16 - 1360292132000-11-26pittsburgh steelersl 48 - 2863925142000-12-03arizona cardinalsw 24 - 1350289152000-12-10tennessee titansl 35 - 368498162000-12-17jacksonville jaguarsw 17 - 1450469172000-12-24philadelphia eaglesl 16 - 764902\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN attendance = 62170 AND opponent = 'dallas cowboys' THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE week = 11;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-786.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: brian watts finished with a score of 68 + 69 + 73 = 210\nInput Table: 1998 open championship\n\n\nplaceplayercountryscoreto_par1brian wattsunited states68 + 69 + 73 = 210et2jim furykunited states70 + 70 + 72 = 212+ 2t2mark o'mearaunited states72 + 68 + 72 = 212+ 2t2jesper parneviksweden68 + 72 + 72 = 212+ 25justin rose (a)england72 + 66 + 75 = 213+ 3t6thomas bj\u00e3rndenmark68 + 71 + 76 = 215+ 5t6brad faxonunited states67 + 74 + 74 = 215+ 5t6john hustonunited states65 + 77 + 73 = 215+ 5t6tiger woodsunited states65 + 73 + 77 = 215+ 5t10david duvalunited states70 + 71 + 75 = 216+ 6t10costantino roccaitaly72 + 74 + 70 = 216+ 6t10raymond russellscotland68 + 73 + 75 = 216+ 6t10katsuyoshi tomorijapan75 + 71 + 70 = 216+ 6\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT score FROM table_sql WHERE player = 'brian watts') = '68 + 69 + 73 = 210' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-268.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the perth wildcats and townsville crocodiles both have the same loss records for the season\nInput Table: 2008 - 09 nbl season\n\n\nteamlostlast_5streakhomeaway%_pts%_wonsouth dragons84 - 1won 213 - 29 - 6110.2573.33melbourne tigers103 - 2lost 111 - 49 - 6106.4766.67new zealand breakers122 - 3won 210 - 58 - 7106.0860.0perth wildcats134 - 1won 211 - 46 - 9102.0656.67townsville crocodiles134 - 1lost 112 - 35 - 1099.2656.67adelaide 36ers153 - 2lost 112 - 33 - 12100.9250.0wollongong hawks192 - 3lost 19 - 62 - 1395.0336.67sydney spirit190 - 5lost 89 - 62 - 1394.5136.67cairns taipans191 - 4lost 35 - 106 - 993.5736.67gold coast blaze223 - 2won 36 - 92 - 1393.4526.67\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT lost FROM table_sql WHERE team = 'perth wildcats') = \n             (SELECT lost FROM table_sql WHERE team = 'townsville crocodiles') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1716.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: glenn capriola was selected with the 24th pick in the 9th round\nInput Table: indianapolis colts draft history\n\n\nroundpickoverallnamepositioncollege12626randy burkewide receiverkentucky22553mike ozdowskidefensive endvirginia624163calvin o'neallinebackermichigan726193blanchard carteroffensive tackleunlv825220ken helmsoffensive tacklegeorgia924247glenn capriolarunning backboston college1026277ron bakerguardoklahoma state1125304brian rufflinebackerthe citadel1224331bill deutschrunning backnorth dakota\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT pick FROM table_sql WHERE name = 'glenn capriola' AND round = 9) = 24 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-848.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: ac sparta prague and team netherlands are both located on the european continent\nInput Table: list of superleague formula football clubs\n\n\nnofootball_clubcontinentassociated_football_clubseasonsracing_drivers3ac milaneuropeac milan2008 2009 2010robert doornbos giorgio pantano yelmer buurman4ac sparta pragueeuropeac sparta prague2011filip salaquarda5team luxembourgeuropenone2011fr\u00e9d\u00e9ric vervisch6team new zealandoceanianone2011earl bamber7team japanasianone2011duncan tappy8 1 (in 2011)rsc anderlechteuropersc anderlecht2008 2009 2010 2011craig dolby yelmer buurman davide rigon neel jani8team netherlandseuropenone2011robert doornbos10fc basel 1893europefc basel2008 2009 2010max wissel max wissel max wissel12 24 (in 2010)beijing guoanasiabeijing guoan fc2008 2010davide rigon john martin14team brazils americanone2011ant\u00f4nio pizzonia17rangers fceuroperangers fc2008 2009ryan dalziel , james walker john martin24fc midtjyllandeuropefc midtjylland2009kasper andersen24team australiaoceanianone2011john martin31team englandeuropenone2011craig dolby\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT continent FROM table_sql WHERE football_club = 'ac sparta prague') = \n             (SELECT continent FROM table_sql WHERE football_club = 'team netherlands') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1976.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: otto graham has won 44 more games than he lost\nInput Table: list of cleveland browns starting quarterbacks\n\n\nquarterbackuniform_no_(s)games_startedwinslossestieswinning_pctsipe , brian1711257550589.0kosar , bernie1910553511595.0ryan , frank137652222697.0graham , otto60 , 147157131810.0couch , tim25922370373.0nelsen , bill165134161676.0phipps , mike155124252490.0plum , milt165133162667.0anderson , derek33416180471.0testaverde , vinny123116150516.0mcdonald , paul16218130381.0mccoy , colt12216150286.0frye , charlie9196130316.0weeden , brandon3195140263.0o'connell , tommy15141031750.0holcomb , kelly1012480333.0quinn , brady1012390250.0ninowski , jim15 , 1111560455.0dilfer , trent811470364.0garcia , jeff510370300.0danielson , gary188530625.0tomczak , mike188440500.0pederson , doug188170125.0pagel , mike107250286.0wallace , seneca67160143.0ratterman , george12 , 165230400.0philcox , todd175230400.0delhomme , jake174220500.0mays , dave104130250.0zeier , eric104130250.0mccown , luke1240400.0parilli , babe183120333.0rypien , mark113210667.0dorsey , ken1130300.0hoyer , brian633001.0strock , don1222001.0christensen , jeff112110500.0detmer , ty1120200.0campbell , jason172110500.0gault , don1111001.0lane , gary1510100.0dawson , len1811001.0wynn , spergon1310100.0luck , terry710100.0cureton , will1610100.0gradkowski , bruce710100.0lewis , thaddeus910100.0\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT wins FROM table_sql WHERE quarterback = 'graham , otto') - \n             (SELECT losses FROM table_sql WHERE quarterback = 'graham , otto') = 44 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1355.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: in the 28 matches that migues zapata played , he scored only 17 goals\nInput Table: 2008 - 09 segunda divisi\u00f3n b\n\n\ngoalkeepergoalsmatchesaverageteammiguel zapata17280.61atl\u00e9tico ciudadrub\u00e9n mart\u00ednez24320.75cartagenaorlando quintana29340.85lorca deportiva\u00e1lvaro campos24280.86real murcia bmat\u00edas garavano26300.87m\u00e9rida\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT goals FROM table_sql WHERE goalkeeper = 'miguel zapata' AND matches = 28) = 17 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1439.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: on september 17 , the final score at texas stadium was 10 - 27\nInput Table: nbc sunday night football results (2006 - present)\n\n\ndatevisiting_teamfinal_scorehost_teamstadium9999-09-07miami dolphins17 - 28pittsburgh steelersheinz field9999-09-10indianapolis colts26 - 21new york giantsgiants stadium9999-09-17washington redskins10 - 27dallas cowboystexas stadium9999-09-24denver broncos17 - 7new england patriotsgillette stadium9999-10-01seattle seahawks6 - 37chicago bearssoldier field9999-10-08pittsburgh steelers13 - 23san diego chargersqualcomm stadium9999-10-15oakland raiders3 - 13denver broncosinvesco field at mile high9999-10-29dallas cowboys35 - 14carolina panthersbank of america stadium9999-11-05indianapolis colts27 - 20new england patriotsgillette stadium9999-11-12chicago bears38 - 20new york giantsgiants stadium9999-11-19san diego chargers35 - 27denver broncosinvesco field at mile high9999-11-26philadelphia eagles21 - 45indianapolis coltsrca dome9999-12-03seattle seahawks23 - 20denver broncosinvesco field at mile high9999-12-10new orleans saints42 - 17dallas cowboystexas stadium9999-12-17kansas city chiefs9 - 20san diego chargersqualcomm stadium9999-12-25philadelphia eagles23 - 7dallas cowboystexas stadium9999-12-31green bay packers26 - 7chicago bearssoldier field0001-01-06kansas city chiefs8 - 23indianapolis coltsrca dome0001-01-06dallas cowboys20 - 21seattle seahawksqwest field\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT final_score FROM table_sql WHERE date = '9999-09-17' AND stadium = 'texas stadium') = '10 - 27' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1140.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: footscray score 14.8 when they visited essendon on july 13 1946\nInput Table: 1946 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddategeelong15.7 (97)melbourne21.14 (140)kardinia park115001946-07-13essendon16.24 (120)footscray14.8 (92)windy hill290001946-07-13collingwood15.23 (113)hawthorn11.14 (80)victoria park110001946-07-13carlton12.13 (85)south melbourne11.18 (84)princes park260001946-07-13st kilda10.14 (74)north melbourne12.11 (83)junction oval70001946-07-13richmond14.14 (98)fitzroy10.12 (72)punt road oval190001946-07-13\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT away_team_score FROM table_sql WHERE away_team = 'footscray' AND home_team = 'essendon' AND date = '1946-07-13') = '14.8 (92)' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-671.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: vince carter and hakeem olajuwon were the high rebounders in game 62 against houston\nInput Table: 2001 - 02 toronto raptors season\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord609999-03-01portlandl 81 - 91 (ot)vince carter (25)antonio davis , hakeem olajuwon (8)chris childs (7)air canada centre 1980029 - 31619999-03-03philadelphial 84 - 96 (ot)antonio davis (26)antonio davis (9)alvin williams (6)air canada centre 1980029 - 32629999-03-05houstonl 109 - 112 (ot)vince carter (43)vince carter , hakeem olajuwon (7)alvin williams (9)compaq center 1422129 - 33639999-03-07dallasl 103 - 122 (ot)vince carter (19)keon clark , antonio davis (15)alvin williams (7)american airlines center 1994529 - 34640000-03-08miamiw 83 - 74 (ot)antonio davis (23)antonio davis (10)chris childs (6)american airlines arena 1650030 - 34659999-03-10orlandol 79 - 92 (ot)vince carter (16)antonio davis (12)chris childs (7)td waterhouse centre 1617130 - 35669999-03-12new jerseyl 84 - 86 (ot)antonio davis (27)antonio davis , jerome williams (13)vince carter (4)continental airlines arena 1610530 - 36670000-03-17sacramentol 113 - 116 (ot)vince carter (22)hakeem olajuwon (13)chris childs (7)air canada centre 1980030 - 37689999-03-19minnesotal 80 - 112 (ot)morris peterson (19)antonio davis (13)alvin williams (7)target center 1701030 - 38699999-03-22clevelandw 94 - 80 (ot)morris peterson (18)keon clark (10)alvin williams (4)gund arena 1784731 - 38709999-03-24washingtonw 92 - 91 (ot)morris peterson (26)antonio davis (9)alvin williams (9)air canada centre 1980032 - 38719999-03-27miamiw 81 - 80 (ot)morris peterson (21)antonio davis , jerome williams (10)chris childs (6)air canada centre 1980033 - 38729999-03-28atlantaw 85 - 83 (ot)antonio davis , morris peterson (15)antonio davis (9)chris childs (7)philips arena 1203634 - 38739999-03-31philadelphiaw 72 - 70 (ot)antonio davis (16)jerome williams (9)chris childs (9)first union center 2065035 - 38\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT high_rebounds FROM table_sql WHERE game = 62) = 'vince carter , hakeem olajuwon (7)' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1027.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: chord finder by microsoft was released on 2010 - 11 - 17 under the category of utilities\nInput Table: list of zune applications\n\n\ntitledevelopercategoryrelease_dateversionalarm clockmicrosoftutilities2010-12-161.1calculatormicrosoftutilities2009-09-011.0calendarmatchboxutilities2011-07-291.0.0.3chord findermicrosoftutilities2010-11-171.0drum machine hddino gamesutilities2010-10-201.0emailmicrosoftutilities2011-04-011.1.0.1facebookmatchboxsocial networking2010-12-161.4fan predictionihwy , incentertainment2011-06-231.0fingerpaintbabarogaentertainment2011-07-291.1levelmicrosoftutilities2011-06-231.0metronomedino gamesutilities2010-09-091.0msn moneymicrosoftutilities2010-07-291.0notesmicrosoftutilities2011-06-231.0pianomicrosoftentertainment2009-11-011.0shuffle by albummicrosoftutilities2011-02-181.1stopwatchmicrosoftutilities2010-08-051.1twittermatchboxsocial networking2010-12-161.6weathermicrosoftutilities2009-09-011.0windows live messengermicrosoftsocial networking2010-11-171.4zune readermicrosoftutilities2011-02-181.2\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT title FROM table_sql WHERE release_date = '2010-11-17' AND developer = 'microsoft' AND category = 'utilities') = 'chord finder' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-468.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: jim colbert is in 2nd place with a score of 70 + 68 = 138\nInput Table: 1973 u.s. open (golf)\n\n\nplaceplayercountryscoreto_par1gary playersouth africa67 + 70 = 137- 52jim colbertunited states70 + 68 = 138- 4t3jack nicklausunited states71 + 69 = 140- 2t3johnny millerunited states71 + 69 = 140- 2t3bob charlesnew zealand71 + 69 = 140- 2t6gene borekunited states77 + 65 = 142et6julius borosunited states73 + 69 = 142et6tom weiskopfunited states73 + 69 = 142et6arnold palmerunited states71 + 71 = 142et6lee trevinounited states70 + 72 = 142e\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT place FROM table_sql WHERE player = 'jim colbert' AND score = '70 + 68 = 138') = 2 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1450.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: republican phil crane was first elected in 1969\nInput Table: united states house of representatives elections , 1980\n\n\ndistrictincumbentpartyfirst_electedresultcandidatesillinois 2morgan f murphydemocratic1970-01-01retired democratic holdgus savage (d) 88.2% marsha a harris (r) 11.8%illinois 6henry hyderepublican1974-01-01re - electedhenry hyde (r) 67.0% mario reymond reda (d) 33.0%illinois 7cardiss collinsdemocratic1973-01-01re - electedcardiss collins (d) 85.1% ruth r hooper (r) 14.9%illinois 12phil cranerepublican1969-01-01re - electedphil crane (r) 74.1% david mccartney (d) 25.9%illinois 13robert mccloryrepublican1962-01-01re - electedrobert mcclory (r) 71.7% michael reese (d) 28.3%illinois 15tom corcoranrepublican1976-01-01re - electedtom corcoran (r) 76.7% john p quillin (d) 23.3%illinois 19tom railsbackrepublican1966-01-01re - electedtom railsback (r) 73.4% thomas j hand (d) 26.6%illinois 20paul findleyrepublican1960-01-01re - electedpaul findley (r) 56.0% david robinson (d) 44.0%\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE first_elected = '1969-01-01' \nAND party = 'republican' \nAND incumbent = 'phil crane';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1319.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: in the elections with goodloe byron as the incumbent politician , goodloe byron (d) won with 73.7% of the vote vs elton rwampler (r)\nInput Table: united states house of representatives elections , 1974\n\n\ndistrictincumbentpartyfirst_electedresultcandidatesmaryland 1robert baumanrepublican1973-01-01re - electedrobert bauman (r) 53.0% thomas j hatem (d) 47.0%maryland 2clarence longdemocratic1962-01-01re - electedclarence long (d) 77.1% john m seney (r) 22.9%maryland 4marjorie holtrepublican1972-01-01re - electedmarjorie holt (r) 58.1% fred l wineland (d) 41.9%maryland 6goodloe byrondemocratic1970-01-01re - electedgoodloe byron (d) 73.7% elton r wampler (r) 26.3%maryland 7parren mitchelldemocratic1970-01-01re - electedparren mitchell (d) unopposed\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT result FROM table_sql WHERE incumbent = 'goodloe byron' AND candidates LIKE '%goodloe byron%' AND candidates LIKE '%73.7%') = 're - elected' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1904.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: two of the teams hold the first two positions with an equal number of points\nInput Table: 1940 in brazilian football\n\n\npositionteampointsplayedagainstdifference1flamengo1381282fluminense13815103corinthians981544palestra it\u00e1lia881935portuguesa7823- 106botafogo682507vasco da gama6819- 28am\u00e9rica6825- 109s\u00e3o paulo4824- 13\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 1 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE position <= 2 \nAND points = (SELECT points FROM table_sql WHERE position = 1)\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1437.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the indianapolis colts played the new york giants on september 10 at giants stadium , final score 26 - 21\nInput Table: nbc sunday night football results (2006 - present)\n\n\ndatevisiting_teamfinal_scorehost_teamstadium9999-09-07miami dolphins17 - 28pittsburgh steelersheinz field9999-09-10indianapolis colts26 - 21new york giantsgiants stadium9999-09-17washington redskins10 - 27dallas cowboystexas stadium9999-09-24denver broncos17 - 7new england patriotsgillette stadium9999-10-01seattle seahawks6 - 37chicago bearssoldier field9999-10-08pittsburgh steelers13 - 23san diego chargersqualcomm stadium9999-10-15oakland raiders3 - 13denver broncosinvesco field at mile high9999-10-29dallas cowboys35 - 14carolina panthersbank of america stadium9999-11-05indianapolis colts27 - 20new england patriotsgillette stadium9999-11-12chicago bears38 - 20new york giantsgiants stadium9999-11-19san diego chargers35 - 27denver broncosinvesco field at mile high9999-11-26philadelphia eagles21 - 45indianapolis coltsrca dome9999-12-03seattle seahawks23 - 20denver broncosinvesco field at mile high9999-12-10new orleans saints42 - 17dallas cowboystexas stadium9999-12-17kansas city chiefs9 - 20san diego chargersqualcomm stadium9999-12-25philadelphia eagles23 - 7dallas cowboystexas stadium9999-12-31green bay packers26 - 7chicago bearssoldier field0001-01-06kansas city chiefs8 - 23indianapolis coltsrca dome0001-01-06dallas cowboys20 - 21seattle seahawksqwest field\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE date = '9999-09-10' \nAND visiting_team = 'indianapolis colts' \nAND final_score = '26 - 21' \nAND host_team = 'new york giants' \nAND stadium = 'giants stadium';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-140.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: australia did not received any gold medals\nInput Table: 2003 world taekwondo championships\n\n\nranknationgoldsilverbronzetotal1south korea802102iran22153chinese taipei20134united states12365spain11356china11137greece10238croatia02139france020210germany012311canada011211denmark011113cuba010113great britain010113mexico010116azerbaijan004417thailand002218australia001118austria001118belarus001118kazakhstan001118morocco001118philippines001118turkey001118venezuela0011totaltotal16163264\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT gold FROM table_sql WHERE nation = 'australia') = 0 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-807.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the world cup had four games throughout june 1998 , all of which were in france\nInput Table: 1998 in paraguayan football\n\n\ndatevenuescorecompreport1998-02-08estadio defensores del chaco asunci\u00f3n , paraguay4 - 0f4501998-03-14qualcomm stadium san diego , united states2 - 2f4511998-03-18estadio ol\u00edmpico universitario mexico city , mexico1 - 1f4521998-03-28yale bowl new haven , united states1 - 1f4531998-04-22stadio ennio tardini parma , italy3 - 1f4541998-05-17olympic stadium tokyo , japan1 - 1kirin cup4551998-05-21kobe universiade memorial stadium kobe , japan1 - 0kirin cup4561998-06-01philips stadion eindhoven , netherlands5 - 1f4571998-06-03steaua stadium bucharest , romania3 - 2f4581998-06-06king baudouin stadium brussels , belgium1 - 0f4591998-06-12stade de la mosson montpellier , france0 - 0world cupreport1998-06-19stade geoffroy - guichard saint - \u00e9tienne , france0 - 0world cupreport1998-06-24stade de toulouse toulouse , france1 - 3world cupreport1998-06-28stade f\u00e9lix bollaert lens , france0 - 0 ( 1 - 0 aet )world cupreport\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 4 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE comp = 'world cup' \nAND date LIKE '1998-06%';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-614.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the series number of the fallen star is 20\nInput Table: none\n\n\nepisodeseriesepisode_titleoriginal_air_dateproduction_code271return to genesis2008-04-05201282the suspension2008-04-06202293a team reinvented2008-04-12203304the new captain2008-04-13204315the homecoming2008-04-19205326netherball rules!2008-04-20206337doubts within2008-04-26207348rocket 's decent2008-04-27208359the all - stars2008-05-032093610rocket vs sinedd2008-05-042103711the champions stumble2008-05-102113812last stand2008-05-112123913fluxless2008-05-172134014new order2008-07-262144115revelations2008-07-272154216new rules2008-08-022164317open doors2008-08-032174418warren steps in2008-08-092184519the technodroid v3s2008-08-102194620the fallen star2008-08-162204721coach artegor2008-08-172214822rocket , the midfielder2008-08-232224923destiny2008-08-242235024final preparations2008-08-312245125a team unravels2008-08-31225\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT series FROM table_sql WHERE episode_title = 'the fallen star') = 20 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-774.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: series number 54 was written by m scott veach & rebecca kirsch\nInput Table: list of leverage episodes\n\n\nseriesseasontitledirected_bywritten_byoriginal_air_dateus_viewers_(in_millions)451the long way down jobdean devlinjoe hortua & john rogers2011-06-263.42462the 10 li'l grifters jobarvin browngeoffrey thorne2011-07-032.46473the 15 minutes jobmarc roskinjosh schaer2011-07-103.24484the van gogh jobjohn rogerschris downey2011-07-174.06495the hot potato jobjohn harrisonjenn kao2011-07-243.25506the carnival jobfrank ozm scott veach & paul guyot2011-07-313.38517the grave danger jobjohn harrisonrebecca kirsch2011-08-143.36528the boiler room jobarvin brownpaul guyot2011-08-143.295410the queen 's gambit jobjonathan frakesm scott veach & rebecca kirsch2011-08-283.225511the experimental jobmarc roskinm scott veach2011-11-272.15612the office jobjonathan frakesjeremy bernstein & josh schaer2011-12-041.835713the girls' night out jobmarc roskinchris downey & jenn kao2011-12-111.835814the boys' night out jobjohn rogersjohn rogers2011-12-182.115915the lonely hearts jobjonathan frakeskerry glover2011-12-251.996016the gold jobmarc roskinjoe hortua2012-01-012.266117the radio jobdean devlinchris downey & paul guyot2012-01-082.32\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT written_by FROM table_sql WHERE series = 54) = 'm scott veach & rebecca kirsch' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-628.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: bell media owns the radio station with frequency 0 101.5 fm\nInput Table: media in kelowna\n\n\nfrequencycall_signbrandingformatowner1150 amckfram 1150news / talkastral media00 88.9 fmcbtk - fmcbc radio onepublic news / talkcanadian broadcasting corporation00 89.7 fmcbu - fm - 3cbc radio 2public musiccanadian broadcasting corporation00 90.5 fmcbuf - fm - 2premi\u00e8re cha\u00eenepublic news / talkcanadian broadcasting corporation00 96.3 fmckko - fmk96.3classic rocksun country cablevision00 99.9 fmchsu - fm99.9 sun fmcontemporary hits radiobell media0 101.5 fmcilk - fm101.5 ez rockadult contemporarybell media0 103.1 fmckqq - fmq103hot adult contemporaryjim pattison group0 103.9 fmcjui - fm103.9 the juiceadult hitsvista broadcast group0 104.7 fmcklz - fmpower 104active rockjim pattison group\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE frequency = '0 101.5 fm' \nAND owner = 'bell media';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1682.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: on november 14th louisville played at dowdy - ficklen stadium greenville , nc\nInput Table: east carolina pirates football , 1990 - 99\n\n\ndateopponentsiteresultattendance9999-09-05virginia techlane stadium blacksburg , val3 - 38481349999-09-12chattanoogadowdy - ficklen stadium greenville , ncw31 - 0340289999-09-19ohiopeden stadium athens , ohw21 - 14191869999-10-03armydowdy - ficklen stadium greenville , ncw30 - 25406079999-10-10uabdowdy - ficklen stadium greenville , ncw26 - 7310029999-10-17alabamalegion field birmingham , all22 - 23800799999-10-24southern missmm roberts stadium hattiesburg , msl7 - 41240209999-10-31houstondowdy - ficklen stadium greenville , ncl31 - 34268219999-11-05cincinnatinippert stadium cincinnati , ohw24 - 21190989999-11-14louisvilledowdy - ficklen stadium greenville , ncl45 - 63262589999-11-21memphisliberty bowl memorial stadium memphis , tnw34 - 31160529999-01-01all times are in easternall times are in easternall times are in easternall times are in eastern\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE date = '9999-11-14' \nAND opponent = 'louisville' \nAND site = 'dowdy - ficklen stadium greenville , nc';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-435.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: alex soler - roig has the highest position at 25 on grid following howden ganley at 24 with jackie stewart in the 1st postion\nInput Table: 1971 south african grand prix\n\n\ndriverconstructorlapstime_/_retiredgridmario andrettiferrari791:47:35.54jackie stewarttyrrell - ford79+ 20.91clay regazzoniferrari79+ 31.43reine wiselllotus - ford79+ 1:09.414chris amonmatra78+ 1 lap2denny hulmemclaren - ford78+ 1 lap7brian redmansurtees - ford78+ 1 lap17jacky ickxferrari78+ 1 lap8graham hillbrabham - ford77+ 2 laps19ronnie petersonmarch - ford77+ 2 laps13henri pescarolomarch - ford77+ 2 laps18rolf stommelensurtees - ford77+ 2 laps15andrea de adamichmarch - alfa romeo75+ 4 laps22emerson fittipaldilotus - ford58engine5john surteessurtees - ford56gearbox6fran\u00e7ois ceverttyrrell - ford45accident9howden ganleybrm42physical24pedro rodr\u00edguezbrm33overheating10dave charltonbrabham - ford31engine16jo siffertbrm31overheating12john lovemarch - ford30differential21jackie pretoriusbrabham - ford22engine20peter gethinmclaren - ford7fuel leak11jo bonniermclaren - ford5suspension23alex soler - roigmarch - ford5engine25\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT grid FROM table_sql WHERE driver = 'alex soler - roig') = 25 \n             AND (SELECT grid FROM table_sql WHERE driver = 'howden ganley') = 24 \n             AND (SELECT grid FROM table_sql WHERE driver = 'jackie stewart') = 1 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1387.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: glasgow govan is one the four constituency with result as snp gain\nInput Table: scottish parliament general election , 2007\n\n\nrankconstituencywinning_party_2003swing_to_gainsnp_'s_place_2003result1galloway & upper nithsdaleconservative0.172ndcon hold2tweeddale , ettrick & lauderdaleliberal democrats1.012ndld hold3cumbernauld & kilsythlabour1.072ndlab hold4kilmarnock & loudounlabour1.922ndsnp gain5dundee westlabour2.132ndsnp gain6western isleslabour2.912ndsnp gain7glasgow govanlabour2.922ndsnp gain8aberdeen centrallabour2.962ndlab hold9linlithgowlabour3.562ndlab hold10west renfrewshirelabour4.412ndlab hold11paisley southlabour4.912ndlab hold\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 1 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE result = 'snp gain' \nAND constituency = 'glasgow govan';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-175.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the total rebounds of player herb estes are 734\nInput Table: none\n\n\nrankplayeryearsgamesreb_avgtotal_rebounds1jim nowers1972-01-01 - 1976-01-011129.410482kenny sanders1985-01-01 - 1989-01-011079.610263will thomas2004-01-01 - 2008-01-011317.69934george evans1997-01-01 - 2001-01-011168.29535robert dykes1987-01-01 - 1991-01-011227.59256andre gaddy1977-01-01 - 1982-01-01989.39167jai lewis2002-01-01 - 2006-01-011257.28958rob rose1982-01-01 - 1986-01-011137.18059herb estes1973-01-01 - 1976-01-01809.273410jesse young1999-01-01 - 2003-01-011156.2708\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT total_rebounds FROM table_sql WHERE player = 'herb estes') = 734 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-28.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: when the score was 10 - 4 , the colorado rockies' record went to 68 - 70 in a game against the athletics\nInput Table: 1997 colorado rockies season\n\n\ndateopponentscorelossattendancerecord9999-08-01pirates7 - 6rinc\u00f3n (4 - 5)2265752 - 589999-08-02pirates6 - 5swift (4 - 5)3238852 - 599999-08-03pirates8 - 4reed (3 - 5)2498952 - 609999-08-04phillies7 - 3castillo (8 - 10)1523052 - 619999-08-05phillies4 - 2bottalico (2 - 4)1642853 - 619999-08-06mets4 - 0mlicki (5 - 8)2663354 - 619999-08-07mets12 - 4swift (4 - 6)2953654 - 629999-08-08pirates5 - 3lieber (6 - 12)4826255 - 629999-08-09pirates8 - 7rinc\u00f3n (4 - 6)4832356 - 629999-08-10pirates8 - 7wilkins (7 - 3)4801857 - 629999-08-12phillies5 - 0thomson (4 - 7)4822857 - 639999-08-13phillies12 - 8wright (6 - 8)4849157 - 649999-08-15mets6 - 2reed (10 - 6)4830858 - 649999-08-16mets7 - 5mcmichael (7 - 10)4831159 - 649999-08-17mets6 - 4mlicki (5 - 10)4844060 - 649999-08-19reds6 - 5wright (6 - 9)3172260 - 659999-08-20reds5 - 3white (1 - 1)2196861 - 659999-08-21astros10 - 4bailey (9 - 9)2296261 - 669999-08-22astros9 - 1thomson (5 - 8)3306161 - 679999-08-23astros6 - 3hudek (0 - 2)3237462 - 679999-08-24astros3 - 1wright (6 - 10)2891862 - 689999-08-25reds7 - 6castillo (10 - 11)4814362 - 699999-08-25reds6 - 4hutton (3 - 2)4808162 - 709999-08-26reds9 - 5mart\u00ednez (1 - 1)4806363 - 709999-08-27reds7 - 5remlinger (6 - 6)4803264 - 709999-08-28mariners9 - 5olivares (6 - 9)4842265 - 709999-08-29mariners6 - 5timlin (3 - 3)4817866 - 709999-08-30athletics4 - 3mohler (1 - 10)4830867 - 709999-08-31athletics10 - 4oquist (2 - 5)4804168 - 70\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT record FROM table_sql WHERE score = '10 - 4' AND opponent = 'athletics') = '68 - 70' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1764.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: ilir meta , bashkim fino , ylli bufi and pandeli majko (1st time) were all members of the socialist party of albania political party\nInput Table: list of prime ministers of albania\n\n\nnameborn_-_diedterm_startterm_endpolitical_partyprime ministers 1991 onwards1991-01-011991-01-011991-01-01prime ministers 1991 onwardsfatos nano (1st time)9999-01-011991-02-221991-06-05party of labour of albaniaylli bufi9999-01-011991-06-051991-12-10socialist party of albaniavilson ahmeti9999-01-011991-12-101992-04-13non - partyaleksand\u00ebr meksi9999-01-011992-04-131997-03-11democratic party of albaniabashkim fino9999-01-011997-03-111997-07-24socialist party of albaniafatos nano (2nd time)9999-01-011997-07-241998-10-02socialist party of albaniapandeli majko (1st time)9999-01-011998-10-021999-10-29socialist party of albaniailir meta9999-01-011999-10-292002-02-22socialist party of albaniapandeli majko (2nd time)9999-01-012002-02-222002-07-31socialist party of albaniafatos nano (3rd time)9999-01-012002-07-312005-09-11socialist party of albaniasali berisha1944-01-012005-09-112013-09-15democratic party of albaniaedi rama9999-01-012013-09-159999-01-01socialist party of albania\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE political_party = 'socialist party of albania' AND name IN ('ilir meta', 'bashkim fino', 'ylli bufi', 'pandeli majko (1st time)')) = 4 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-654.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: at dream 11 , his fight with shinya aoki went to 4:56\nInput Table: joachim hansen (fighter)\n\n\nresrecordopponentmethodeventroundtimelocationwin23 - 11 - 1doo won seosubmission (arm triangle choke)road fc 1122:24seoul , south korealoss22 - 11 - 1tatsuya kawajirisubmission (arm triangle choke)dream 1732:30saitama , saitama , japanwin22 - 10 - 1mitsuhiro ishidadecision (split)dream : fight for japan!25:00saitama , saitama , japanwin21 - 10 - 1usama azizsubmission (armbar)super challenge 623:47stockholm , swedenwin20 - 10 - 1hideo tokorosubmission (triangle choke)dream 1612:48nagoya , japanloss19 - 10 - 1hiroyuki takayako (punches)dream 1414:27saitama , saitama , japanloss19 - 9 - 1bibiano fernandesdecision (split)dream 1325:00yokohama , japanloss19 - 8 - 1shinya aokisubmission (armbar)dream 1124:56yokohama , japanwin19 - 7 - 1shinya aokitko (punches)dream 514:19osaka , japanwin18 - 7 - 1kultar gillsubmission (armbar)dream 512:33osaka , japanloss17 - 7 - 1eddie alvarezdecision (unanimous)dream 325:00saitama , saitama , japanwin17 - 6 - 1kotetsu bokudecision (unanimous)dream 125:00saitama , saitama , japanwin16 - 6 - 1kazuyuki miyatasubmission (rear naked choke)dynamite!! 200721:33osaka , japanloss15 - 6 - 1eiji mitsuokadecision (majority)shooto : back to our roots 635:00tokyo , japanwin15 - 5 - 1jason irelandsubmission (armbar)pride 3332:33las vegas , nevada , united statesloss14 - 5 - 1shinya aokisubmission (gogoplata)pride shockwave 200612:24saitama , saitama , japanwin14 - 4 - 1luiz azeredoko (knee)pride bushido 1017:09tokyo , japanloss13 - 4 - 1tatsuya kawajiridq (kick to groin)shooto : the victory of the truth10:08tokyo , japanloss13 - 3 - 1hayato sakuraidecision (unanimous)pride bushido 925:00tokyo , japanwin13 - 2 - 1yves edwardsdecision (split)pride bushido 925:00tokyo , japanwin12 - 2 - 1kenichiro togashidecision (unanimous)shooto : alive road35:00yokohama , japanwin11 - 2 - 1masakazu imanariko (knee)pride bushido 812:34nagoya , japanwin10 - 2 - 1caol unoko (knee)deep - 1334:48saitama , saitama , japanwin9 - 2 - 1sergey golyaevsubmission (rear naked choke)euphoria - road to the titles13:24atlantic city , new jersey , united stateswin8 - 2 - 1gesias cavalcantedecision (majority)shooto 2004: 7 / 1635:00tokyo , japanwin7 - 2 - 1metin yakuttko (punches)shooto finland : capital punishment 223:50helsinki , finlandloss6 - 2 - 1vitor ribeirosubmission (arm triangle choke)shooto 2003: year end show22:37chiba , chiba , japanwin6 - 1 - 1takanori gomidecision (majority)shooto 2003: 8 / 1035:00yokohama , japanwin5 - 1 - 1rumina satotko (punches)shooto 2003: 3 / 1812:09tokyo , japanwin4 - 1 - 1takumi nakayamadecision (majority)shooto 2002: year - end show35:00chiba , chiba , japanwin3 - 1 - 1sami hyyppasubmissionshooto finland : the first time14:00turku , finlanddraw2 - 1 - 1rafles la rosedrawcw 325:00galway , irelandwin2 - 1olof ingerdecisionfire fight 5n / an / aturku , finlandloss1 - 1jani laxsubmission (rear naked choke)fire fight 419:25turku , finlandwin1 - 0marcus peltonentkofire fight 311:38turku , finland\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT time FROM table_sql WHERE event = 'dream 11' AND opponent = 'shinya aoki') = '4:56' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-476.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: home team carlton played away team st kilda at princess park\nInput Table: 1927 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddatefootscray10.6 (66)melbourne10.13 (73)western oval110001927-09-10carlton15.16 (106)st kilda7.9 (51)princes park240001927-09-10richmond16.23 (119)hawthorn6.17 (53)punt road oval110001927-09-10south melbourne14.11 (95)geelong15.15 (105)lake oval150001927-09-10fitzroy5.13 (43)essendon14.10 (94)brunswick street oval110001927-09-10north melbourne7.14 (56)collingwood11.16 (82)arden street oval110001927-09-10\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE home_team = 'carlton' \nAND away_team = 'st kilda' \nAND venue = 'princes park';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1905.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the top two teams have the same number of points but separated by a goal difference\nInput Table: 1940 in brazilian football\n\n\npositionteampointsplayedagainstdifference1flamengo1381282fluminense13815103corinthians981544palestra it\u00e1lia881935portuguesa7823- 106botafogo682507vasco da gama6819- 28am\u00e9rica6825- 109s\u00e3o paulo4824- 13\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT points FROM table_sql WHERE position = 1) = \n             (SELECT points FROM table_sql WHERE position = 2) \n             AND (SELECT difference FROM table_sql WHERE position = 1) != \n                 (SELECT difference FROM table_sql WHERE position = 2) \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-393.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: botswana defence force xi had a lower agg than arsenal (maseru)\nInput Table: 1992 african cup of champions clubs\n\n\nteam_1aggteam_21st_leg2nd_legbotswana defence force xi1 - 2mbabane highlanders1 - 10 - 1arsenal (maseru)4 - 0eleven arrows fc3 - 01 - 0cd el\u00e1 nguema2 - 6primeiro de agosto2 - 30 - 3 1lprc oilers2 - 3mighty blackpool1 - 01 - 3asc police2 - 2 (4 - 5)as real bamako1 - 11 - 1port autonome0 - 0 (1 - 3)sporting clube da praia0 - 00 - 0saint - george sa2 - 4al ittihad2 - 10 - 3saint - louis fc2 - 7young africans1 - 31 - 4sahel sc4 - 2postel sport2 - 12 - 1tourbillon fc1 - 1forces arm\u00e9es ca0 - 01 - 1\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT agg FROM table_sql WHERE team_1 = 'botswana defence force xi') < \n             (SELECT agg FROM table_sql WHERE team_1 = 'arsenal (maseru)') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-892.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the total number of draws for bridgenorth was 0\nInput Table: none\n\n\nntfa_div_1winsbyeslossesdrawsagainstbridgenorth150301247rocherlea130501661bracknell120511589george town90811431scottsdale801001607deloraine601021639longford501211607hillwood101612071\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT draws FROM table_sql WHERE ntfa_div_1 = 'bridgenorth') = 0 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1445.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: kwadukuza egoli hotel tower 1 , trust bank building has 31 floors and was the tallest from years 1970 - 1973\nInput Table: list of tallest buildings in africa\n\n\nnamecityyears_as_tallestmetresfeetfloorscarlton centrejohannesburg1973-01-01 - present223.073250kwadukuza egoli hotel tower 1 , trust bank buildingjohannesburg1970-01-01 - 1973-01-01140.045931standard bank buildingjohannesburg1968-01-01 - 1970-01-01138.845534schlesinger buildingjohannesburg9999-01-01110.036121naspers centrecape town9999-01-0193.020522mutual heights buildingcape town1940-01-01 - 1962-01-0191.029818chamber of mines buildingjohannesburg1936-01-01 - 1940-01-0180.026218union buildingspretoria1913-01-01 - 1936-01-0160.019610\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE name = 'kwadukuza egoli hotel tower 1 , trust bank building' \nAND floors = 31 \nAND years_as_tallest = '1970-01-01 - 1973-01-01';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-799.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: only round 3 is not listed two times\nInput Table: 2004 - 05 philadelphia flyers season\n\n\nroundplayerpositionnationalitycollege_/_junior_/_club_team_(league)3rob bellamyright wingunited statesnew england jr coyotes ( ejhl )4r j andersondefenseunited statescentennial high school (minn)4david laliberteright wingcanadaprince edward island rocket ( qmjhl )5chris zarbdefenseunited statestri - city storm ( ushl )5gino piselliniright wingunited statesplymouth whalers ( ohl )6ladislav scurkocenterslovakiaspi\u0161sk\u00e1 nov\u00e1 ves (slovakia)6frederik cabanacentercanadahalifax mooseheads (qmjhl)8martin houlegoaltendercanadacape breton screaming eagles (qmjhl)8travis gawryletzdefensecanadatrail smoke eaters ( bchl )9triston grantleft wingcanadavancouver giants ( whl )9john cartercenterunited statesbrewster bulldogs (emjhl)\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 1 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE round = 3;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-218.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: on march 15 , 2007 and in region 4 , the highest number of episodes was 4\nInput Table: none\n\n\nvolumediscsepisodesregion_1region_2region_41142006-01-312007-02-192007-03-152142006-03-282007-06-042007-07-053142006-05-302007-09-032008-03-134142006-07-182008-02-182008-06-195142006-09-192008-05-262009-03-05\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT episodes FROM table_sql WHERE region_4 = '2007-03-15') = 4 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-2016.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the dundee hurricanes had two losing seasons , in 2006 and 2009\nInput Table: dundee hurricanes\n\n\nseasondivisionwinslossestiesfinal_positionnotes2003bafl division 2 north6404 / 11-2004bafl division 2 north6211 / 3-2005bafl division 2 scottish5502 / 4-2006bafl division 2 scottish3402 / 3-2007bafl division 2 north9101 / 6promoted to division 1 north2008bafl division 1 north5233 / 6-2009bafl division 1 north2615 / 7-\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE season = 2006 AND losses > wins) > 0 \n             AND (SELECT COUNT(*) FROM table_sql WHERE season = 2009 AND losses > wins) > 0 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1207.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the score of the sheffield wednesday versus southampton game was 0 - 0\nInput Table: 1983 - 84 fa cup\n\n\ntie_nohome_teamscoreaway_teamdate1notts county1 - 2everton1984-03-102sheffield wednesday0 - 0southampton1984-03-11replaysouthampton5 - 1sheffield wednesday1984-03-203plymouth argyle0 - 0derby county1984-03-10replayderby county0 - 1plymouth argyle1984-03-144birmingham city1 - 3watford1984-03-10\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT score FROM table_sql WHERE home_team = 'sheffield wednesday' AND away_team = 'southampton') = '0 - 0' \n             OR (SELECT score FROM table_sql WHERE home_team = 'southampton' AND away_team = 'sheffield wednesday') = '0 - 0' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-869.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: when the engine was ferrari v12s and the driver was peter whitehead the tyres were p and when the engine was ferrari v12s and the driver was luigi villoresi the tyres were p\nInput Table: 1950 swiss grand prix\n\n\ndriverentrantconstructorchassisenginetyrenello paganiscuderia achille varzimaseratimaserati 4clt - 48maserati l4spjohnny claesecurie belgetalbot - lagotalbot - lago t26ctalbot l6dyves giraud - cabantousautomobiles talbot - darracq satalbot - lagotalbot - lago t26c - datalbot l6deug\u00e8ne martinautomobiles talbot - darracq satalbot - lagotalbot - lago t26c - datalbot l6dlouis rosierautomobiles talbot - darracq satalbot - lagotalbot - lago t26c - datalbot l6dluigi fagiolisa alfa romeoalfa romeoalfa romeo 158alfa romeo l8spjuan manuel fangiosa alfa romeoalfa romeoalfa romeo 158alfa romeo l8spnino farinasa alfa romeoalfa romeoalfa romeo 158alfa romeo l8spalberto ascariscuderia ferrariferrariferrari 125ferrari v12spraymond sommerscuderia ferrariferrariferrari 125ferrari v12spluigi villoresiscuderia ferrariferrariferrari 125ferrari v12sppeter whiteheadscuderia ferrariferrariferrari 125ferrari v12splouis chironofficine alfieri maseratimaseratimaserati 4clt - 48maserati l4spfranco rolofficine alfieri maseratimaseratimaserati 4clt - 48maserati l4spprince biraenrico plat\u00e9maseratimaserati 4clt - 48maserati l4sptoulo de graffenriedenrico plat\u00e9maseratimaserati 4clt - 48maserati l4spfelice bonettoscuderia milanomaseratimaserati milano 4clt - 50maserati l4spreg parnellscuderia ambrosianamaseratimaserati 4clt - 48maserati l4sdrudi fischerecurie espadonsva - fiatsva 1500fiat l4sptoni brancaprivatemaseratimaserati 4clmaserati l4spphilippe \u00e9tancelinprivatetalbot - lagotalbot - lago t26ctalbot l6dharry schellecurie bleuetalbot - lagotalbot - lago t26ctalbot l6d\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT tyre FROM table_sql WHERE engine = 'ferrari v12s' AND driver = 'peter whitehead') = 'p' \n             AND (SELECT tyre FROM table_sql WHERE engine = 'ferrari v12s' AND driver = 'luigi villoresi') = 'p' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1958.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: 16.22 (118) was the away team score against a home team score of 20.20 (140)\nInput Table: 1982 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddatefootscray7.8 (50)richmond16.16 (112)western oval162591982-08-07fitzroy21.16 (142)st kilda11.12 (78)junction oval99871982-08-07north melbourne22.18 (150)geelong11.16 (82)arden street oval116341982-08-07hawthorn20.20 (140)collingwood16.22 (118)princes park186991982-08-07essendon20.17 (137)melbourne14.17 (101)vfl park283791982-08-07swans15.16 (106)carlton9.18 (72)scg256011982-08-01\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT away_team_score FROM table_sql WHERE home_team_score = '20.20 (140)') = '16.22 (118)' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1760.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the size of the crowd when essendon was the away team was 28158\nInput Table: 1954 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddatecollingwood12.13 (85)st kilda7.15 (57)victoria park165001954-07-31carlton9.11 (65)richmond6.10 (46)princes park258631954-07-31melbourne16.14 (110)hawthorn5.3 (33)mcg267081954-07-31south melbourne6.5 (41)footscray11.12 (78)lake oval195001954-07-31north melbourne8.19 (67)fitzroy8.6 (54)arden street oval110001954-07-31geelong16.14 (110)essendon11.10 (76)kardinia park281581954-07-31\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT crowd FROM table_sql WHERE away_team = 'essendon') = 28158 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1898.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: gary beach is one of four nominees for a tony award\nInput Table: la cage aux folles (musical)\n\n\nyearawardcategorynomineeresult2005tony awardbest revival of a musicalbest revival of a musicalwon2005tony awardbest performance by a leading actor in a musicalgary beachnominated2005tony awardbest choreographyjerry mitchellwon2005tony awardbest costume designwilliam ivey longnominated2005drama desk awardoutstanding revival of a musicaloutstanding revival of a musicalwon2005drama desk awardoutstanding choreographyjerry mitchellwon2005drama desk awardoutstanding costume designwilliam ivey longnominated\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE year = 2005 \nAND award = 'tony award' \nAND category = 'best performance by a leading actor in a musical' \nAND nominee = 'gary beach';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-352.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: xi or xian is the name when the state is jin\nInput Table: list of state leaders in 820s bc\n\n\nstatetypenametitleroyal_housefromcaisovereignyimarquisji837 bccaosovereignyoucount-835 bccaosovereigndaicount-826 bcchensovereignliduke-831 bcchusovereignxiong yan the youngerviscountmi837 bcchusovereignxiong shuangviscountmi827 bcchusovereignxiong xunviscountmi821 bcjinsovereignximarquisji840 bcjinsovereignxianmarquisji822 bclusovereignshendukeji854 bclusovereignwudukeji825 bcqisovereignwudukejiang850 bcqisovereignlidukejiang824 bcqinsovereignqin zhongrulerying845 bcqinsovereignzhuangdukeying822 bcsongsovereignhuiduke-830 bcweysovereignlimarquis-855 bcyansovereignhuimarquis-864 bcyansovereignlimarquis-826 bc\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE state = 'jin' AND (name = 'xi' OR name = 'xian')) > 0 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-923.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there was 23.8 points per game during the season where there were 15.0 rebounds per game\nInput Table: list of career achievements by dwight howard\n\n\nselectionmonthseasonteam_recordpoints_per_gamefield_goal_percentagerebounds_per_gameblocks_per_game9999-01-012006-04-012005-06-017-218.153114.00.79999-01-022006-10-012006-07-0112-417.157613.61.99999-01-032007-10-012007-08-0114-423.861815.02.79999-01-042007-12-012007-08-018-721.759816.12.99999-01-052010-10-012010-11-0113-421.8 (5th)594 (2nd)12.1 (4th in league)2.4\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT points_per_game FROM table_sql WHERE season = '2007-08-01') = 23.8 \n             AND (SELECT rebounds_per_game FROM table_sql WHERE season = '2007-08-01') = 15.0 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-370.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: on september 27th , the black knights lost to villanova dropping their record to 2 - 1\nInput Table: 1975 army cadets football team\n\n\ngamedateopponentresultblack_knights_pointsopponentsrecord19999-09-13holy crosswin4471 - 029999-09-20lehighwin54322 - 039999-09-27villanovaloss0102 - 149999-10-04stanfordloss14672 - 259999-10-11dukeloss10212 - 369999-10-18pittsburghloss20522 - 479999-10-25penn stateloss0312 - 589999-11-01air forceloss3332 - 699999-11-08boston collegeloss0312 - 7109999-11-15vanderbiltloss14232 - 8\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT result FROM table_sql WHERE date = '9999-09-27' AND opponent = 'villanova') = 'loss' \n             AND (SELECT record FROM table_sql WHERE date = '9999-09-27' AND opponent = 'villanova') = '2 - 1' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-904.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the majority of the athletes with the longest mark are from the united states\nInput Table: long jump\n\n\nmarkwindathletenationalityvenuedate8.95 m (29ft4\u00bcin)0.3mike powellunited statestokyo1991-08-308.90 m (29ft2\u00bcin) a2.0bob beamonunited statesmexico city1968-10-188.87 m (29ft1in)0.2carl lewisunited statestokyo1991-08-308.86 m (29ft0\u00bein) a1.9robert emmiyansoviet uniontsakhkadzor1987-05-228.74 m (28ft8in)1.4larry myricksunited statesindianapolis1988-07-188.74 m (28ft8in) a2.0erick walderunited statesel paso1994-04-028.74 m (28ft8in)1.2dwight phillipsunited stateseugene2009-06-078.73 m (28ft7\u00bdin)1.2irving saladinopanamahengelo2008-05-248.71 m (28ft6\u00bein)1.9iv\u00e1n pedrosocubasalamanca1995-07-188.66 m (28ft4\u00bein)1.6lo\u00fais ts\u00e1toumasgreecekalam\u00e1ta2007-06-02\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE nationality = 'united states' AND mark = (SELECT MAX(mark) FROM table_sql)) > \n             (SELECT COUNT(*) FROM table_sql WHERE nationality != 'united states' AND mark = (SELECT MAX(mark) FROM table_sql)) \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1830.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the date of vacancy is 28 december 2011 with the incoming head coach being carlos azenha\nInput Table: 2010 - 11 primeira liga\n\n\nteamoutgoing_head_coachmanner_of_departuredate_of_vacancyposition_in_tableincoming_head_coachdate_of_appointmentuni\u00e3o de leirialito vidigalsacked2010-07-07off - seasonpedro caixinha2010-07-10mar\u00edtimomitchell van der gaagsacked2010-09-1415thpedro martins2010-09-14naval 1 de maiovictor zvunkasacked2010-09-2714throg\u00e9rio gon\u00e7alves2010-10-06acad\u00e9micajorge costaresigned2010-12-219thjos\u00e9 guilherme2010-12-27naval 1 de maiorog\u00e9rio gon\u00e7alvessacked2010-12-1916thcarlos mozer2010-12-30portimonenselitossacked2011-12-2816thcarlos azenha2010-12-29acad\u00e9micajos\u00e9 guilhermeresigned2011-02-2013thulisses morais2011-02-22sportingpaulo s\u00e9rgioresigned2011-02-263rdjos\u00e9 couceiro2011-02-26beira - marleonardo jardimresigned2011-02-2810thrui bento2011-03-01vit\u00f3ria de set\u00fabalmanuel fernandessacked2011-03-0114thbruno ribeiro2011-03-01\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT date_of_vacancy FROM table_sql WHERE date_of_vacancy = '2011-12-28' AND incoming_head_coach = 'carlos azenha') IS NOT NULL \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-306.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the score was 1 - 0 when the home team was shrewsbury town\nInput Table: 1990 - 91 fa cup\n\n\ntie_nohome_teamscoreaway_teamdate1liverpool2 - 2brighton & hove albion1991-01-26replaybrighton & hove albion2 - 3liverpool1991-01-302notts county2 - 0oldham athletic1991-01-263crewe alexandra1 - 0rotherham united1991-01-264luton town1 - 1west ham united1991-01-26replaywest ham united5 - 0luton town1991-01-305woking0 - 1everton1991-01-276shrewsbury town1 - 0wimbledon1991-01-267newcastle united2 - 2nottingham forest1991-02-13replaynottingham forest3 - 0newcastle united1991-02-188tottenham hotspur4 - 2oxford united1991-01-269coventry city1 - 1southampton1991-01-26replaysouthampton2 - 0coventry city1991-01-2910portsmouth5 - 1bournemouth1991-01-2611manchester united1 - 0bolton wanderers1991-01-2612norwich city3 - 1swindon town1991-01-2613millwall4 - 4sheffield wednesday1991-01-26replaysheffield wednesday2 - 0millwall1991-01-3014port vale1 - 2manchester city1991-01-2615arsenal0 - 0leeds united1991-01-27replayleeds united1 - 1arsenal1991-01-30replayarsenal0 - 0leeds united1991-02-13replayleeds united1 - 2arsenal1991-02-1616cambridge united2 - 0middlesbrough1991-01-26\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT score FROM table_sql WHERE home_team = 'shrewsbury town') = '1 - 0' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1354.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: for all 28 matches that atletico ciudad played , his average was never below 0.61\nInput Table: 2008 - 09 segunda divisi\u00f3n b\n\n\ngoalkeepergoalsmatchesaverageteammiguel zapata17280.61atl\u00e9tico ciudadrub\u00e9n mart\u00ednez24320.75cartagenaorlando quintana29340.85lorca deportiva\u00e1lvaro campos24280.86real murcia bmat\u00edas garavano26300.87m\u00e9rida\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE team = 'atl\u00e9tico ciudad' \nAND matches = 28 \nAND average < 0.61;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1227.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the lions finished with a record of 6 wins and 8 losses\nInput Table: 1976 detroit lions season\n\n\nweekdateopponentresultattendance11976-09-12chicago bearsl 10 - 35412521976-09-19atlanta falconsw 24 - 105084031976-09-26minnesota vikingsl 10 - 97729241976-10-03green bay packersl 24 - 145504151976-10-10new england patriotsw 30 - 106017461976-10-17washington redskinsl 20 - 74590871976-10-24seattle seahawksw 41 - 146128081976-10-31green bay packersw 27 - 67499291976-11-07minnesota vikingsl 31 - 2346735101976-11-14new orleans saintsl 17 - 1642048111976-11-21chicago bearsw 14 - 1078042121976-11-25buffalo billsw 27 - 1466875131976-12-05new york giantsl 24 - 1066069141976-12-11los angeles ramsl 20 - 1773470\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE result LIKE 'w%') = 6 \n             AND (SELECT COUNT(*) FROM table_sql WHERE result LIKE 'l%') = 8 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-233.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: irregular galaxy has two ngc numbers in the list\nInput Table: list of ngc objects (5001 - 6000)\n\n\nngc_numberobject_typeconstellationright_ascension_(_j2000_)declination_(_j2000_)apparent_magnitude5408irregular galaxycentaurus14h03 m21.0s degree22\u203244\u203314.05457spiral galaxyursa major14h03 m12.5s degree20\u203253\u20338.75466globular clusterbo\u00f6tes14h05 m27.4s degree32\u203204\u203310.55474spiral galaxyursa major14h05 m01.5s degree39\u203245\u203311.95477irregular galaxyursa major14h05 m33.1s degree27\u203240\u203314.5\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 2 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE object_type = 'irregular galaxy';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1887.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the total sum of the agriculture is 54 when including all 5 years listed\nInput Table: none\n\n\nyearregional_gvaagricultureindustryservices199547531111103632200065841013025277200382011113746816200589781114657502200794321115657856\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN SUM(agriculture) = 54 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-274.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the toronto blue jays played in 8 games with an attendance greater than 5000 in may of the 1991 season\nInput Table: 1991 toronto blue jays season\n\n\ndateopponentscorelossattendancerecord9999-05-01rangers3 - 0key (4 - 1)3343912 - 109999-05-02royals3 - 1appier (1 - 4)2289613 - 109999-05-03royals5 - 1davis (2 - 2)2080914 - 109999-05-04royals6 - 5boucher (0 - 2)2262814 - 119999-05-05royals3 - 0gordon (1 - 2)2258815 - 119999-05-07rangers3 - 2key (4 - 2)4462215 - 129999-05-08rangers4 - 2ryan (3 - 3)4321116 - 129999-05-09white sox2 - 0p\u00e3rez (1 - 2)4723617 - 129999-05-10white sox5 - 3 (12)fraser (0 - 1)5019817 - 139999-05-11white sox5 - 2hough (0 - 2)5020618 - 139999-05-12white sox4 - 2hibbard (2 - 1)5010819 - 139999-05-13royals4 - 2davis (2 - 4)4427520 - 139999-05-14royals4 - 1gubicza (0 - 1)4335721 - 139999-05-15royals6 - 4boucher (0 - 3)5011321 - 149999-05-17white sox5 - 3timlin (3 - 1)3009521 - 159999-05-18white sox9 - 2hibbard (2 - 2)3486122 - 159999-05-19white sox5 - 4timlin (3 - 2)4101522 - 169999-05-20athletics1 - 0welch (4 - 3)2463123 - 169999-05-21athletics11 - 7dressendorfer (3 - 3)2273824 - 169999-05-22athletics2 - 1stieb (4 - 3)3402824 - 179999-05-24angels3 - 2finley (7 - 2)2640825 - 179999-05-25angels5 - 0stottlemyre (5 - 1)3673225 - 189999-05-26angels6 - 2wells (5 - 4)4530725 - 199999-05-28athletics8 - 4acker (1 - 2)5029925 - 209999-05-29athletics8 - 3slusarski (1 - 2)5026226 - 209999-05-30athletics8 - 6ward (0 - 2)5027126 - 219999-05-31angels5 - 1langston (6 - 2)5025227 - 21\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) >= 8 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE date LIKE '9999-05%' \nAND attendance > 5000;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1273.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: denver did not lose more than one game in a row during november\nInput Table: 2009 - 10 denver nuggets season\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord39999-11-01grizzliesw 133 - 123 (ot)carmelo anthony (42)nen\u00ea (9)chauncey billups (12)pepsi center 158233 - 049999-11-03pacersw 111 - 93 (ot)carmelo anthony (25)nen\u00ea (13)anthony carter (5)conseco fieldhouse 106274 - 059999-11-04netsw 122 - 94 (ot)ty lawson (23)kenyon martin (10)chauncey billups (5)izod center 153195 - 079999-11-07hawksl 100 - 125 (ot)carmelo anthony (30)chris andersen (11)chauncey billups (7)philips arena 178015 - 289999-11-10bullsw 90 - 89 (ot)carmelo anthony (20)nen\u00ea (12)chauncey billups (6)united center 214096 - 299999-11-11bucksl 102 - 108 (ot)carmelo anthony (32)carmelo anthony (10)chauncey billups , ty lawson (5)bradley center 129876 - 3109999-11-13lakersw 105 - 79 (ot)carmelo anthony (25)chris andersen (11)chauncey billups (8)pepsi center 191417 - 3119999-11-17raptorsw 130 - 112 (ot)carmelo anthony (32)nen\u00ea (10)chauncey billups (10)pepsi center 164468 - 3129999-11-20clippersl 99 - 106 (ot)carmelo anthony (37)nen\u00ea (12)chauncey billups (7)staples center 181558 - 4139999-11-21bullsw 112 - 93 (ot)carmelo anthony (30)carmelo anthony , kenyon martin (11)carmelo anthony (7)pepsi center 193599 - 4149999-11-24netsw 101 - 87 (ot)carmelo anthony (27)nen\u00ea (9)chauncey billups (7)pepsi center 1630710 - 4159999-11-25timberwolvesw 124 - 111 (ot)carmelo anthony (22)nen\u00ea (8)nen\u00ea , ty lawson (6)target center 1310111 - 4169999-11-27knicksw 128 - 125 (ot)carmelo anthony (50)nen\u00ea , kenyon martin (11)chauncey billups (8)pepsi center 1915512 - 4\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE record LIKE '%- 1%') > 1 \n        THEN 'FALSE' \n        ELSE 'TRUE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-941.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there are nil industrial and commercial panels that have a labour panel greater than 1 , a nominated by the taoiseach lesss than 11 and a cultural and educational panel smaller than 0\nInput Table: members of the 7th seanad\n\n\npartyadministrative_panelagricultural_panelcultural_and_educational_panelindustrial_and_commercial_panellabour_panelnational_university_of_irelanduniversity_of_dublinnominated_by_the_taoiseachtotalfianna f\u00e1il2433210924fine gael131111008labour party110020004clann na talmhan020010003clann na poblachta000010001indenpendent1003213010total7115911331160\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT industrial_and_commercial_panel FROM table_sql WHERE labour_panel > 1 AND nominated_by_the_taoiseach < 11 AND cultural_and_educational_panel < 0) IS NULL \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-759.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the record for the discus throw was set in the 5th of september 1986 by bulgaria\nInput Table: memorial van damme\n\n\neventrecordathletenationalitydate100 m10.72 ( - 0.3 m / s)shelly - ann fraser - prycejamaica2013-09-06200 m21.64 ( + 0.8 m / s)merlene otteyjamaica1991-09-13400 m48.83sanya richardsunited states2009-09-04800 m1:55.16pamela jelimokenya2008-09-061000 m2:28.98svetlana masterkovarussia1996-08-231500 m3:55.33s\u00fcreyya ayhanturkey2003-09-05mile4:17.75maryam yusuf jamalbahrain2007-09-142000 m5:30.19gelete burkaethiopia2009-09-043000 m8:24.81 +meseret defarethiopia2007-09-14two miles8:58.58meseret defarethiopia2007-09-145000 m14:25.43vivian cheruiyotkenya2008-09-06100 m hurdles12.42 ( - 0.3 m / s)yordanka donkovabulgaria1986-09-05400 m hurdles53.43nezha bidouanemorocco1998-08-283000 m steeplechase9:15.06milcah chemoskenya2013-09-06high jump2.05 manna chicherovarussia2011-09-16pole vault4.93 myelena isinbayevarussia2005-08-26long jump7.25 m ( + 1.7 m / s)heike drechslergermany1991-09-13triple jump15.14 m ( + 0.3 m / s)tatyana lebedevarussia2003-09-05shot put20.57 mnatalya lisovskayasoviet union1987-09-11discus throw69.84 mtsvetanka christovabulgaria1986-09-05javelin throw72.18 m ( old design ) 67.76 m ( current design )fatima whitbread trine hattestadunited kingdom norway1986-09-054100 m relay42.97united statesunited states1988-08-19\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT record FROM table_sql WHERE event = 'discus throw' AND date = '1986-09-05') = '69.84 m' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1742.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the pentium dual - core t2410 has a p socket\nInput Table: list of intel pentium dual - core microprocessors\n\n\nmodel_numbersspec_numberfrequencyl2_cachefsbmultvoltagetdpsocketrelease_datepart_number_(s)release_price_(_usd_)pentium dual - core t2310slaec (m0)1.47 ghz1 mb533 mt / s111.075 - 1.175v35 wsocket p2007-10-01lf80537 ge0201 m90pentium dual - core t2330sla4k (m0)1.6 ghz1 mb533 mt / s121.075 - 1.175v35 wsocket p2007-10-01lf80537 ge0251 mnoempentium dual - core t2370sla4j (m0)1.73 ghz1 mb533 mt / s131.075 - 1.175v35 wsocket p2007-10-01lf80537 ge0301 moempentium dual - core t2390sla4h (m0)1.87 ghz1 mb533 mt / s141.075 - 1.175v35 wsocket p2008-04-01lf80537 ge0361 moempentium dual - core t2410sla4 g (m0)2 ghz1 mb533 mt / s151.075 - 1.175v35 wsocket p2008-07-01lf80537 ge0411 moempentium dual - core t3200slavg (m0)2 ghz1 mb667 mt / s121.075 - 1.175v35 wsocket p2008-10-01lf80537 gf0411 moem\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE model_number = 'pentium dual - core t2410' \nAND socket = 'socket p';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-213.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there are no defensive end picks and an overall smaller than 2\nInput Table: jacksonville jaguars draft history\n\n\nroundpickoverallnamepositioncollege122kevin hardylinebackerillinois2333tony brackensdefensive endtexas23060michael cheevercentergeorgia tech3263aaron beasleycornerbackwest virginia415110reggie barlowwide receiveralabama state514146jimmy herndonguardhouston63170john fisherdefensive backmissouri western618185chris doeringwide receiverflorida718227clarence joneswide receivertennessee state719228gregory spannwide receiverjackson state\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE position = 'defensive end' \nAND overall < 2;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-189.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there was a tour match held in october and a test match held in november in twickenham , london\nInput Table: 1978 new zealand rugby union tour of britain and ireland\n\n\nopposing_teamagainstdatevenuestatuscambridge university121978-10-18grange road , cambridgetour matchcardiff71978-10-21cardiff arms park , cardifftour matchwest wales xv71978-10-25st helen 's , swanseatour matchlondon counties121978-10-28twickenham , londontour matchmunster121978-10-31thomond park , limericktour matchireland61978-11-04lansdowne road , dublintest matchulster71978-11-07ravenhill , belfasttour matchwales121978-11-01cardiff arms park , cardifftest matchsouth and south - west counties01978-11-15memorial ground , bristoltour matchmidland counties151978-11-18welford road , leicestertour matchcombined services61978-11-21aldershot military stadium , aldershottour matchengland61978-11-25twickenham , londontest matchmonmouthshire91978-11-29rodney parade , newporttour matchnorth of england61978-12-02birkenhead park , birkenheadtour matchnorth and midland of scotland31978-12-05linksfield stadium , aberdeentour matchscotland91978-12-09murrayfield , edinburghtest matchbridgend61978-12-13brewery field , bridgendtour matchbarbarians161978-12-16cardiff arms park , cardifftour match\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE (date LIKE '1978-10%' AND venue = 'twickenham , london' AND status = 'tour match')) > 0 \n             AND (SELECT COUNT(*) FROM table_sql WHERE (date LIKE '1978-11%' AND venue = 'twickenham , london' AND status = 'test match')) > 0 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-809.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: neither team scored for the first two game of the world cup in france\nInput Table: 1998 in paraguayan football\n\n\ndatevenuescorecompreport1998-02-08estadio defensores del chaco asunci\u00f3n , paraguay4 - 0f4501998-03-14qualcomm stadium san diego , united states2 - 2f4511998-03-18estadio ol\u00edmpico universitario mexico city , mexico1 - 1f4521998-03-28yale bowl new haven , united states1 - 1f4531998-04-22stadio ennio tardini parma , italy3 - 1f4541998-05-17olympic stadium tokyo , japan1 - 1kirin cup4551998-05-21kobe universiade memorial stadium kobe , japan1 - 0kirin cup4561998-06-01philips stadion eindhoven , netherlands5 - 1f4571998-06-03steaua stadium bucharest , romania3 - 2f4581998-06-06king baudouin stadium brussels , belgium1 - 0f4591998-06-12stade de la mosson montpellier , france0 - 0world cupreport1998-06-19stade geoffroy - guichard saint - \u00e9tienne , france0 - 0world cupreport1998-06-24stade de toulouse toulouse , france1 - 3world cupreport1998-06-28stade f\u00e9lix bollaert lens , france0 - 0 ( 1 - 0 aet )world cupreport\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT score FROM table_sql WHERE comp = 'world cup' AND rowid = 11) = '0 - 0' \n             AND (SELECT score FROM table_sql WHERE comp = 'world cup' AND rowid = 12) = '0 - 0' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1381.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: ukraine has a total score of 2 with 0 gold and 1 silver\nInput Table: 2006 - 07 isu junior grand prix\n\n\nranknationgoldsilverbronzetotal1united states24128442russia556163canada127104japan14385estonia12145italy03146south korea00337france01127ukraine01128spain01018china01018czech republic0011\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT total FROM table_sql WHERE nation = 'ukraine') = 2 \n             AND (SELECT gold FROM table_sql WHERE nation = 'ukraine') = 0 \n             AND (SELECT silver FROM table_sql WHERE nation = 'ukraine') = 1 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1711.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: for the class hercules , with wheel arrangement 2 - 4 - 0 , the manufacturer was nine elms works\nInput Table: locomotives of the southern railway\n\n\nclasswheel_arrangementmanufactureryear_madequantity_madequantity_preservedyear_(s)_withdrawnjoseph hamilton beattie (1850 - 1871)joseph hamilton beattie (1850 - 1871)joseph hamilton beattie (1850 - 1871)joseph hamilton beattie (1850 - 1871)joseph hamilton beattie (1850 - 1871)joseph hamilton beattie (1850 - 1871)joseph hamilton beattie (1850 - 1871)hercules2 - 4 - 0nine elms works1851 - 18541501875 - 1884tartar2 - 2 - 2wtsharp brothers1852601871 - 1874sussex2 - 2 - 2wtnine elms works1852801871 - 1876canute2 - 2 - 2nine elms works1855 - 18591201875 - 1885saxon2 - 4 - 0nine elms works1855 - 18571201877 - 1885chaplin2 - 2 - 2wtnine elms works1856301876 - 1877minerva2 - 4 - 0wtnine elms works1856301874 - 1883nelson2 - 4 - 0wtnine elms works1858301882 - 1885nile2 - 4 - 0wtnine elms works1859301882tweed2 - 4 - 0nine elms works1858 - 1859601877 - 1879undine2 - 4 - 0nine elms works1859 - 601201884 - 1886clyde2 - 4 - 0nine elms works1859 - 18681301883 - 1899gem2 - 4 - 0nine elms works1862 - 1863601884 - 1885eagle2 - 4 - 0nine elms works1862301885 - 1886falcon2 - 4 - 0nine elms works1863 - 18671701882 - 18981772 - 4 - 0wtbeyer , peacock & co (82) nine elms works (3)1863 - 18758521886 - 1899 , 1962lion0 - 6 - 0nine elms works1863 - 18733801886 - 1900volcano2 - 4 - 0nine elms works1866 - 18731801886 - 18972210 - 6 - 0beyer , peacock & co1866 - 18732401891 - 19242312 - 4 - 0beyer , peacock & co1866601892 - 1899vesuvius2 - 4 - 0nine elms works1869 - 18753201893 - 1899\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE class = 'hercules' \nAND wheel_arrangement = '2 - 4 - 0' \nAND manufacturer = 'nine elms works';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1777.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: in the period 2000 - 2005 , there was a tfr of 2.25 and an nc of 13.4\nInput Table: none\n\n\nperiodlive_births_per_yeardeaths_per_yearnatural_change_per_yearcbrcdrnctfrimrlife_expectancy_totallife_expectancy_maleslife_expectancy_females1950-01-01 - 1955-01-012 572 000900 0001 672 00044.115.528.66.1513550.949.252.61955-01-01 - 1960-01-012 918 000947 0001 971 00043.214.029.16.1512253.351.555.21960-01-01 - 1965-01-013 303 000986 0002 317 00042.212.629.66.1510955.753.857.69999-01-01 - 1970-01-013 330 000998 0002 332 00037.011.125.95.3810057.655.759.61970-01-01 - 1975-01-013 441 0001 014 0002 427 00033.79.923.84.729159.557.361.81975-01-01 - 1980-01-013 741 0001 043 0002 698 00032.59.023.54.317961.559.263.91980-01-01 - 1985-01-013 974 0001 064 0002 910 00030.88.222.63.86363.460.466.81985-01-01 - 1990-01-013 757 0001 055 0002 702 00026.37.418.93.15265.361.969.11990-01-01 - 1995-01-013 519 0001 058 0002 461 00022.66.815.82.64367.363.671.21995-01-01 - 2000-01-013 624 0001 086 0002 538 00021.56.515.12.453469.365.573.32000-01-01 - 2005-01-013 572 0001 147 0002 425 00019.86.413.42.252770.967.274.8\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN tfr = 2.25 AND nc = 13.4 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE period = '2000-01-01 - 2005-01-01';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-467.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: bob charles , from new zealand , was tied for 3rd\nInput Table: 1973 u.s. open (golf)\n\n\nplaceplayercountryscoreto_par1gary playersouth africa67 + 70 = 137- 52jim colbertunited states70 + 68 = 138- 4t3jack nicklausunited states71 + 69 = 140- 2t3johnny millerunited states71 + 69 = 140- 2t3bob charlesnew zealand71 + 69 = 140- 2t6gene borekunited states77 + 65 = 142et6julius borosunited states73 + 69 = 142et6tom weiskopfunited states73 + 69 = 142et6arnold palmerunited states71 + 71 = 142et6lee trevinounited states70 + 72 = 142e\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE place = 't3' \nAND player = 'bob charles' \nAND country = 'new zealand';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-849.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: team brazil , team australia , and team england are three of the clubs that participated in the 2011 season\nInput Table: list of superleague formula football clubs\n\n\nnofootball_clubcontinentassociated_football_clubseasonsracing_drivers3ac milaneuropeac milan2008 2009 2010robert doornbos giorgio pantano yelmer buurman4ac sparta pragueeuropeac sparta prague2011filip salaquarda5team luxembourgeuropenone2011fr\u00e9d\u00e9ric vervisch6team new zealandoceanianone2011earl bamber7team japanasianone2011duncan tappy8 1 (in 2011)rsc anderlechteuropersc anderlecht2008 2009 2010 2011craig dolby yelmer buurman davide rigon neel jani8team netherlandseuropenone2011robert doornbos10fc basel 1893europefc basel2008 2009 2010max wissel max wissel max wissel12 24 (in 2010)beijing guoanasiabeijing guoan fc2008 2010davide rigon john martin14team brazils americanone2011ant\u00f4nio pizzonia17rangers fceuroperangers fc2008 2009ryan dalziel , james walker john martin24fc midtjyllandeuropefc midtjylland2009kasper andersen24team australiaoceanianone2011john martin31team englandeuropenone2011craig dolby\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 3 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE seasons LIKE '%2011%' \nAND (football_club = 'team brazil' OR football_club = 'team australia' OR football_club = 'team england');\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1318.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: parren mitchell was re - elected for maryland district 7 in 1970\nInput Table: united states house of representatives elections , 1974\n\n\ndistrictincumbentpartyfirst_electedresultcandidatesmaryland 1robert baumanrepublican1973-01-01re - electedrobert bauman (r) 53.0% thomas j hatem (d) 47.0%maryland 2clarence longdemocratic1962-01-01re - electedclarence long (d) 77.1% john m seney (r) 22.9%maryland 4marjorie holtrepublican1972-01-01re - electedmarjorie holt (r) 58.1% fred l wineland (d) 41.9%maryland 6goodloe byrondemocratic1970-01-01re - electedgoodloe byron (d) 73.7% elton r wampler (r) 26.3%maryland 7parren mitchelldemocratic1970-01-01re - electedparren mitchell (d) unopposed\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE district = 'maryland 7' \nAND incumbent = 'parren mitchell' \nAND result = 're - elected' \nAND first_elected = '1970-01-01';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1970.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: ny rangers were the visitor to vancouver on february 24\nInput Table: 1992 - 93 vancouver canucks season\n\n\ndatevisitorscorehomedecisionattendancerecord01-02-9999minnesota5 - 4vancouvermclean1483029 - 15 - 89999-02-03tampa bay2 - 4vancouverwhitmore1417130 - 15 - 89999-02-09vancouver5 - 1quebecmclean1436031 - 15 - 801-02-11vancouver2 - 5torontomclean1572031 - 16 - 801-02-12vancouver3 - 1buffalowhitmore1632532 - 16 - 801-02-15vancouver0 - 3los angelesmclean1600532 - 17 - 89999-02-18philadelphia3 - 2vancouverwhitmore1615032 - 18 - 89999-02-20winnipeg2 - 4vancouvermclean1615033 - 18 - 89999-02-22toronto8 - 1vancouvermclean1615033 - 19 - 89999-02-24ny rangers4 - 5vancouverwhitmore1615034 - 19 - 89999-02-26vancouver7 - 4winnipegmclean1539835 - 19 - 8\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE visitor = 'ny rangers' \nAND home = 'vancouver' \nAND date LIKE '%02-24%';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-548.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: week 12 was on december 2 , 2001\nInput Table: 2001 cincinnati bengals season\n\n\nweekdateopponentresultattendance12001-09-09new england patriotsw 23 - 175152122001-09-23baltimore ravensw 21 - 105112132001-09-30san diego chargersl 28 - 145604842001-10-07pittsburgh steelersl 16 - 76233552001-10-14cleveland brownsw 24 - 146421762001-10-21chicago bearsl 24 - 06340872001-10-28detroit lionsw 31 - 276934392001-11-11jacksonville jaguarsl 30 - 1357161102001-11-18tennessee titansl 20 - 763865112001-11-25cleveland brownsl 18 - 072918122001-12-02tampa bay buccaneersl 16 - 1352135132001-12-09jacksonville jaguarsl 14 - 1044920142001-12-16new york jetsl 15 - 1477745152001-12-23baltimore ravensl 16 - 068987162001-12-30pittsburgh steelersw 26 - 2363751172002-01-06tennessee titansw 23 - 2168798\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE week = 12 \nAND date = '2001-12-02';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-787.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: justin rose finished in 5th place with a score of 72 + 66 + 75 = 213\nInput Table: 1998 open championship\n\n\nplaceplayercountryscoreto_par1brian wattsunited states68 + 69 + 73 = 210et2jim furykunited states70 + 70 + 72 = 212+ 2t2mark o'mearaunited states72 + 68 + 72 = 212+ 2t2jesper parneviksweden68 + 72 + 72 = 212+ 25justin rose (a)england72 + 66 + 75 = 213+ 3t6thomas bj\u00e3rndenmark68 + 71 + 76 = 215+ 5t6brad faxonunited states67 + 74 + 74 = 215+ 5t6john hustonunited states65 + 77 + 73 = 215+ 5t6tiger woodsunited states65 + 73 + 77 = 215+ 5t10david duvalunited states70 + 71 + 75 = 216+ 6t10costantino roccaitaly72 + 74 + 70 = 216+ 6t10raymond russellscotland68 + 73 + 75 = 216+ 6t10katsuyoshi tomorijapan75 + 71 + 70 = 216+ 6\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT score FROM table_sql WHERE player = 'justin rose (a)') = '72 + 66 + 75 = 213' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-2005.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: collingwood did not have a home team score higher than that of geelong\nInput Table: 1954 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddategeelong13.12 (90)hawthorn7.6 (48)kardinia park168701954-08-14collingwood12.16 (88)south melbourne13.12 (90)victoria park185561954-08-14carlton10.16 (76)essendon11.14 (80)princes park297441954-08-14richmond10.18 (78)melbourne15.4 (94)punt road oval240001954-08-14north melbourne9.14 (68)footscray9.14 (68)arden street oval220001954-08-14st kilda13.14 (92)fitzroy9.15 (69)junction oval115001954-08-14\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT home_team_score FROM table_sql WHERE home_team = 'collingwood') > \n             (SELECT home_team_score FROM table_sql WHERE home_team = 'geelong') \n        THEN 'FALSE' \n        ELSE 'TRUE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-387.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: roy burdine directed episode s07e04\nInput Table: teenage mutant ninja turtles (2003 tv series) (season 7)\n\n\nno_in_seriesno_in_seasontitledirected_bywritten_byoriginalairdatetv_broadcast1441tempus fugitroy burdineeric basart2008-09-13s07e011452karate schooledroy burdinemichael ryan2008-09-20s07e021463something wickedroy burdinemichael ryan2008-09-27s07e031474the engagement ringroy burdinerobert david2008-10-04s07e041485hacking stockmanroy burdinejoe kelly2008-10-18s07e051496incredible shrinking serlingroy burdinerobert david2008-10-25s07e061507identity crisisroy burdinemichael ryan2008-11-01s07e071518web wranglersroy burdinerobert david2008-11-08s07e081529superquestroy burdinerobert david2008-11-15s07e0915310virtual reality checkroy burdinemichael ryan2008-11-22s07e1015411city under siegeroy burdinesteve melching2008-11-29s07e1115512super power struggleroy burdinerobert david2009-02-21s07e1215613wedding bells and bytesroy burdinematthew drek & robert david2009-02-28s07e13\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE directed_by = 'roy burdine' \nAND tv_broadcast = 's07e04';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1786.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the republican party had the first elected official in california in 1926\nInput Table: united states house of representatives elections , 1942\n\n\ndistrictincumbentpartyfirst_electedresultcandidatescalifornia 2harry lane englebrightrepublican1926-01-01re - electedharry lane englebright (r) unopposedcalifornia 4thomas rolphrepublican1940-01-01re - electedthomas rolph (r) 98.3% archie brown ( w / i ) 1.7%california 7john h tolandemocratic1934-01-01re - electedjohn h tolan (d) unopposedcalifornia 9bertrand w gearhartrepublican1934-01-01re - electedbertrand w gearhart (r) unopposedcalifornia 10alfred j elliottdemocratic1937-01-01re - electedalfred j elliott (d) unopposedcalifornia 17cecil r kingdemocratic1942-08-25re - electedcecil r king (d) unopposedcalifornia 22none (district created)none (district created)9999-01-01new seat republican gainjohn j phillips (r) 57.6% n e west (d) 42.4%\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE first_elected = '1926-01-01' \nAND party = 'republican';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-501.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: jaime vergara won in the 11th stage , with the team classification given to epm - une and the mountains classification given to oscar solis\nInput Table: 2010 vuelta a colombia\n\n\nstagewinnergeneral_classificationpoints_classificationmountains_classificationsprints_classificationteam_classification1ind ant - idea - fla - lot de medell\u00ednsergio luis henaono awardno awardno awardind ant - idea - fla - lot de medell\u00edn2jaime casta\u00f1eda\u00f3scar sevillajaime casta\u00f1edajaime vergaracamilo g\u00f3mezind ant - idea - fla - lot de medell\u00edn3jairo p\u00e9rezjairo p\u00e9rezjaime casta\u00f1edajaime vergarajulian lopezind ant - idea - fla - lot de medell\u00edn4sergio luis henao\u00f3scar sevilla\u00f3scar sevillajaime vergarajulian lopezind ant - idea - fla - lot de medell\u00edn5fabio duarte\u00f3scar sevilla\u00f3scar sevillajaime vergarajulian lopezind ant - idea - fla - lot de medell\u00edn6luis felipe laverde\u00f3scar sevilla\u00f3scar sevillajaime vergarajaime suazaind ant - idea - fla - lot de medell\u00edn7freddy gonzalez\u00f3scar sevilla\u00f3scar sevillajaime vergaracamilo g\u00f3mezcol es pasion caf\u00e9 de colombia 4728diego calder\u00f3n\u00f3scar sevilla\u00f3scar sevillaoscar solisjuan alejandro garciaind ant - idea - fla - lot de medell\u00edn9jos\u00e9 rujanosergio luis henaosergio luis henaooscar solisjuan alejandro garciaind ant - idea - fla - lot de medell\u00edn10sergio luis henaosergio luis henaosergio luis henaooscar solisjuan alejandro garciaepm - une11jaime vergarasergio luis henaosergio luis henaooscar solisjuan alejandro garciaepm - une12fabio duartesergio luis henaosergio luis henaooscar solisjuan alejandro garciacol es pasion caf\u00e9 de colombia 47213javier gonzalezsergio luis henaosergio luis henaojos\u00e9 rujanojuan alejandro garciaepm - une\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT winner FROM table_sql WHERE stage = 11) = 'jaime vergara' \n             AND (SELECT team_classification FROM table_sql WHERE stage = 11) = 'epm - une' \n             AND (SELECT mountains_classification FROM table_sql WHERE stage = 11) = 'oscar solis' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1357.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: miguel zapata had the fewest number of goals with 17\nInput Table: 2008 - 09 segunda divisi\u00f3n b\n\n\ngoalkeepergoalsmatchesaverageteammiguel zapata17280.61atl\u00e9tico ciudadrub\u00e9n mart\u00ednez24320.75cartagenaorlando quintana29340.85lorca deportiva\u00e1lvaro campos24280.86real murcia bmat\u00edas garavano26300.87m\u00e9rida\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT goals FROM table_sql WHERE goalkeeper = 'miguel zapata') = \n             (SELECT MIN(goals) FROM table_sql) \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1018.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: oleksandr vorobiov ( ukr ) had a total score of 16.25\nInput Table: gymnastics at the 2008 summer olympics - men 's rings\n\n\npositiongymnasta_scoreb_scoretotal1chen yibing ( chn )7.39.22516.5252yordan yovchev ( bul )7.38.97516.2753oleksandr vorobiov ( ukr )7.29.0516.254yang wei ( chn )7.38.92516.2255matteo morandi ( ita )7.18.92516.0256andrea coppolino ( ita )6.89.17515.9757danny pinheiro rodrigues ( fra )7.28.615.88robert stanescu ( rou )7.08.7515.75\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE gymnast = 'oleksandr vorobiov ( ukr )' \nAND total = 16.25;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-85.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there have been 19 games since 13 august 2005 which had an attendance of 60000 or more\nInput Table: 2005 - 06 manchester united f.c. season\n\n\ndateopponentsh_/_aresult_f_-_aattendanceleague_position2005-08-13evertona2 - 0386104th2005-08-20aston villah1 - 0679344th2005-08-28newcastle uniteda2 - 0523274th2005-09-10manchester cityh1 - 1678394th2005-09-18liverpoola0 - 0449173rd2005-09-24blackburn roversh1 - 2677656th2005-10-01fulhama3 - 2218624th2005-10-15sunderlanda3 - 1390853rd2005-10-22tottenham hotspurh1 - 1678565th2005-10-29middlesbrougha1 - 4305797th2005-11-06chelseah1 - 0678644th2005-11-19charlton athletica3 - 1267303rd2005-11-27west ham uniteda2 - 1347552nd2005-12-03portsmouthh3 - 0676842nd2005-12-11evertonh1 - 1678313rd2005-12-14wigan athletich4 - 0677932nd2005-12-17aston villaa2 - 0371282nd2005-12-26west bromwich albionh3 - 0679722nd2005-12-28birmingham citya2 - 2284592nd2005-12-31bolton wanderersh4 - 1678582nd2006-01-03arsenala0 - 0383132nd2006-01-14manchester citya1 - 3471922nd2006-01-22liverpoolh1 - 0678742nd2006-02-01blackburn roversa3 - 4254842nd2006-02-04fulhamh4 - 2678442nd2006-02-11portsmoutha3 - 1202062nd2006-03-06wigan athletica2 - 1235242nd2006-03-12newcastle unitedh2 - 0678582nd2006-03-18west bromwich albiona2 - 1276232nd2006-03-26birmingham cityh3 - 0690702nd2006-03-29west ham unitedh1 - 0695222nd2006-04-01bolton wanderersa2 - 1277182nd2006-04-09arsenalh2 - 0709082nd2006-04-14sunderlandh0 - 0725192nd2006-04-17tottenham hotspura2 - 1361412nd2006-04-29chelseaa0 - 3422192nd2006-05-01middlesbroughh0 - 0695312nd2006-05-07charlton athletich4 - 0730062nd\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) >= 19 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE date >= '2005-08-13' \nAND attendance >= 60000;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-745.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the yugoslavian national team suffered its worst outcome losing 1:4 in the balkan cup against romania on august 27\nInput Table: yugoslavia national football team results\n\n\ndatecityopponentresultstype_of_game9999-03-22sarajevouruguay2:1friendly9999-03-30belgraderomania2:0balkan cup9999-04-26borovopoland2:1friendly9999-08-27bucharest , romaniaromania1:4balkan cup9999-09-10luxembourgluxembourg5:01982 wcq9999-09-27ljubljanadenmark2:11982 wcq9999-11-15torino , italyitaly0:21982 wcq\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT results FROM table_sql WHERE type_of_game = 'balkan cup' AND opponent = 'romania' AND date = '9999-08-27') = '1:4' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-135.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the toronto maple leafs is the only opponent with 63 points\nInput Table: none\n\n\ngamemarchopponentscorerecordpoints639999-01-04detroit red wings2 - 224 - 28 - 1159649999-01-06california golden seals4 - 424 - 28 - 1260659999-01-07minnesota north stars1 - 324 - 29 - 1260669999-01-10pittsburgh penguins2 - 224 - 29 - 1361679999-01-12new york rangers2 - 724 - 30 - 1361689999-01-13toronto maple leafs3 - 225 - 30 - 1363699999-01-18new york rangers2 - 126 - 30 - 1365709999-01-20boston bruins3 - 526 - 31 - 1365719999-01-21toronto maple leafs1 - 126 - 31 - 1466729999-01-24montreal canadiens3 - 526 - 32 - 1466739999-01-25minnesota north stars2 - 226 - 32 - 1567749999-01-27chicago black hawks1 - 326 - 33 - 1567759999-01-28pittsburgh penguins3 - 127 - 33 - 1569\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 1 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE points = 63 \nAND opponent = 'toronto maple leafs';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-307.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: for the home team of woking , the tie number was 5 and the score was 0 - 1\nInput Table: 1990 - 91 fa cup\n\n\ntie_nohome_teamscoreaway_teamdate1liverpool2 - 2brighton & hove albion1991-01-26replaybrighton & hove albion2 - 3liverpool1991-01-302notts county2 - 0oldham athletic1991-01-263crewe alexandra1 - 0rotherham united1991-01-264luton town1 - 1west ham united1991-01-26replaywest ham united5 - 0luton town1991-01-305woking0 - 1everton1991-01-276shrewsbury town1 - 0wimbledon1991-01-267newcastle united2 - 2nottingham forest1991-02-13replaynottingham forest3 - 0newcastle united1991-02-188tottenham hotspur4 - 2oxford united1991-01-269coventry city1 - 1southampton1991-01-26replaysouthampton2 - 0coventry city1991-01-2910portsmouth5 - 1bournemouth1991-01-2611manchester united1 - 0bolton wanderers1991-01-2612norwich city3 - 1swindon town1991-01-2613millwall4 - 4sheffield wednesday1991-01-26replaysheffield wednesday2 - 0millwall1991-01-3014port vale1 - 2manchester city1991-01-2615arsenal0 - 0leeds united1991-01-27replayleeds united1 - 1arsenal1991-01-30replayarsenal0 - 0leeds united1991-02-13replayleeds united1 - 2arsenal1991-02-1616cambridge united2 - 0middlesbrough1991-01-26\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT tie_no FROM table_sql WHERE home_team = 'woking') = 5 \n             AND (SELECT score FROM table_sql WHERE home_team = 'woking') = '0 - 1' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-465.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: johnny miller placed t3\nInput Table: 1973 u.s. open (golf)\n\n\nplaceplayercountryscoreto_par1gary playersouth africa67 + 70 = 137- 52jim colbertunited states70 + 68 = 138- 4t3jack nicklausunited states71 + 69 = 140- 2t3johnny millerunited states71 + 69 = 140- 2t3bob charlesnew zealand71 + 69 = 140- 2t6gene borekunited states77 + 65 = 142et6julius borosunited states73 + 69 = 142et6tom weiskopfunited states73 + 69 = 142et6arnold palmerunited states71 + 71 = 142et6lee trevinounited states70 + 72 = 142e\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE place = 't3' \nAND player = 'johnny miller';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1283.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the nat mkd has the name nikolovski\nInput Table: 2008 - 09 apoel f.c. season\n\n\nnatnamemoving_totypetransfer_windowtransfer_feesourcegremachlasretiredretirementsummer-contragrcypmakridesmetalurh donetskend of contractsummerfreekerkidanetser\u010dorovi\u0107ael limassolloan returnsummer--cyploukaael limassolend of contractsummerfreekerkidanetgrekapsislevadiakosend of contractsummerfree-cypdaskalakisaek larnacaend of contractsummerfreeapoelnetbraz\u00e9 carlostrofensecontract terminationsummerfreeapoelfccomcycypvourkoudoxa katokopialoansummerfree-cyppanayiotoudigenis morphouloansummerfree-mkdnikolovskiaep paphosmutual consentwinterfree-cyppapathanasiouermis aradippouloanwinterfree-porpaulo costaanorthosis famagustamutual consent loan returnwinterfreeapoelfccomcy\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE nat = 'mkd' \nAND name = 'nikolovski';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1831.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: when the team is uni\u00e3o de leiria , the date of appointment is 10 july 2010\nInput Table: 2010 - 11 primeira liga\n\n\nteamoutgoing_head_coachmanner_of_departuredate_of_vacancyposition_in_tableincoming_head_coachdate_of_appointmentuni\u00e3o de leirialito vidigalsacked2010-07-07off - seasonpedro caixinha2010-07-10mar\u00edtimomitchell van der gaagsacked2010-09-1415thpedro martins2010-09-14naval 1 de maiovictor zvunkasacked2010-09-2714throg\u00e9rio gon\u00e7alves2010-10-06acad\u00e9micajorge costaresigned2010-12-219thjos\u00e9 guilherme2010-12-27naval 1 de maiorog\u00e9rio gon\u00e7alvessacked2010-12-1916thcarlos mozer2010-12-30portimonenselitossacked2011-12-2816thcarlos azenha2010-12-29acad\u00e9micajos\u00e9 guilhermeresigned2011-02-2013thulisses morais2011-02-22sportingpaulo s\u00e9rgioresigned2011-02-263rdjos\u00e9 couceiro2011-02-26beira - marleonardo jardimresigned2011-02-2810thrui bento2011-03-01vit\u00f3ria de set\u00fabalmanuel fernandessacked2011-03-0114thbruno ribeiro2011-03-01\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE team = 'uni\u00e3o de leiria' \nAND date_of_appointment = '2010-07-10';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1457.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the new york jets took the same amount of wins as losses during the 1993 season\nInput Table: 1993 new york jets season\n\n\nweekdateopponentresultgame_siteattendance11993-09-05denver broncosl 26 - 20the meadowlands6813021993-09-12miami dolphinsw 24 - 14joe robbie stadium7031441993-09-26new england patriotsw 45 - 7the meadowlands6483651993-10-03philadelphia eaglesl 35 - 30the meadowlands7259361993-10-10los angeles raidersl 24 - 20los angeles memorial coliseum4162781993-10-24buffalo billsl 19 - 10the meadowlands7154191993-10-31new york giantsw 10 - 6giants stadium71659101993-11-07miami dolphinsw 27 - 10the meadowlands71306111993-11-14indianapolis coltsw 31 - 17rca dome47351121993-11-21cincinnati bengalsw 17 - 12the meadowlands64264131993-11-28new england patriotsw 6 - 0foxboro stadium42810141993-12-05indianapolis coltsl 9 - 6the meadowlands45799151993-12-11washington redskinsw 3 - 0robert f kennedy memorial stadium47970161993-12-18dallas cowboysl 28 - 7the meadowlands73233171993-12-26buffalo billsl 16 - 14rich stadium70817181994-01-02houston oilersl 24 - 0houston astrodome61040\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE result = 'w') = (SELECT COUNT(*) FROM table_sql WHERE result = 'l') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1844.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: rattlers was the opponent team at the bishop kearney field\nInput Table: 2005 philadelphia barrage season\n\n\ndateopponenthome_/_awayfieldresult9999-05-29cannonshomevillanova stadiuml 12 - 139999-06-04lizardshomevillanova stadiuml 14 - 199999-06-12bayhawksawayjohnny unitas stadiuml 9 - 319999-06-18prideawayalumni stadium (kean university)w 11 - 109999-06-25lizardsawaymitchel athletic complexl 12 - 189999-06-30cannonsawaynickerson fieldw 15 - 149999-07-09rattlersawaybishop kearney fieldw 26 - 159999-07-14rattlershomevillanova stadiuml 10 - 149999-07-23cannonsawaynickerson fieldl 10 - 119999-07-28lizardshomevillanova stadiumw 16 - 149999-08-04bayhawkshomevillanova stadiuml 9 - 199999-08-11pridehomevillanova stadiuml 12 - 16\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE opponent = 'rattlers' \nAND field = 'bishop kearney field';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1057.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the aggregate result of the game with score 4 - 1 was 4 - 1\nInput Table: kwak tae - hwi\n\n\ndatevenuescoreresultcompetition2008-02-02seoul , south korea1 - 04 - 02010 world cup qualification2008-02-17chongqing , china3 - 23 - 22008 east asian cup2008-10-15seoul , south korea4 - 14 - 12010 world cup qualification2010-03-03london , england2 - 02 - 0friendly2012-06-08doha , qatar2 - 14 - 12014 world cup qualification\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT result FROM table_sql WHERE score = '4 - 1') = '4 - 1' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-789.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: brian watts was 1st place and had a score of 68 + 69 + 73 = 210\nInput Table: 1998 open championship\n\n\nplaceplayercountryscoreto_par1brian wattsunited states68 + 69 + 73 = 210et2jim furykunited states70 + 70 + 72 = 212+ 2t2mark o'mearaunited states72 + 68 + 72 = 212+ 2t2jesper parneviksweden68 + 72 + 72 = 212+ 25justin rose (a)england72 + 66 + 75 = 213+ 3t6thomas bj\u00e3rndenmark68 + 71 + 76 = 215+ 5t6brad faxonunited states67 + 74 + 74 = 215+ 5t6john hustonunited states65 + 77 + 73 = 215+ 5t6tiger woodsunited states65 + 73 + 77 = 215+ 5t10david duvalunited states70 + 71 + 75 = 216+ 6t10costantino roccaitaly72 + 74 + 70 = 216+ 6t10raymond russellscotland68 + 73 + 75 = 216+ 6t10katsuyoshi tomorijapan75 + 71 + 70 = 216+ 6\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT place FROM table_sql WHERE player = 'brian watts' AND score = '68 + 69 + 73 = 210') = 1 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1280.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: paulo costa is moving to anorthosis famagusta during the transfer window\nInput Table: 2008 - 09 apoel f.c. season\n\n\nnatnamemoving_totypetransfer_windowtransfer_feesourcegremachlasretiredretirementsummer-contragrcypmakridesmetalurh donetskend of contractsummerfreekerkidanetser\u010dorovi\u0107ael limassolloan returnsummer--cyploukaael limassolend of contractsummerfreekerkidanetgrekapsislevadiakosend of contractsummerfree-cypdaskalakisaek larnacaend of contractsummerfreeapoelnetbraz\u00e9 carlostrofensecontract terminationsummerfreeapoelfccomcycypvourkoudoxa katokopialoansummerfree-cyppanayiotoudigenis morphouloansummerfree-mkdnikolovskiaep paphosmutual consentwinterfree-cyppapathanasiouermis aradippouloanwinterfree-porpaulo costaanorthosis famagustamutual consent loan returnwinterfreeapoelfccomcy\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE name = 'paulo costa' \nAND moving_to = 'anorthosis famagusta' \nAND transfer_window = 'winter';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-806.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the kirin cup had games on both may 17 and 21 , 1998\nInput Table: 1998 in paraguayan football\n\n\ndatevenuescorecompreport1998-02-08estadio defensores del chaco asunci\u00f3n , paraguay4 - 0f4501998-03-14qualcomm stadium san diego , united states2 - 2f4511998-03-18estadio ol\u00edmpico universitario mexico city , mexico1 - 1f4521998-03-28yale bowl new haven , united states1 - 1f4531998-04-22stadio ennio tardini parma , italy3 - 1f4541998-05-17olympic stadium tokyo , japan1 - 1kirin cup4551998-05-21kobe universiade memorial stadium kobe , japan1 - 0kirin cup4561998-06-01philips stadion eindhoven , netherlands5 - 1f4571998-06-03steaua stadium bucharest , romania3 - 2f4581998-06-06king baudouin stadium brussels , belgium1 - 0f4591998-06-12stade de la mosson montpellier , france0 - 0world cupreport1998-06-19stade geoffroy - guichard saint - \u00e9tienne , france0 - 0world cupreport1998-06-24stade de toulouse toulouse , france1 - 3world cupreport1998-06-28stade f\u00e9lix bollaert lens , france0 - 0 ( 1 - 0 aet )world cupreport\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 2 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE comp = 'kirin cup' \nAND date IN ('1998-05-17', '1998-05-21');\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1230.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the most points scored by the lions in a single game was 41\nInput Table: 1976 detroit lions season\n\n\nweekdateopponentresultattendance11976-09-12chicago bearsl 10 - 35412521976-09-19atlanta falconsw 24 - 105084031976-09-26minnesota vikingsl 10 - 97729241976-10-03green bay packersl 24 - 145504151976-10-10new england patriotsw 30 - 106017461976-10-17washington redskinsl 20 - 74590871976-10-24seattle seahawksw 41 - 146128081976-10-31green bay packersw 27 - 67499291976-11-07minnesota vikingsl 31 - 2346735101976-11-14new orleans saintsl 17 - 1642048111976-11-21chicago bearsw 14 - 1078042121976-11-25buffalo billsw 27 - 1466875131976-12-05new york giantsl 24 - 1066069141976-12-11los angeles ramsl 20 - 1773470\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN MAX(CAST(SUBSTR(result, INSTR(result, ' ') + 1, INSTR(result, ' - ') - INSTR(result, ' ') - 1) AS INTEGER)) = 41 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-917.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the highest scoring game of the season was against the angels on september 8th final score was 12 - 10\nInput Table: 1997 toronto blue jays season\n\n\ndateopponentscorelossattendancerecord9999-09-01mets3 - 0hentgen (14 - 9)1919665 - 719999-09-02mets8 - 5clemens (20 - 5)1763565 - 729999-09-03mets4 - 2quantrill (6 - 6)1451365 - 739999-09-04rangers6 - 2carpenter (1 - 7)2617865 - 749999-09-05rangers5 - 1pavlik (2 - 4)2712166 - 749999-09-06rangers2 - 1burkett (7 - 12)3123267 - 749999-09-07rangers4 - 0oliver (11 - 11)3021268 - 749999-09-08angels12 - 10james (4 - 5)2577569 - 749999-09-09angels2 - 0hill (7 - 12)2567470 - 749999-09-10athletics3 - 2plesac (1 - 4)476470 - 759999-09-11athletics8 - 7escobar (2 - 1)613570 - 769999-09-12mariners7 - 3clemens (21 - 6)3704470 - 779999-09-13mariners6 - 3ayala (10 - 5)5163171 - 779999-09-14mariners3 - 2risley (0 - 1)4547771 - 789999-09-15mariners7 - 3williams (8 - 14)4168471 - 799999-09-17red sox4 - 3quantrill (6 - 7)2364871 - 809999-09-18red sox3 - 2escobar (3 - 2)2799071 - 819999-09-19yankees3 - 0gooden (8 - 5)3119572 - 819999-09-20yankees4 - 3 (11)janzen (1 - 1)3833272 - 829999-09-21yankees5 - 4 (10)almanzar (0 - 1)4003872 - 839999-09-22yankees8 - 1hentgen (15 - 10)2338072 - 849999-09-23orioles3 - 2clemens (21 - 7)2927672 - 859999-09-24orioles9 - 3daal (1 - 1)2744372 - 869999-09-25orioles4 - 3mussina (15 - 8)2832473 - 869999-09-26red sox3 - 0henry (7 - 3)3415574 - 869999-09-27red sox12 - 5corsi (5 - 3)3740175 - 869999-09-28red sox3 - 2gordon (6 - 10)4025176 - 86\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MAX(score) FROM table_sql WHERE opponent = 'angels' AND date = '9999-09-08') = '12 - 10' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-631.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: vista broadcast group 's radio station plays adult hits\nInput Table: media in kelowna\n\n\nfrequencycall_signbrandingformatowner1150 amckfram 1150news / talkastral media00 88.9 fmcbtk - fmcbc radio onepublic news / talkcanadian broadcasting corporation00 89.7 fmcbu - fm - 3cbc radio 2public musiccanadian broadcasting corporation00 90.5 fmcbuf - fm - 2premi\u00e8re cha\u00eenepublic news / talkcanadian broadcasting corporation00 96.3 fmckko - fmk96.3classic rocksun country cablevision00 99.9 fmchsu - fm99.9 sun fmcontemporary hits radiobell media0 101.5 fmcilk - fm101.5 ez rockadult contemporarybell media0 103.1 fmckqq - fmq103hot adult contemporaryjim pattison group0 103.9 fmcjui - fm103.9 the juiceadult hitsvista broadcast group0 104.7 fmcklz - fmpower 104active rockjim pattison group\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE owner = 'vista broadcast group' \nAND format = 'adult hits';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1806.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: equestrian at the asian games has been located in a different city every year that it occured\nInput Table: equestrian at the asian games\n\n\nyearlocationgoldsilverbronze1982new delhinadia al - moutawaajamila al - moutawaabariaa salem al - sabbah1986seoultakashi tomurashuichi tokiryuzo okuno1994hiroshimakonoshin kuwahararyuzo okunonatya chantrasmi1998bangkokjin kannosohn bong - gakquzier ambak fathil2002busanmikaela mar\u00e3\u00ada jaworskilee jin - kyungtadayoshi hayashi2006dohaali yousuf al - rumaihijasmine chen - shao manjoo jung - hyun2010guangzhouramzy al duhamilatifa al maktomkhaled al - eid\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(DISTINCT location) = COUNT(*) THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-972.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the westgaard bridge is in the style of a pratt pony through truss bridge\nInput Table: list of bridges on the national register of historic places in north dakota\n\n\nnamelistedlocationcountytypebeaver creek bridge1997-02-27finleysteelepratt through trusscaledonia bridge1997-02-27caledoniatraillpratt through trusscedar creek bridge1997-02-27haynesadamspratt through trusscolton 's crossing bridge1997-02-27lisbonransompratt through trusscrystal bridge1997-05-30crystalpembinaconcrete t - beam bridgeeastwood park bridge1975-04-21minotwardcantilever typeelliott bridge1997-02-27townermchenrypratt through trussfairview lift bridge1997-03-14cartwrightmckenzierailroad lift bridgegrace city bridge1997-02-27grace cityfosterpratt through trussgreat northern railway underpass1997-02-27stanleymountrailconcrete deck girder bridgeknife river bridge near stanton2001-04-25stantonmercerpratt through trusslisbon bridge1997-02-27lisbonransomsteel cantilever bean bridgemidland continental overpass1997-02-27jamestownstutsmansteel cantilever beam bridgemidway bridge1997-02-27johnstowngrand forkswarren bedstead bridgenesheim bridge1997-02-27mcvillenelsonpratt through trussnew rockford bridge1997-03-13new rockford closed to trafficeddywarren through truss bridgenorthwood bridge1997-02-27northwoodgrand forkspratt pony trussnorway bridge1997-02-27mayvilletraillpratt pony trussost valle bridge1997-02-27thompsongrand forkspratt through trussromness bridge1997-02-27cooperstowngriggspratt through trusssorlie memorial bridge1999-07-19grand forksgrand forksparker through truss bridgeviking bridge1997-02-27portlandtraillpratt through trusswest antelope bridge1997-02-27florabensonpratt pony truss bridgewest park bridge1997-02-27valley citybarnesconcrete false arch bridgewestgaard bridge1997-02-27voltairemchenrypratt pony through trussblanchard bridge1997-02-27blanchardtraillpratt through trussgoose river bridge1997-02-27hillsborotraillpratt through trussliberty memorial bridge1997-03-11 removed 2009-03-25bismarckburleighwarren - turner through trussporter elliott bridge1997-02-27hillsborotraillwarren through trussportland park bridge2004-09-23portlandtraillsteel through girderrainbow arch bridge2004-09-23valley citybarnesmarsh rainbow arch\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT type FROM table_sql WHERE name = 'westgaard bridge') = 'pratt pony through truss' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-988.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there were three episodes that aired in january , while only two aired in february\nInput Table: list of republic of doyle episodes\n\n\nUnnamed:_0titledirected_bywritten_byviewersoriginal_airdateprod_code1fathers and sonsmike clattenburgallan hawco , perry chafe and malcolm macrury9690002010-01-061012the return of the grievous angelsteve dimarcoallan hawco and avrum jacobson7150002010-01-131023duchess of georgemike clattenburgallan hawco , perry chafe and malcolm macrury6850002010-01-201035hit and rumsteve dimarcomatt maclennan5940002010-02-031056the one who got awaylarry mcleanjesse mckeown10120002010-02-101067the woman who knew too littlerobert liebermanjeremy boxen10530002010-03-031078the tell - tale safejerry ciccorittijohn callaghan and steve cochrane9860002010-03-101089he sleeps with the chipsphil earnshawperry chafe9080002010-03-1710910the pen is mightier than the doylerobert liebermansteve cochrane and avrum jacobson8970002010-03-2411011a horse dividedsteve scainijesse mckeown9020002010-03-31111\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE original_airdate LIKE '2010-01%') = 3 \n             AND (SELECT COUNT(*) FROM table_sql WHERE original_airdate LIKE '2010-02%') = 2 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-363.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: curtis dickey was picked during an earlier round than randy bielski\nInput Table: indianapolis colts draft history\n\n\nroundpickoverallnamepositioncollege155curtis dickeyrunning backtexas a&m12424derrick hatchettcornerbacktexas2432ray donaldsoncentergeorgia22351tim foleyoffensive tacklenotre dame4588ray butlerwide receiverusc66144chris footecenterusc75170wes robertsdefensive endtcu82195ken walteroffensive tackletexas tech96227mark brightrunning backtemple105254larry stewartoffensive tacklemaryland113280ed whitleytight endkansas state126311randy bielskiplacekickertowson1219324marvin simsfullbackclemson\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT round FROM table_sql WHERE name = 'curtis dickey') < \n             (SELECT round FROM table_sql WHERE name = 'randy bielski') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-156.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the united states contributed the most players of all the countries\nInput Table: utah jazz all - time roster\n\n\nplayernationalitypositionyears_for_jazzschool_/_club_teamrick adelmanunited statesguard1974-01-01loyola (ca)john amaechienglandcenter / forward2001-03-01penn statelouis amundsonunited statesforward2007-01-01unlvj j andersonunited statesforward1982-01-01bradleyshandon andersonunited statesguard / forward9999-01-01georgiarafael ara\u00e3jobrazilcenter2006-01-01byucarlos arroyopuerto ricoguard2002-05-01florida internationalisaac austinunited statescenter1991-01-01arizona stateanthony aventunited statesforward1998-01-01seton hall\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE nationality = 'united states') > \n             (SELECT COUNT(*) FROM table_sql WHERE nationality != 'united states') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1294.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: robert garrett and james connolly represent the same country\nInput Table: list of multiple olympic medalists\n\n\nmedal_countdateathletenationsportrecord_medal_event11896-04-06james connollyunited statesathleticstriple jump g11896-04-06alexandre tuff\u00e8refranceathleticstriple jump s11896-04-06ioannis persakisgreeceathleticstriple jump b11896-04-06robert garrettunited statesathleticsdiscus g11896-04-06panagiotis paraskevopoulosgreeceathleticsdiscus s11896-04-06sotirios versisgreeceathleticsdiscus b21896-04-07robert garrettunited statesathleticslong jump s21896-04-07james connollyunited statesathleticslong jump b31896-04-07robert garrettunited statesathleticsshot put g31896-04-09carl schuhmanngermanygymnasticsvault g31896-04-09hermann weing\u00e4rtnergermanygymnasticsvault b41896-04-09hermann weing\u00e4rtnergermanygymnasticspommel horse s51896-04-09hermann weing\u00e4rtnergermanygymnasticsrings s61896-04-09hermann weing\u00e4rtnergermanygymnasticshorizontal bar g61900-07-16robert garrettunited statesathleticsstanding triple jump b61904-09-03ray ewryunited statesathleticsstanding triple jump g71908-07-20ray ewryunited statesathleticsstanding long jump g81908-07-23ray ewryunited statesathleticsstanding high jump g81920-07-29carl osburnunited statesshootingteam 300 m / 600 m military rifle , prone g91920-07-30carl osburnunited statesshooting300 m military rifle , standing g101920-07-31carl osburnunited statesshootingteam free rifle g111924-06-27carl osburnunited statesshooting600 m free rifle s111928-08-03paavo nurmifinlandathletics5000 m s121928-08-04paavo nurmifinlandathletics3000 m steeplechase s121960-09-02edoardo mangiarottiitalyfencingteam foil s131960-09-09edoardo mangiarottiitalyfencingteam \u00e9p\u00e9e g131964-10-21larisa latyninasoviet uniongymnasticsteam g141964-10-21larisa latyninasoviet uniongymnasticsall - around s151964-10-22larisa latyninasoviet uniongymnasticsvault s161964-10-22larisa latyninasoviet uniongymnasticsuneven bars b171964-10-23larisa latyninasoviet uniongymnasticsbalance beam b181964-10-23larisa latyninasoviet uniongymnasticsfloor exercise g182012-07-31michael phelpsunited statesswimming200 m butterfly s192012-07-31michael phelpsunited statesswimming4 x 200 m freestyle g202012-08-02michael phelpsunited statesswimming200 m individual medley g212012-08-03michael phelpsunited statesswimming100 m butterfly g222012-08-04michael phelpsunited statesswimming4 100 m medley relay g\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT nation FROM table_sql WHERE athlete = 'robert garrett') = \n             (SELECT nation FROM table_sql WHERE athlete = 'james connolly') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-776.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: season 1 is directed by dean devlin\nInput Table: list of leverage episodes\n\n\nseriesseasontitledirected_bywritten_byoriginal_air_dateus_viewers_(in_millions)451the long way down jobdean devlinjoe hortua & john rogers2011-06-263.42462the 10 li'l grifters jobarvin browngeoffrey thorne2011-07-032.46473the 15 minutes jobmarc roskinjosh schaer2011-07-103.24484the van gogh jobjohn rogerschris downey2011-07-174.06495the hot potato jobjohn harrisonjenn kao2011-07-243.25506the carnival jobfrank ozm scott veach & paul guyot2011-07-313.38517the grave danger jobjohn harrisonrebecca kirsch2011-08-143.36528the boiler room jobarvin brownpaul guyot2011-08-143.295410the queen 's gambit jobjonathan frakesm scott veach & rebecca kirsch2011-08-283.225511the experimental jobmarc roskinm scott veach2011-11-272.15612the office jobjonathan frakesjeremy bernstein & josh schaer2011-12-041.835713the girls' night out jobmarc roskinchris downey & jenn kao2011-12-111.835814the boys' night out jobjohn rogersjohn rogers2011-12-182.115915the lonely hearts jobjonathan frakeskerry glover2011-12-251.996016the gold jobmarc roskinjoe hortua2012-01-012.266117the radio jobdean devlinchris downey & paul guyot2012-01-082.32\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE season = 1 \nAND directed_by = 'dean devlin';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1999.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: princes park is home to the carlton team\nInput Table: 1945 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddateessendon7.14 (56)fitzroy11.14 (80)windy hill100001945-07-14collingwood11.14 (80)south melbourne7.12 (54)victoria park240001945-07-14carlton13.12 (90)hawthorn8.11 (59)princes park100001945-07-14richmond18.10 (118)north melbourne15.9 (99)punt road oval210001945-07-14st kilda9.10 (64)melbourne10.23 (83)junction oval60001945-07-14geelong11.14 (80)footscray13.19 (97)kardinia park60001945-07-14\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE venue = 'princes park' \nAND home_team = 'carlton';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1191.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: learco guerra was the race leader for the first race of the 1933 giro d'italia , and did not become race leader again for the rest of the circuit\nInput Table: 1933 giro d'italia\n\n\ndatecoursedistancewinnerrace_leader9999-05-06milan to turin-learco guerra ( ita )learco guerra ( ita )9999-05-07turin to genoa-alfredo binda ( ita )alfredo binda ( ita )9999-05-08genoa to pisa-learco guerra ( ita )alfredo binda ( ita )9999-05-09rest dayrest dayrest dayrest day9999-05-10pisa to florence-giuseppe olmo ( ita )alfredo binda ( ita )9999-05-11florence to grosseto-learco guerra ( ita )jef demuysere ( bel )9999-05-12grosseto to rome-mario cipriani ( ita )jef demuysere ( bel )9999-05-13rest dayrest dayrest dayrest day9999-05-14rome to naples-gerard loncke ( bel )jef demuysere ( bel )9999-05-15naples to foggia-alfredo binda ( ita )alfredo binda ( ita )9999-05-16rest dayrest dayrest dayrest day9999-05-17foggia to chieti-alfredo binda ( ita )alfredo binda ( ita )9999-05-18chieti to ascoli piceno-alfredo binda ( ita )alfredo binda ( ita )9999-05-19rest dayrest dayrest dayrest day9999-05-20ascoli piceno to riccione-fernand cornez ( fra )alfredo binda ( ita )9999-05-21riccione to bologna-giuseppe olmo ( ita )alfredo binda ( ita )9999-05-22bologna to ferrara-alfredo binda ( ita )alfredo binda ( ita )9999-05-23rest dayrest dayrest dayrest day9999-05-24ferrara to udine-ettore meini ( ita )alfredo binda ( ita )9999-05-25udine to bassano del grappa-ettore meini ( ita )alfredo binda ( ita )9999-05-26bassano del grappa to bolzano-gerard loncke ( bel )alfredo binda ( ita )9999-05-27rest dayrest dayrest dayrest day9999-05-28bolzano to milan-alfredo binda ( ita )alfredo binda ( ita )2023-09-20-km (mi)-km (mi)\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT race_leader FROM table_sql WHERE date = '9999-05-06') = 'learco guerra ( ita )' \n             AND (SELECT race_leader FROM table_sql WHERE date > '9999-05-06') != 'learco guerra ( ita )' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-187.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there were 4 test matches in the last 2 months of 1978\nInput Table: 1978 new zealand rugby union tour of britain and ireland\n\n\nopposing_teamagainstdatevenuestatuscambridge university121978-10-18grange road , cambridgetour matchcardiff71978-10-21cardiff arms park , cardifftour matchwest wales xv71978-10-25st helen 's , swanseatour matchlondon counties121978-10-28twickenham , londontour matchmunster121978-10-31thomond park , limericktour matchireland61978-11-04lansdowne road , dublintest matchulster71978-11-07ravenhill , belfasttour matchwales121978-11-01cardiff arms park , cardifftest matchsouth and south - west counties01978-11-15memorial ground , bristoltour matchmidland counties151978-11-18welford road , leicestertour matchcombined services61978-11-21aldershot military stadium , aldershottour matchengland61978-11-25twickenham , londontest matchmonmouthshire91978-11-29rodney parade , newporttour matchnorth of england61978-12-02birkenhead park , birkenheadtour matchnorth and midland of scotland31978-12-05linksfield stadium , aberdeentour matchscotland91978-12-09murrayfield , edinburghtest matchbridgend61978-12-13brewery field , bridgendtour matchbarbarians161978-12-16cardiff arms park , cardifftour match\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 4 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE date >= '1978-11-01' \nAND date <= '1978-12-31' \nAND status = 'test match';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1500.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: rankin county was home to multiple projects that were proposed and listed\nInput Table: list of superfund sites in mississippi\n\n\ncerclis_idnamecountyproposedlistedconstruction_completedpartially_deleteddeletedmsd004006995american creosote works , incwinston2001-06-142001-09-139999-01-01--msd008154486chemfax , incharrison1993-06-239999-01-019999-01-01--msd046497012davis timber companylamar2000-05-112000-07-279999-01-01--msd980710941flowood siterankin1983-09-081984-09-211993-09-17-02 / 16 / 1996msd980840045newsom brothers / old reichhold chemicals , incmarion1984-10-151986-06-101997-08-08-09 / 27 / 2000msd065490930picayune wood treatingpearl river2004-03-082004-07-229999-01-01--msd056029648potter cocopiah1993-05-109999-01-019999-01-01--msd086556388sonford productsrankin2006-09-272007-03-079999-01-01--msd980601736walcotte chemical co warehouseswashington9999-01-019999-01-011982-12-30-12 / 30 / 1982\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) > 1 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE county = 'rankin' \nAND (proposed != '9999-01-01' AND listed != '9999-01-01');\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1671.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the results were counted in bhind district five times and three times in datia\nInput Table: bhind (lok sabha constituency)\n\n\nconstituency_numbernamereserved_for_(_sc_/_st_/_none)districtnumber_of_electorates_(2009)9aternonebhind17733410bhindnonebhind19718311laharnonebhind20583912mehgaonnonebhind21064913gohadscbhind16689320sewdanonedatia13016121bhanderscdatia13960022datianonedatia143593total :total :total :total :1371252\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE district = 'bhind') = 5 \n             AND (SELECT COUNT(*) FROM table_sql WHERE district = 'datia') = 3 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1180.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: at 20.45 the react was less than 164 in lane 6\nInput Table: athletics at the 2008 summer olympics - men 's 200 metres\n\n\nlaneathletenationalitytimereact8paul hessionireland20.320.194wallace spearmonunited states20.390.2026jaysuma saidy ndurenorway20.450.1317rondell sorillotrinidad and tobago20.630.1645ramil guliyevazerbaijan20.660.1743visa hongistofinland20.760.1242thuso mpuangsouth africa21.040.1629marvin andersonjamaicadnf0.187\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN react < 0.164 AND lane = 6 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE time = 20.45;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-716.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: only seven players were transferred at the end of their contract\nInput Table: 2008 - 09 rangers f.c. season\n\n\nnatnamemoving_totypetransfer_windowtransfer_feesconicholas gallacher9999-01-01end of contract9999-06-01n / aivory coastlacine cherif9999-01-01end of contract9999-06-01n / ascoalistair park9999-01-01end of contract9999-06-01n / aengmichael donald9999-01-01end of contract9999-06-01n / ascocalum reidford9999-01-01end of contract9999-06-01n / ascochris smith9999-01-01end of contract9999-06-01n / abeljeroen van den broeck9999-01-01end of contract9999-06-01n / aslovakiafilip \u0161ebo9999-01-01transfer9999-06-011 mbelthomas buffel9999-01-01transfer9999-06-01n / aespcarlos cu\u00e9llar9999-01-01transfer9999-06-017.8 mscosteven lennon9999-01-01loan9999-06-01n / ascomark weir9999-01-01loan9999-06-01n / ascoandy webster9999-01-01loan9999-06-01n / arsadean furman9999-01-01loan9999-06-01n / ascoalan lowing9999-01-01loan9999-06-01n / ascopaul emslie9999-01-01loan9999-06-01n / ascoscott gallacher9999-01-01loan9999-06-01n / agabondaniel cousin9999-01-01transfer9999-06-013.5 mscoalan gow9999-01-01loan9999-06-01n / aenglee robinson9999-01-01loan9999-01-01n / ascoandrew shinnie9999-01-01loan9999-01-01n / ascosteven kinniburgh9999-01-01loan9999-01-01n / ascorory loy9999-01-01loan9999-01-01n / ascowilliam mclachlan9999-01-01loan9999-01-01n / ascolee robinson9999-01-01loan9999-01-01n / afrajean - claude darcheville9999-01-01transfer9999-01-01freescojordan mcmillan9999-01-01loan9999-01-01n / ascochris burke9999-01-01transfer9999-01-01freecypgeorgios efrem9999-01-01loan9999-01-01n / ascoalan gow9999-01-01loan9999-01-01n / ascocharlie adam9999-01-01loan9999-01-01n / ascoross harvey9999-01-01loan9999-01-01n / ascosteven kinniburgh9999-01-01loan9999-01-01n / a\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 7 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE type = 'end of contract' \nAND transfer_window = '9999-06-01' \nAND transfer_fee = 'n / a';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1310.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: fred couples had a score of 72 + 67 + 71 = 210\nInput Table: 1988 u.s. open (golf)\n\n\nplaceplayercountryscoreto_par1curtis strangeunited states70 + 67 + 69 = 206- 7t2nick faldoengland72 + 67 + 68 = 207- 6t2bob gilderunited states68 + 69 + 70 = 207- 6t2scott simpsonunited states69 + 66 + 72 = 207- 6t5larry mizeunited states69 + 67 + 72 = 208- 5t5d a weibringunited states71 + 69 + 68 = 208- 57mark o'mearaunited states71 + 72 + 66 = 209- 48fred couplesunited states72 + 67 + 71 = 210- 39lanny wadkinsunited states70 + 71 + 70 = 211- 210ken greenunited states72 + 70 + 70 = 212- 1\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT score FROM table_sql WHERE player = 'fred couples') = '72 + 67 + 71 = 210' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-35.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: steve stricker had a score lower than phil mickelson\nInput Table: 2006 u.s. open (golf)\n\n\nplaceplayercountryscoreto_par1steve strickerunited states70 + 69 = 139- 12colin montgomeriescotland69 + 71 = 140et3kenneth ferrieengland71 + 70 = 141+ 1t3geoff ogilvyaustralia71 + 70 = 141+ 1t5jim furykunited states70 + 72 = 142+ 2t5p\u00e1draig harringtonireland70 + 72 = 142+ 2t7jason dufnerunited states72 + 71 = 143+ 3t7graeme mcdowellnorthern ireland71 + 72 = 143+ 3t7phil mickelsonunited states70 + 73 = 143+ 3t7arron oberholserunited states75 + 68 = 143+ 3\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT score FROM table_sql WHERE player = 'steve stricker') < \n             (SELECT score FROM table_sql WHERE player = 'phil mickelson') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1723.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there was only one game played on may 20\nInput Table: 2005 texas rangers season\n\n\ndatewinning_teamscorewinning_pitcherlosing_pitcherattendancelocation9999-05-20texas7 - 3kenny rogersbrandon backe38109arlington9999-05-21texas18 - 3chris youngezequiel astacio35781arlington9999-05-22texas2 - 0chan ho parkroy oswalt40583arlington9999-06-24houston5 - 2roy oswaltricardo rodr\u00edguez36199houston9999-06-25texas6 - 5chris youngbrandon backe41868houston\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 1 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE date = '9999-05-20';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-734.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there were two times the attendance was over 50000\nInput Table: 2008 arizona diamondbacks season\n\n\ndateopponentscorelossattendancerecord9999-09-01cardinals8 - 6mcclellan (2 - 7)3507570 - 679999-09-02cardinals8 - 2petit (3 - 4)2756870 - 689999-09-03cardinals4 - 3perez (2 - 2)2435071 - 689999-09-05dodgers7 - 0haren (14 - 8)5227071 - 699999-09-06dodgers7 - 2webb (19 - 7)4754371 - 709999-09-07dodgers5 - 3rauch (4 - 6)5413771 - 719999-09-08giants6 - 2petit (3 - 5)3025271 - 729999-09-09giants5 - 4rauch (4 - 7)3051871 - 739999-09-10giants4 - 3lyon (2 - 5)3099271 - 749999-09-12reds3 - 2harang (4 - 16)2904672 - 749999-09-13reds3 - 2 (10)pe\u00f1a (1 - 2)4507572 - 759999-09-14reds2 - 1 (10)rauch (4 - 8)2729772 - 769999-09-15giants3 - 1hennessey (1 - 2)2596973 - 769999-09-16giants2 - 0cain (8 - 13)3319574 - 769999-09-17giants7 - 6s\u00e1nchez (9 - 11)2261675 - 769999-09-18giants3 - 2lincecum (17 - 4)3432376 - 769999-09-19rockies3 - 2scherzer (0 - 3)4313776 - 779999-09-20rockies5 - 3fuentes (1 - 5)3828377 - 779999-09-21rockies13 - 4reynolds (2 - 8)3291578 - 779999-09-22cardinals4 - 2wellemeyer (12 - 9)4034979 - 779999-09-23cardinals7 - 4johnson (10 - 10)4001379 - 789999-09-24cardinals4 - 2scherzer (0 - 4)4002979 - 799999-09-25cardinals12 - 3rosales (1 - 1)4050279 - 809999-09-26rockies6 - 4grilli (3 - 3)3495080 - 809999-09-27rockies6 - 4corpas (3 - 4)3323481 - 809999-09-28rockies2 - 1vizca\u00edno (1 - 2)3590882 - 80\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) >= 2 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE attendance > 50000;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1936.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the 4.2.1 jelly bean , released november 27th , 2012 , is the stable verson of the software\nInput Table: html5 video\n\n\nbrowseroperating_systemlatest_stable_releasetheorah264vp8_(_webm_)vp9_(_webm_)android browserandroid2012-11-279999-02-039999-01-039999-02-039999-01-01chromiumall supported9999-01-019999-01-019999-01-019999-01-019999-01-01google chrome30.0.1599.101 (october 15 , 2013 )2013-10-159999-01-039999-01-039999-01-069999-01-29internet explorerwindows2013-10-179999-01-019999-09-019999-01-019999-01-01internet explorerwindows phone2012-11-219999-01-019999-09-019999-01-019999-01-01internet explorerwindows rt9999-01-109999-01-019999-01-109999-01-019999-01-01konquerorall supported2013-10-019999-04-019999-04-019999-04-019999-01-01safariios2013-10-249999-01-019999-03-019999-01-019999-01-01safarimacos x2013-10-249999-01-019999-03-019999-01-019999-01-01\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN latest_stable_release = '2012-11-27' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE operating_system = 'android' \nAND browser = 'android browser';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-199.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "To determine if the prediction is correct, we need",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: 1 / 3 of the away teams had a score greater than 10\nInput Table: 1972 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddatefootscray14.7 (91)st kilda9.11 (65)western oval186551972-07-15fitzroy16.14 (110)north melbourne9.12 (66)junction oval70071972-07-15essendon13.12 (90)richmond17.9 (111)windy hill222511972-07-15carlton20.8 (128)south melbourne8.15 (63)princes park144651972-07-15hawthorn19.14 (128)geelong15.8 (98)glenferrie oval124251972-07-15collingwood10.13 (73)melbourne8.10 (58)vfl park308831972-07-15\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE away_team_score > 10) >= (SELECT COUNT(*) FROM table_sql WHERE away_team_score IS NOT NULL) / 3 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1252.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: neither singapore nor mongolia have won a gold medal for wushu at the asian games\nInput Table: wushu at the asian games\n\n\nranknationgoldsilverbronzetotal1china (chn)4373532iran (iri)435123malaysia (mas)31594hong kong (hkg)294155thailand (tha)236116japan (jpn)165127philippines (phi)158148macau (mac)154109south korea (kor)1461110chinese taipei (tpe)13111511myanmar (mya)112412vietnam (vie)0971613indonesia (ina)022414laos (lao)015615india (ind)012316pakistan (pak)011217singapore (sin)005518mongolia (mgl)003319kazakhstan (kaz)002220yemen (yem)0011totaltotal606187208\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT gold FROM table_sql WHERE nation = 'singapore (sin)') = 0 \n             AND (SELECT gold FROM table_sql WHERE nation = 'mongolia (mgl)') = 0 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1632.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: in 1996 , the southeast region had a record of 24 - 9\nInput Table: vcu rams men 's basketball\n\n\nyearrecordseedregionresults198018 - 1212eastl 72 - 86198124 - 55eastw 85 - 69 l 56 - 58 ot198324 - 75eastw 76 - 67 l 54 - 56198423 - 76eastw 70 - 69 l 63 - 78198526 - 62westw 81 - 65 l 59 - 63199624 - 912southeastl 51 - 58200423 - 813eastl 78 - 79200728 - 711westw 79 - 77 l 79 - 84 ot200924 - 1011eastl 64 - 65201128 - 1211southwestw 59 - 46 w 74 - 56 w 94 - 76 w 72 - 71 ot w 71 - 61 l 62 - 70201229 - 712midwestw 62 - 59 l 61 - 63201327 - 95southw 88 - 42 l 53 - 78\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE year = 1996 \nAND region = 'southeast' \nAND record = '24 - 9';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1446.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there are no buildings with less than 196 feet\nInput Table: list of tallest buildings in africa\n\n\nnamecityyears_as_tallestmetresfeetfloorscarlton centrejohannesburg1973-01-01 - present223.073250kwadukuza egoli hotel tower 1 , trust bank buildingjohannesburg1970-01-01 - 1973-01-01140.045931standard bank buildingjohannesburg1968-01-01 - 1970-01-01138.845534schlesinger buildingjohannesburg9999-01-01110.036121naspers centrecape town9999-01-0193.020522mutual heights buildingcape town1940-01-01 - 1962-01-0191.029818chamber of mines buildingjohannesburg1936-01-01 - 1940-01-0180.026218union buildingspretoria1913-01-01 - 1936-01-0160.019610\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE feet < 196;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-944.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: diego milito , who scored 86 goals , had a debut year of 2008\nInput Table: football records in italy\n\n\nrankall_-_time_ranknamedebut_yearcurrent_clubgoalsapps12francesco totti1992-01-01roma230543211antonio di natale2002-01-01udinese180368316alberto gilardino1999-01-01genoa164425453luca toni2000-01-01verona114258577antonio cassano1999-01-01parma99334681giampaolo pazzini2004-01-01milan95275681mirko vu\u010dini\u01072000-01-01juventus95298897diego milito2008-01-01inter86145897sergio pellissier2002-01-01chievo8633310n / aamauri2000-01-01parma76292\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT debut_year FROM table_sql WHERE name = 'diego milito' AND goals = 86) = '2008-01-01' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1288.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there 's no countries that have 1 gold and a rank smaller then 2\nInput Table: 1967 world judo championships\n\n\nranknationgoldsilverbronzetotal1japan534122netherlands11133germany01233south korea01235soviet union00226great britain0011\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE gold = 1 \nAND rank < 2;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1662.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: a majority of the people who scored under par are from the united states\nInput Table: 1989 u.s. open (golf)\n\n\nplaceplayercountryscoreto_parmoney1curtis strangeunited states71 + 64 + 73 + 70 = 278- 2200000t2chip beckunited states71 + 69 + 71 + 68 = 279- 167823t2mark mccumberunited states70 + 68 + 72 + 69 = 279- 167823t2ian woosnamwales70 + 68 + 73 + 68 = 279- 1678235brian claarunited states71 + 72 + 68 + 69 = 280e34345t6masashi ozakijapan70 + 71 + 68 + 72 = 281+ 128220t6scott simpsonunited states67 + 70 + 69 + 75 = 281+ 1282208peter jacobsenunited states71 + 70 + 71 + 70 = 282+ 224307t9paul azingerunited states71 + 72 + 70 + 70 = 283+ 319968t9hubert greenunited states69 + 72 + 74 + 68 = 283+ 319968t9tom kiteunited states67 + 69 + 69 + 78 = 283+ 319968t9jos\u00e9 mar\u00eda olaz\u00e1balspain69 + 72 + 70 + 72 = 283+ 319968\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE to_par < 0 AND country = 'united states') > \n             (SELECT COUNT(*) FROM table_sql WHERE to_par < 0 AND country != 'united states') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-677.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: player nick faldo is from england\nInput Table: 2002 u.s. open (golf)\n\n\nplaceplayercountryscoreto_par1tiger woodsunited states67 + 68 + 70 = 205- 52sergio garc\u00edaspain68 + 74 + 67 = 209- 1t3jeff maggertunited states69 + 73 + 68 = 210et3phil mickelsonunited states70 + 73 + 67 = 210et5robert allenbyaustralia74 + 70 + 67 = 211+ 1t5p\u00e1draig harringtonireland70 + 68 + 73 = 211+ 1t5billy mayfairunited states69 + 74 + 68 = 211+ 1t8nick faldoengland70 + 76 + 66 = 212+ 2t8justin leonardunited states73 + 71 + 68 = 212+ 2t10tom byrumunited states72 + 72 + 70 = 214+ 4t10davis love iiiunited states71 + 71 + 72 = 214+ 4t10scott mccarronunited states72 + 72 + 70 = 214+ 4\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE player = 'nick faldo' \nAND country = 'england';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1622.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: in the episode ballrooms and biscotti in the show gilmore girls , the director was not matthew diamond\nInput Table: list of gilmore girls episodes\n\n\nno-titledirectorwriter_(s)original_air_dateprod_codeus_viewers_(million)661ballrooms and biscottiamy sherman - palladinoamy sherman - palladino2003-09-231761515.2672the lorelais' first day at yalechris longdaniel palladino2003-09-301761523.9683the hobbit , the sofa and digger stilesmatthew diamondamy sherman - palladino2003-10-071761534.9694chicken or beefchris longjane espenson2003-10-141761545.5705the fundamental things applyneema barnettejohn stephens2003-10-211761555.5716an affair to remembermatthew diamondamy sherman - palladino2003-10-281761565.2727the festival of living artchris longdaniel palladino2003-11-041761574.7738die , jerktom mooredaniel palladino2003-11-111761584.9749ted koppel 's big night outjamie babbitamy sherman - palladino2003-11-181761595.27510the nanny and the professorpeter lauerscott kaufer2004-01-201761604.17611in the clamor and the clangormichael grossmansheila r lawrence , janet leahy2004-01-271761614.47712a family matterkenny ortegadaniel palladino2004-02-031761624.97914the incredible sinking lorelaisstephen clancyamy sherman - palladino , daniel palladino2004-02-171761644.88015scene in a mallchris longdaniel palladino2004-02-241761654.88116the reigning lorelaimarita grabiakjane espenson2004-03-021761665.08217girls in bikinis , boys doin' the twistjamie babbitamy sherman - palladino2004-04-131761674.58318tick , tick , tick , boom!daniel palladinodaniel palladino2004-04-201761684.28419afterboommichael zinbergsheila r lawrence2004-04-271761694.38520luke can see her facematthew diamondamy sherman - palladino , daniel palladino2004-05-041761704.28621last week fights , this week tightschris longdaniel palladino2004-05-111761714.6\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT director FROM table_sql WHERE title = 'ballrooms and biscotti') != 'matthew diamond' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-284.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: rio ave 's head coach was carlos brito and club sporting cp has jos\u00e9 peseiro\nInput Table: 2004 - 05 primeira liga\n\n\nclubhead_coachcitystadium2003_-_2004_seasonacad\u00e9mica de coimbrajo\u00e3o carlos pereiracoimbraest\u00e1dio cidade de coimbra13th in the ligabelenensescarlos carvalhallisbonest\u00e1dio do restelo15th in the ligabenficagiovanni trapattonilisbonest\u00e1dio da luz2nd in the ligaboavistajaime pachecoportoest\u00e1dio do bessa - s\u00e9culo xxi8th in the ligabragajesualdo ferreirabragaest\u00e1dio municipal de braga - axa5th in the ligaestoril - praialitosestorilest\u00e1dio ant\u00f3nio coimbra da mota1st in the liga de honragil vicentelu\u00eds camposbarcelosest\u00e1dio cidade de barcelos12th in the ligauni\u00e3o de leiriav\u00edtor pontesleiriaest\u00e1dio dr magalh\u00e3es pessoa10th in the ligapenafielmanuel fernandespenafielest\u00e1dio municipal 25 de abril3rd in the liga de honramar\u00edtimomanuel cajudafunchalest\u00e1dio dos barreiros6th in the liganacionalcasemiro miorfunchalest\u00e1dio da madeira4th in the ligabeira - marmick wadsworthaveiroest\u00e1dio municipal de aveiro11th in the ligamoreirensev\u00edtor oliveiraguimar\u00e3esest\u00e1dio do moreirense9th in the ligaportoluigi delneriportoest\u00e1dio do drag\u00e3o1st in the ligasporting cpjos\u00e9 peseirolisbonest\u00e1dio jos\u00e9 alvalade - s\u00e9culo xxi3rd in the ligario avecarlos britovila do condeest\u00e1dio dos arcos7th in the ligavit\u00f3ria de guimar\u00e3esmanuel machadoguimar\u00e3esest\u00e1dio d afonso henriques14th in the ligavit\u00f3ria de set\u00fabaljos\u00e9 couceiroset\u00fabalest\u00e1dio do bonfim2nd in the liga de honra\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT head_coach FROM table_sql WHERE club = 'rio ave') = 'carlos brito' \n             AND (SELECT club FROM table_sql WHERE head_coach = 'jos\u00e9 peseiro') = 'sporting cp' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-241.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the ar - 15a3 competition hbar has a barrel length of 16 in\nInput Table: none\n\n\ncolt_model_nonamestockfire_controlrear_sightforward_assistcase_deflectorbarrel_lengthbarrel_profilebarrel_twisthand_guardsbayonet_lugmuzzle_devicer6000ar - 15 sporter (sp1)a1s - 1a1nono20 ina11:12triangularyestype 2 duckbill or a1r6001ar - 15 sporter carbine (sp1 carbine)2nd generations - 1a1nono16 ina11:12short ribbedyesa1r6002ar - 15 sporter (sp1 , bundled with 3x scope)a1s - 1a1nono20 ina11:12triangularyesa1r6420ar - 15a2 sporter ii carbine3rd generations - 1a1yesno & yes16 ina11:7short ribbedyesa2r6430sporter lightweight (9 mm)a2s - 1a1noremovable16 ina11:10short ribbedyesa1r6450ar - 15 9 mm carbine3rd generations - 1a1nono & removable16 ina11:10short ribbedyesa1r6500ar - 15a2 sporter iia2s - 1a1yesno & yes20 ina21:7ribbedyesa2r6520ar - 15a2 government carbine3rd generations - 1a2yesyes16 ina11:7short ribbedyesa2r6530sporter lightweight 2233rd generations - 1a2yesyes16 ina11:7short ribbednoa2r6550ar - 15a2 governmenta2s - 1a2yesyes20 ina21:7ribbedyesa2r6550ccar - 15a2 government (w / factory camouflage finish)a2s - 1a2yesyes20 ina21:7ribbedyesa2r6551sporter targeta2s - 1a2yesyes20 ina21:7ribbednoa2r6600ar - 15a2 hbara2s - 1a2yesyes20 inhbar1:7ribbedyesa2r6601sporter match hbara2s - 1a2yesyes20 inhbar1:7ribbednoa2r6700sporter competition hbara2s - 1flattopyesyes20 inhbar1:9ribbednoa2r6721ar - 15a3 tactical carbine4th generations - 1a2yesyes16 inhbar1:9short ribbedyesa2r6724sporter competition hbara2s - 1flattopyesyes24 inhbar1:9ribbednoa2r6731ar - 15a3 competition hbara2s - 1a2yesyes16 inhbar1:9short ribbednoa2r6750sporter competition hbar (bundled w / bipod)a2s - 1a2yesyes20 insuper - heavy1:7ribbednoa2r6821sporter carbine (7.62x39 mm)3rd generations - 1a2yesyes16 inhbar1:12short ribbednoa1\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT barrel_length FROM table_sql WHERE colt_model_no = 'r6731') = '16 in' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1636.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the earliest year with a record of 18 - 12 was the year 1980\nInput Table: vcu rams men 's basketball\n\n\nyearrecordseedregionresults198018 - 1212eastl 72 - 86198124 - 55eastw 85 - 69 l 56 - 58 ot198324 - 75eastw 76 - 67 l 54 - 56198423 - 76eastw 70 - 69 l 63 - 78198526 - 62westw 81 - 65 l 59 - 63199624 - 912southeastl 51 - 58200423 - 813eastl 78 - 79200728 - 711westw 79 - 77 l 79 - 84 ot200924 - 1011eastl 64 - 65201128 - 1211southwestw 59 - 46 w 74 - 56 w 94 - 76 w 72 - 71 ot w 71 - 61 l 62 - 70201229 - 712midwestw 62 - 59 l 61 - 63201327 - 95southw 88 - 42 l 53 - 78\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE record = '18 - 12' \nAND year = 1980;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1352.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the opponent was the yankees when the record was 4 - 5\nInput Table: 1989 toronto blue jays season\n\n\ndateopponentscorelossattendancerecord9999-04-03royals4 - 3gubicza (0 - 1)385951 - 0'9999-04-05'royals2 - 1stottlemyre (0 - 1)171261 - 19999-04-06royals3 - 2ward (0 - 1)188831 - 2'9999-04-07'rangers10 - 9guante (1 - 1)229142 - 29999-04-08rangers5 - 4key (1 - 1)260732 - 39999-04-09rangers3 - 2henke (0 - 1)194982 - 4'9999-04-10'yankees8 - 0hawkins (0 - 2)171923 - 49999-04-11yankees11 - 6 (10)righetti (0 - 1)202774 - 4'9999-04-12'yankees5 - 3castillo (1 - 1)179004 - 59999-04-14royals3 - 0leibrandt (0 - 1)460285 - 5'9999-04-15'royals10 - 5ward (0 - 2)252475 - 6'9999-04-16'royals15 - 8saberhagen (1 - 1)352106 - 60000-04-17yankees7 - 2flanagan (0 - 1)232606 - 79999-04-18yankees2 - 0musselman (0 - 1)250406 - 89999-04-19yankees4 - 2key (2 - 2)264716 - 99999-04-21rangers6 - 3brown (1 - 1)221867 - 99999-04-22rangers4 - 2hough (2 - 1)272788 - 99999-04-23rangers4 - 1stottlemyre (0 - 2)314738 - 109999-04-24athletics5 - 4henke (1 - 2)250998 - 119999-04-25athletics3 - 1cerutti (0 - 1)124378 - 129999-04-26mariners7 - 6wells (1 - 1)73998 - 139999-04-27mariners6 - 1dunne (0 - 1)86009 - 139999-04-28angels9 - 0stottlemyre (0 - 3)309589 - 149999-04-29angels4 - 3 (10)ward (1 - 3)499069 - 159999-04-30angels1 - 0 (11)henke (1 - 3)311259 - 16\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE opponent = 'yankees' \nAND record = '4 - 5';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-665.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: bradford city went against port vale two times according to the chart\nInput Table: 2008 - 09 bradford city a.f.c. season\n\n\ngamedateopponentvenueresultattendance12008-08-09notts countyhome2 - 11403822008-08-16macclesfield townaway2 - 0255632008-08-23rochdalehome2 - 01315442008-08-30aldershot townaway2 - 3380552008-09-06port valeaway2 - 0727362008-09-13exeter cityhome4 - 11268372008-09-20bournemouthhome1 - 31282482008-09-27shrewsbury townaway0 - 2651792008-10-04luton townhome1 - 113083102008-10-11accrington stanleyaway3 - 23012112008-10-18gillinghamhome2 - 212432122008-10-21darlingtonaway1 - 23034132008-10-24grimsby townaway3 - 14470142008-10-28buryhome1 - 012830152008-11-01barnethome3 - 312510162008-11-15wycombe wanderersaway0 - 15002172008-11-22rotherham unitedaway2 - 04586182008-11-25chesterfieldhome3 - 212145192008-12-06dagenham & redbridgehome1 - 112145202008-12-13brentfordaway1 - 24339212008-12-20chester cityhome0 - 012092222008-12-26lincoln cityaway0 - 06156232008-12-28morecambehome4 - 013105242009-01-03shrewsbury townhome0 - 012877252009-01-17accrington stanleyhome1 - 112172262009-01-24luton townaway3 - 36053272009-01-27buryaway0 - 14112282009-01-31grimsby townhome2 - 012816292009-02-07gillinghamaway2 - 04866302009-02-14wycombe wanderershome1 - 012689312009-02-17darlingtonhome0 - 012782322009-02-21barnetaway1 - 42445332009-02-28notts countyaway1 - 35138342009-03-01macclesfield townhome1 - 011908352009-03-07aldershot townhome5 - 012465362009-03-10rochdaleaway0 - 35157372009-03-14exeter cityaway0 - 15253382009-03-17bournemouthaway1 - 44847392009-03-21port valehome0 - 112436402009-03-28chester cityaway0 - 02735412009-04-04brentfordhome1 - 112832422009-04-10morecambeaway1 - 24546432009-04-13lincoln cityhome1 - 112932\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 2 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE opponent = 'port vale';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-585.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: 8 games in the 2005 milwaukee brewers season were attended by more than 30000 people\nInput Table: 2005 milwaukee brewers season\n\n\ndateopponentscorelossattendancerecord9999-09-01padres5 - 6davis (1 - 1)2478565 - 699999-09-02padres12 - 2lawrence (7 - 14)1823166 - 699999-09-03padres1 - 6obermueller (1 - 3)3202266 - 709999-09-04padres3 - 2otsuka (1 - 6)2004267 - 709999-09-05reds6 - 1belisle (3 - 7)1614468 - 709999-09-06reds1 - 2 (10)de la rosa (2 - 2)1335168 - 719999-09-07reds14 - 5milton (7 - 14)1588669 - 719999-09-09astros7 - 4clemens (11 - 7)1813070 - 719999-09-10astros5 - 7ohka (10 - 8)2443770 - 729999-09-11astros4 - 2oswalt (17 - 12)1739271 - 729999-09-13diamondbacks3 - 1v\u00e3\u00a1zquez (10 - 15)2370872 - 729999-09-14diamondbacks1 - 2 (12)lehr (0 - 1)2379372 - 739999-09-15diamondbacks14 - 2estes (7 - 8)2074173 - 739999-09-16astros1 - 2eveland (1 - 1)3376773 - 749999-09-17astros0 - 7obermueller (1 - 4)3775673 - 759999-09-18astros1 - 6capuano (17 - 10)3505273 - 769999-09-20cubs5 - 3williams (5 - 9)3013674 - 769999-09-21cubs7 - 6van buren (0 - 2)3004975 - 769999-09-22cubs0 - 3helling (2 - 1)3113775 - 779999-09-23cardinals9 - 6carpenter (21 - 5)2247276 - 779999-09-24cardinals8 - 7mulder (16 - 8)3350677 - 779999-09-25cardinals0 - 2davis (11 - 11)2015077 - 789999-09-26reds12 - 9coffey (4 - 1)1441278 - 789999-09-27reds6 - 2claussen (10 - 10)2803179 - 789999-09-28reds4 - 11capuano (18 - 11)2118179 - 799999-09-29reds2 - 0milton (8 - 15)1317380 - 799999-09-30pirates6 - 5vogelsong (2 - 2)2092281 - 79\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) >= 8 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE attendance > 30000;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1602.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: during the 2007 - 08 minnesota wild season , the score on february 10 and february 24 was 2 - 1\nInput Table: 2007 - 08 minnesota wild season\n\n\ndatevisitorscorehomedecisionattendancerecord01-02-9999minnesota4 - 1columbusbackstrom1852930 - 19 - 39999-02-05detroit3 - 2minnesotabackstrom1856830 - 19 - 401-02-07dallas1 - 0minnesotabackstrom1856830 - 20 - 49999-02-09ny islanders3 - 4minnesotabackstrom1856831 - 20 - 401-02-10minnesota2 - 1st louisharding1647732 - 20 - 401-02-12minnesota2 - 4edmontonharding1683932 - 21 - 401-02-14minnesota5 - 4vancouverbackstrom1863033 - 21 - 49999-02-17nashville4 - 5minnesotabackstrom1856834 - 21 - 49999-02-19vancouver3 - 2minnesotabackstrom1856834 - 21 - 59999-02-20minnesota0 - 3chicagoharding1781234 - 22 - 59999-02-24calgary2 - 1minnesotabackstrom1856834 - 23 - 59999-02-26minnesota1 - 4washingtonbackstrom1739134 - 24 - 59999-02-27minnesota3 - 2tampa baybackstrom1721135 - 24 - 59999-02-29minnesota3 - 2floridabackstrom1692736 - 24 - 5\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT score FROM table_sql WHERE date = '01-02-10') = '2 - 1' \n             AND (SELECT score FROM table_sql WHERE date = '9999-02-24') = '2 - 1' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1440.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: when the indianapolis colts were the visiting team at giants stadium , the final score was 26 - 21\nInput Table: nbc sunday night football results (2006 - present)\n\n\ndatevisiting_teamfinal_scorehost_teamstadium9999-09-07miami dolphins17 - 28pittsburgh steelersheinz field9999-09-10indianapolis colts26 - 21new york giantsgiants stadium9999-09-17washington redskins10 - 27dallas cowboystexas stadium9999-09-24denver broncos17 - 7new england patriotsgillette stadium9999-10-01seattle seahawks6 - 37chicago bearssoldier field9999-10-08pittsburgh steelers13 - 23san diego chargersqualcomm stadium9999-10-15oakland raiders3 - 13denver broncosinvesco field at mile high9999-10-29dallas cowboys35 - 14carolina panthersbank of america stadium9999-11-05indianapolis colts27 - 20new england patriotsgillette stadium9999-11-12chicago bears38 - 20new york giantsgiants stadium9999-11-19san diego chargers35 - 27denver broncosinvesco field at mile high9999-11-26philadelphia eagles21 - 45indianapolis coltsrca dome9999-12-03seattle seahawks23 - 20denver broncosinvesco field at mile high9999-12-10new orleans saints42 - 17dallas cowboystexas stadium9999-12-17kansas city chiefs9 - 20san diego chargersqualcomm stadium9999-12-25philadelphia eagles23 - 7dallas cowboystexas stadium9999-12-31green bay packers26 - 7chicago bearssoldier field0001-01-06kansas city chiefs8 - 23indianapolis coltsrca dome0001-01-06dallas cowboys20 - 21seattle seahawksqwest field\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT final_score FROM table_sql WHERE visiting_team = 'indianapolis colts' AND host_team = 'new york giants') = '26 - 21' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-445.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the highest scoring team for the games that happened on the 18th of june was carlton\nInput Table: 1938 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddategeelong11.23 (89)hawthorn6.13 (49)corio oval70001938-06-18fitzroy16.12 (108)south melbourne8.8 (56)brunswick street oval120001938-06-18st kilda14.12 (96)melbourne16.16 (112)junction oval140001938-06-18richmond15.14 (104)essendon15.9 (99)punt road oval200001938-06-18footscray13.9 (87)collingwood10.5 (65)western oval180001938-06-18north melbourne11.5 (71)carlton16.25 (121)arden street oval130001938-06-18\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MAX(home_team_score) FROM table_sql WHERE date = '1938-06-18') = \n             (SELECT MAX(away_team_score) FROM table_sql WHERE date = '1938-06-18') \n        THEN 'FALSE' \n        ELSE 'TRUE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1282.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: por has a free transfer fee\nInput Table: 2008 - 09 apoel f.c. season\n\n\nnatnamemoving_totypetransfer_windowtransfer_feesourcegremachlasretiredretirementsummer-contragrcypmakridesmetalurh donetskend of contractsummerfreekerkidanetser\u010dorovi\u0107ael limassolloan returnsummer--cyploukaael limassolend of contractsummerfreekerkidanetgrekapsislevadiakosend of contractsummerfree-cypdaskalakisaek larnacaend of contractsummerfreeapoelnetbraz\u00e9 carlostrofensecontract terminationsummerfreeapoelfccomcycypvourkoudoxa katokopialoansummerfree-cyppanayiotoudigenis morphouloansummerfree-mkdnikolovskiaep paphosmutual consentwinterfree-cyppapathanasiouermis aradippouloanwinterfree-porpaulo costaanorthosis famagustamutual consent loan returnwinterfreeapoelfccomcy\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT transfer_fee FROM table_sql WHERE nat = 'por') = 'free' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-847.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: beijing guoan is one of the two football clubs in asia , and participated in the 2008 and 2010 seasons\nInput Table: list of superleague formula football clubs\n\n\nnofootball_clubcontinentassociated_football_clubseasonsracing_drivers3ac milaneuropeac milan2008 2009 2010robert doornbos giorgio pantano yelmer buurman4ac sparta pragueeuropeac sparta prague2011filip salaquarda5team luxembourgeuropenone2011fr\u00e9d\u00e9ric vervisch6team new zealandoceanianone2011earl bamber7team japanasianone2011duncan tappy8 1 (in 2011)rsc anderlechteuropersc anderlecht2008 2009 2010 2011craig dolby yelmer buurman davide rigon neel jani8team netherlandseuropenone2011robert doornbos10fc basel 1893europefc basel2008 2009 2010max wissel max wissel max wissel12 24 (in 2010)beijing guoanasiabeijing guoan fc2008 2010davide rigon john martin14team brazils americanone2011ant\u00f4nio pizzonia17rangers fceuroperangers fc2008 2009ryan dalziel , james walker john martin24fc midtjyllandeuropefc midtjylland2009kasper andersen24team australiaoceanianone2011john martin31team englandeuropenone2011craig dolby\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE continent = 'asia' AND football_club = 'beijing guoan' AND seasons LIKE '%2008%') > 0 \n             AND (SELECT COUNT(*) FROM table_sql WHERE continent = 'asia' AND football_club = 'beijing guoan' AND seasons LIKE '%2010%') > 0 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-314.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: adrian dantley was on the team the entire time that brad davis was\nInput Table: utah jazz all - time roster\n\n\nplayernationalitypositionyears_for_jazzschool_/_club_teamadrian dantleyunited statesguard - forward1979-01-01notre damebrad davisunited statesguard1979-01-01marylanddarryl dawkinsunited statescenter1987-01-01maynard evans hspaul dawkinsunited statesguard1979-01-01northern illinoisgreg deaneunited statesguard1979-01-01utahjames donaldsonunited statescenter1993-01-01, 1994-01-01, 1995-01-01washington statejohn drewunited statesguard - forward1982-01-01gardner - webbjohn durenunited statesguard1980-01-01georgetown\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT years_for_jazz FROM table_sql WHERE player = 'adrian dantley') <= \n             (SELECT years_for_jazz FROM table_sql WHERE player = 'brad davis') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1645.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: north melbourne had the highest score out all the way team\nInput Table: 1975 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddategeelong14.20 (104)melbourne14.14 (98)kardinia park133281975-06-07st kilda15.9 (99)north melbourne17.19 (121)moorabbin oval178111975-06-07richmond19.14 (128)essendon12.9 (81)mcg494691975-06-07hawthorn19.24 (138)collingwood13.11 (89)princes park238301975-06-07fitzroy15.7 (97)carlton16.10 (106)junction oval162491975-06-07footscray13.11 (89)south melbourne12.15 (87)vfl park140561975-06-07\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MAX(away_team_score) FROM table_sql) = (SELECT away_team_score FROM table_sql WHERE away_team = 'north melbourne') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-963.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: episode number 202 aired on february 4 , 2008\nInput Table: cities of the underworld\n\n\nproduction_noepisode_nooriginal_airdateepisode_titlehost152012008-01-28underground apocalypsedon wildman162022008-02-04vietnamdon wildman172032008-02-11a - bomb undergrounddon wildman182042008-02-25viking undergrounddon wildman192052008-03-03hitler 's last secretdon wildman202062008-03-10maya undergrounddon wildman212072008-03-17mob undergrounddon wildman222082008-03-24prophecies from belowdon wildman232092008-03-31new york : secret societiesdon wildman242102008-04-14washington , dc : seat of powerdon wildman252112008-04-21stalin 's secret lairdon wildman262122008-04-28katrina undergrounddon wildman272132008-05-05secret soviet basesdon wildman\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE episode_no = 202 \nAND original_airdate = '2008-02-04';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-918.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: september 25th game was against the orioles the final score was 4 - 3 , 28324 fans were in attendance\nInput Table: 1997 toronto blue jays season\n\n\ndateopponentscorelossattendancerecord9999-09-01mets3 - 0hentgen (14 - 9)1919665 - 719999-09-02mets8 - 5clemens (20 - 5)1763565 - 729999-09-03mets4 - 2quantrill (6 - 6)1451365 - 739999-09-04rangers6 - 2carpenter (1 - 7)2617865 - 749999-09-05rangers5 - 1pavlik (2 - 4)2712166 - 749999-09-06rangers2 - 1burkett (7 - 12)3123267 - 749999-09-07rangers4 - 0oliver (11 - 11)3021268 - 749999-09-08angels12 - 10james (4 - 5)2577569 - 749999-09-09angels2 - 0hill (7 - 12)2567470 - 749999-09-10athletics3 - 2plesac (1 - 4)476470 - 759999-09-11athletics8 - 7escobar (2 - 1)613570 - 769999-09-12mariners7 - 3clemens (21 - 6)3704470 - 779999-09-13mariners6 - 3ayala (10 - 5)5163171 - 779999-09-14mariners3 - 2risley (0 - 1)4547771 - 789999-09-15mariners7 - 3williams (8 - 14)4168471 - 799999-09-17red sox4 - 3quantrill (6 - 7)2364871 - 809999-09-18red sox3 - 2escobar (3 - 2)2799071 - 819999-09-19yankees3 - 0gooden (8 - 5)3119572 - 819999-09-20yankees4 - 3 (11)janzen (1 - 1)3833272 - 829999-09-21yankees5 - 4 (10)almanzar (0 - 1)4003872 - 839999-09-22yankees8 - 1hentgen (15 - 10)2338072 - 849999-09-23orioles3 - 2clemens (21 - 7)2927672 - 859999-09-24orioles9 - 3daal (1 - 1)2744372 - 869999-09-25orioles4 - 3mussina (15 - 8)2832473 - 869999-09-26red sox3 - 0henry (7 - 3)3415574 - 869999-09-27red sox12 - 5corsi (5 - 3)3740175 - 869999-09-28red sox3 - 2gordon (6 - 10)4025176 - 86\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE date = '9999-09-25' \nAND opponent = 'orioles' \nAND score = '4 - 3' \nAND attendance = 28324;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1239.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: bcw410 is the production code for episode 10\nInput Table: list of white collar episodes\n\n\nno_in_seriesno_in_seasontitledirected_bywritten_byus_viewers_(million)original_air_dateproduction_code471wantedpaul holahanjeff eastin3.212012-07-10bcw401482most wantedpaul holahanmark goffman2.982012-07-17bcw402493diminishing returnsstefan schwartzjim campolongo3.012012-07-24bcw403504parting shotsrobert duncan mcneillalexandra mcnally2.822012-07-31bcw404515honor among thievesarlene sanfordjoe henderson2.932012-08-14bcw405526identity crisisdavid straitonchanning powell3.892012-08-21bcw406537compromising positionspaul holahanmatthew negrete3.362012-08-28bcw407548ancient historyrussell lee finedaniel shattuck3.382012-09-04bcw408559gloves offrenny harlinmark goffman3.82012-09-11bcw4095610vested interestrussell lee finejeff eastin3.412012-09-18bcw4105711family businesspaul holahanjoe henderson2.772013-01-22bcw4115812brass tacksanton cropperjim campolongo & alexandra mcnally2.612013-01-29bcw4125913empire citytim dekaychanning powell & daniel shattuck2.282013-02-05bcw4136014shoot the moonrussell lee finematthew negrete & bob derosa2.422013-02-19bcw4146115the originaljohn kretchmermark goffman2.122013-02-26bcw415\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN production_code = 'bcw410' THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE no_in_series = 56;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-466.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: tom weiskopf is from the united states and finished in t6\nInput Table: 1973 u.s. open (golf)\n\n\nplaceplayercountryscoreto_par1gary playersouth africa67 + 70 = 137- 52jim colbertunited states70 + 68 = 138- 4t3jack nicklausunited states71 + 69 = 140- 2t3johnny millerunited states71 + 69 = 140- 2t3bob charlesnew zealand71 + 69 = 140- 2t6gene borekunited states77 + 65 = 142et6julius borosunited states73 + 69 = 142et6tom weiskopfunited states73 + 69 = 142et6arnold palmerunited states71 + 71 = 142et6lee trevinounited states70 + 72 = 142e\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE player = 'tom weiskopf' \nAND country = 'united states' \nAND place = 't6';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-498.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the song title for track 9 is just a little bit\nInput Table: walk a mile in my shoes : the essential '70s masters\n\n\ntrackrecordedoriginal_issuesong_titletime11971-05-15wonderful world of christmasmerry christmas , baby9999-01-0121971-05-20previously unreleasedi shall be released9999-01-0131971-05-16elvisdon't think twice , it 's all right9999-01-0141971-05-19elvisit 's still here9999-01-0151971-05-19elvisi'll take you home again , kathleen9999-01-0161971-05-19elvisi will be true9999-01-0171971-06-10previously unreleasedmy way9999-01-0181972-03-27previously unreleasedfor the good times9999-01-0191973-07-22raised on rockjust a little bit9999-01-01101973-07-21previously unreleasedit 's diff 'rent now9999-01-01111973-09-23raised on rockare you sincere9999-01-01121973-12-10good timesi got a feelin' in my body9999-01-01131973-12-11promised landyou asked me to9999-01-01141973-12-13good timesgood time charlie 's got the blues9999-01-01151973-12-14good timestalk about the good times9999-01-01161975-03-11previously unreleasedtiger man9999-01-01171975-03-10todayi can help9999-01-01181975-03-11todaysusan when she tried9999-01-01191975-03-11todayshake a hand9999-01-01201976-02-01unreleased alternate takeshe thinks i still care9999-01-01211976-02-05from elvis presley boulevarddanny boy9999-01-01221976-02-01from elvis presley boulevardlove coming down9999-01-01231976-10-30moody bluehe'll have to go9999-01-01\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN song_title = 'just a little bit' THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE track = 9;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-932.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: when new jersey was the visitor on february 27 , the score was 2 - 6\nInput Table: none\n\n\ndatevisitorscorehomerecord9999-02-03ny islanders7 - 2new jersey11 - 32 - 119999-02-05new jersey4 - 5washington11 - 33 - 119999-02-06vancouver4 - 4new jersey11 - 33 - 129999-02-09new jersey4 - 5chicago11 - 34 - 1201-02-12new jersey1 - 5st louis11 - 35 - 1201-02-15minnesota3 - 2new jersey11 - 36 - 129999-02-20new jersey0 - 3philadelphia11 - 37 - 1201-02-21buffalo4 - 4new jersey11 - 37 - 139999-02-24detroit1 - 4new jersey12 - 37 - 139999-02-26new jersey4 - 5pittsburgh12 - 38 - 139999-02-27new jersey2 - 6buffalo12 - 39 - 13\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT score FROM table_sql WHERE date = '9999-02-27' AND visitor = 'new jersey') = '2 - 6' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-429.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: series 101 is in season 10\nInput Table: will & grace (season 5)\n\n\nseriesseasontitledirected_bywritten_byoriginal_air_dateus_viewers_(millions)931and the horse he rode in onjames burrowsadam barr2002-09-2621.5942bacon and eggsjames burrowsalex herschlag2002-10-0320.6953the kid stays out of the picturejames burrowsjhoni marchinko2002-10-1020.2964humongous growthjames burrowskari lizer2002-10-1719.5975it 's the gay pumpkin , charlie brownjames burrowsgary janetti2002-10-3117.2986boardroom and a parked placejames burrowsgail lerner2002-11-0721.1997the needle and the omelet 's donejames burrowstracy poust & jon kinnally2002-11-1419.11008 - 9marry me a little , marry me a little morejames burrowsjeff greenstein & bill wrubel2002-11-2124.310110the honeymoon 's overjames burrowssally bradford2002-12-0519.310211all about christmas evejames burrowsadam barr2002-12-1216.210312field of queensjames burrowskatie palmer2003-01-0916.210413fagmalion part i : gay it forwardjames burrowstracy poust & jon kinnally2003-01-1616.010514fagmalion part ii : attack of the clonesjames burrowsgary janetti2003-01-3015.810615homojojames burrowsbill wrubel2003-02-0616.510716women and children firstjames burrowslaura kightlinger2003-02-1318.710817fagmalion part iii : bye , bye , beardyjames burrowsalex herschlag2003-02-2016.410918fagmalion part iv : the guy who loved mejames burrowsgail lerner2003-03-1315.011019sex , losers , and videotapejames burrowssteve gabriel2003-04-0315.011120leo unwrappedjames burrowssonja warfield2003-04-1714.711221dolls and dollsjames burrowskari lizer2003-04-2417.7\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE series = 101 \nAND season = 10;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-242.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the sporter target has a s - 1 fire control\nInput Table: none\n\n\ncolt_model_nonamestockfire_controlrear_sightforward_assistcase_deflectorbarrel_lengthbarrel_profilebarrel_twisthand_guardsbayonet_lugmuzzle_devicer6000ar - 15 sporter (sp1)a1s - 1a1nono20 ina11:12triangularyestype 2 duckbill or a1r6001ar - 15 sporter carbine (sp1 carbine)2nd generations - 1a1nono16 ina11:12short ribbedyesa1r6002ar - 15 sporter (sp1 , bundled with 3x scope)a1s - 1a1nono20 ina11:12triangularyesa1r6420ar - 15a2 sporter ii carbine3rd generations - 1a1yesno & yes16 ina11:7short ribbedyesa2r6430sporter lightweight (9 mm)a2s - 1a1noremovable16 ina11:10short ribbedyesa1r6450ar - 15 9 mm carbine3rd generations - 1a1nono & removable16 ina11:10short ribbedyesa1r6500ar - 15a2 sporter iia2s - 1a1yesno & yes20 ina21:7ribbedyesa2r6520ar - 15a2 government carbine3rd generations - 1a2yesyes16 ina11:7short ribbedyesa2r6530sporter lightweight 2233rd generations - 1a2yesyes16 ina11:7short ribbednoa2r6550ar - 15a2 governmenta2s - 1a2yesyes20 ina21:7ribbedyesa2r6550ccar - 15a2 government (w / factory camouflage finish)a2s - 1a2yesyes20 ina21:7ribbedyesa2r6551sporter targeta2s - 1a2yesyes20 ina21:7ribbednoa2r6600ar - 15a2 hbara2s - 1a2yesyes20 inhbar1:7ribbedyesa2r6601sporter match hbara2s - 1a2yesyes20 inhbar1:7ribbednoa2r6700sporter competition hbara2s - 1flattopyesyes20 inhbar1:9ribbednoa2r6721ar - 15a3 tactical carbine4th generations - 1a2yesyes16 inhbar1:9short ribbedyesa2r6724sporter competition hbara2s - 1flattopyesyes24 inhbar1:9ribbednoa2r6731ar - 15a3 competition hbara2s - 1a2yesyes16 inhbar1:9short ribbednoa2r6750sporter competition hbar (bundled w / bipod)a2s - 1a2yesyes20 insuper - heavy1:7ribbednoa2r6821sporter carbine (7.62x39 mm)3rd generations - 1a2yesyes16 inhbar1:12short ribbednoa1\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE name = 'sporter target' \nAND fire_control = 's - 1';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1773.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the cdr for the period 1975 - 1980 is 9.0 and the life expectancy is 61.5\nInput Table: none\n\n\nperiodlive_births_per_yeardeaths_per_yearnatural_change_per_yearcbrcdrnctfrimrlife_expectancy_totallife_expectancy_maleslife_expectancy_females1950-01-01 - 1955-01-012 572 000900 0001 672 00044.115.528.66.1513550.949.252.61955-01-01 - 1960-01-012 918 000947 0001 971 00043.214.029.16.1512253.351.555.21960-01-01 - 1965-01-013 303 000986 0002 317 00042.212.629.66.1510955.753.857.69999-01-01 - 9999-01-013 330 000998 0002 332 00037.011.125.95.3810057.655.759.61970-01-01 - 1975-01-013 441 0001 014 0002 427 00033.79.923.84.729159.557.361.81975-01-01 - 1980-01-013 741 0001 043 0002 698 00032.59.023.54.317961.559.263.91980-01-01 - 1985-01-013 974 0001 064 0002 910 00030.88.222.63.86363.460.466.81985-01-01 - 1990-01-013 757 0001 055 0002 702 00026.37.418.93.15265.361.969.11990-01-01 - 1995-01-013 519 0001 058 0002 461 00022.66.815.82.64367.363.671.21995-01-01 - 2000-01-013 624 0001 086 0002 538 00021.56.515.12.453469.365.573.32000-01-01 - 2005-01-013 572 0001 147 0002 425 00019.86.413.42.252770.967.274.8\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN cdr = 9.0 AND life_expectancy_total = 61.5 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE period = '1975-01-01 - 1980-01-01';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-616.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: episode 28 is titled the suspension\nInput Table: none\n\n\nepisodeseriesepisode_titleoriginal_air_dateproduction_code271return to genesis2008-04-05201282the suspension2008-04-06202293a team reinvented2008-04-12203304the new captain2008-04-13204315the homecoming2008-04-19205326netherball rules!2008-04-20206337doubts within2008-04-26207348rocket 's decent2008-04-27208359the all - stars2008-05-032093610rocket vs sinedd2008-05-042103711the champions stumble2008-05-102113812last stand2008-05-112123913fluxless2008-05-172134014new order2008-07-262144115revelations2008-07-272154216new rules2008-08-022164317open doors2008-08-032174418warren steps in2008-08-092184519the technodroid v3s2008-08-102194620the fallen star2008-08-162204721coach artegor2008-08-172214822rocket , the midfielder2008-08-232224923destiny2008-08-242235024final preparations2008-08-312245125a team unravels2008-08-31225\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN episode_title = 'the suspension' THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE episode = 28;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1028.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: facebook by matchbox was released on 2010 - 12 - 16\nInput Table: list of zune applications\n\n\ntitledevelopercategoryrelease_dateversionalarm clockmicrosoftutilities2010-12-161.1calculatormicrosoftutilities2009-09-011.0calendarmatchboxutilities2011-07-291.0.0.3chord findermicrosoftutilities2010-11-171.0drum machine hddino gamesutilities2010-10-201.0emailmicrosoftutilities2011-04-011.1.0.1facebookmatchboxsocial networking2010-12-161.4fan predictionihwy , incentertainment2011-06-231.0fingerpaintbabarogaentertainment2011-07-291.1levelmicrosoftutilities2011-06-231.0metronomedino gamesutilities2010-09-091.0msn moneymicrosoftutilities2010-07-291.0notesmicrosoftutilities2011-06-231.0pianomicrosoftentertainment2009-11-011.0shuffle by albummicrosoftutilities2011-02-181.1stopwatchmicrosoftutilities2010-08-051.1twittermatchboxsocial networking2010-12-161.6weathermicrosoftutilities2009-09-011.0windows live messengermicrosoftsocial networking2010-11-171.4zune readermicrosoftutilities2011-02-181.2\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE title = 'facebook' \nAND developer = 'matchbox' \nAND release_date = '2010-12-16';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1281.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: for the nat por , it is a mutual consent loan return , and the transfer fee is free\nInput Table: 2008 - 09 apoel f.c. season\n\n\nnatnamemoving_totypetransfer_windowtransfer_feesourcegremachlasretiredretirementsummer-contragrcypmakridesmetalurh donetskend of contractsummerfreekerkidanetser\u010dorovi\u0107ael limassolloan returnsummer--cyploukaael limassolend of contractsummerfreekerkidanetgrekapsislevadiakosend of contractsummerfree-cypdaskalakisaek larnacaend of contractsummerfreeapoelnetbraz\u00e9 carlostrofensecontract terminationsummerfreeapoelfccomcycypvourkoudoxa katokopialoansummerfree-cyppanayiotoudigenis morphouloansummerfree-mkdnikolovskiaep paphosmutual consentwinterfree-cyppapathanasiouermis aradippouloanwinterfree-porpaulo costaanorthosis famagustamutual consent loan returnwinterfreeapoelfccomcy\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT transfer_fee FROM table_sql WHERE nat = 'por' AND type = 'mutual consent loan return') = 'free' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1993.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the theme of d - 10 locomotive by artist dan fell was from 2002\nInput Table: royal canadian mint numismatic coins (2000s)\n\n\nyearthemeartistmintageissue_price2000steam buggyjohn mardon4436759.952000the bluenosej franklin wrightincluded in steam buggy59.952000the torontojohn mardonincluded in steam buggy59.952001the russell light fourjohn mardon4182859.952001the marco poloj franklin wrightincluded in the russell59.952001the scotiadon curleyincluded in the russell59.952002the gray - dortjohn mardon3594459.952002the william lawrencebonnie rossincluded in the gray - dort59.952002d - 10 locomotivedan fellincluded in the gray - dort59.952003hmcs bras dordon curley3199759.952003cnr fa - 1 diesel electricjohn mardonincluded in hmcs bras dor59.952003bricklin sv - 1brian hughesincluded in hmcs bras dor59.95\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE theme = 'd - 10 locomotive' \nAND artist = 'dan fell' \nAND year = 2002;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-927.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: new jersey was the home team in the game on february 3\nInput Table: none\n\n\ndatevisitorscorehomerecord9999-02-03ny islanders7 - 2new jersey11 - 32 - 119999-02-05new jersey4 - 5washington11 - 33 - 119999-02-06vancouver4 - 4new jersey11 - 33 - 129999-02-09new jersey4 - 5chicago11 - 34 - 1201-02-12new jersey1 - 5st louis11 - 35 - 1201-02-15minnesota3 - 2new jersey11 - 36 - 129999-02-20new jersey0 - 3philadelphia11 - 37 - 1201-02-21buffalo4 - 4new jersey11 - 37 - 139999-02-24detroit1 - 4new jersey12 - 37 - 139999-02-26new jersey4 - 5pittsburgh12 - 38 - 139999-02-27new jersey2 - 6buffalo12 - 39 - 13\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE date = '9999-02-03' \nAND home = 'new jersey';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1789.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: california 22 , a newly created district , resulted in a republican gain\nInput Table: united states house of representatives elections , 1942\n\n\ndistrictincumbentpartyfirst_electedresultcandidatescalifornia 2harry lane englebrightrepublican1926-01-01re - electedharry lane englebright (r) unopposedcalifornia 4thomas rolphrepublican1940-01-01re - electedthomas rolph (r) 98.3% archie brown ( w / i ) 1.7%california 7john h tolandemocratic1934-01-01re - electedjohn h tolan (d) unopposedcalifornia 9bertrand w gearhartrepublican1934-01-01re - electedbertrand w gearhart (r) unopposedcalifornia 10alfred j elliottdemocratic1937-01-01re - electedalfred j elliott (d) unopposedcalifornia 17cecil r kingdemocratic1942-08-25re - electedcecil r king (d) unopposedcalifornia 22none (district created)none (district created)9999-01-01new seat republican gainjohn j phillips (r) 57.6% n e west (d) 42.4%\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN result = 'new seat republican gain' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE district = 'california 22';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-219.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there were four episodes in region 4 on march 13 , 2008\nInput Table: none\n\n\nvolumediscsepisodesregion_1region_2region_41142006-01-312007-02-192007-03-152142006-03-282007-06-042007-07-053142006-05-302007-09-032008-03-134142006-07-182008-02-182008-06-195142006-09-192008-05-262009-03-05\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE episodes = 4 \nAND region_4 = '2008-03-13';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1272.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: attendance of all games at the pepsi center was over 15000\nInput Table: 2009 - 10 denver nuggets season\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord39999-11-01grizzliesw 133 - 123 (ot)carmelo anthony (42)nen\u00ea (9)chauncey billups (12)pepsi center 158233 - 049999-11-03pacersw 111 - 93 (ot)carmelo anthony (25)nen\u00ea (13)anthony carter (5)conseco fieldhouse 106274 - 059999-11-04netsw 122 - 94 (ot)ty lawson (23)kenyon martin (10)chauncey billups (5)izod center 153195 - 079999-11-07hawksl 100 - 125 (ot)carmelo anthony (30)chris andersen (11)chauncey billups (7)philips arena 178015 - 289999-11-10bullsw 90 - 89 (ot)carmelo anthony (20)nen\u00ea (12)chauncey billups (6)united center 214096 - 299999-11-11bucksl 102 - 108 (ot)carmelo anthony (32)carmelo anthony (10)chauncey billups , ty lawson (5)bradley center 129876 - 3109999-11-13lakersw 105 - 79 (ot)carmelo anthony (25)chris andersen (11)chauncey billups (8)pepsi center 191417 - 3119999-11-17raptorsw 130 - 112 (ot)carmelo anthony (32)nen\u00ea (10)chauncey billups (10)pepsi center 164468 - 3129999-11-20clippersl 99 - 106 (ot)carmelo anthony (37)nen\u00ea (12)chauncey billups (7)staples center 181558 - 4139999-11-21bullsw 112 - 93 (ot)carmelo anthony (30)carmelo anthony , kenyon martin (11)carmelo anthony (7)pepsi center 193599 - 4149999-11-24netsw 101 - 87 (ot)carmelo anthony (27)nen\u00ea (9)chauncey billups (7)pepsi center 1630710 - 4159999-11-25timberwolvesw 124 - 111 (ot)carmelo anthony (22)nen\u00ea (8)nen\u00ea , ty lawson (6)target center 1310111 - 4169999-11-27knicksw 128 - 125 (ot)carmelo anthony (50)nen\u00ea , kenyon martin (11)chauncey billups (8)pepsi center 1915512 - 4\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE location_attendance > 15000;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-785.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: danish thomas bjorn finished with a score of 68 + 71 + 76 = 215\nInput Table: 1998 open championship\n\n\nplaceplayercountryscoreto_par1brian wattsunited states68 + 69 + 73 = 210et2jim furykunited states70 + 70 + 72 = 212+ 2t2mark o'mearaunited states72 + 68 + 72 = 212+ 2t2jesper parneviksweden68 + 72 + 72 = 212+ 25justin rose (a)england72 + 66 + 75 = 213+ 3t6thomas bj\u00e3rndenmark68 + 71 + 76 = 215+ 5t6brad faxonunited states67 + 74 + 74 = 215+ 5t6john hustonunited states65 + 77 + 73 = 215+ 5t6tiger woodsunited states65 + 73 + 77 = 215+ 5t10david duvalunited states70 + 71 + 75 = 216+ 6t10costantino roccaitaly72 + 74 + 70 = 216+ 6t10raymond russellscotland68 + 73 + 75 = 216+ 6t10katsuyoshi tomorijapan75 + 71 + 70 = 216+ 6\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT score FROM table_sql WHERE player = 'thomas bj\u00e3rn') = '68 + 71 + 76 = 215' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-322.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: pennsylvania17 is the only district that had someone first elected in the 1980s\nInput Table: united states house of representatives elections , 1994\n\n\ndistrictincumbentpartyfirst_electedstatusopponentpennsylvania4ron klinkdemocratic1992-01-01re - electedron klink (d) 64.2% ed peglow (r) 35.8%pennsylvania5william f clinger , jrrepublican1978-01-01re - electedwilliam f clinger , jr (r) unopposedpennsylvania7curt weldonrepublican1986-01-01re - electedcurt weldon (r) 69.7% sara r nichols (d) 30.3%pennsylvania9bud shusterrepublican1972-01-01re - electedbud shuster (r) unopposedpennsylvania12john murthademocratic1974-01-01re - electedjohn murtha (d) 68.9% bill choby (r) 31.1%pennsylvania17george gekasrepublican1982-01-01re - electedgeorge gekas (r) unopposedpennsylvania18rick santorumrepublican1990-01-01retired to run for us senate democratic gainmichael f doyle (d) 54.8% john mccarty (r) 45.2%pennsylvania19william f goodlingrepublican1974-01-01re - electedwilliam f goodling (r) unopposed\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 1 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE first_elected LIKE '198%' \nAND district = 'pennsylvania17';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-304.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the score was 2 - 3 when the away team was liverpool on the date of 30 / 01 / 1991\nInput Table: 1990 - 91 fa cup\n\n\ntie_nohome_teamscoreaway_teamdate1liverpool2 - 2brighton & hove albion1991-01-26replaybrighton & hove albion2 - 3liverpool1991-01-302notts county2 - 0oldham athletic1991-01-263crewe alexandra1 - 0rotherham united1991-01-264luton town1 - 1west ham united1991-01-26replaywest ham united5 - 0luton town1991-01-305woking0 - 1everton1991-01-276shrewsbury town1 - 0wimbledon1991-01-267newcastle united2 - 2nottingham forest1991-02-13replaynottingham forest3 - 0newcastle united1991-02-188tottenham hotspur4 - 2oxford united1991-01-269coventry city1 - 1southampton1991-01-26replaysouthampton2 - 0coventry city1991-01-2910portsmouth5 - 1bournemouth1991-01-2611manchester united1 - 0bolton wanderers1991-01-2612norwich city3 - 1swindon town1991-01-2613millwall4 - 4sheffield wednesday1991-01-26replaysheffield wednesday2 - 0millwall1991-01-3014port vale1 - 2manchester city1991-01-2615arsenal0 - 0leeds united1991-01-27replayleeds united1 - 1arsenal1991-01-30replayarsenal0 - 0leeds united1991-02-13replayleeds united1 - 2arsenal1991-02-1616cambridge united2 - 0middlesbrough1991-01-26\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT score FROM table_sql WHERE away_team = 'liverpool' AND date = '1991-01-30') = '2 - 3' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1735.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the week 1 game had an attendance of 62936\nInput Table: 1970 new york giants season\n\n\nweekdateopponentresultgame_siteattendance11970-09-19chicago bearsl 24 - 16yankee stadium6293621970-09-27dallas cowboysl 28 - 10cotton bowl5723631970-10-04new orleans saintsl 14 - 10tulane stadium6912641970-10-11philadelphia eaglesw 30 - 23yankee stadium6282051970-10-18boston patriotsw 16 - 0harvard stadium3909161970-10-25st louis cardinalsw 35 - 17yankee stadium6298471970-11-01new york jetsw 22 - 10shea stadium6390381970-11-08dallas cowboysw 23 - 20yankee stadium6293891970-11-15washington redskinsw 35 - 33yankee stadium62915101970-11-23philadelphia eaglesl 23 - 20franklin field59117111970-11-29washington redskinsw 27 - 24robert f kennedy memorial stadium50415121970-12-06buffalo billsw 20 - 6yankee stadium62870131970-12-13st louis cardinalsw 34 - 17busch memorial stadium50845141970-12-20los angeles ramsl 31 - 3yankee stadium62870\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE week = 1 \nAND attendance = 62936;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1304.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: on january 7th 2003 , the attendance was 62740\nInput Table: 2002 - 03 manchester united f.c. season\n\n\ndateroundopponentsresult_f_-_aattendance2002-11-05round 3leicester city2 - 0478482002-12-03round 4burnley2 - 0220342002-12-17round 5chelsea1 - 0579852003-01-07semi - final first legblackburn rovers1 - 1627402003-01-22semi - final second legblackburn rovers3 - 1290482003-03-02finalliverpool0 - 274500\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE date = '2003-01-07' \nAND attendance = 62740;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-690.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: paul brown stadium was the stadium that held the game where 65.677 people attended\nInput Table: 2004 cleveland browns season\n\n\nweekdateopponentresultstadiumrecordattendance12004-09-12baltimore ravensw 20 - 3cleveland browns stadium1 - 073068.022004-09-19dallas cowboysl 12 - 19texas stadium1 - 163119.032004-09-26new york giantsl 10 - 27giants stadium1 - 278521.042004-10-03washington redskinsw 17 - 13cleveland browns stadium2 - 273348.052004-10-10pittsburgh steelersl 23 - 34heinz field2 - 363609.062004-10-17cincinnati bengalsw 34 - 17cleveland browns stadium3 - 373263.072004-10-24philadelphia eaglesl 31 - 34cleveland browns stadium3 - 473394.089999-01-01----nan92004-11-07baltimore ravensl 13 - 27m&t bank stadium3 - 569781.0102004-11-14pittsburgh steelersl 10 - 24cleveland browns stadium3 - 673703.0112004-11-21new york jetsl 7 - 10cleveland browns stadium3 - 772547.0122004-11-28cincinnati bengalsl 48 - 58paul brown stadium3 - 865677.0132004-12-05new england patriotsl 15 - 42cleveland browns stadium3 - 973028.0142004-12-12buffalo billsl 7 - 37ralph wilson stadium3 - 1072330.0152004-12-19san diego chargersl 0 - 21cleveland browns stadium3 - 1172489.0162004-12-26miami dolphinsl 7 - 10pro player stadium3 - 1273169.0172005-01-02houston texansw 22 - 14reliant stadium4 - 1270724.0\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN stadium = 'paul brown stadium' AND attendance = 65677.0 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE attendance = 65677.0 \nAND stadium = 'paul brown stadium';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-691.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: 73263 was the attendance of the game on october 17 , 2004\nInput Table: 2004 cleveland browns season\n\n\nweekdateopponentresultstadiumrecordattendance12004-09-12baltimore ravensw 20 - 3cleveland browns stadium1 - 073068.022004-09-19dallas cowboysl 12 - 19texas stadium1 - 163119.032004-09-26new york giantsl 10 - 27giants stadium1 - 278521.042004-10-03washington redskinsw 17 - 13cleveland browns stadium2 - 273348.052004-10-10pittsburgh steelersl 23 - 34heinz field2 - 363609.062004-10-17cincinnati bengalsw 34 - 17cleveland browns stadium3 - 373263.072004-10-24philadelphia eaglesl 31 - 34cleveland browns stadium3 - 473394.089999-01-01----nan92004-11-07baltimore ravensl 13 - 27m&t bank stadium3 - 569781.0102004-11-14pittsburgh steelersl 10 - 24cleveland browns stadium3 - 673703.0112004-11-21new york jetsl 7 - 10cleveland browns stadium3 - 772547.0122004-11-28cincinnati bengalsl 48 - 58paul brown stadium3 - 865677.0132004-12-05new england patriotsl 15 - 42cleveland browns stadium3 - 973028.0142004-12-12buffalo billsl 7 - 37ralph wilson stadium3 - 1072330.0152004-12-19san diego chargersl 0 - 21cleveland browns stadium3 - 1172489.0162004-12-26miami dolphinsl 7 - 10pro player stadium3 - 1273169.0172005-01-02houston texansw 22 - 14reliant stadium4 - 1270724.0\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN attendance = 73263.0 AND date = '2004-10-17' THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE week = 6;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1396.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: only one game was played on november 27\nInput Table: 2009 - 10 temple owls men 's basketball team\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord19999-11-14delawarew 76 - 56ryan brooks - 23lavoy allen - 15juan fernandez - 5bob carpenter center , newark , de (3080)1 - 029999-11-17georgetown (19)l 46 - 45allen - 12allen - 14luiz guzman - 6verizon center , washington , dc (8712)1 - 139999-11-21sienaw 73 - 69fernandez - 20allen - 7allen - 5liacouras center , philadelphia , pa (6759)2 - 149999-11-24ball statew 66 - 46brooks - 17allen - 9allen / brooks - 7liacouras center , philadelphia , pa (3597)3 - 159999-11-27virginia techw 61 - 50allen - 18allen - 10fernandez - 6palestra , philadelphia , pa (3750)4 - 1\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 1 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE date = '9999-11-27';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-895.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the bowler with 13 wickets appeared in more matches than the bowler with 11 wickets\nInput Table: 1948 ashes series\n\n\nplayerteammatcheswicketsaveragebest_bowlingray lindwallaustralia52719.626 / 20bill johnstonaustralia52723.335 / 36alec bedserengland51838.224 / 81keith milleraustralia51323.154 / 125ernie toshackaustralia41133.095 / 40norman yardleyengland5922.662 / 32jim lakerengland3952.444 / 138\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT matches FROM table_sql WHERE wickets = 13) > \n             (SELECT matches FROM table_sql WHERE wickets = 11) \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1320.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there is only 1 instance where robert bauman is the incumbent politician\nInput Table: united states house of representatives elections , 1974\n\n\ndistrictincumbentpartyfirst_electedresultcandidatesmaryland 1robert baumanrepublican1973-01-01re - electedrobert bauman (r) 53.0% thomas j hatem (d) 47.0%maryland 2clarence longdemocratic1962-01-01re - electedclarence long (d) 77.1% john m seney (r) 22.9%maryland 4marjorie holtrepublican1972-01-01re - electedmarjorie holt (r) 58.1% fred l wineland (d) 41.9%maryland 6goodloe byrondemocratic1970-01-01re - electedgoodloe byron (d) 73.7% elton r wampler (r) 26.3%maryland 7parren mitchelldemocratic1970-01-01re - electedparren mitchell (d) unopposed\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 1 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE incumbent = 'robert bauman';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1788.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: alfred j elliott was re - elected to california 's 10th district in 1937\nInput Table: united states house of representatives elections , 1942\n\n\ndistrictincumbentpartyfirst_electedresultcandidatescalifornia 2harry lane englebrightrepublican1926-01-01re - electedharry lane englebright (r) unopposedcalifornia 4thomas rolphrepublican1940-01-01re - electedthomas rolph (r) 98.3% archie brown ( w / i ) 1.7%california 7john h tolandemocratic1934-01-01re - electedjohn h tolan (d) unopposedcalifornia 9bertrand w gearhartrepublican1934-01-01re - electedbertrand w gearhart (r) unopposedcalifornia 10alfred j elliottdemocratic1937-01-01re - electedalfred j elliott (d) unopposedcalifornia 17cecil r kingdemocratic1942-08-25re - electedcecil r king (d) unopposedcalifornia 22none (district created)none (district created)9999-01-01new seat republican gainjohn j phillips (r) 57.6% n e west (d) 42.4%\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE district = 'california 10' \nAND incumbent = 'alfred j elliott' \nAND party = 'democratic' \nAND first_elected = '1937-01-01' \nAND result = 're - elected';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-930.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: when the record was 11 - 35 - 12 , the home team was st louis , and it was against new jersey\nInput Table: none\n\n\ndatevisitorscorehomerecord9999-02-03ny islanders7 - 2new jersey11 - 32 - 119999-02-05new jersey4 - 5washington11 - 33 - 119999-02-06vancouver4 - 4new jersey11 - 33 - 129999-02-09new jersey4 - 5chicago11 - 34 - 1201-02-12new jersey1 - 5st louis11 - 35 - 1201-02-15minnesota3 - 2new jersey11 - 36 - 129999-02-20new jersey0 - 3philadelphia11 - 37 - 1201-02-21buffalo4 - 4new jersey11 - 37 - 139999-02-24detroit1 - 4new jersey12 - 37 - 139999-02-26new jersey4 - 5pittsburgh12 - 38 - 139999-02-27new jersey2 - 6buffalo12 - 39 - 13\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE record = '11 - 35 - 12' \nAND home = 'st louis' \nAND visitor = 'new jersey';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-164.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there are 3 c - 95 aircrafts of brazilian origin currently in service\nInput Table: uruguayan air force\n\n\naircraftorigintypeversionsin_servicecessna a - 37 dragonflyunited statesattack / fightera - 37b12 (16 delivered)fma ia 58 pucar\u00e3\u00a1argentinaattacka - 585 (6 delivered)lockheed c - 130 herculesunited statestransport / utilityc - 130b2embraer emb 110 bandeirantebraziltransport / utilityc - 953beechcraft twin bonanzaunited statestransport / utilityd501casa c - 212 aviocarspaintransportc - 212 - 2002embraer emb 120 brasiliabraziltransportemb 1201cessna 206 stationairunited statesutility / liaisonu206h10beechcraft b58 baronunited statestrainer / liaisonb - 582british aerospace 125united kingdomvip transport700a 600a2aermacchi sf260italytrainert - 260 eu12pilatus pc - 7 turbo trainerswitzerlandtrainer- 925 (6 delivered)cessna t - 41 mescalerounited statestrainert - 41d7aerospatiale as 365 dauphinfranceliaison / transportas 3651bell 212 twin hueyunited statestransport / utilitybell 2124bell uh - 1 iroquoisunited statestransport / utilityuh - 1h13\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE origin = 'brazil' AND type = 'transport / utility' AND versions = 'c - 95' AND in_service >= 3) = 1 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1497.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: construction was completed in 1993 on the flowood site and in 1997 on the newsome brothers / old reichold chemicals project\nInput Table: list of superfund sites in mississippi\n\n\ncerclis_idnamecountyproposedlistedconstruction_completedpartially_deleteddeletedmsd004006995american creosote works , incwinston2001-06-142001-09-139999-01-01--msd008154486chemfax , incharrison1993-06-239999-01-019999-01-01--msd046497012davis timber companylamar2000-05-112000-07-279999-01-01--msd980710941flowood siterankin1983-09-081984-09-211993-09-17-02 / 16 / 1996msd980840045newsom brothers / old reichhold chemicals , incmarion1984-10-151986-06-101997-08-08-09 / 27 / 2000msd065490930picayune wood treatingpearl river2004-03-082004-07-229999-01-01--msd056029648potter cocopiah1993-05-109999-01-019999-01-01--msd086556388sonford productsrankin2006-09-272007-03-079999-01-01--msd980601736walcotte chemical co warehouseswashington9999-01-019999-01-011982-12-30-12 / 30 / 1982\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT construction_completed FROM table_sql WHERE name = 'flowood site') = '1993-09-17' \n             AND (SELECT construction_completed FROM table_sql WHERE name = 'newsom brothers / old reichhold chemicals , inc') = '1997-08-08' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-444.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there were no home teams that scored less than 11\nInput Table: 1938 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddategeelong11.23 (89)hawthorn6.13 (49)corio oval70001938-06-18fitzroy16.12 (108)south melbourne8.8 (56)brunswick street oval120001938-06-18st kilda14.12 (96)melbourne16.16 (112)junction oval140001938-06-18richmond15.14 (104)essendon15.9 (99)punt road oval200001938-06-18footscray13.9 (87)collingwood10.5 (65)western oval180001938-06-18north melbourne11.5 (71)carlton16.25 (121)arden street oval130001938-06-18\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE home_team_score < '11';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-527.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: kardinia park is one of the six venues that were put to use on 3 june , 1961\nInput Table: 1961 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddatenorth melbourne9.14 (68)st kilda11.16 (82)arden street oval130001961-06-03hawthorn10.13 (73)richmond8.12 (60)glenferrie oval150001961-06-03collingwood18.11 (119)essendon8.10 (58)victoria park282901961-06-03geelong13.13 (91)footscray4.14 (38)kardinia park186831961-06-03south melbourne7.8 (50)fitzroy17.15 (117)lake oval145001961-06-03melbourne15.14 (104)carlton11.13 (79)mcg496781961-06-03\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE date = '1961-06-03' \nAND venue = 'kardinia park';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1187.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: alfredo binda was the race leader for 13 races in the 1933 giro d'italia\nInput Table: 1933 giro d'italia\n\n\ndatecoursedistancewinnerrace_leader9999-05-06milan to turin-learco guerra ( ita )learco guerra ( ita )9999-05-07turin to genoa-alfredo binda ( ita )alfredo binda ( ita )9999-05-08genoa to pisa-learco guerra ( ita )alfredo binda ( ita )9999-05-09rest dayrest dayrest dayrest day9999-05-10pisa to florence-giuseppe olmo ( ita )alfredo binda ( ita )9999-05-11florence to grosseto-learco guerra ( ita )jef demuysere ( bel )9999-05-12grosseto to rome-mario cipriani ( ita )jef demuysere ( bel )9999-05-13rest dayrest dayrest dayrest day9999-05-14rome to naples-gerard loncke ( bel )jef demuysere ( bel )9999-05-15naples to foggia-alfredo binda ( ita )alfredo binda ( ita )9999-05-16rest dayrest dayrest dayrest day9999-05-17foggia to chieti-alfredo binda ( ita )alfredo binda ( ita )9999-05-18chieti to ascoli piceno-alfredo binda ( ita )alfredo binda ( ita )9999-05-19rest dayrest dayrest dayrest day9999-05-20ascoli piceno to riccione-fernand cornez ( fra )alfredo binda ( ita )9999-05-21riccione to bologna-giuseppe olmo ( ita )alfredo binda ( ita )9999-05-22bologna to ferrara-alfredo binda ( ita )alfredo binda ( ita )9999-05-23rest dayrest dayrest dayrest day9999-05-24ferrara to udine-ettore meini ( ita )alfredo binda ( ita )9999-05-25udine to bassano del grappa-ettore meini ( ita )alfredo binda ( ita )9999-05-26bassano del grappa to bolzano-gerard loncke ( bel )alfredo binda ( ita )9999-05-27rest dayrest dayrest dayrest day9999-05-28bolzano to milan-alfredo binda ( ita )alfredo binda ( ita )2023-09-20-km (mi)-km (mi)\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 13 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE race_leader = 'alfredo binda ( ita )';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1485.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there was only 1 event in 2011 and it was on 10 - 12 june 2011\nInput Table: tsuyoshi fujita\n\n\nseasonevent_typelocationformatdaterank1997 - 98nationalstokyospecial1998-07-0441998 - 99grand prixkyotolimited1999-01-1641998 - 99apac region championshipsingaporespecial1999-03-2731999 - 00grand prixtaipeiextended2000-02-1222000 - 01grand prixkyotoextended2000-11-1212000 - 01grand prixhiroshimalimited2001-01-2762000 - 01pro tourtokyoblock constructed2001-03-1622001 - 02grand prixhong konglimited2001-11-1732001 - 02masterssan diegostandard2002-01-1172001 - 02grand prixfukuokalimited2002-02-1662001 - 02grand prixnagoyateam limited2002-05-1142002 - 03grand prixutsunomiyalimited2002-10-1232002 - 03grand prixhiroshimaextended2003-01-2572002 - 03grand prixbangkokstandard2003-07-1212003 - 04nationalsosakaspecial2004-06-1112003 - 04grand prixkuala lumpurstandard2004-07-2442005grand prixseattleextended2005-03-0572005invitationallos angelesspecial2005-05-1722005pro tourlondonbooster draft2005-07-0822005pro tourlos angelesextended2005-10-2852011pro tournagoyablock constructed and booster draft2011-06-105\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 1 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE season = '2011' \nAND date >= '2011-06-10' \nAND date <= '2011-06-12';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-845.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: team brazil is the only football club located on the south american continent\nInput Table: list of superleague formula football clubs\n\n\nnofootball_clubcontinentassociated_football_clubseasonsracing_drivers3ac milaneuropeac milan2008 2009 2010robert doornbos giorgio pantano yelmer buurman4ac sparta pragueeuropeac sparta prague2011filip salaquarda5team luxembourgeuropenone2011fr\u00e9d\u00e9ric vervisch6team new zealandoceanianone2011earl bamber7team japanasianone2011duncan tappy8 1 (in 2011)rsc anderlechteuropersc anderlecht2008 2009 2010 2011craig dolby yelmer buurman davide rigon neel jani8team netherlandseuropenone2011robert doornbos10fc basel 1893europefc basel2008 2009 2010max wissel max wissel max wissel12 24 (in 2010)beijing guoanasiabeijing guoan fc2008 2010davide rigon john martin14team brazils americanone2011ant\u00f4nio pizzonia17rangers fceuroperangers fc2008 2009ryan dalziel , james walker john martin24fc midtjyllandeuropefc midtjylland2009kasper andersen24team australiaoceanianone2011john martin31team englandeuropenone2011craig dolby\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 1 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE continent = 's america' \nAND football_club = 'team brazil';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1013.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: melbourne was the away team when the home was st kilda\nInput Table: 2000 ansett australia cup\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scoregroundcrowddateadelaide17.5 (107)melbourne19.11 (125)football park122399999-01-30geelong10.14 (74)st kilda11.12 (78)waverley park73949999-01-30st kilda9.12 (66)melbourne13.14 (92)waverley park105339999-02-05adelaide19.10 (124)geelong15.12 (102)football park113269999-02-06adelaide14.11 (95)st kilda15.12 (102)football park130869999-02-13geelong17.12 (114)melbourne11.16 (82)waverley park495201-14-9999\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE home_team = 'st kilda' \nAND away_team = 'melbourne';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1907.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: two of the teams have the same number of goals scored against them\nInput Table: 1940 in brazilian football\n\n\npositionteampointsplayedagainstdifference1flamengo1381282fluminense13815103corinthians981544palestra it\u00e1lia881935portuguesa7823- 106botafogo682507vasco da gama6819- 28am\u00e9rica6825- 109s\u00e3o paulo4824- 13\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) > 0 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE against IN (\n    SELECT against \n    FROM table_sql \n    GROUP BY against \n    HAVING COUNT(*) > 1\n)\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1734.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the new orleans saints played before week 7 at tulane stadium\nInput Table: 1970 new york giants season\n\n\nweekdateopponentresultgame_siteattendance11970-09-19chicago bearsl 24 - 16yankee stadium6293621970-09-27dallas cowboysl 28 - 10cotton bowl5723631970-10-04new orleans saintsl 14 - 10tulane stadium6912641970-10-11philadelphia eaglesw 30 - 23yankee stadium6282051970-10-18boston patriotsw 16 - 0harvard stadium3909161970-10-25st louis cardinalsw 35 - 17yankee stadium6298471970-11-01new york jetsw 22 - 10shea stadium6390381970-11-08dallas cowboysw 23 - 20yankee stadium6293891970-11-15washington redskinsw 35 - 33yankee stadium62915101970-11-23philadelphia eaglesl 23 - 20franklin field59117111970-11-29washington redskinsw 27 - 24robert f kennedy memorial stadium50415121970-12-06buffalo billsw 20 - 6yankee stadium62870131970-12-13st louis cardinalsw 34 - 17busch memorial stadium50845141970-12-20los angeles ramsl 31 - 3yankee stadium62870\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE week < 7 \nAND opponent = 'new orleans saints' \nAND game_site = 'tulane stadium';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-167.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: with 2 in service by the us , the beechcraft represents the b58 model aircraft\nInput Table: uruguayan air force\n\n\naircraftorigintypeversionsin_servicecessna a - 37 dragonflyunited statesattack / fightera - 37b12 (16 delivered)fma ia 58 pucar\u00e3\u00a1argentinaattacka - 585 (6 delivered)lockheed c - 130 herculesunited statestransport / utilityc - 130b2embraer emb 110 bandeirantebraziltransport / utilityc - 953beechcraft twin bonanzaunited statestransport / utilityd501casa c - 212 aviocarspaintransportc - 212 - 2002embraer emb 120 brasiliabraziltransportemb 1201cessna 206 stationairunited statesutility / liaisonu206h10beechcraft b58 baronunited statestrainer / liaisonb - 582british aerospace 125united kingdomvip transport700a 600a2aermacchi sf260italytrainert - 260 eu12pilatus pc - 7 turbo trainerswitzerlandtrainer- 925 (6 delivered)cessna t - 41 mescalerounited statestrainert - 41d7aerospatiale as 365 dauphinfranceliaison / transportas 3651bell 212 twin hueyunited statestransport / utilitybell 2124bell uh - 1 iroquoisunited statestransport / utilityuh - 1h13\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT in_service FROM table_sql WHERE aircraft = 'beechcraft b58 baron' AND origin = 'united states' AND versions = 'b - 58') = 2 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-905.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: erick walder and bob beamon had the same wind\nInput Table: long jump\n\n\nmarkwindathletenationalityvenuedate8.95 m (29ft4\u00bcin)0.3mike powellunited statestokyo1991-08-308.90 m (29ft2\u00bcin) a2.0bob beamonunited statesmexico city1968-10-188.87 m (29ft1in)0.2carl lewisunited statestokyo1991-08-308.86 m (29ft0\u00bein) a1.9robert emmiyansoviet uniontsakhkadzor1987-05-228.74 m (28ft8in)1.4larry myricksunited statesindianapolis1988-07-188.74 m (28ft8in) a2.0erick walderunited statesel paso1994-04-028.74 m (28ft8in)1.2dwight phillipsunited stateseugene2009-06-078.73 m (28ft7\u00bdin)1.2irving saladinopanamahengelo2008-05-248.71 m (28ft6\u00bein)1.9iv\u00e1n pedrosocubasalamanca1995-07-188.66 m (28ft4\u00bein)1.6lo\u00fais ts\u00e1toumasgreecekalam\u00e1ta2007-06-02\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT wind FROM table_sql WHERE athlete = 'erick walder') = \n             (SELECT wind FROM table_sql WHERE athlete = 'bob beamon') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-797.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: five players are from the united states and canada each\nInput Table: 2004 - 05 philadelphia flyers season\n\n\nroundplayerpositionnationalitycollege_/_junior_/_club_team_(league)3rob bellamyright wingunited statesnew england jr coyotes ( ejhl )4r j andersondefenseunited statescentennial high school (minn)4david laliberteright wingcanadaprince edward island rocket ( qmjhl )5chris zarbdefenseunited statestri - city storm ( ushl )5gino piselliniright wingunited statesplymouth whalers ( ohl )6ladislav scurkocenterslovakiaspi\u0161sk\u00e1 nov\u00e1 ves (slovakia)6frederik cabanacentercanadahalifax mooseheads (qmjhl)8martin houlegoaltendercanadacape breton screaming eagles (qmjhl)8travis gawryletzdefensecanadatrail smoke eaters ( bchl )9triston grantleft wingcanadavancouver giants ( whl )9john cartercenterunited statesbrewster bulldogs (emjhl)\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE nationality = 'united states') = 5 \n             AND (SELECT COUNT(*) FROM table_sql WHERE nationality = 'canada') = 5 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-796.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: except for slovakia , all other countries are from north america\nInput Table: 2004 - 05 philadelphia flyers season\n\n\nroundplayerpositionnationalitycollege_/_junior_/_club_team_(league)3rob bellamyright wingunited statesnew england jr coyotes ( ejhl )4r j andersondefenseunited statescentennial high school (minn)4david laliberteright wingcanadaprince edward island rocket ( qmjhl )5chris zarbdefenseunited statestri - city storm ( ushl )5gino piselliniright wingunited statesplymouth whalers ( ohl )6ladislav scurkocenterslovakiaspi\u0161sk\u00e1 nov\u00e1 ves (slovakia)6frederik cabanacentercanadahalifax mooseheads (qmjhl)8martin houlegoaltendercanadacape breton screaming eagles (qmjhl)8travis gawryletzdefensecanadatrail smoke eaters ( bchl )9triston grantleft wingcanadavancouver giants ( whl )9john cartercenterunited statesbrewster bulldogs (emjhl)\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE nationality != 'slovakia' \nAND nationality NOT LIKE '%canada%' \nAND nationality NOT LIKE '%united states%';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1722.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: chris young was the winning pitcher on june 25th\nInput Table: 2005 texas rangers season\n\n\ndatewinning_teamscorewinning_pitcherlosing_pitcherattendancelocation9999-05-20texas7 - 3kenny rogersbrandon backe38109arlington9999-05-21texas18 - 3chris youngezequiel astacio35781arlington9999-05-22texas2 - 0chan ho parkroy oswalt40583arlington9999-06-24houston5 - 2roy oswaltricardo rodr\u00edguez36199houston9999-06-25texas6 - 5chris youngbrandon backe41868houston\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE date = '9999-06-25' \nAND winning_pitcher = 'chris young';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1766.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: sali berisha was the first person since aleksand\u00ebr meksi , to be elected as a member of the democratic party of albania political party\nInput Table: list of prime ministers of albania\n\n\nnameborn_-_diedterm_startterm_endpolitical_partyprime ministers 1991 onwards1991-01-011991-01-011991-01-01prime ministers 1991 onwardsfatos nano (1st time)9999-01-011991-02-221991-06-05party of labour of albaniaylli bufi9999-01-011991-06-051991-12-10socialist party of albaniavilson ahmeti9999-01-011991-12-101992-04-13non - partyaleksand\u00ebr meksi9999-01-011992-04-131997-03-11democratic party of albaniabashkim fino9999-01-011997-03-111997-07-24socialist party of albaniafatos nano (2nd time)9999-01-011997-07-241998-10-02socialist party of albaniapandeli majko (1st time)9999-01-011998-10-021999-10-29socialist party of albaniailir meta9999-01-011999-10-292002-02-22socialist party of albaniapandeli majko (2nd time)9999-01-012002-02-222002-07-31socialist party of albaniafatos nano (3rd time)9999-01-012002-07-312005-09-11socialist party of albaniasali berisha1944-01-012005-09-112013-09-15democratic party of albaniaedi rama9999-01-012013-09-159999-01-01socialist party of albania\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT name FROM table_sql WHERE political_party = 'democratic party of albania' AND term_start > (SELECT term_start FROM table_sql WHERE name = 'aleksand\u00ebr meksi')) = 'sali berisha' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-908.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the most recent long jump record was set by dwight phillips\nInput Table: long jump\n\n\nmarkwindathletenationalityvenuedate8.95 m (29ft4\u00bcin)0.3mike powellunited statestokyo1991-08-308.90 m (29ft2\u00bcin) a2.0bob beamonunited statesmexico city1968-10-188.87 m (29ft1in)0.2carl lewisunited statestokyo1991-08-308.86 m (29ft0\u00bein) a1.9robert emmiyansoviet uniontsakhkadzor1987-05-228.74 m (28ft8in)1.4larry myricksunited statesindianapolis1988-07-188.74 m (28ft8in) a2.0erick walderunited statesel paso1994-04-028.74 m (28ft8in)1.2dwight phillipsunited stateseugene2009-06-078.73 m (28ft7\u00bdin)1.2irving saladinopanamahengelo2008-05-248.71 m (28ft6\u00bein)1.9iv\u00e1n pedrosocubasalamanca1995-07-188.66 m (28ft4\u00bein)1.6lo\u00fais ts\u00e1toumasgreecekalam\u00e1ta2007-06-02\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MAX(date) FROM table_sql) = '2009-06-07' \n             AND (SELECT athlete FROM table_sql WHERE date = '2009-06-07') = 'dwight phillips' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1799.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: gerardo reinoso was sacked by firpo on august 25th , 2008\nInput Table: primera divisi\u00f3n de f\u00fatbol profesional apertura 2008\n\n\nteamoutgoing_managermanner_of_departuredate_of_vacancyreplaced_bydate_of_appointmentposition_in_tablenejapamauricio cienfuegosmutual consent2008-08-14daniel uberti2008-09-0510thfirpogerardo reinososacked2008-08-25oscar benitez2008-09-027thbalboagustavo de simonesacked2008-08-30roberto gamarra2008-09-0510thalianzapablo centronesacked2008-09-14carlos jurado2008-09-165thfirpooscar ben\u00edtezsacked2008-12-09agust\u00edn castillo2008-12-23post - season (6th)\u00e1guilaagust\u00edn castillosacked2008-12-15pablo centrone2008-12-24post - season (semifinals)fasnelson anchetasacked2008-12-27roberto gamarra2009-01-01post - season (semifinals)nejapadaniel ubertisacked2008-12-29nelson ancheta2008-12-29post - season (10th)balboaroberto gamarramutual consent2009-01-01carlos de toro2009-01-16post - season (7th)\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE team = 'firpo' \nAND outgoing_manager = 'gerardo reinoso' \nAND manner_of_departure = 'sacked' \nAND date_of_vacancy = '2008-08-25';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1467.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: linda fratianne was the winner and anett p\u00f6tzsch was ranked in second place in the 1979 world figure skating championships\nInput Table: 1979 world figure skating championships\n\n\nranknamenationsp_+_fspointsplaces1linda fratianneunited states1186.92112anett p\u00f6tzscheast germany3184.36183emi watanabejapan4180.52314dagmar lurzwest germany6179.96335denise biellmannswitzerland2177.28496lisa - marie allenunited states5176.68547claudia kristofics - binderaustria7175.44638susanna drianoitaly9173.46709carola wei\u00dfenbergeast germany11170.548810kristiina wegeliusfinland15169.269811carrie rughunited states10169.349712sanda dubrav\u010di\u0107yugoslavia8166.9611513natalia strelkovasoviet union16164.9413414deborah cottrillunited kingdom20164.813615karin riedigerwest germany17164.514216renata baierovaczechoslovakia13164.014417petra ernertwest germany14163.2414918kira ivanovasoviet union12164.0214719janet morrisseycanada18162.0416220reiko kobayashijapan21161.317021jeanne chapmannorway19161.816622anita siegfriedswitzerland26150.3420723astrid jansen in de walnetherlands25149.1821624franca bianconiitaly22149.0421825bodil olssonsweden23147.0222526corine wyrschswitzerland27146.7623327kim myo silnorth korea24145.4823728belinda coulthardaustralia28145.9223829katie symmondsnew zealand29134.5826130shin hae sooksouth korea30120.4427031gloria masspain31112.28279\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT rank FROM table_sql WHERE name = 'linda fratianne') = 1 \n             AND (SELECT rank FROM table_sql WHERE name = 'anett p\u00f6tzsch') = 2 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1128.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: among the players in df position , dave sutton has the most league goals\nInput Table: 1979 - 80 huddersfield town f.c. season\n\n\nnamepositionleague_appsleague_goalsfa_cup_appsfa_cup_goalsleague_cup_appsleague_cup_goalstotal_appstotal_goalsjim branagandf00000 (1)00 (1)0malcolm browndf4622041523david cowlingmf39 (1)10104044 (1)10peter fletcherfw30 (8)17203135 (8)18keith hanveydf3320040392peter hartmf4641140515ian holmesmf6 (4)3004110 (4)4steve kindonfw22 (1)14000022 (1)14mick laverickmf4542040514bernard purdiedf18 (4)0200020 (4)0andy rankingk2400000240ian robinsfw452520425127fred robinsondf3012040361tommy smithfw00001010brian stantonmf4192000439alan starlinggk2202040280dave suttondf4662041527chris toppingdf1302000150\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MAX(league_goals) FROM table_sql WHERE position = 'df') = \n             (SELECT league_goals FROM table_sql WHERE name = 'dave sutton' AND position = 'df') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-410.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: pascal fabre started in grid 26 and completed 71 laps\nInput Table: 1987 hungarian grand prix\n\n\ndriverconstructorlapstime_/_retiredgridnelson piquetwilliams - honda761:59:26.7933ayrton sennalotus - honda76+ 37.7276alain prostmclaren - tag76+ 1:27.4564thierry boutsenbenetton - ford75+ 1 lap7riccardo patresebrabham - bmw75+ 1 lap10derek warwickarrows - megatron74+ 2 laps9jonathan palmertyrrell - ford74+ 2 laps16eddie cheeverarrows - megatron74+ 2 laps11philippe streifftyrrell - ford74+ 2 laps14ivan capellimarch - ford74+ 2 laps18alessandro nanniniminardi - motori moderni73+ 3 laps20piercarlo ghinzaniligier - megatron73+ 3 laps25pascal fabreags - ford71+ 5 laps26nigel mansellwilliams - honda70wheel1alex caffiosella - alfa romeo64fuel system21ren\u00e9 arnouxligier - megatron57electrical19philippe alliotlola - ford48accident15martin brundlezakspeed45turbo22michele alboretoferrari43engine5andrea de cesarisbrabham - bmw43gearbox13stefan johanssonmclaren - tag14gearbox8teo fabibenetton - ford14gearbox12adri\u00e1n camposminardi - motori moderni14spun off24gerhard bergerferrari13differential2christian dannerzakspeed3engine23satoru nakajimalotus - honda1drive - shaft17\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT grid FROM table_sql WHERE driver = 'pascal fabre') = 26 \n             AND (SELECT laps FROM table_sql WHERE driver = 'pascal fabre') = 71 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1251.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: china has won 39 more gold medals than iran for wushu at the asian games\nInput Table: wushu at the asian games\n\n\nranknationgoldsilverbronzetotal1china (chn)4373532iran (iri)435123malaysia (mas)31594hong kong (hkg)294155thailand (tha)236116japan (jpn)165127philippines (phi)158148macau (mac)154109south korea (kor)1461110chinese taipei (tpe)13111511myanmar (mya)112412vietnam (vie)0971613indonesia (ina)022414laos (lao)015615india (ind)012316pakistan (pak)011217singapore (sin)005518mongolia (mgl)003319kazakhstan (kaz)002220yemen (yem)0011totaltotal606187208\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT gold FROM table_sql WHERE nation = 'china (chn)') - \n             (SELECT gold FROM table_sql WHERE nation = 'iran (iri)') = 39 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1796.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: zo\u00eb wanamaker plays the character ariadne oliver\nInput Table: list of agatha christie 's poirot episodes\n\n\nactorcharactertitle_/_rankseriesyearsdavid suchethercule poirotvarious1 - 131989 - 2013hugh fraserarthur hastingscaptain obe1 - 8 , 131989 - 2002 , 2013philip jacksonjames jappchief inspector1 - 8 , 131989 - 2001 , 2013pauline moranfelicity lemonsecretary1 - 3 , 5 - 8 , 131989 - 1991 , 1993 - 2001 , 2013zo\u00eb wanamakerariadne olivercrime novelist10 - 132006 - 2013david yellandgeorgebutler10 - 132006 - 2013\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE actor = 'zo\u00eb wanamaker' \nAND character = 'ariadne oliver';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-400.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: asc diaraf lost to stade malien in the 1971 african cup of champions clubs\nInput Table: 1971 african cup of champions clubs\n\n\nteam_1aggteam_21st_leg2nd_legal - merrikh2 - 2 (5 - 4 pen)tele sc asmara9999-01-029999-01-01abaluhya united1 - 3great olympics9999-01-019999-01-01asc diaraf3 - 4stade malien9999-03-019999-01-01maseru united3 - 5mmm tamatave9999-01-029999-02-03as porto novo0 - 3victoria club mokanda9999-01-019999-01-02canon yaound\u00e99 - 4as solidarit\u00e99999-07-039999-01-02esp\u00e9rance1 - 0al - ahly (benghazi)9999-01-019999-01-01secteur 61 - 2enugu rangers9999-01-019999-01-01young africans2 - 0lavori publici9999-01-019999-01-01\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT team_1 FROM table_sql WHERE team_1 = 'asc diaraf' AND team_2 = 'stade malien' AND agg LIKE '%-%') IS NOT NULL \n             AND (SELECT team_2 FROM table_sql WHERE team_1 = 'asc diaraf' AND team_2 = 'stade malien' AND agg LIKE '%-%') IS NOT NULL \n             AND (SELECT agg FROM table_sql WHERE team_1 = 'asc diaraf' AND team_2 = 'stade malien' AND agg LIKE '%-%') LIKE '%3 - 4%' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-929.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: when the record was 11 - 32 - 11 , the score was 7 - 2\nInput Table: none\n\n\ndatevisitorscorehomerecord9999-02-03ny islanders7 - 2new jersey11 - 32 - 119999-02-05new jersey4 - 5washington11 - 33 - 119999-02-06vancouver4 - 4new jersey11 - 33 - 129999-02-09new jersey4 - 5chicago11 - 34 - 1201-02-12new jersey1 - 5st louis11 - 35 - 1201-02-15minnesota3 - 2new jersey11 - 36 - 129999-02-20new jersey0 - 3philadelphia11 - 37 - 1201-02-21buffalo4 - 4new jersey11 - 37 - 139999-02-24detroit1 - 4new jersey12 - 37 - 139999-02-26new jersey4 - 5pittsburgh12 - 38 - 139999-02-27new jersey2 - 6buffalo12 - 39 - 13\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT score FROM table_sql WHERE record = '11 - 32 - 11') = '7 - 2' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-874.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: when the engine was ferrari v12s and the driver was raymond sommer\nInput Table: 1950 swiss grand prix\n\n\ndriverentrantconstructorchassisenginetyrenello paganiscuderia achille varzimaseratimaserati 4clt - 48maserati l4spjohnny claesecurie belgetalbot - lagotalbot - lago t26ctalbot l6dyves giraud - cabantousautomobiles talbot - darracq satalbot - lagotalbot - lago t26c - datalbot l6deug\u00e8ne martinautomobiles talbot - darracq satalbot - lagotalbot - lago t26c - datalbot l6dlouis rosierautomobiles talbot - darracq satalbot - lagotalbot - lago t26c - datalbot l6dluigi fagiolisa alfa romeoalfa romeoalfa romeo 158alfa romeo l8spjuan manuel fangiosa alfa romeoalfa romeoalfa romeo 158alfa romeo l8spnino farinasa alfa romeoalfa romeoalfa romeo 158alfa romeo l8spalberto ascariscuderia ferrariferrariferrari 125ferrari v12spraymond sommerscuderia ferrariferrariferrari 125ferrari v12spluigi villoresiscuderia ferrariferrariferrari 125ferrari v12sppeter whiteheadscuderia ferrariferrariferrari 125ferrari v12splouis chironofficine alfieri maseratimaseratimaserati 4clt - 48maserati l4spfranco rolofficine alfieri maseratimaseratimaserati 4clt - 48maserati l4spprince biraenrico plat\u00e9maseratimaserati 4clt - 48maserati l4sptoulo de graffenriedenrico plat\u00e9maseratimaserati 4clt - 48maserati l4spfelice bonettoscuderia milanomaseratimaserati milano 4clt - 50maserati l4spreg parnellscuderia ambrosianamaseratimaserati 4clt - 48maserati l4sdrudi fischerecurie espadonsva - fiatsva 1500fiat l4sptoni brancaprivatemaseratimaserati 4clmaserati l4spphilippe \u00e9tancelinprivatetalbot - lagotalbot - lago t26ctalbot l6dharry schellecurie bleuetalbot - lagotalbot - lago t26ctalbot l6d\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE engine = 'ferrari v12s' \nAND driver = 'raymond sommer';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-922.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: mike mussina got the win in the september 25th game against the orioles\nInput Table: 1997 toronto blue jays season\n\n\ndateopponentscorelossattendancerecord9999-09-01mets3 - 0hentgen (14 - 9)1919665 - 719999-09-02mets8 - 5clemens (20 - 5)1763565 - 729999-09-03mets4 - 2quantrill (6 - 6)1451365 - 739999-09-04rangers6 - 2carpenter (1 - 7)2617865 - 749999-09-05rangers5 - 1pavlik (2 - 4)2712166 - 749999-09-06rangers2 - 1burkett (7 - 12)3123267 - 749999-09-07rangers4 - 0oliver (11 - 11)3021268 - 749999-09-08angels12 - 10james (4 - 5)2577569 - 749999-09-09angels2 - 0hill (7 - 12)2567470 - 749999-09-10athletics3 - 2plesac (1 - 4)476470 - 759999-09-11athletics8 - 7escobar (2 - 1)613570 - 769999-09-12mariners7 - 3clemens (21 - 6)3704470 - 779999-09-13mariners6 - 3ayala (10 - 5)5163171 - 779999-09-14mariners3 - 2risley (0 - 1)4547771 - 789999-09-15mariners7 - 3williams (8 - 14)4168471 - 799999-09-17red sox4 - 3quantrill (6 - 7)2364871 - 809999-09-18red sox3 - 2escobar (3 - 2)2799071 - 819999-09-19yankees3 - 0gooden (8 - 5)3119572 - 819999-09-20yankees4 - 3 (11)janzen (1 - 1)3833272 - 829999-09-21yankees5 - 4 (10)almanzar (0 - 1)4003872 - 839999-09-22yankees8 - 1hentgen (15 - 10)2338072 - 849999-09-23orioles3 - 2clemens (21 - 7)2927672 - 859999-09-24orioles9 - 3daal (1 - 1)2744372 - 869999-09-25orioles4 - 3mussina (15 - 8)2832473 - 869999-09-26red sox3 - 0henry (7 - 3)3415574 - 869999-09-27red sox12 - 5corsi (5 - 3)3740175 - 869999-09-28red sox3 - 2gordon (6 - 10)4025176 - 86\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE date = '9999-09-25' \nAND opponent = 'orioles' \nAND loss LIKE '%mussina%' \nAND score LIKE '%4 - 3%';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-744.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the yugoslavian national team won both of its friendlies matches by a score of 2:1\nInput Table: yugoslavia national football team results\n\n\ndatecityopponentresultstype_of_game9999-03-22sarajevouruguay2:1friendly9999-03-30belgraderomania2:0balkan cup9999-04-26borovopoland2:1friendly9999-08-27bucharest , romaniaromania1:4balkan cup9999-09-10luxembourgluxembourg5:01982 wcq9999-09-27ljubljanadenmark2:11982 wcq9999-11-15torino , italyitaly0:21982 wcq\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 2 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE type_of_game = 'friendly' \nAND results = '2:1';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1829.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the date of vacancy when the position in the table is 10th and the manner of departure was resigned is 28 february 2011\nInput Table: 2010 - 11 primeira liga\n\n\nteamoutgoing_head_coachmanner_of_departuredate_of_vacancyposition_in_tableincoming_head_coachdate_of_appointmentuni\u00e3o de leirialito vidigalsacked2010-07-07off - seasonpedro caixinha2010-07-10mar\u00edtimomitchell van der gaagsacked2010-09-1415thpedro martins2010-09-14naval 1 de maiovictor zvunkasacked2010-09-2714throg\u00e9rio gon\u00e7alves2010-10-06acad\u00e9micajorge costaresigned2010-12-219thjos\u00e9 guilherme2010-12-27naval 1 de maiorog\u00e9rio gon\u00e7alvessacked2010-12-1916thcarlos mozer2010-12-30portimonenselitossacked2011-12-2816thcarlos azenha2010-12-29acad\u00e9micajos\u00e9 guilhermeresigned2011-02-2013thulisses morais2011-02-22sportingpaulo s\u00e9rgioresigned2011-02-263rdjos\u00e9 couceiro2011-02-26beira - marleonardo jardimresigned2011-02-2810thrui bento2011-03-01vit\u00f3ria de set\u00fabalmanuel fernandessacked2011-03-0114thbruno ribeiro2011-03-01\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE position_in_table = '10th' \nAND manner_of_departure = 'resigned' \nAND date_of_vacancy = '2011-02-28';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-907.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: bob beamon is the athlete who set his long jump record the longest time ago\nInput Table: long jump\n\n\nmarkwindathletenationalityvenuedate8.95 m (29ft4\u00bcin)0.3mike powellunited statestokyo1991-08-308.90 m (29ft2\u00bcin) a2.0bob beamonunited statesmexico city1968-10-188.87 m (29ft1in)0.2carl lewisunited statestokyo1991-08-308.86 m (29ft0\u00bein) a1.9robert emmiyansoviet uniontsakhkadzor1987-05-228.74 m (28ft8in)1.4larry myricksunited statesindianapolis1988-07-188.74 m (28ft8in) a2.0erick walderunited statesel paso1994-04-028.74 m (28ft8in)1.2dwight phillipsunited stateseugene2009-06-078.73 m (28ft7\u00bdin)1.2irving saladinopanamahengelo2008-05-248.71 m (28ft6\u00bein)1.9iv\u00e1n pedrosocubasalamanca1995-07-188.66 m (28ft4\u00bein)1.6lo\u00fais ts\u00e1toumasgreecekalam\u00e1ta2007-06-02\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN MIN(date) = (SELECT MIN(date) FROM table_sql) THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE athlete = 'bob beamon';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1188.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: alfredo binda won six races of the 1933 giro d'italia , but he was the race leader for 13 races\nInput Table: 1933 giro d'italia\n\n\ndatecoursedistancewinnerrace_leader9999-05-06milan to turin-learco guerra ( ita )learco guerra ( ita )9999-05-07turin to genoa-alfredo binda ( ita )alfredo binda ( ita )9999-05-08genoa to pisa-learco guerra ( ita )alfredo binda ( ita )9999-05-09rest dayrest dayrest dayrest day9999-05-10pisa to florence-giuseppe olmo ( ita )alfredo binda ( ita )9999-05-11florence to grosseto-learco guerra ( ita )jef demuysere ( bel )9999-05-12grosseto to rome-mario cipriani ( ita )jef demuysere ( bel )9999-05-13rest dayrest dayrest dayrest day9999-05-14rome to naples-gerard loncke ( bel )jef demuysere ( bel )9999-05-15naples to foggia-alfredo binda ( ita )alfredo binda ( ita )9999-05-16rest dayrest dayrest dayrest day9999-05-17foggia to chieti-alfredo binda ( ita )alfredo binda ( ita )9999-05-18chieti to ascoli piceno-alfredo binda ( ita )alfredo binda ( ita )9999-05-19rest dayrest dayrest dayrest day9999-05-20ascoli piceno to riccione-fernand cornez ( fra )alfredo binda ( ita )9999-05-21riccione to bologna-giuseppe olmo ( ita )alfredo binda ( ita )9999-05-22bologna to ferrara-alfredo binda ( ita )alfredo binda ( ita )9999-05-23rest dayrest dayrest dayrest day9999-05-24ferrara to udine-ettore meini ( ita )alfredo binda ( ita )9999-05-25udine to bassano del grappa-ettore meini ( ita )alfredo binda ( ita )9999-05-26bassano del grappa to bolzano-gerard loncke ( bel )alfredo binda ( ita )9999-05-27rest dayrest dayrest dayrest day9999-05-28bolzano to milan-alfredo binda ( ita )alfredo binda ( ita )2023-09-20-km (mi)-km (mi)\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE winner = 'alfredo binda ( ita )') = 6 \n             AND (SELECT COUNT(*) FROM table_sql WHERE race_leader = 'alfredo binda ( ita )') = 13 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-359.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: 2 players were picked during the 2nd round of the draft\nInput Table: indianapolis colts draft history\n\n\nroundpickoverallnamepositioncollege155curtis dickeyrunning backtexas a&m12424derrick hatchettcornerbacktexas2432ray donaldsoncentergeorgia22351tim foleyoffensive tacklenotre dame4588ray butlerwide receiverusc66144chris footecenterusc75170wes robertsdefensive endtcu82195ken walteroffensive tackletexas tech96227mark brightrunning backtemple105254larry stewartoffensive tacklemaryland113280ed whitleytight endkansas state126311randy bielskiplacekickertowson1219324marvin simsfullbackclemson\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 2 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE round = 2;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1151.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: gaming alerts asked for 200000\nInput Table: dragons' den (uk)\n\n\nepisodefirst_airedentrepreneur_(s)company_or_product_namemoney_requestedinvesting_dragon_(s)episode 12007-10-15celia norowzian & ian forshewbeach break live50000peter jonesepisode 12007-10-15laban roomesgoldgenie (formerly midas touch)60000james caanepisode 22007-10-22sarah luyoudoodoll35000deborah meadenepisode 22007-10-22emmie matthews & ed stevensgaming alerts200000theo paphitisepisode 32007-10-29mark champkinsconcentrate design100000peter jonesepisode 42007-11-05max mcmurdoreestore50000deborah meaden & theo paphitisepisode 42007-11-05jamie jenkinsoncush'n 'shade100000deborah meaden & peter jonesepisode 52007-11-19shane lake and tony charleshungryhousecouk100000james caan & duncan bannatyneepisode 62007-11-26ian helmoresteri spray145000deborah meaden & theo paphitisepisode 62007-11-26mark and eleanor daviscaribbean ready meals100000james caan & duncan bannatyneepisode 72007-12-03sammy frenchfit fur life100000james caanepisode 72007-12-03jerry mantalvanos & paul merkerjpm eco logistics100000deborah meaden & theo paphitisepisode 82007-12-11peter mouleelectroexpo , chocbox150000duncan bannatyne & james caanepisode 92007-12-18amanda jones & james brownred button design50000all five dragons\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT money_requested FROM table_sql WHERE company_or_product_name = 'gaming alerts') = 200000 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1800.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: daniel uberti was sacked on december 29th , 2008 and nelson ancheta was appointed manager the same day\nInput Table: primera divisi\u00f3n de f\u00fatbol profesional apertura 2008\n\n\nteamoutgoing_managermanner_of_departuredate_of_vacancyreplaced_bydate_of_appointmentposition_in_tablenejapamauricio cienfuegosmutual consent2008-08-14daniel uberti2008-09-0510thfirpogerardo reinososacked2008-08-25oscar benitez2008-09-027thbalboagustavo de simonesacked2008-08-30roberto gamarra2008-09-0510thalianzapablo centronesacked2008-09-14carlos jurado2008-09-165thfirpooscar ben\u00edtezsacked2008-12-09agust\u00edn castillo2008-12-23post - season (6th)\u00e1guilaagust\u00edn castillosacked2008-12-15pablo centrone2008-12-24post - season (semifinals)fasnelson anchetasacked2008-12-27roberto gamarra2009-01-01post - season (semifinals)nejapadaniel ubertisacked2008-12-29nelson ancheta2008-12-29post - season (10th)balboaroberto gamarramutual consent2009-01-01carlos de toro2009-01-16post - season (7th)\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT manner_of_departure FROM table_sql WHERE outgoing_manager = 'daniel uberti' AND date_of_vacancy = '2008-12-29') = 'sacked' \n             AND (SELECT date_of_appointment FROM table_sql WHERE replaced_by = 'nelson ancheta' AND date_of_vacancy = '2008-12-29') = '2008-12-29' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-371.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the black knights scored 54 points against lehigh on september 20th raising their record to 2 - 0\nInput Table: 1975 army cadets football team\n\n\ngamedateopponentresultblack_knights_pointsopponentsrecord19999-09-13holy crosswin4471 - 029999-09-20lehighwin54322 - 039999-09-27villanovaloss0102 - 149999-10-04stanfordloss14672 - 259999-10-11dukeloss10212 - 369999-10-18pittsburghloss20522 - 479999-10-25penn stateloss0312 - 589999-11-01air forceloss3332 - 699999-11-08boston collegeloss0312 - 7109999-11-15vanderbiltloss14232 - 8\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT black_knights_points FROM table_sql WHERE game = 2) = 54 \n             AND (SELECT record FROM table_sql WHERE game = 2) = '2 - 0' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1089.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: three episodes have titles beginning with the letter t\nInput Table: list of all that episodes\n\n\nseasonseriesepisode_titleoriginal_air_datenick_prod138tia & tamera mowry / ll cool j1996-11-16338239montell jordan1996-11-23339441dru hill1996-12-07341542tyra banks / blackstreet1996-12-14342643music special1996-12-17343744a tribe called quest1996-12-213448457021996-12-28345946tony! toni! tone!1997-01-043461047chris farley / mint condition1997-01-1134711481121997-01-183481249sherman hemsley / nas1997-01-253491350john leguizamo / mona lisa1997-02-013501451ray j1997-02-083511552for real1997-09-203521653aaliyah1997-10-043531754az yet1997-09-273541855monica1997-10-113551956mc lyte1997-10-18356\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 3 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE episode_title LIKE 't%';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1322.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the result for the voting district of maryland 7 is re - election of the incumbent\nInput Table: united states house of representatives elections , 1974\n\n\ndistrictincumbentpartyfirst_electedresultcandidatesmaryland 1robert baumanrepublican1973-01-01re - electedrobert bauman (r) 53.0% thomas j hatem (d) 47.0%maryland 2clarence longdemocratic1962-01-01re - electedclarence long (d) 77.1% john m seney (r) 22.9%maryland 4marjorie holtrepublican1972-01-01re - electedmarjorie holt (r) 58.1% fred l wineland (d) 41.9%maryland 6goodloe byrondemocratic1970-01-01re - electedgoodloe byron (d) 73.7% elton r wampler (r) 26.3%maryland 7parren mitchelldemocratic1970-01-01re - electedparren mitchell (d) unopposed\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN result = 're - elected' THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE district = 'maryland 7';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-678.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: robert allenby placed t5 with a score of 74 + 70 + 67 = 211\nInput Table: 2002 u.s. open (golf)\n\n\nplaceplayercountryscoreto_par1tiger woodsunited states67 + 68 + 70 = 205- 52sergio garc\u00edaspain68 + 74 + 67 = 209- 1t3jeff maggertunited states69 + 73 + 68 = 210et3phil mickelsonunited states70 + 73 + 67 = 210et5robert allenbyaustralia74 + 70 + 67 = 211+ 1t5p\u00e1draig harringtonireland70 + 68 + 73 = 211+ 1t5billy mayfairunited states69 + 74 + 68 = 211+ 1t8nick faldoengland70 + 76 + 66 = 212+ 2t8justin leonardunited states73 + 71 + 68 = 212+ 2t10tom byrumunited states72 + 72 + 70 = 214+ 4t10davis love iiiunited states71 + 71 + 72 = 214+ 4t10scott mccarronunited states72 + 72 + 70 = 214+ 4\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT place FROM table_sql WHERE player = 'robert allenby' AND score = '74 + 70 + 67 = 211') = 't5' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-788.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: thomas bj\u00f8rn , of denmark , has a score of 68 + 71 + 76 = 215\nInput Table: 1998 open championship\n\n\nplaceplayercountryscoreto_par1brian wattsunited states68 + 69 + 73 = 210et2jim furykunited states70 + 70 + 72 = 212+ 2t2mark o'mearaunited states72 + 68 + 72 = 212+ 2t2jesper parneviksweden68 + 72 + 72 = 212+ 25justin rose (a)england72 + 66 + 75 = 213+ 3t6thomas bj\u00e3rndenmark68 + 71 + 76 = 215+ 5t6brad faxonunited states67 + 74 + 74 = 215+ 5t6john hustonunited states65 + 77 + 73 = 215+ 5t6tiger woodsunited states65 + 73 + 77 = 215+ 5t10david duvalunited states70 + 71 + 75 = 216+ 6t10costantino roccaitaly72 + 74 + 70 = 216+ 6t10raymond russellscotland68 + 73 + 75 = 216+ 6t10katsuyoshi tomorijapan75 + 71 + 70 = 216+ 6\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT score FROM table_sql WHERE player = 'thomas bj\u00e3rn' AND country = 'denmark') = '68 + 71 + 76 = 215' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-39.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there are 5 players that are from the united states\nInput Table: 2006 u.s. open (golf)\n\n\nplaceplayercountryscoreto_par1steve strickerunited states70 + 69 = 139- 12colin montgomeriescotland69 + 71 = 140et3kenneth ferrieengland71 + 70 = 141+ 1t3geoff ogilvyaustralia71 + 70 = 141+ 1t5jim furykunited states70 + 72 = 142+ 2t5p\u00e1draig harringtonireland70 + 72 = 142+ 2t7jason dufnerunited states72 + 71 = 143+ 3t7graeme mcdowellnorthern ireland71 + 72 = 143+ 3t7phil mickelsonunited states70 + 73 = 143+ 3t7arron oberholserunited states75 + 68 = 143+ 3\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 5 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE country = 'united states';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-931.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: when chicago was home , new jersey was the visitor\nInput Table: none\n\n\ndatevisitorscorehomerecord9999-02-03ny islanders7 - 2new jersey11 - 32 - 119999-02-05new jersey4 - 5washington11 - 33 - 119999-02-06vancouver4 - 4new jersey11 - 33 - 129999-02-09new jersey4 - 5chicago11 - 34 - 1201-02-12new jersey1 - 5st louis11 - 35 - 1201-02-15minnesota3 - 2new jersey11 - 36 - 129999-02-20new jersey0 - 3philadelphia11 - 37 - 1201-02-21buffalo4 - 4new jersey11 - 37 - 139999-02-24detroit1 - 4new jersey12 - 37 - 139999-02-26new jersey4 - 5pittsburgh12 - 38 - 139999-02-27new jersey2 - 6buffalo12 - 39 - 13\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) > 0 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE home = 'chicago' \nAND visitor = 'new jersey';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1084.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the low attendance rate of 20066 occurred multiple times\nInput Table: 2003 - 04 detroit red wings season\n\n\ndatevisitorscorehomedecisionattendancerecord0002-01-01detroit4 - 1carolinajoseph1705324 - 12 - 4 - 10001-01-03anaheim1 - 3detroitlegace2006625 - 12 - 4 - 10000-01-05nashville0 - 6detroitjoseph2006626 - 12 - 4 - 10001-01-07boston3 - 0detroitjoseph2006626 - 13 - 4 - 10000-01-10detroit1 - 2bostonjoseph1756526 - 13 - 4 - 29999-01-14chicago2 - 4detroitlegace2006627 - 13 - 4 - 20000-01-16phoenix3 - 3detroitjoseph2006627 - 13 - 5 - 29999-01-19detroit1 - 2san josejoseph1736127 - 14 - 5 - 29999-01-21detroit2 - 2anaheimlegace1717427 - 14 - 6 - 29999-01-22detroit5 - 4los angelesjoseph1811828 - 14 - 6 - 29999-01-24detroit2 - 5phoenixjoseph1901928 - 15 - 6 - 29999-01-26detroit2 - 2dallaslegace1853228 - 15 - 7 - 29999-01-29new jersey2 - 5detroitjoseph2006629 - 15 - 7 - 29999-01-31carolina4 - 4detroitlegace2006630 - 15 - 8 - 2\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) > 1 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE attendance = 20066;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1455.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: during the 1993 new york jets season , the new york jets played eight games at the game site name the meadowlands\nInput Table: 1993 new york jets season\n\n\nweekdateopponentresultgame_siteattendance11993-09-05denver broncosl 26 - 20the meadowlands6813021993-09-12miami dolphinsw 24 - 14joe robbie stadium7031441993-09-26new england patriotsw 45 - 7the meadowlands6483651993-10-03philadelphia eaglesl 35 - 30the meadowlands7259361993-10-10los angeles raidersl 24 - 20los angeles memorial coliseum4162781993-10-24buffalo billsl 19 - 10the meadowlands7154191993-10-31new york giantsw 10 - 6giants stadium71659101993-11-07miami dolphinsw 27 - 10the meadowlands71306111993-11-14indianapolis coltsw 31 - 17rca dome47351121993-11-21cincinnati bengalsw 17 - 12the meadowlands64264131993-11-28new england patriotsw 6 - 0foxboro stadium42810141993-12-05indianapolis coltsl 9 - 6the meadowlands45799151993-12-11washington redskinsw 3 - 0robert f kennedy memorial stadium47970161993-12-18dallas cowboysl 28 - 7the meadowlands73233171993-12-26buffalo billsl 16 - 14rich stadium70817181994-01-02houston oilersl 24 - 0houston astrodome61040\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 8 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE game_site = 'the meadowlands';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1529.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: draft pick number 155 comes from arizona university\nInput Table: 1990 buffalo bills season\n\n\nroundpickplayerpositioncollege116james williamsdefensive backfresno state243carwell gardnerrunning backlouisville370glenn parkerguardarizona4101eddie fullerrunning backlsu6155john niespunterarizona7167brent griffithguardminnesota - duluth7171brent collinslinebackercarson - newman7182fred derigginose tacklesyracuse8209marvcus pattonmiddle linebackerucla9239clarkston hineswide receiverduke10266mike lodishdefensive tackleucla11293al edwardswide receivernorthwestern state , la\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE pick = 155 \nAND college = 'arizona';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1798.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: daniel uberti was sacked by nejapa on december 29th , 2008\nInput Table: primera divisi\u00f3n de f\u00fatbol profesional apertura 2008\n\n\nteamoutgoing_managermanner_of_departuredate_of_vacancyreplaced_bydate_of_appointmentposition_in_tablenejapamauricio cienfuegosmutual consent2008-08-14daniel uberti2008-09-0510thfirpogerardo reinososacked2008-08-25oscar benitez2008-09-027thbalboagustavo de simonesacked2008-08-30roberto gamarra2008-09-0510thalianzapablo centronesacked2008-09-14carlos jurado2008-09-165thfirpooscar ben\u00edtezsacked2008-12-09agust\u00edn castillo2008-12-23post - season (6th)\u00e1guilaagust\u00edn castillosacked2008-12-15pablo centrone2008-12-24post - season (semifinals)fasnelson anchetasacked2008-12-27roberto gamarra2009-01-01post - season (semifinals)nejapadaniel ubertisacked2008-12-29nelson ancheta2008-12-29post - season (10th)balboaroberto gamarramutual consent2009-01-01carlos de toro2009-01-16post - season (7th)\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE team = 'nejapa' \nAND outgoing_manager = 'daniel uberti' \nAND manner_of_departure = 'sacked' \nAND date_of_vacancy = '2008-12-29';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1375.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: iran has an mideast rank of one and a asia rank of 6\nInput Table: list of asian and pacific countries by gdp (ppp)\n\n\nrank_mideastrank_asiarank_worldcountry2011_gdp_(ppp)_billions_of_usd1617iran930.2362923saudi arabia677.66331848united arab emirates261.18941950israel235.44652155qatar181.91262258kuwait150.00272360iraq127.34882666syria107.80392976oman81.005103083yemen63.344113184lebanon61.738123597jordan36.8971337104bahrain30.889\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT rank_mideast FROM table_sql WHERE country = 'iran') = 1 \n             AND (SELECT rank_asia FROM table_sql WHERE country = 'iran') = 6 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-205.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: on june 16th jeff gordon was on hendrick motorsports\nInput Table: pocono 400\n\n\nyeardatedriverteammanufacturerlaps-race_timeaverage_speed_(mph)report1982-01-019999-06-06bobby allisondigard motorsportsbuick200500 (804.672)4:24:08113.579report1983-01-019999-06-12bobby allisondigard motorsportsbuick200500 (804.672)3:53:13128.636report1984-01-019999-06-10cale yarboroughranier - lundychevrolet200500 (804.672)3:37:08138.164report1985-01-019999-06-09bill elliottmelling racingford200500 (804.672)3:35:48138.974report1986-01-019999-06-08tim richmondhendrick motorsportschevrolet200500 (804.672)4:24:50113.279report1987-01-019999-06-14tim richmondhendrick motorsportschevrolet200500 (804.672)4:05:57122.166report1988-01-019999-06-19geoffrey bodinehendrick motorsportschevrolet200500 (804.672)3:58:21126.147report1989-01-019999-06-18terry labontejunior johnson & associatesford200500 (804.672)3:48:27131.32report1990-01-019999-06-17harry gantleo jackson racingoldsmobile200500 (804.672)4:08:25120.6report1991-01-019999-06-16darrell waltripdarwal , incchevrolet200500 (804.672)4:04:34122.666report1992-01-019999-06-14alan kulwickiak racingford200500 (804.672)3:28:18144.023report1993-01-019999-06-13kyle pettysabco racingpontiac200500 (804.672)3:37:23138.005report1994-01-019999-06-12rusty wallacepenske racingford200500 (804.672)3:52:55128.801report1995-01-019999-06-11terry labontehendrick motorsportschevrolet200500 (804.672)3:37:50137.72report1996-01-019999-06-16jeff gordonhendrick motorsportschevrolet200500 (804.672)3:35:40139.104report1997-01-019999-06-08jeff gordonhendrick motorsportschevrolet200500 (804.672)3:34:33139.828report1998-01-019999-06-21jeremy mayfieldpenske racingford200500 (804.672)4:14:39117.809report1999-01-019999-06-20bobby labontejoe gibbs racingpontiac200500 (804.672)4:12:19118.898report2000-01-019999-06-19jeremy mayfieldpenske racingford200500 (804.672)3:34:41139.741report2001-01-019999-06-17ricky ruddrobert yates racingford200500 (804.672)3:43:14134.389report2002-01-019999-06-09dale jarrettrobert yates racingford200500 (804.672)3:29:10143.426report2003-01-019999-06-08tony stewartjoe gibbs racingchevrolet200500 (804.672)3:42:24134.892report2004-01-019999-06-13jimmie johnsonhendrick motorsportschevrolet200500 (804.672)4:27:33112.129report2005-01-019999-06-12carl edwardsroush racingford201502.5 (808.695)3:53:24129.177report2006-01-019999-06-11denny hamlinjoe gibbs racingchevrolet200500 (804.672)3:47:52131.656report2007-01-019999-06-10jeff gordonhendrick motorsportschevrolet106265 (426.476)1:57:15135.608report2008-01-019999-06-08kasey kahnegillett evernham motorsportsdodge200500 (804.672)3:59:36125.209report2009-01-019999-06-07tony stewartstewart - haas racingchevrolet200500 (804.672)3:36:35138.515report2010-01-019999-06-06denny hamlinjoe gibbs racingtoyota204510 (820.765)3:44:30136.303report2011-01-019999-06-12jeff gordonhendrick motorsportschevrolet200500 (804.672)3:26:21145.384report2012-01-019999-06-10joey loganojoe gibbs racingtoyota160400 (643.737)3:03:12131.004report\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE date = '9999-06-16' \nAND driver = 'jeff gordon' \nAND team = 'hendrick motorsports';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1892.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the collingwood electorate was assigned to the nelson province\nInput Table: 3rd new zealand parliament\n\n\nmemberelectorateprovincemps_termelection_datealfred creykeavoncanterburyfirst1861-01-01frederick weldcheviotcanterburythird1861-01-01andrew richmondcollingwoodnelsonfirst1861-04-01isaac cooksonkaiapoicanterburysecond1861-07-01herbert curtismotuekanelsonsecond1861-05-01william foxrangitikiwellingtonsecond1861-04-01alfred saunderswaimeamarlboroughfirst1861-01-01\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE electorate = 'collingwood' \nAND province = 'nelson';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-623.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the fifth rank has a total for bronze at 2 and silver at 1\nInput Table: fivb volleyball world league\n\n\nrankgoldsilverbronzetotal194417283314335715415395112461113710128043790101total24242472\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT bronze FROM table_sql WHERE rank = 5) = 2 \n             AND (SELECT silver FROM table_sql WHERE rank = 5) = 1 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-891.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the teams with 3 losses have 0 ties\nInput Table: 1894 ahac season\n\n\nteamgames_playedwinslossestiesgoals_forgoals_againstmontreal hockey club85302515ottawa hockey club85302416montreal victorias85303620quebec hockey club85302627montreal crystals80801043\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT ties FROM table_sql WHERE losses = 3) = 0 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1787.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: in all elections where the democrat held the seat , the party maintained the office\nInput Table: united states house of representatives elections , 1942\n\n\ndistrictincumbentpartyfirst_electedresultcandidatescalifornia 2harry lane englebrightrepublican1926-01-01re - electedharry lane englebright (r) unopposedcalifornia 4thomas rolphrepublican1940-01-01re - electedthomas rolph (r) 98.3% archie brown ( w / i ) 1.7%california 7john h tolandemocratic1934-01-01re - electedjohn h tolan (d) unopposedcalifornia 9bertrand w gearhartrepublican1934-01-01re - electedbertrand w gearhart (r) unopposedcalifornia 10alfred j elliottdemocratic1937-01-01re - electedalfred j elliott (d) unopposedcalifornia 17cecil r kingdemocratic1942-08-25re - electedcecil r king (d) unopposedcalifornia 22none (district created)none (district created)9999-01-01new seat republican gainjohn j phillips (r) 57.6% n e west (d) 42.4%\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = (SELECT COUNT(*) FROM table_sql WHERE party = 'democratic') \n             AND COUNT(*) = (SELECT COUNT(*) FROM table_sql WHERE party = 'democratic' AND result = 're - elected') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE party = 'democratic' \nAND result = 're - elected';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-954.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: on april 17 the home team was the chicago black hawks and the record was 2 - 3\nInput Table: 1965 - 66 chicago black hawks season\n\n\ndatevisitorscorehomerecord'9999-04-07'detroit red wings1 - 2chicago black hawks1 - 0'9999-04-10'detroit red wings7 - 0chicago black hawks1 - 1'9999-04-12'chicago black hawks2 - 1detroit red wings2 - 19999-04-14chicago black hawks1 - 5detroit red wings2 - 20000-04-17detroit red wings5 - 3chicago black hawks2 - 39999-04-19chicago black hawks2 - 3detroit red wings2 - 4\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE date = '0000-04-17' \nAND home = 'chicago black hawks' \nAND record = '2 - 3';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1683.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there were 80079 people in attendance when alabama was the opponent\nInput Table: east carolina pirates football , 1990 - 99\n\n\ndateopponentsiteresultattendance9999-09-05virginia techlane stadium blacksburg , val3 - 38481349999-09-12chattanoogadowdy - ficklen stadium greenville , ncw31 - 0340289999-09-19ohiopeden stadium athens , ohw21 - 14191869999-10-03armydowdy - ficklen stadium greenville , ncw30 - 25406079999-10-10uabdowdy - ficklen stadium greenville , ncw26 - 7310029999-10-17alabamalegion field birmingham , all22 - 23800799999-10-24southern missmm roberts stadium hattiesburg , msl7 - 41240209999-10-31houstondowdy - ficklen stadium greenville , ncl31 - 34268219999-11-05cincinnatinippert stadium cincinnati , ohw24 - 21190989999-11-14louisvilledowdy - ficklen stadium greenville , ncl45 - 63262589999-11-21memphisliberty bowl memorial stadium memphis , tnw34 - 31160529999-01-01all times are in easternall times are in easternall times are in easternall times are in eastern\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN attendance = 80079 AND opponent = 'alabama' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE date = '9999-10-17';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-973.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: cooperstown has a pratt through truss type bridge\nInput Table: list of bridges on the national register of historic places in north dakota\n\n\nnamelistedlocationcountytypebeaver creek bridge1997-02-27finleysteelepratt through trusscaledonia bridge1997-02-27caledoniatraillpratt through trusscedar creek bridge1997-02-27haynesadamspratt through trusscolton 's crossing bridge1997-02-27lisbonransompratt through trusscrystal bridge1997-05-30crystalpembinaconcrete t - beam bridgeeastwood park bridge1975-04-21minotwardcantilever typeelliott bridge1997-02-27townermchenrypratt through trussfairview lift bridge1997-03-14cartwrightmckenzierailroad lift bridgegrace city bridge1997-02-27grace cityfosterpratt through trussgreat northern railway underpass1997-02-27stanleymountrailconcrete deck girder bridgeknife river bridge near stanton2001-04-25stantonmercerpratt through trusslisbon bridge1997-02-27lisbonransomsteel cantilever bean bridgemidland continental overpass1997-02-27jamestownstutsmansteel cantilever beam bridgemidway bridge1997-02-27johnstowngrand forkswarren bedstead bridgenesheim bridge1997-02-27mcvillenelsonpratt through trussnew rockford bridge1997-03-13new rockford closed to trafficeddywarren through truss bridgenorthwood bridge1997-02-27northwoodgrand forkspratt pony trussnorway bridge1997-02-27mayvilletraillpratt pony trussost valle bridge1997-02-27thompsongrand forkspratt through trussromness bridge1997-02-27cooperstowngriggspratt through trusssorlie memorial bridge1999-07-19grand forksgrand forksparker through truss bridgeviking bridge1997-02-27portlandtraillpratt through trusswest antelope bridge1997-02-27florabensonpratt pony truss bridgewest park bridge1997-02-27valley citybarnesconcrete false arch bridgewestgaard bridge1997-02-27voltairemchenrypratt pony through trussblanchard bridge1997-02-27blanchardtraillpratt through trussgoose river bridge1997-02-27hillsborotraillpratt through trussliberty memorial bridge1997-03-11 removed 2009-03-25bismarckburleighwarren - turner through trussporter elliott bridge1997-02-27hillsborotraillwarren through trussportland park bridge2004-09-23portlandtraillsteel through girderrainbow arch bridge2004-09-23valley citybarnesmarsh rainbow arch\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE location = 'cooperstown' \nAND type = 'pratt through truss';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1930.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: mark cavendish is the only person to win two consecutive stages\nInput Table: 2010 vuelta a espa\u00f1a\n\n\nstagewinnergeneral_classificationpoints_classificationmountains_classificationcombination_classificationteam_classification1team htc - columbiamark cavendishmark cavendish 1not awardedmark cavendishteam htc - columbia2yauheni hutarovichmark cavendishyauheni hutarovichmicka\u00ebl delagejavier ram\u00edrezteam htc - columbia3philippe gilbertphilippe gilbertphilippe gilbertseraf\u00edn mart\u00ednezseraf\u00edn mart\u00ednezteam htc - columbia4igor ant\u00f3nphilippe gilbertigor ant\u00f3nseraf\u00edn mart\u00ednezvincenzo nibalicaisse d'epargne5tyler farrarphilippe gilbertigor ant\u00f3nseraf\u00edn mart\u00ednezvincenzo nibalicaisse d'epargne6thor hushovdphilippe gilbertphilippe gilbertseraf\u00edn mart\u00ednezphilippe gilbertcaisse d'epargne7alessandro petacchiphilippe gilbertmark cavendishseraf\u00edn mart\u00ednezphilippe gilbertcaisse d'epargne8david moncouti\u00e9igor ant\u00f3nmark cavendishseraf\u00edn mart\u00ednezvincenzo nibalicaisse d'epargne9david l\u00f3pezigor ant\u00f3nmark cavendishdavid moncouti\u00e9vincenzo nibalicaisse d'epargne10imanol ervitijoaquim rodr\u00edguezmark cavendishdavid moncouti\u00e9david moncouti\u00e9caisse d'epargne11igor ant\u00f3nigor ant\u00f3nigor ant\u00f3ndavid moncouti\u00e9igor ant\u00f3ncaisse d'epargne12mark cavendishigor ant\u00f3nmark cavendishdavid moncouti\u00e9igor ant\u00f3ncaisse d'epargne13mark cavendishigor ant\u00f3nmark cavendishdavid moncouti\u00e9igor ant\u00f3ncaisse d'epargne14joaquim rodr\u00edguezvincenzo nibalimark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezcaisse d'epargne15carlos barredovincenzo nibalimark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezteam katusha16mikel nievejoaquim rodr\u00edguezmark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezteam katusha17peter velitsvincenzo nibalimark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezteam katusha18mark cavendishvincenzo nibalimark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezteam katusha19philippe gilbertvincenzo nibalimark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezteam katusha20ezequiel mosquera 2vincenzo nibalimark cavendishdavid moncouti\u00e9vincenzo nibaliteam katusha21tyler farrarvincenzo nibalimark cavendishdavid moncouti\u00e9vincenzo nibaliteam katusha\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 1 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE winner = 'mark cavendish' \nAND stage = (SELECT stage + 1 FROM table_sql WHERE winner = 'mark cavendish')\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1086.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: ryan hunter - reay and jimmy vasser both had fewer than two points and grids larger than 4 , and were on the american spirit team johansson team\nInput Table: 2003 tecate telmex monterrey grand prix\n\n\ndriverteamlapstime_/_retiredgridpointspaul tracyteam player 's852:03:04.677222michel jourdain , jrteam rahal85+ 2.0 secs516alex taglianirocketsports racing3+ 12.0 secs314adrian fern\u00e1ndezfern\u00e1ndez racing85+ 14.2 secs612bruno junqueiranewman / haas racing85+ 14.9 secs710roberto morenoherdez competition85+ 30.9 secs148darren manningwalker racing85+ 35.2 secs136patrick carpentierteam player 's84+ 1 lap155alex yoongdale coyne racing84+ 1 lap174patrick lemari\u00e9pk racing84+ 1 lap123jo\u00ebl camathiasdale coyne racing84+ 1 lap192ryan hunter - reayamerican spirit team johansson83+ 2 laps91mario dom\u00ednguezherdez competition83+ 2 laps80jimmy vasseramerican spirit team johansson83+ 2 laps160rodolfo lav\u00ednwalker racing81+ 4 laps180mario haberfeldmi - jack conquest racing67contact110s\u00e9bastien bourdaisnewman / haas racing40contact11oriol servi\u00e0patrick racing38contact40tiago monteirofittipaldi - dingman racing2mechanical100\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE points < 2 AND grid > 4 AND team = 'american spirit team johansson' AND (driver = 'ryan hunter - reay' OR driver = 'jimmy vasser')) > 0 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-45.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: brian finch rank is greater than 3 and he finished with a time of 2:14.59.0\nInput Table: 1970 isle of man tt\n\n\nrankriderteamspeedtime1frank whitewaysuzuki89.94 mph2:05.52.02gordon pantalltriumph88.90 mph2:07.20.03ray knighttriumph88.89 mph2:07.20.44rbaylietriumph87.58 mph2:09.15.05graham pennytriumph86.70 mph2:10.34.46jwadesuzuki85.31 mph2:12.42.07brian finchvelocette83.86 mph2:14.59.0\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN rank > 3 AND time = '2:14.59.0' THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE rider = 'brian finch';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1567.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: ben curtis , j b holmes , steve flesch , and david toms are from the united states\nInput Table: 2008 pga championship\n\n\nplaceplayercountryscoreto_par1ben curtisunited states73 + 67 + 68 = 208- 2t2j b holmesunited states71 + 68 + 70 = 209- 1t2henrik stensonsweden71 + 70 + 68 = 209- 1t4sergio garc\u00edaspain69 + 73 + 69 = 211+ 1t4p\u00e1draig harringtonireland71 + 74 + 66 = 211+ 1t4charlie wisouth korea70 + 70 + 71 = 211+ 1t7andr\u00e9s romeroargentina69 + 78 + 65 = 212+ 2t7jeev milkha singhindia68 + 74 + 70 = 212+ 2t9aaron baddeleyaustralia71 + 71 + 71 = 213+ 3t9steve fleschunited states73 + 70 + 70 = 213+ 3t9david tomsunited states72 + 69 + 72 = 213+ 3t9camilo villegascolombia74 + 72 = 67 = 213+ 3\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 4 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE country = 'united states' \nAND player IN ('ben curtis', 'j b holmes', 'steve flesch', 'david toms');\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1826.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: at punt road oval , melbourne was richmond 's away team opponent\nInput Table: 1943 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddatehawthorn13.10 (88)south melbourne7.14 (56)glenferrie oval150001943-08-21collingwood16.17 (113)fitzroy9.9 (63)victoria park65001943-08-21carlton15.23 (113)north melbourne7.5 (47)princes park80001943-08-21richmond15.19 (109)melbourne12.13 (85)punt road oval90001943-08-21footscray9.10 (64)essendon6.15 (51)western oval60001943-08-21\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE venue = 'punt road oval' \nAND home_team = 'richmond' \nAND away_team = 'melbourne';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1315.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the incumbent for maryland district 6 was goodloe byron , and he was re - elected over candidate elton r wampler (r)\nInput Table: united states house of representatives elections , 1974\n\n\ndistrictincumbentpartyfirst_electedresultcandidatesmaryland 1robert baumanrepublican1973-01-01re - electedrobert bauman (r) 53.0% thomas j hatem (d) 47.0%maryland 2clarence longdemocratic1962-01-01re - electedclarence long (d) 77.1% john m seney (r) 22.9%maryland 4marjorie holtrepublican1972-01-01re - electedmarjorie holt (r) 58.1% fred l wineland (d) 41.9%maryland 6goodloe byrondemocratic1970-01-01re - electedgoodloe byron (d) 73.7% elton r wampler (r) 26.3%maryland 7parren mitchelldemocratic1970-01-01re - electedparren mitchell (d) unopposed\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT incumbent FROM table_sql WHERE district = 'maryland 6') = 'goodloe byron' \n             AND (SELECT result FROM table_sql WHERE district = 'maryland 6') = 're - elected' \n             AND (SELECT candidates FROM table_sql WHERE district = 'maryland 6') LIKE '%elton r wampler (r)%' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-942.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: diego milito debuted in 2008 and had 86 goals\nInput Table: football records in italy\n\n\nrankall_-_time_ranknamedebut_yearcurrent_clubgoalsapps12francesco totti1992-01-01roma230543211antonio di natale2002-01-01udinese180368316alberto gilardino1999-01-01genoa164425453luca toni2000-01-01verona114258577antonio cassano1999-01-01parma99334681giampaolo pazzini2004-01-01milan95275681mirko vu\u010dini\u01072000-01-01juventus95298897diego milito2008-01-01inter86145897sergio pellissier2002-01-01chievo8633310n / aamauri2000-01-01parma76292\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT debut_year FROM table_sql WHERE name = 'diego milito') = '2008-01-01' \n             AND (SELECT goals FROM table_sql WHERE name = 'diego milito') = 86 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1785.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the candidates were john j phillips (r) 57.6% vs n e west (d) 42.4%\nInput Table: united states house of representatives elections , 1942\n\n\ndistrictincumbentpartyfirst_electedresultcandidatescalifornia 2harry lane englebrightrepublican1926-01-01re - electedharry lane englebright (r) unopposedcalifornia 4thomas rolphrepublican1940-01-01re - electedthomas rolph (r) 98.3% archie brown ( w / i ) 1.7%california 7john h tolandemocratic1934-01-01re - electedjohn h tolan (d) unopposedcalifornia 9bertrand w gearhartrepublican1934-01-01re - electedbertrand w gearhart (r) unopposedcalifornia 10alfred j elliottdemocratic1937-01-01re - electedalfred j elliott (d) unopposedcalifornia 17cecil r kingdemocratic1942-08-25re - electedcecil r king (d) unopposedcalifornia 22none (district created)none (district created)9999-01-01new seat republican gainjohn j phillips (r) 57.6% n e west (d) 42.4%\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT candidates FROM table_sql WHERE district = 'california 22') = 'john j phillips (r) 57.6% n e west (d) 42.4%' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1184.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: when set 3 was 18 - 25 , the total was 53 - 75\nInput Table: 2002 fivb women 's volleyball world championship qualification\n\n\ndatescoreset_1set_2set_3total9999-07-130 - 39 - 2517 - 2512 - 2538 - 759999-07-133 - 025 - 2325 - 1025 - 1375 - 469999-07-143 - 025 - 1325 - 1025 - 1175 - 349999-07-141 - 325 - 2216 - 2515 - 2570 - 979999-07-150 - 316 - 2519 - 2518 - 2553 - 759999-07-153 - 025 - 2325 - 1625 - 1475 - 53\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT total FROM table_sql WHERE set_3 = '18 - 25') = '53 - 75' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-139.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the nation of croatia won 3 medals all together , 2 of which were silver\nInput Table: 2003 world taekwondo championships\n\n\nranknationgoldsilverbronzetotal1south korea802102iran22153chinese taipei20134united states12365spain11356china11137greece10238croatia02139france020210germany012311canada011211denmark011113cuba010113great britain010113mexico010116azerbaijan004417thailand002218australia001118austria001118belarus001118kazakhstan001118morocco001118philippines001118turkey001118venezuela0011totaltotal16163264\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT silver FROM table_sql WHERE nation = 'croatia') = 2 \n             AND (SELECT total FROM table_sql WHERE nation = 'croatia') = 3 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1569.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: j b holmes from the united states and henrik stenson from sweden tied for second place with - 1 to par\nInput Table: 2008 pga championship\n\n\nplaceplayercountryscoreto_par1ben curtisunited states73 + 67 + 68 = 208- 2t2j b holmesunited states71 + 68 + 70 = 209- 1t2henrik stensonsweden71 + 70 + 68 = 209- 1t4sergio garc\u00edaspain69 + 73 + 69 = 211+ 1t4p\u00e1draig harringtonireland71 + 74 + 66 = 211+ 1t4charlie wisouth korea70 + 70 + 71 = 211+ 1t7andr\u00e9s romeroargentina69 + 78 + 65 = 212+ 2t7jeev milkha singhindia68 + 74 + 70 = 212+ 2t9aaron baddeleyaustralia71 + 71 + 71 = 213+ 3t9steve fleschunited states73 + 70 + 70 = 213+ 3t9david tomsunited states72 + 69 + 72 = 213+ 3t9camilo villegascolombia74 + 72 = 67 = 213+ 3\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT place FROM table_sql WHERE player = 'j b holmes' AND country = 'united states' AND to_par = '- 1') = \n             (SELECT place FROM table_sql WHERE player = 'henrik stenson' AND country = 'sweden' AND to_par = '- 1') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-436.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there is a four way tie for the most laps at 79 with a two way tie for the least amount at 5\nInput Table: 1971 south african grand prix\n\n\ndriverconstructorlapstime_/_retiredgridmario andrettiferrari791:47:35.54jackie stewarttyrrell - ford79+ 20.91clay regazzoniferrari79+ 31.43reine wiselllotus - ford79+ 1:09.414chris amonmatra78+ 1 lap2denny hulmemclaren - ford78+ 1 lap7brian redmansurtees - ford78+ 1 lap17jacky ickxferrari78+ 1 lap8graham hillbrabham - ford77+ 2 laps19ronnie petersonmarch - ford77+ 2 laps13henri pescarolomarch - ford77+ 2 laps18rolf stommelensurtees - ford77+ 2 laps15andrea de adamichmarch - alfa romeo75+ 4 laps22emerson fittipaldilotus - ford58engine5john surteessurtees - ford56gearbox6fran\u00e7ois ceverttyrrell - ford45accident9howden ganleybrm42physical24pedro rodr\u00edguezbrm33overheating10dave charltonbrabham - ford31engine16jo siffertbrm31overheating12john lovemarch - ford30differential21jackie pretoriusbrabham - ford22engine20peter gethinmclaren - ford7fuel leak11jo bonniermclaren - ford5suspension23alex soler - roigmarch - ford5engine25\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE laps = 79) = 4 \n             AND (SELECT COUNT(*) FROM table_sql WHERE laps = 5) = 2 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-426.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: james burrows directed the episode sex , losers , and videotape for season 19\nInput Table: will & grace (season 5)\n\n\nseriesseasontitledirected_bywritten_byoriginal_air_dateus_viewers_(millions)931and the horse he rode in onjames burrowsadam barr2002-09-2621.5942bacon and eggsjames burrowsalex herschlag2002-10-0320.6953the kid stays out of the picturejames burrowsjhoni marchinko2002-10-1020.2964humongous growthjames burrowskari lizer2002-10-1719.5975it 's the gay pumpkin , charlie brownjames burrowsgary janetti2002-10-3117.2986boardroom and a parked placejames burrowsgail lerner2002-11-0721.1997the needle and the omelet 's donejames burrowstracy poust & jon kinnally2002-11-1419.11008 - 9marry me a little , marry me a little morejames burrowsjeff greenstein & bill wrubel2002-11-2124.310110the honeymoon 's overjames burrowssally bradford2002-12-0519.310211all about christmas evejames burrowsadam barr2002-12-1216.210312field of queensjames burrowskatie palmer2003-01-0916.210413fagmalion part i : gay it forwardjames burrowstracy poust & jon kinnally2003-01-1616.010514fagmalion part ii : attack of the clonesjames burrowsgary janetti2003-01-3015.810615homojojames burrowsbill wrubel2003-02-0616.510716women and children firstjames burrowslaura kightlinger2003-02-1318.710817fagmalion part iii : bye , bye , beardyjames burrowsalex herschlag2003-02-2016.410918fagmalion part iv : the guy who loved mejames burrowsgail lerner2003-03-1315.011019sex , losers , and videotapejames burrowssteve gabriel2003-04-0315.011120leo unwrappedjames burrowssonja warfield2003-04-1714.711221dolls and dollsjames burrowskari lizer2003-04-2417.7\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE season = 19 \nAND directed_by = 'james burrows' \nAND title = 'sex , losers , and videotape';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-25.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: in a game on august 30 , mohler (1 - 10) took the loss while in a game on august 31 oquist (2 - 5) suffered the loss\nInput Table: 1997 colorado rockies season\n\n\ndateopponentscorelossattendancerecord9999-08-01pirates7 - 6rinc\u00f3n (4 - 5)2265752 - 589999-08-02pirates6 - 5swift (4 - 5)3238852 - 599999-08-03pirates8 - 4reed (3 - 5)2498952 - 609999-08-04phillies7 - 3castillo (8 - 10)1523052 - 619999-08-05phillies4 - 2bottalico (2 - 4)1642853 - 619999-08-06mets4 - 0mlicki (5 - 8)2663354 - 619999-08-07mets12 - 4swift (4 - 6)2953654 - 629999-08-08pirates5 - 3lieber (6 - 12)4826255 - 629999-08-09pirates8 - 7rinc\u00f3n (4 - 6)4832356 - 629999-08-10pirates8 - 7wilkins (7 - 3)4801857 - 629999-08-12phillies5 - 0thomson (4 - 7)4822857 - 639999-08-13phillies12 - 8wright (6 - 8)4849157 - 649999-08-15mets6 - 2reed (10 - 6)4830858 - 649999-08-16mets7 - 5mcmichael (7 - 10)4831159 - 649999-08-17mets6 - 4mlicki (5 - 10)4844060 - 649999-08-19reds6 - 5wright (6 - 9)3172260 - 659999-08-20reds5 - 3white (1 - 1)2196861 - 659999-08-21astros10 - 4bailey (9 - 9)2296261 - 669999-08-22astros9 - 1thomson (5 - 8)3306161 - 679999-08-23astros6 - 3hudek (0 - 2)3237462 - 679999-08-24astros3 - 1wright (6 - 10)2891862 - 689999-08-25reds7 - 6castillo (10 - 11)4814362 - 699999-08-25reds6 - 4hutton (3 - 2)4808162 - 709999-08-26reds9 - 5mart\u00ednez (1 - 1)4806363 - 709999-08-27reds7 - 5remlinger (6 - 6)4803264 - 709999-08-28mariners9 - 5olivares (6 - 9)4842265 - 709999-08-29mariners6 - 5timlin (3 - 3)4817866 - 709999-08-30athletics4 - 3mohler (1 - 10)4830867 - 709999-08-31athletics10 - 4oquist (2 - 5)4804168 - 70\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT loss FROM table_sql WHERE date = '9999-08-30') = 'mohler (1 - 10)' \n             AND (SELECT loss FROM table_sql WHERE date = '9999-08-31') = 'oquist (2 - 5)' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1493.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: only three of the projects have been completed so far\nInput Table: list of superfund sites in mississippi\n\n\ncerclis_idnamecountyproposedlistedconstruction_completedpartially_deleteddeletedmsd004006995american creosote works , incwinston2001-06-142001-09-139999-01-01--msd008154486chemfax , incharrison1993-06-239999-01-019999-01-01--msd046497012davis timber companylamar2000-05-112000-07-279999-01-01--msd980710941flowood siterankin1983-09-081984-09-211993-09-17-02 / 16 / 1996msd980840045newsom brothers / old reichhold chemicals , incmarion1984-10-151986-06-101997-08-08-09 / 27 / 2000msd065490930picayune wood treatingpearl river2004-03-082004-07-229999-01-01--msd056029648potter cocopiah1993-05-109999-01-019999-01-01--msd086556388sonford productsrankin2006-09-272007-03-079999-01-01--msd980601736walcotte chemical co warehouseswashington9999-01-019999-01-011982-12-30-12 / 30 / 1982\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 3 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE construction_completed != '9999-01-01';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-615.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: series number 8 had a production code of 208\nInput Table: none\n\n\nepisodeseriesepisode_titleoriginal_air_dateproduction_code271return to genesis2008-04-05201282the suspension2008-04-06202293a team reinvented2008-04-12203304the new captain2008-04-13204315the homecoming2008-04-19205326netherball rules!2008-04-20206337doubts within2008-04-26207348rocket 's decent2008-04-27208359the all - stars2008-05-032093610rocket vs sinedd2008-05-042103711the champions stumble2008-05-102113812last stand2008-05-112123913fluxless2008-05-172134014new order2008-07-262144115revelations2008-07-272154216new rules2008-08-022164317open doors2008-08-032174418warren steps in2008-08-092184519the technodroid v3s2008-08-102194620the fallen star2008-08-162204721coach artegor2008-08-172214822rocket , the midfielder2008-08-232224923destiny2008-08-242235024final preparations2008-08-312245125a team unravels2008-08-31225\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT production_code FROM table_sql WHERE series = 8) = 208 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-0.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the wildcats kept the opposing team scoreless in four games\nInput Table: 1947 kentucky wildcats football team\n\n\ngamedateopponentresultwildcats_pointsopponentsrecord19999-09-20ole missloss7140 - 129999-09-27cincinnatiwin2001 - 139999-10-04xavierwin2072 - 149999-10-119 georgiawin2603 - 1 , 2059999-10-1810 vanderbiltwin1404 - 1 , 1469999-10-25michigan statewin765 - 1 , 1379999-11-0118 alabamaloss0135 - 289999-11-08west virginiawin1566 - 299999-11-15evansvillewin3607 - 2109999-11-22tennesseeloss6137 - 3\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 4 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE opponents = 0;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-37.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: kenneth ferrie and geoff ogilvy were the only players to score a + 1 to par\nInput Table: 2006 u.s. open (golf)\n\n\nplaceplayercountryscoreto_par1steve strickerunited states70 + 69 = 139- 12colin montgomeriescotland69 + 71 = 140et3kenneth ferrieengland71 + 70 = 141+ 1t3geoff ogilvyaustralia71 + 70 = 141+ 1t5jim furykunited states70 + 72 = 142+ 2t5p\u00e1draig harringtonireland70 + 72 = 142+ 2t7jason dufnerunited states72 + 71 = 143+ 3t7graeme mcdowellnorthern ireland71 + 72 = 143+ 3t7phil mickelsonunited states70 + 73 = 143+ 3t7arron oberholserunited states75 + 68 = 143+ 3\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 2 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE to_par = '+ 1';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-2007.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the home team score equals the away team score at the game taking place at arden street oval\nInput Table: 1954 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddategeelong13.12 (90)hawthorn7.6 (48)kardinia park168701954-08-14collingwood12.16 (88)south melbourne13.12 (90)victoria park185561954-08-14carlton10.16 (76)essendon11.14 (80)princes park297441954-08-14richmond10.18 (78)melbourne15.4 (94)punt road oval240001954-08-14north melbourne9.14 (68)footscray9.14 (68)arden street oval220001954-08-14st kilda13.14 (92)fitzroy9.15 (69)junction oval115001954-08-14\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT home_team_score FROM table_sql WHERE venue = 'arden street oval') = \n             (SELECT away_team_score FROM table_sql WHERE venue = 'arden street oval') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1807.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: nadia al - moutawaa was the first person to win the gold medal in equestrian at the asian games\nInput Table: equestrian at the asian games\n\n\nyearlocationgoldsilverbronze1982new delhinadia al - moutawaajamila al - moutawaabariaa salem al - sabbah1986seoultakashi tomurashuichi tokiryuzo okuno1994hiroshimakonoshin kuwahararyuzo okunonatya chantrasmi1998bangkokjin kannosohn bong - gakquzier ambak fathil2002busanmikaela mar\u00e3\u00ada jaworskilee jin - kyungtadayoshi hayashi2006dohaali yousuf al - rumaihijasmine chen - shao manjoo jung - hyun2010guangzhouramzy al duhamilatifa al maktomkhaled al - eid\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE year = 1982 \nAND gold = 'nadia al - moutawaa';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1731.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: week 9 was on october 30 , 1983\nInput Table: 1983 detroit lions season\n\n\nweekdateopponentresultattendance11983-09-04tampa bay buccaneersw 11 - 06215421983-09-11cleveland brownsl 31 - 266009531983-09-18atlanta falconsl 30 - 145462241983-09-25minnesota vikingsl 20 - 175825451983-10-02los angeles ramsl 21 - 104940361983-10-09green bay packersw 38 - 146773871983-10-16chicago bearsw 31 - 176670981983-10-23washington redskinsl 38 - 174318991983-10-30chicago bearsw 38 - 1758764101983-11-07new york giantsw 15 - 968985111983-11-13houston oilersl 27 - 1740660121983-11-20green bay packersw 23 - 20 ot50050131983-11-24pittsburgh steelersw 45 - 377724141983-12-05minnesota vikingsw 13 - 279169151983-12-11cincinnati bengalsl 17 - 945728161983-12-18tampa bay buccaneersw 23 - 2078392\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE week = 9 \nAND date = '1983-10-30';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-295.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the super league xii score on 21 / 07 / 07 was 14 - 10\nInput Table: 2007 bradford bulls season\n\n\ndatehome_teamscoreaway_teamgoalsattendancecompetition2007-11-02bradford18 - 14huddersfield giantsdeacon 3 / 412130super league xii0007-02-18warrington wolves20 - 36bradforddeacon 6 / 712607super league xii2007-02-24bradford32 - 28wigan warriorsdeacon 6 / 612798super league xii2007-02-03st helens34 - 22bradforddeacon 3 / 411793super league xii2007-11-03bradford56 - 18salford city redsdeacon 8 / 1010640super league xii0007-03-17harlequins rl22 - 36bradforddeacon 6 / 64011super league xii2007-03-25bradford22 - 29catalans dragonsdeacon 3 / 411298super league xii2007-03-30bradford24 - 16castleford tigersdeacon 4 / 46748rugby league challenge cup2007-05-04bradford14 - 18leeds rhinosdeacon 3 / 516706super league xii2007-09-04wakefield trinity wildcats24 - 36bradforddeacon 6 / 79106super league xii2007-04-15bradford52 - 22hull krdeacon 8 / 910881super league xii2007-04-20hull fc22 - 32bradforddeacon 4 / 612767super league xii2007-04-29bradford36 - 24warrington wolvesdeacon 3 / 3 , i harris 3 / 5 ,11200super league xii2007-06-05bradford38 - 42leeds rhinosdeacon 7 / 726667super league xii0007-05-13wakefield trinity wildcats4 - 14bradforddeacon 1 / 33568rugby league challenge cup0007-05-18huddersfield giants36 - 12bradfordi harris 2 / 28667super league xii2007-05-27bradford44 - 18harlequins rldeacon 6 / 810418super league xii2007-02-06catalans dragons20 - 28bradforddeacon 4 / 57555super league xii2007-10-06bradford52 - 20huddersfield giantsdeacon 8 / 107811rugby league challenge cup0007-06-17bradford34 - 8hull fcdeacon 4 / 6 , vainikolo 1 / 111557super league xii2007-06-29leeds rhinos14 - 38bradforddeacon 7 / 722000super league xii2007-06-07wigan warriors25 - 18bradforddeacon 5 / 515107super league xii0007-07-13bradford10 - 4st helensdeacon 3 / 311217super league xii2007-07-21salford city reds14 - 10bradforddeacon 1 / 23438super league xii2007-07-28bradford16 - 35st helensdeacon 1 / 314316rugby league challenge cup2007-05-08bradford38 - 24wakefield trinity wildcatsburgess 5 / 810701super league xii2007-12-08hull kr10 - 28bradfordi harris 4 / 56695super league xii0007-08-19huddersfield giants26 - 22bradfordharris 5 / 56824super league xii2007-09-02bradford16 - 16leeds rhinosdeacon 2 / 418000super league xii2007-09-09bradford40 - 8catalans dragonsiestyn harris (6 / 7)9350super league xii2007-09-14hull fc20 - 10bradfordi harris (1 / 2)14409super league xii2007-09-21bradford30 - 31wigan warriorsi harris (5 / 6)9000super league xii\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT score FROM table_sql WHERE date = '2007-07-21' AND competition = 'super league xii') = '14 - 10' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-360.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: wes roberts was picked by the indianapolis colts before ed whitley was chosen\nInput Table: indianapolis colts draft history\n\n\nroundpickoverallnamepositioncollege155curtis dickeyrunning backtexas a&m12424derrick hatchettcornerbacktexas2432ray donaldsoncentergeorgia22351tim foleyoffensive tacklenotre dame4588ray butlerwide receiverusc66144chris footecenterusc75170wes robertsdefensive endtcu82195ken walteroffensive tackletexas tech96227mark brightrunning backtemple105254larry stewartoffensive tacklemaryland113280ed whitleytight endkansas state126311randy bielskiplacekickertowson1219324marvin simsfullbackclemson\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT overall FROM table_sql WHERE name = 'wes roberts') < \n             (SELECT overall FROM table_sql WHERE name = 'ed whitley') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-866.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: ecurie espadon was the entrant when sva - fiat was the constructor and sva 1500 was the chassis and scuderia ambrosiana was the entrant when maserati was the constructor and maserati 4clt - 48 was the chassis\nInput Table: 1950 swiss grand prix\n\n\ndriverentrantconstructorchassisenginetyrenello paganiscuderia achille varzimaseratimaserati 4clt - 48maserati l4spjohnny claesecurie belgetalbot - lagotalbot - lago t26ctalbot l6dyves giraud - cabantousautomobiles talbot - darracq satalbot - lagotalbot - lago t26c - datalbot l6deug\u00e8ne martinautomobiles talbot - darracq satalbot - lagotalbot - lago t26c - datalbot l6dlouis rosierautomobiles talbot - darracq satalbot - lagotalbot - lago t26c - datalbot l6dluigi fagiolisa alfa romeoalfa romeoalfa romeo 158alfa romeo l8spjuan manuel fangiosa alfa romeoalfa romeoalfa romeo 158alfa romeo l8spnino farinasa alfa romeoalfa romeoalfa romeo 158alfa romeo l8spalberto ascariscuderia ferrariferrariferrari 125ferrari v12spraymond sommerscuderia ferrariferrariferrari 125ferrari v12spluigi villoresiscuderia ferrariferrariferrari 125ferrari v12sppeter whiteheadscuderia ferrariferrariferrari 125ferrari v12splouis chironofficine alfieri maseratimaseratimaserati 4clt - 48maserati l4spfranco rolofficine alfieri maseratimaseratimaserati 4clt - 48maserati l4spprince biraenrico plat\u00e9maseratimaserati 4clt - 48maserati l4sptoulo de graffenriedenrico plat\u00e9maseratimaserati 4clt - 48maserati l4spfelice bonettoscuderia milanomaseratimaserati milano 4clt - 50maserati l4spreg parnellscuderia ambrosianamaseratimaserati 4clt - 48maserati l4sdrudi fischerecurie espadonsva - fiatsva 1500fiat l4sptoni brancaprivatemaseratimaserati 4clmaserati l4spphilippe \u00e9tancelinprivatetalbot - lagotalbot - lago t26ctalbot l6dharry schellecurie bleuetalbot - lagotalbot - lago t26ctalbot l6d\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE entrant = 'ecurie espadon' AND constructor = 'sva - fiat' AND chassis = 'sva 1500') > 0 \n             AND (SELECT COUNT(*) FROM table_sql WHERE entrant = 'scuderia ambrosiana' AND constructor = 'maserati' AND chassis = 'maserati 4clt - 48') > 0 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1611.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: olimpia , in position 10 , has 2 wins\nInput Table: 2005 in paraguayan football\n\n\npositionteamplayedwinsdrawslossesscoredconcededpoints1cerro porte\u00f1o1810623015362guaran\u00ed189452118313nacional1893625223043 de febrero18774241728512 de octubre186842222266tacuary1841132419237libertad184772123198sportivo luque\u00f1o183872022179general caballero zc1827916281310olimpia18279102713\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT wins FROM table_sql WHERE team = 'olimpia' AND position = 10) = 2 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-624.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the total for the rank 7 is 2 and the bronze is 1\nInput Table: fivb volleyball world league\n\n\nrankgoldsilverbronzetotal194417283314335715415395112461113710128043790101total24242472\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT total FROM table_sql WHERE rank = 7) = 2 \n             AND (SELECT bronze FROM table_sql WHERE rank = 7) = 1 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-865.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: when the drive was harry schell the entrant was ecurie bleue and when the driver was philippe etancelin the entrant was private\nInput Table: 1950 swiss grand prix\n\n\ndriverentrantconstructorchassisenginetyrenello paganiscuderia achille varzimaseratimaserati 4clt - 48maserati l4spjohnny claesecurie belgetalbot - lagotalbot - lago t26ctalbot l6dyves giraud - cabantousautomobiles talbot - darracq satalbot - lagotalbot - lago t26c - datalbot l6deug\u00e8ne martinautomobiles talbot - darracq satalbot - lagotalbot - lago t26c - datalbot l6dlouis rosierautomobiles talbot - darracq satalbot - lagotalbot - lago t26c - datalbot l6dluigi fagiolisa alfa romeoalfa romeoalfa romeo 158alfa romeo l8spjuan manuel fangiosa alfa romeoalfa romeoalfa romeo 158alfa romeo l8spnino farinasa alfa romeoalfa romeoalfa romeo 158alfa romeo l8spalberto ascariscuderia ferrariferrariferrari 125ferrari v12spraymond sommerscuderia ferrariferrariferrari 125ferrari v12spluigi villoresiscuderia ferrariferrariferrari 125ferrari v12sppeter whiteheadscuderia ferrariferrariferrari 125ferrari v12splouis chironofficine alfieri maseratimaseratimaserati 4clt - 48maserati l4spfranco rolofficine alfieri maseratimaseratimaserati 4clt - 48maserati l4spprince biraenrico plat\u00e9maseratimaserati 4clt - 48maserati l4sptoulo de graffenriedenrico plat\u00e9maseratimaserati 4clt - 48maserati l4spfelice bonettoscuderia milanomaseratimaserati milano 4clt - 50maserati l4spreg parnellscuderia ambrosianamaseratimaserati 4clt - 48maserati l4sdrudi fischerecurie espadonsva - fiatsva 1500fiat l4sptoni brancaprivatemaseratimaserati 4clmaserati l4spphilippe \u00e9tancelinprivatetalbot - lagotalbot - lago t26ctalbot l6dharry schellecurie bleuetalbot - lagotalbot - lago t26ctalbot l6d\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT entrant FROM table_sql WHERE driver = 'harry schell') = 'ecurie bleue' \n             AND (SELECT entrant FROM table_sql WHERE driver = 'philippe \u00e9tancelin') = 'private' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1070.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the buffalo bills lost more games than they won\nInput Table: 1976 buffalo bills season\n\n\nweekdateopponentresultattendance11976-09-13miami dolphinsl 30 - 217768321976-09-19houston oilersl 13 - 36138431976-09-26tampa bay buccaneersw 14 - 94450541976-10-03kansas city chiefsw 50 - 175190951976-10-10new york jetsl 17 - 145911061976-10-17baltimore coltsl 31 - 137100971976-10-24new england patriotsl 26 - 224514481976-10-31new york jetsl 19 - 144128591976-11-07new england patriotsl 20 - 1061157101976-11-15dallas cowboysl 17 - 1051799111976-11-21san diego chargersl 34 - 1336539121976-11-25detroit lionsl 27 - 1466875131976-12-05miami dolphinsl 45 - 2743475141976-12-12baltimore coltsl 58 - 2050451\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE result LIKE 'w%') < \n             (SELECT COUNT(*) FROM table_sql WHERE result LIKE 'l%') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1307.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: players larry mize and d a are tied for 5th place\nInput Table: 1988 u.s. open (golf)\n\n\nplaceplayercountryscoreto_par1curtis strangeunited states70 + 67 + 69 = 206- 7t2nick faldoengland72 + 67 + 68 = 207- 6t2bob gilderunited states68 + 69 + 70 = 207- 6t2scott simpsonunited states69 + 66 + 72 = 207- 6t5larry mizeunited states69 + 67 + 72 = 208- 5t5d a weibringunited states71 + 69 + 68 = 208- 57mark o'mearaunited states71 + 72 + 66 = 209- 48fred couplesunited states72 + 67 + 71 = 210- 39lanny wadkinsunited states70 + 71 + 70 = 211- 210ken greenunited states72 + 70 + 70 = 212- 1\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT place FROM table_sql WHERE player = 'larry mize') = \n             (SELECT place FROM table_sql WHERE player = 'd a weibring') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1994.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: a mintage of 31997 had an issue price of 59.95\nInput Table: royal canadian mint numismatic coins (2000s)\n\n\nyearthemeartistmintageissue_price2000steam buggyjohn mardon4436759.952000the bluenosej franklin wrightincluded in steam buggy59.952000the torontojohn mardonincluded in steam buggy59.952001the russell light fourjohn mardon4182859.952001the marco poloj franklin wrightincluded in the russell59.952001the scotiadon curleyincluded in the russell59.952002the gray - dortjohn mardon3594459.952002the william lawrencebonnie rossincluded in the gray - dort59.952002d - 10 locomotivedan fellincluded in the gray - dort59.952003hmcs bras dordon curley3199759.952003cnr fa - 1 diesel electricjohn mardonincluded in hmcs bras dor59.952003bricklin sv - 1brian hughesincluded in hmcs bras dor59.95\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT issue_price FROM table_sql WHERE mintage = 31997) = 59.95 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1949.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the new york knicks did not win a game against the boston celtics in the 1984 - 85 season\nInput Table: 1984 - 85 boston celtics season\n\n\ngamedateopponentscorelocationrecord339999-01-02new jersey nets110 - 95brendan byrne arena27 - 6349999-01-04new york knicks105 - 94boston garden28 - 6359999-01-07new york knicks108 - 97madison square garden29 - 6369999-01-09chicago bulls111 - 108boston garden30 - 6379999-01-11washington bullets103 - 101boston garden31 - 6389999-01-12atlanta hawks119 - 111the omni32 - 6399999-01-16los angeles lakers104 - 102boston garden33 - 6409999-01-18indiana pacers86 - 91market square arena33 - 7419999-01-20philadelphia 76ers113 - 97boston garden34 - 7429999-01-23seattle supersonics97 - 107boston garden34 - 8439999-01-25indiana pacers125 - 94boston garden35 - 8449999-01-27portland trail blazers128 - 127boston garden36 - 8459999-01-29detroit pistons131 - 130hartford civic center37 - 8469999-01-30philadelphia 76ers104 - 122the spectrum37 - 9\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE opponent = 'new york knicks' \nAND score LIKE '% - %' \nAND score NOT LIKE '1%' \nAND score NOT LIKE '%1' \nAND record LIKE '3%';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-608.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the most highly attended game was against miami at the prudential center\nInput Table: 2010 - 11 new jersey nets season\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord759999-04-01philadelphial 90 - 115 (ot)brandan wright (15)brandan wright (11)deron williams (7)wells fargo center 1669523 - 52769999-04-03miamil 94 - 108 (ot)deron williams (18)travis outlaw (9)deron williams (9)prudential center 1871123 - 5377'9999-04-05'minnesotaw 107 - 105 (ot)brook lopez (30)brook lopez (12)deron williams (21)prudential center 1346124 - 53789999-04-06detroitl 109 - 116 (ot)brook lopez (39)brook lopez (7)jordan farmar (11)the palace of auburn hills 1455424 - 54799999-04-08new yorkl 93 - 116 (ot)brook lopez (27)jordan farmar (8)jordan farmar (9)prudential center 1802324 - 5580'9999-04-10'torontol 92 - 99 (ot)brook lopez (35)brook lopez (11)jordan farmar (7)air canada centre 1775524 - 56819999-04-11charlottel 103 - 105 (ot)brook lopez (31)dan gadzuric (8)jordan farmar (9)prudential center 1385324 - 57\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MAX(location_attendance) FROM table_sql WHERE team = 'miami') = \n             (SELECT location_attendance FROM table_sql WHERE team = 'miami' AND game = 76) \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-303.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the score was 1 - 0 when the away team was bolton wanderers\nInput Table: 1990 - 91 fa cup\n\n\ntie_nohome_teamscoreaway_teamdate1liverpool2 - 2brighton & hove albion1991-01-26replaybrighton & hove albion2 - 3liverpool1991-01-302notts county2 - 0oldham athletic1991-01-263crewe alexandra1 - 0rotherham united1991-01-264luton town1 - 1west ham united1991-01-26replaywest ham united5 - 0luton town1991-01-305woking0 - 1everton1991-01-276shrewsbury town1 - 0wimbledon1991-01-267newcastle united2 - 2nottingham forest1991-02-13replaynottingham forest3 - 0newcastle united1991-02-188tottenham hotspur4 - 2oxford united1991-01-269coventry city1 - 1southampton1991-01-26replaysouthampton2 - 0coventry city1991-01-2910portsmouth5 - 1bournemouth1991-01-2611manchester united1 - 0bolton wanderers1991-01-2612norwich city3 - 1swindon town1991-01-2613millwall4 - 4sheffield wednesday1991-01-26replaysheffield wednesday2 - 0millwall1991-01-3014port vale1 - 2manchester city1991-01-2615arsenal0 - 0leeds united1991-01-27replayleeds united1 - 1arsenal1991-01-30replayarsenal0 - 0leeds united1991-02-13replayleeds united1 - 2arsenal1991-02-1616cambridge united2 - 0middlesbrough1991-01-26\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT score FROM table_sql WHERE away_team = 'bolton wanderers') = '1 - 0' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1451.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: in the illinois 6th district , republican henry hyde , incumbent since 1974 , beat democrat mario reymond reda\nInput Table: united states house of representatives elections , 1980\n\n\ndistrictincumbentpartyfirst_electedresultcandidatesillinois 2morgan f murphydemocratic1970-01-01retired democratic holdgus savage (d) 88.2% marsha a harris (r) 11.8%illinois 6henry hyderepublican1974-01-01re - electedhenry hyde (r) 67.0% mario reymond reda (d) 33.0%illinois 7cardiss collinsdemocratic1973-01-01re - electedcardiss collins (d) 85.1% ruth r hooper (r) 14.9%illinois 12phil cranerepublican1969-01-01re - electedphil crane (r) 74.1% david mccartney (d) 25.9%illinois 13robert mccloryrepublican1962-01-01re - electedrobert mcclory (r) 71.7% michael reese (d) 28.3%illinois 15tom corcoranrepublican1976-01-01re - electedtom corcoran (r) 76.7% john p quillin (d) 23.3%illinois 19tom railsbackrepublican1966-01-01re - electedtom railsback (r) 73.4% thomas j hand (d) 26.6%illinois 20paul findleyrepublican1960-01-01re - electedpaul findley (r) 56.0% david robinson (d) 44.0%\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT result FROM table_sql WHERE district = 'illinois 6' AND incumbent = 'henry hyde' AND party = 'republican' AND first_elected = '1974-01-01') = 're - elected' \n             AND (SELECT candidates FROM table_sql WHERE district = 'illinois 6' AND incumbent = 'henry hyde' AND party = 'republican' AND first_elected = '1974-01-01') LIKE '%henry hyde (r)%' \n             AND (SELECT candidates FROM table_sql WHERE district = 'illinois 6' AND incumbent = 'henry hyde' AND party = 'republican' AND first_elected = '1974-01-01') LIKE '%mario reymond reda (d)%' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-885.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: denis menchov on the rabobank team scored 40 uci points\nInput Table: 2007 volta a catalunya\n\n\ncyclistcountryteamtimeuci_pointsvladimir karpetsrussiacaisse d'epargne9999-01-0150denis menchovrussiarabobank9999-01-0140michael rogersaustraliat - mobile team9999-01-0135christophe moreaufranceag2r pr\u00e9voyance9999-01-0130\u00f3scar sevillaspainrelax - gam9999-01-01n / afrancisco mancebospainrelax - gam9999-01-01n / ajohn gadretfranceag2r pr\u00e9voyance9999-01-0215marcos - antonio serranospainkarpin - galicia9999-01-01n / alaurens ten damnetherlandsunibetcom9999-01-015janez brajkovi\u010dsloveniadiscovery channel9999-01-022\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT uci_points FROM table_sql WHERE cyclist = 'denis menchov' AND team = 'rabobank') = 40 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1056.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the score of the 2014 world cup qualification was 2 - 1\nInput Table: kwak tae - hwi\n\n\ndatevenuescoreresultcompetition2008-02-02seoul , south korea1 - 04 - 02010 world cup qualification2008-02-17chongqing , china3 - 23 - 22008 east asian cup2008-10-15seoul , south korea4 - 14 - 12010 world cup qualification2010-03-03london , england2 - 02 - 0friendly2012-06-08doha , qatar2 - 14 - 12014 world cup qualification\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT score FROM table_sql WHERE competition = '2014 world cup qualification') = '2 - 1' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1198.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the 1977 , 1978 and 1989 seasons each have less than 26 points , more than 18 games , and exactly 13 losses\nInput Table: coquitlam adanacs\n\n\nseasonteam_namegameslossespoints1965coquitlam adanacs3018241966coquitlam adanacs3011381967coquitlam adanacs3015291968portland adanacs3814481969coquitlam adanacs293521970coquitlam adanacs3016281971coquitlam adanacs3112371972coquitlam adanacs3623181973coquitlam adanacs259321974coquitlam adanacs2415171975coquitlam adanacs2416161976coquitlam adanacs2415181977coquitlam adanacs2413221978coquitlam adanacs2413211979coquitlam adanacs3012351980coquitlam adanacs249301981coquitlam adanacs247341982coquitlam adanacs2416161983coquitlam adanacs2414201984coquitlam adanacs2414201985coquitlam adanacs2410281986coquitlam adanacs2414201987coquitlam adanacs2411261988coquitlam adanacs2411261989coquitlam adanacs2413221990coquitlam adanacs2418121991coquitlam adanacs246361992coquitlam adanacs2414201993coquitlam adanacs236341994coquitlam adanacs207261995coquitlam adanacs2511251996coquitlam adanacs2015101997coquitlam adanacs2010191998coquitlam adanacs259311999coquitlam adanacs257362000coquitlam adanacs2511282001coquitlam adanacs208242002coquitlam adanacs206272003coquitlam adanacs203342004coquitlam adanacs209222005coquitlam adanacs184272006coquitlam adanacs186232007coquitlam adanacs187202008coquitlam adanacs183282009coquitlam adanacs18918total45 seasons10944931177\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE season IN (1977, 1978, 1989) AND points < 26 AND games > 18 AND losses = 13) = 3 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1033.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: climax straight - 4 has lotus 16 , cooper t45 , and cooper t51 chassis\nInput Table: bruce halford\n\n\nyearentrantchassisenginepoints1956bruce halfordmaserati 250fmaserati straight - 601957bruce halfordmaserati 250fmaserati straight - 601959john fisherlotus 16climax straight - 401960fred tuck carscooper t45climax straight - 401960yeoman credit racing teamcooper t51climax straight - 40\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 3 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE engine = 'climax straight - 4' \nAND (chassis = 'lotus 16' OR chassis = 'cooper t45' OR chassis = 'cooper t51');\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-490.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: anne street has no major junctions in the milepost\nInput Table: massachusetts route 139\n\n\ncountylocationstreet_namesmilepostroads_intersectednotesnorfolkstoughtonpleasant street turnpike street lindelof avenue3.0route 24route 24 exit 20norfolkweymouthanne street(no major junctions)(no major junctions)(no major junctions)plymouthrocklandnorth avenue plain street market street12.2route 123western terminus of route 123 / 139 concurrencyplymouthrocklandnorth avenue plain street market street12.8route 123eastern terminus of route 123 / 139 concurrencyplymouthhanoverhanover street rockland street columbia road17.9route 53northern terminus of route 53 / 139 concurrency\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN roads_intersected = '(no major junctions)' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE street_names = 'anne street' \nAND milepost = '(no major junctions)';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1763.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the term start for bashkim fino was after the term start for vilson ahmeti\nInput Table: list of prime ministers of albania\n\n\nnameborn_-_diedterm_startterm_endpolitical_partyprime ministers 1991 onwards1991-01-011991-01-011991-01-01prime ministers 1991 onwardsfatos nano (1st time)9999-01-011991-02-221991-06-05party of labour of albaniaylli bufi9999-01-011991-06-051991-12-10socialist party of albaniavilson ahmeti9999-01-011991-12-101992-04-13non - partyaleksand\u00ebr meksi9999-01-011992-04-131997-03-11democratic party of albaniabashkim fino9999-01-011997-03-111997-07-24socialist party of albaniafatos nano (2nd time)9999-01-011997-07-241998-10-02socialist party of albaniapandeli majko (1st time)9999-01-011998-10-021999-10-29socialist party of albaniailir meta9999-01-011999-10-292002-02-22socialist party of albaniapandeli majko (2nd time)9999-01-012002-02-222002-07-31socialist party of albaniafatos nano (3rd time)9999-01-012002-07-312005-09-11socialist party of albaniasali berisha1944-01-012005-09-112013-09-15democratic party of albaniaedi rama9999-01-012013-09-159999-01-01socialist party of albania\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT term_start FROM table_sql WHERE name = 'bashkim fino') > \n             (SELECT term_start FROM table_sql WHERE name = 'vilson ahmeti') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-103.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: jack nicklaus of the united states has a score of 72 + 70 + 75 + 72 = 289\nInput Table: 1975 u.s. open (golf)\n\n\nplaceplayercountryscoreto_parmoneyt1lou grahamunited states74 + 72 + 68 + 73 = 287+ 3playofft1john mahaffeyunited states73 + 71 + 72 + 71 = 287+ 3playofft3frank beardunited states74 + 69 + 67 + 78 = 288+ 410875t3ben crenshawunited states70 + 68 + 76 + 74 = 288+ 410875t3hale irwinunited states74 + 71 + 73 + 70 = 288+ 410875t3bob murphyunited states74 + 73 + 72 + 69 = 288+ 410875t7jack nicklausunited states72 + 70 + 75 + 72 = 289+ 57500t7peter oosterhuisengland69 + 73 + 72 + 75 = 289+ 57500t9pat fitzsimonsunited states67 + 73 + 73 + 77 = 290+ 65000t9arnold palmerunited states69 + 75 + 73 + 73 = 290+ 65000t9tom watsonunited states67 + 68 + 78 + 77 = 290+ 65000\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE player = 'jack nicklaus' \nAND country = 'united states' \nAND score = '72 + 70 + 75 + 72 = 289';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-928.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: new jersey was the visiting team on february 27 against buffalo\nInput Table: none\n\n\ndatevisitorscorehomerecord9999-02-03ny islanders7 - 2new jersey11 - 32 - 119999-02-05new jersey4 - 5washington11 - 33 - 119999-02-06vancouver4 - 4new jersey11 - 33 - 129999-02-09new jersey4 - 5chicago11 - 34 - 1201-02-12new jersey1 - 5st louis11 - 35 - 1201-02-15minnesota3 - 2new jersey11 - 36 - 129999-02-20new jersey0 - 3philadelphia11 - 37 - 1201-02-21buffalo4 - 4new jersey11 - 37 - 139999-02-24detroit1 - 4new jersey12 - 37 - 139999-02-26new jersey4 - 5pittsburgh12 - 38 - 139999-02-27new jersey2 - 6buffalo12 - 39 - 13\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE date = '9999-02-27' \nAND visitor = 'new jersey' \nAND home = 'buffalo';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1724.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: ricardo rodriguez was the losing pitcher during the game where the winning pitcher was roy oswalt\nInput Table: 2005 texas rangers season\n\n\ndatewinning_teamscorewinning_pitcherlosing_pitcherattendancelocation9999-05-20texas7 - 3kenny rogersbrandon backe38109arlington9999-05-21texas18 - 3chris youngezequiel astacio35781arlington9999-05-22texas2 - 0chan ho parkroy oswalt40583arlington9999-06-24houston5 - 2roy oswaltricardo rodr\u00edguez36199houston9999-06-25texas6 - 5chris youngbrandon backe41868houston\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT losing_pitcher FROM table_sql WHERE winning_pitcher = 'roy oswalt') = 'ricardo rodr\u00edguez' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-67.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the geo id for janke township in logan county is 3804740620\nInput Table: list of townships in north dakota\n\n\ntownshipcountypop_(2010)land_(_sqmi_)water_(sqmi)latitudelongitudegeo_idansi_codejacksonsargent3335.8090.046.066276- 97.94553038081404601036797james hillmountrail3231.824.24348.423125- 102.42993438061405001037048james river valleydickey4028.5970.046.246641- 98.18832938021405401036767jankelogan2835.9950.16346.415512- 99.13170138047406201037193jeffersonpierce4535.0691.12548.232149- 100.18237038069407001759556jim river valleystutsman3834.1341.74647.112388- 98.77847838093407801036484johnsonwells3635.2990.90847.377745- 99.45867738103408201037137johnstowngrand forks7936.1990.048.151362- 97.44903338035409401036624joliettepembina6770.0440.77148.796545- 97.21722738067410201036723\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE township = 'janke' \nAND county = 'logan' \nAND geo_id = 3804740620;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-827.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: in the 1981 open championship there were eight players that tied for 9th\nInput Table: 1981 open championship\n\n\nplaceplayercountryscoreto_part1vicente fern\u00e3\u00a1ndezargentina70et1nick jobengland70et3isao aokijapan71+ 1t3david grahamaustralia71+ 1t3tony jacklinengland71+ 1t3johnny millerunited states71+ 1t3simon owennew zealand71+ 1t3hal sutton (a)united states71+ 1t9howard clarkengland72+ 2t9ben crenshawunited states72+ 2t9david jaggerengland72+ 2t9mark jamesengland72+ 2t9greg normanaustralia72+ 2t9arnold palmerunited states72+ 2t9bill rogersunited states72+ 2t9sam torrancescotland72+ 2\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 8 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE place = 't9';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-2015.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the hurricanes won 90% of their games in 2007 which got them promoted to a higher division\nInput Table: dundee hurricanes\n\n\nseasondivisionwinslossestiesfinal_positionnotes2003bafl division 2 north6404 / 11-2004bafl division 2 north6211 / 3-2005bafl division 2 scottish5502 / 4-2006bafl division 2 scottish3402 / 3-2007bafl division 2 north9101 / 6promoted to division 1 north2008bafl division 1 north5233 / 6-2009bafl division 1 north2615 / 7-\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT CAST(wins AS FLOAT) / (wins + losses + ties) FROM table_sql WHERE season = 2007) >= 0.9 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-828.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: england and the united states had the same number of players in the 1981 open championship with five each\nInput Table: 1981 open championship\n\n\nplaceplayercountryscoreto_part1vicente fern\u00e3\u00a1ndezargentina70et1nick jobengland70et3isao aokijapan71+ 1t3david grahamaustralia71+ 1t3tony jacklinengland71+ 1t3johnny millerunited states71+ 1t3simon owennew zealand71+ 1t3hal sutton (a)united states71+ 1t9howard clarkengland72+ 2t9ben crenshawunited states72+ 2t9david jaggerengland72+ 2t9mark jamesengland72+ 2t9greg normanaustralia72+ 2t9arnold palmerunited states72+ 2t9bill rogersunited states72+ 2t9sam torrancescotland72+ 2\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE country = 'england' AND place LIKE 't%') = \n             (SELECT COUNT(*) FROM table_sql WHERE country = 'united states' AND place LIKE 't%') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-29.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: on august 27 remlinger (6 - 6) took the loss as the rockies went to 64 - 70\nInput Table: 1997 colorado rockies season\n\n\ndateopponentscorelossattendancerecord9999-08-01pirates7 - 6rinc\u00f3n (4 - 5)2265752 - 589999-08-02pirates6 - 5swift (4 - 5)3238852 - 599999-08-03pirates8 - 4reed (3 - 5)2498952 - 609999-08-04phillies7 - 3castillo (8 - 10)1523052 - 619999-08-05phillies4 - 2bottalico (2 - 4)1642853 - 619999-08-06mets4 - 0mlicki (5 - 8)2663354 - 619999-08-07mets12 - 4swift (4 - 6)2953654 - 629999-08-08pirates5 - 3lieber (6 - 12)4826255 - 629999-08-09pirates8 - 7rinc\u00f3n (4 - 6)4832356 - 629999-08-10pirates8 - 7wilkins (7 - 3)4801857 - 629999-08-12phillies5 - 0thomson (4 - 7)4822857 - 639999-08-13phillies12 - 8wright (6 - 8)4849157 - 649999-08-15mets6 - 2reed (10 - 6)4830858 - 649999-08-16mets7 - 5mcmichael (7 - 10)4831159 - 649999-08-17mets6 - 4mlicki (5 - 10)4844060 - 649999-08-19reds6 - 5wright (6 - 9)3172260 - 659999-08-20reds5 - 3white (1 - 1)2196861 - 659999-08-21astros10 - 4bailey (9 - 9)2296261 - 669999-08-22astros9 - 1thomson (5 - 8)3306161 - 679999-08-23astros6 - 3hudek (0 - 2)3237462 - 679999-08-24astros3 - 1wright (6 - 10)2891862 - 689999-08-25reds7 - 6castillo (10 - 11)4814362 - 699999-08-25reds6 - 4hutton (3 - 2)4808162 - 709999-08-26reds9 - 5mart\u00ednez (1 - 1)4806363 - 709999-08-27reds7 - 5remlinger (6 - 6)4803264 - 709999-08-28mariners9 - 5olivares (6 - 9)4842265 - 709999-08-29mariners6 - 5timlin (3 - 3)4817866 - 709999-08-30athletics4 - 3mohler (1 - 10)4830867 - 709999-08-31athletics10 - 4oquist (2 - 5)4804168 - 70\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE date = '9999-08-27' \nAND loss = 'remlinger (6 - 6)' \nAND record = '64 - 70';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1984.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: in three of the games , no goals were scored by either side\nInput Table: 2000 - 01 sheffield wednesday f.c. season\n\n\ndateopponentvenueresultattendance2000-08-13wolverhampton wanderersa1 - 1190862000-08-19huddersfield townh2 - 3227042000-08-26grimsby towna1 - 077552000-08-28blackburn roversh1 - 1156462000-09-09wimbledonh0 - 5158562000-09-13nottingham foresth0 - 1157002000-09-16tranmere roversa0 - 293522000-09-23preston north endh1 - 3173792000-09-30gillinghama0 - 290992000-10-08west bromwich albionh1 - 2153382000-10-14portsmoutha1 - 2133762000-10-17burnleya0 - 1163722000-10-22birmingham cityh1 - 0146952000-10-25queens park rangersa2 - 1103532000-10-28fulhamh3 - 3175592000-11-04crystal palacea1 - 4153332000-11-07watforda3 - 1111662000-11-01norwich cityh3 - 2169562000-11-18barnsleya0 - 1199892000-11-25crewe alexandraa0 - 171032000-12-02queens park rangersh5 - 2217822000-12-09stockport countyh2 - 4163372000-12-16sheffield uniteda1 - 1251562000-12-23wolverhampton wanderersh0 - 1177872000-12-26bolton wanderersa0 - 2213162000-12-30huddersfield towna0 - 0189312001-01-01grimsby townh1 - 0170042001-01-13blackburn roversa0 - 2193082001-01-20bolton wanderersh0 - 3176382001-02-03watfordh2 - 3161342001-02-10wimbledona1 - 467412001-02-13tranmere roversh1 - 0154442001-02-21nottingham foresta1 - 0232662001-02-24preston north enda0 - 2143792001-03-03gillinghamh2 - 1187022001-03-07portsmouthh0 - 0205032001-03-10west bromwich albiona2 - 1186622001-03-17burnleyh2 - 0201842001-03-24birmingham citya2 - 1197332001-04-01sheffield unitedh1 - 2384332001-04-07stockport countya1 - 296662001-04-14crystal palaceh4 - 1198772001-04-16fulhama1 - 1175002001-04-21barnsleyh2 - 1234982001-04-28norwich citya0 - 1212412001-05-06crewe alexandrah0 - 028007\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 3 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE result = '0 - 0';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-800.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: triston grant is the only player listed for left wing\nInput Table: 2004 - 05 philadelphia flyers season\n\n\nroundplayerpositionnationalitycollege_/_junior_/_club_team_(league)3rob bellamyright wingunited statesnew england jr coyotes ( ejhl )4r j andersondefenseunited statescentennial high school (minn)4david laliberteright wingcanadaprince edward island rocket ( qmjhl )5chris zarbdefenseunited statestri - city storm ( ushl )5gino piselliniright wingunited statesplymouth whalers ( ohl )6ladislav scurkocenterslovakiaspi\u0161sk\u00e1 nov\u00e1 ves (slovakia)6frederik cabanacentercanadahalifax mooseheads (qmjhl)8martin houlegoaltendercanadacape breton screaming eagles (qmjhl)8travis gawryletzdefensecanadatrail smoke eaters ( bchl )9triston grantleft wingcanadavancouver giants ( whl )9john cartercenterunited statesbrewster bulldogs (emjhl)\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 1 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE position = 'left wing';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1974.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the cleveland browns have tied a total of ten games\nInput Table: list of cleveland browns starting quarterbacks\n\n\nquarterbackuniform_no_(s)games_startedwinslossestieswinning_pctsipe , brian1711257550589.0kosar , bernie1910553511595.0ryan , frank137652222697.0graham , otto60 , 147157131810.0couch , tim25922370373.0nelsen , bill165134161676.0phipps , mike155124252490.0plum , milt165133162667.0anderson , derek33416180471.0testaverde , vinny123116150516.0mcdonald , paul16218130381.0mccoy , colt12216150286.0frye , charlie9196130316.0weeden , brandon3195140263.0o'connell , tommy15141031750.0holcomb , kelly1012480333.0quinn , brady1012390250.0ninowski , jim15 , 1111560455.0dilfer , trent811470364.0garcia , jeff510370300.0danielson , gary188530625.0tomczak , mike188440500.0pederson , doug188170125.0pagel , mike107250286.0wallace , seneca67160143.0ratterman , george12 , 165230400.0philcox , todd175230400.0delhomme , jake174220500.0mays , dave104130250.0zeier , eric104130250.0mccown , luke1240400.0parilli , babe183120333.0rypien , mark113210667.0dorsey , ken1130300.0hoyer , brian633001.0strock , don1222001.0christensen , jeff112110500.0detmer , ty1120200.0campbell , jason172110500.0gault , don1111001.0lane , gary1510100.0dawson , len1811001.0wynn , spergon1310100.0luck , terry710100.0cureton , will1610100.0gradkowski , bruce710100.0lewis , thaddeus910100.0\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT SUM(ties) FROM table_sql) = 10 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1886.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: in the year 2007 the regional gva was 9432 and the industry was listed as 1565\nInput Table: none\n\n\nyearregional_gvaagricultureindustryservices199547531111103632200065841013025277200382011113746816200589781114657502200794321115657856\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT regional_gva FROM table_sql WHERE year = 2007) = 9432 \n             AND (SELECT industry FROM table_sql WHERE year = 2007) = 1565 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-618.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: episode 31 was originally aired on 19april 2008\nInput Table: none\n\n\nepisodeseriesepisode_titleoriginal_air_dateproduction_code271return to genesis2008-04-05201282the suspension2008-04-06202293a team reinvented2008-04-12203304the new captain2008-04-13204315the homecoming2008-04-19205326netherball rules!2008-04-20206337doubts within2008-04-26207348rocket 's decent2008-04-27208359the all - stars2008-05-032093610rocket vs sinedd2008-05-042103711the champions stumble2008-05-102113812last stand2008-05-112123913fluxless2008-05-172134014new order2008-07-262144115revelations2008-07-272154216new rules2008-08-022164317open doors2008-08-032174418warren steps in2008-08-092184519the technodroid v3s2008-08-102194620the fallen star2008-08-162204721coach artegor2008-08-172214822rocket , the midfielder2008-08-232224923destiny2008-08-242235024final preparations2008-08-312245125a team unravels2008-08-31225\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE episode = 31 \nAND original_air_date = '2008-04-19';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1245.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: active from 1947 - 1964 , titus ozon scored 157 goals\nInput Table: list of top association football goal scorers by country\n\n\nranknameyearsmatchesgoals1dudu georgescu1970-01-01 - 1986-01-013702522ionel danciulescu1993-01-01 - present4272103rodion camataru1974-01-01 - 1989-01-013771984marin radu1974-01-01 - 1989-01-013841905ion oblemenco1964-01-01 - 1976-01-012721705florea dumitrache1966-01-01 - 1983-01-013571707mircea sandu1970-01-01 - 1987-01-014071678victor piturca1975-01-01 - 1989-01-013011669mihai adam9999-01-01 - 1976-01-0135316010titus ozon1947-01-01 - 1964-01-01270157\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT goals FROM table_sql WHERE name = 'titus ozon' AND years = '1947-01-01 - 1964-01-01') = 157 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1112.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: tyler forrest is the lead in beausejour\nInput Table: 2009 canadian olympic curling trials\n\n\nskipthird_/_vice_skipsecondleadcitykerry burtnykdon walchukrichard daneaultgarth smithwinnipegpat simmonsgerry adamjeff sharpsteve laycockdavidsonjeff stoughtonkevin parkrob fowlersteve gouldwinnipegwayne middaughjon meadjohn eppingscott baileyislingtonbrad gushuemark nicholsryan fryjamie korabst john 'smike mcewenb j neufeldmatt wozniakdenni neufeldwinnipegjoel jordisonscott bitzaryn schmidtdean hickemoose jawbob urseljim cotterkevin folkrick sawatskykelownajean - michel m\u00e9nardmartin cr\u00eate\u00e9ric sylvainjean gagnonl\u00e9visted appelmantom appelmanbradon klassenbrendan melnykedmontongreg mcaulayken maskiewichdeane horningaaron watsonrichmondjason gunnlaugsonjustin richterbraden zawadatyler forrestbeausejour\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE lead = 'tyler forrest' \nAND city = 'beausejour';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-216.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the 5th volume was released in region 1 on september 19 , 2006 , there were 4 episodes\nInput Table: none\n\n\nvolumediscsepisodesregion_1region_2region_41142006-01-312007-02-192007-03-152142006-03-282007-06-042007-07-053142006-05-302007-09-032008-03-134142006-07-182008-02-182008-06-195142006-09-192008-05-262009-03-05\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE volume = 5 \nAND region_1 = '2006-09-19' \nAND episodes = 4;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1525.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: carlton scored 20.7 when they played richmond at princes park\nInput Table: 1969 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddategeelong16.14 (110)hawthorn14.11 (95)kardinia park315691969-08-23collingwood19.15 (129)south melbourne6.22 (58)victoria park194281969-08-23carlton20.7 (127)richmond24.12 (156)princes park276571969-08-23st kilda21.18 (144)north melbourne8.10 (58)moorabbin oval111091969-08-23melbourne14.13 (97)fitzroy14.15 (99)mcg177901969-08-23footscray14.10 (94)essendon12.10 (82)western oval160431969-08-23\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT home_team_score FROM table_sql WHERE home_team = 'carlton' AND away_team = 'richmond' AND venue = 'princes park') = '20.7 (127)' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1302.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the round played on january 7th 2003 was the first leg of the semi - final\nInput Table: 2002 - 03 manchester united f.c. season\n\n\ndateroundopponentsresult_f_-_aattendance2002-11-05round 3leicester city2 - 0478482002-12-03round 4burnley2 - 0220342002-12-17round 5chelsea1 - 0579852003-01-07semi - final first legblackburn rovers1 - 1627402003-01-22semi - final second legblackburn rovers3 - 1290482003-03-02finalliverpool0 - 274500\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE date = '2003-01-07' \nAND round = 'semi - final first leg';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1189.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: in the 1933 giro d'italia , gerard loncke won the race on may 26th , despite alfredo binda being the race leader\nInput Table: 1933 giro d'italia\n\n\ndatecoursedistancewinnerrace_leader9999-05-06milan to turin-learco guerra ( ita )learco guerra ( ita )9999-05-07turin to genoa-alfredo binda ( ita )alfredo binda ( ita )9999-05-08genoa to pisa-learco guerra ( ita )alfredo binda ( ita )9999-05-09rest dayrest dayrest dayrest day9999-05-10pisa to florence-giuseppe olmo ( ita )alfredo binda ( ita )9999-05-11florence to grosseto-learco guerra ( ita )jef demuysere ( bel )9999-05-12grosseto to rome-mario cipriani ( ita )jef demuysere ( bel )9999-05-13rest dayrest dayrest dayrest day9999-05-14rome to naples-gerard loncke ( bel )jef demuysere ( bel )9999-05-15naples to foggia-alfredo binda ( ita )alfredo binda ( ita )9999-05-16rest dayrest dayrest dayrest day9999-05-17foggia to chieti-alfredo binda ( ita )alfredo binda ( ita )9999-05-18chieti to ascoli piceno-alfredo binda ( ita )alfredo binda ( ita )9999-05-19rest dayrest dayrest dayrest day9999-05-20ascoli piceno to riccione-fernand cornez ( fra )alfredo binda ( ita )9999-05-21riccione to bologna-giuseppe olmo ( ita )alfredo binda ( ita )9999-05-22bologna to ferrara-alfredo binda ( ita )alfredo binda ( ita )9999-05-23rest dayrest dayrest dayrest day9999-05-24ferrara to udine-ettore meini ( ita )alfredo binda ( ita )9999-05-25udine to bassano del grappa-ettore meini ( ita )alfredo binda ( ita )9999-05-26bassano del grappa to bolzano-gerard loncke ( bel )alfredo binda ( ita )9999-05-27rest dayrest dayrest dayrest day9999-05-28bolzano to milan-alfredo binda ( ita )alfredo binda ( ita )2023-09-20-km (mi)-km (mi)\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT winner FROM table_sql WHERE date = '9999-05-26') = 'gerard loncke ( bel )' \n             AND (SELECT race_leader FROM table_sql WHERE date = '9999-05-26') = 'alfredo binda ( ita )' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-602.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there is only one person with a snatch of 153.0 and his total bodyweight is 104.70\nInput Table: weightlifting at the 2007 pan american games\n\n\nnamebodyweightsnatchclean_&_jerktotal_(kg)jo\u00ebl mackenzie ( cub )101.4175.0205.0380.0pedro stetsiuk ( arg )102.45160.0180.0340.0damian abbiate ( arg )104.45150.0188.0338.0bruno brand\u00e3o ( bra )99.1157.0180.0337.0christian l\u00f3pez ( gua )104.7153.0182.0335.0v\u00edctor osorio ( chi )103.05140.0176.0316.0ivorn mcknee ( bar )103.25140.0-dnfjos\u00e9 espinoza ( nca )99.4--dnfboris burov ( ecu )100.4--dnfakos sandor ( can )104.95--dnffabr\u00edcio mafra ( bra )100.75151.0187.0dsq\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 1 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE snatch = 153.0 \nAND bodyweight = 104.7;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-746.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the yugoslavian national team lost the balkan cup against romania with a aggregate score of 3:4\nInput Table: yugoslavia national football team results\n\n\ndatecityopponentresultstype_of_game9999-03-22sarajevouruguay2:1friendly9999-03-30belgraderomania2:0balkan cup9999-04-26borovopoland2:1friendly9999-08-27bucharest , romaniaromania1:4balkan cup9999-09-10luxembourgluxembourg5:01982 wcq9999-09-27ljubljanadenmark2:11982 wcq9999-11-15torino , italyitaly0:21982 wcq\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT SUM(CAST(SUBSTR(results, 1, 1) AS INTEGER)) FROM table_sql WHERE type_of_game = 'balkan cup' AND opponent = 'romania') < \n             (SELECT SUM(CAST(SUBSTR(results, 3, 1) AS INTEGER)) FROM table_sql WHERE type_of_game = 'balkan cup' AND opponent = 'romania') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-662.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: five of the games listed ended with 0 - 0 result\nInput Table: 2008 - 09 bradford city a.f.c. season\n\n\ngamedateopponentvenueresultattendance12008-08-09notts countyhome2 - 11403822008-08-16macclesfield townaway2 - 0255632008-08-23rochdalehome2 - 01315442008-08-30aldershot townaway2 - 3380552008-09-06port valeaway2 - 0727362008-09-13exeter cityhome4 - 11268372008-09-20bournemouthhome1 - 31282482008-09-27shrewsbury townaway0 - 2651792008-10-04luton townhome1 - 113083102008-10-11accrington stanleyaway3 - 23012112008-10-18gillinghamhome2 - 212432122008-10-21darlingtonaway1 - 23034132008-10-24grimsby townaway3 - 14470142008-10-28buryhome1 - 012830152008-11-01barnethome3 - 312510162008-11-15wycombe wanderersaway0 - 15002172008-11-22rotherham unitedaway2 - 04586182008-11-25chesterfieldhome3 - 212145192008-12-06dagenham & redbridgehome1 - 112145202008-12-13brentfordaway1 - 24339212008-12-20chester cityhome0 - 012092222008-12-26lincoln cityaway0 - 06156232008-12-28morecambehome4 - 013105242009-01-03shrewsbury townhome0 - 012877252009-01-17accrington stanleyhome1 - 112172262009-01-24luton townaway3 - 36053272009-01-27buryaway0 - 14112282009-01-31grimsby townhome2 - 012816292009-02-07gillinghamaway2 - 04866302009-02-14wycombe wanderershome1 - 012689312009-02-17darlingtonhome0 - 012782322009-02-21barnetaway1 - 42445332009-02-28notts countyaway1 - 35138342009-03-01macclesfield townhome1 - 011908352009-03-07aldershot townhome5 - 012465362009-03-10rochdaleaway0 - 35157372009-03-14exeter cityaway0 - 15253382009-03-17bournemouthaway1 - 44847392009-03-21port valehome0 - 112436402009-03-28chester cityaway0 - 02735412009-04-04brentfordhome1 - 112832422009-04-10morecambeaway1 - 24546432009-04-13lincoln cityhome1 - 112932\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 5 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE result = '0 - 0';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1157.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the detroit pistons won by over ten points in three games during this period of their 2010 - 2011 season\nInput Table: 2010 - 11 detroit pistons season\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord629999-03-01milwaukeel 90 - 92 (ot)rodney stuckey (25)greg monroe , charlie villanueva (9)rodney stuckey (5)bradley center 1136422 - 40639999-03-02minnesotal 105 - 116 (ot)austin daye (22)greg monroe (11)rodney stuckey (10)the palace of auburn hills 1312222 - 41649999-03-06washingtonw 113 - 102 (ot)tayshaun prince (20)greg monroe , rodney stuckey (7)rodney stuckey (9)the palace of auburn hills 1750623 - 41659999-03-09san antoniol 104 - 111 (ot)richard hamilton (20)greg monroe (10)tracy mcgrady (9)at&t center 1858123 - 42669999-03-11oklahoma cityl 94 - 104 (ot)richard hamilton (20)greg monroe (10)greg monroe , rodney stuckey (6)oklahoma city arena 1820323 - 43679999-03-12denverl 101 - 131 (ot)chris wilcox (21)austin daye , ben gordon , greg monroe (6)will bynum (10)pepsi center 1915523 - 44689999-03-16torontow 107 - 93 (ot)richard hamilton (24)greg monroe (10)rodney stuckey (14)the palace of auburn hills 1516624 - 44699999-03-18new yorkw 99 - 95 (ot)tayshaun prince (16)chris wilcox (12)will bynum (5)the palace of auburn hills 2207625 - 44709999-03-20atlantal 96 - 104 (ot)rodney stuckey (22)greg monroe (10)rodney stuckey (8)philips arena 1758025 - 45719999-03-23miamil 94 - 100 (ot)richard hamilton (27)greg monroe (12)rodney stuckey (6)the palace of auburn hills 2207625 - 46729999-03-25clevelandl 91 - 97 (ot)richard hamilton , tayshaun prince (15)chris wilcox , greg monroe (8)rodney stuckey (4)quicken loans arena 1990725 - 47739999-03-26indianaw 100 - 88 (ot)richard hamilton (23)greg monroe (13)richard hamilton , rodney stuckey (6)the palace of auburn hills 1921626 - 47\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) >= 3 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE score LIKE 'w%' \nAND CAST(SUBSTR(score, INSTR(score, ' ') + 1, INSTR(score, '-') - INSTR(score, ' ') - 1) AS INTEGER) > 10;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1340.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: in 1962 , the victorian football league season took place on 23 june\nInput Table: 1962 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddatemelbourne11.18 (84)st kilda11.6 (72)mcg489521962-06-23essendon15.17 (107)geelong10.7 (67)windy hill350001962-06-23collingwood10.14 (74)fitzroy9.11 (65)victoria park264881962-06-23carlton12.9 (81)footscray9.10 (64)princes park324001962-06-23south melbourne10.13 (73)richmond11.13 (79)lake oval170001962-06-23north melbourne10.8 (68)hawthorn10.7 (67)arden street oval84701962-06-23\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE date = '1962-06-23';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-529.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: lake oval venue recorded a lower crowd participation than that of the glenferrie oval venue\nInput Table: 1961 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddatenorth melbourne9.14 (68)st kilda11.16 (82)arden street oval130001961-06-03hawthorn10.13 (73)richmond8.12 (60)glenferrie oval150001961-06-03collingwood18.11 (119)essendon8.10 (58)victoria park282901961-06-03geelong13.13 (91)footscray4.14 (38)kardinia park186831961-06-03south melbourne7.8 (50)fitzroy17.15 (117)lake oval145001961-06-03melbourne15.14 (104)carlton11.13 (79)mcg496781961-06-03\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT crowd FROM table_sql WHERE venue = 'lake oval') < \n             (SELECT crowd FROM table_sql WHERE venue = 'glenferrie oval') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-214.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: volume 5 , of 4 episodes , took place of september 19 , 2006 , in region 1\nInput Table: none\n\n\nvolumediscsepisodesregion_1region_2region_41142006-01-312007-02-192007-03-152142006-03-282007-06-042007-07-053142006-05-302007-09-032008-03-134142006-07-182008-02-182008-06-195142006-09-192008-05-262009-03-05\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE volume = 5 \nAND episodes = 4 \nAND region_1 = '2006-09-19';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1752.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: august 31st 1947 was the date of the first game of the season\nInput Table: 1947 san francisco 49ers season\n\n\nweekdateopponentresultscorerecord11947-08-31brooklyn dodgersw23 - 71 - 021947-09-07los angeles donsw17 - 142 - 031947-09-14baltimore coltsw14 - 73 - 041947-09-21new york yankeesl21 - 163 - 151947-09-28buffalo billsw41 - 244 - 161947-10-05baltimore coltst28 - 284 - 1 - 171947-10-12chicago rocketsw42 - 285 - 1 - 181947-10-26cleveland brownsl14 - 75 - 2 - 191947-11-02los angeles donsw26 - 166 - 2 - 1101947-11-09new york yankeesl24 - 166 - 3 - 1111947-11-16cleveland brownsl37 - 146 - 4 - 1121947-11-21chicago rocketsw41 - 167 - 4 - 1131947-11-27brooklyn dodgersw21 - 78 - 4 - 1141947-12-07buffalo billst21 - 218 - 4 - 2\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE date = '1947-08-31';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-601.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: bruno brand\u00e3o from brazil has a snatch of 157.0\nInput Table: weightlifting at the 2007 pan american games\n\n\nnamebodyweightsnatchclean_&_jerktotal_(kg)jo\u00ebl mackenzie ( cub )101.4175.0205.0380.0pedro stetsiuk ( arg )102.45160.0180.0340.0damian abbiate ( arg )104.45150.0188.0338.0bruno brand\u00e3o ( bra )99.1157.0180.0337.0christian l\u00f3pez ( gua )104.7153.0182.0335.0v\u00edctor osorio ( chi )103.05140.0176.0316.0ivorn mcknee ( bar )103.25140.0-dnfjos\u00e9 espinoza ( nca )99.4--dnfboris burov ( ecu )100.4--dnfakos sandor ( can )104.95--dnffabr\u00edcio mafra ( bra )100.75151.0187.0dsq\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT snatch FROM table_sql WHERE name LIKE '%bruno brand\u00e3o%') = 157.0 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1568.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: henrik stenson is from sweden , aaron baddeley is from australia , and charlie wi is from south korea\nInput Table: 2008 pga championship\n\n\nplaceplayercountryscoreto_par1ben curtisunited states73 + 67 + 68 = 208- 2t2j b holmesunited states71 + 68 + 70 = 209- 1t2henrik stensonsweden71 + 70 + 68 = 209- 1t4sergio garc\u00edaspain69 + 73 + 69 = 211+ 1t4p\u00e1draig harringtonireland71 + 74 + 66 = 211+ 1t4charlie wisouth korea70 + 70 + 71 = 211+ 1t7andr\u00e9s romeroargentina69 + 78 + 65 = 212+ 2t7jeev milkha singhindia68 + 74 + 70 = 212+ 2t9aaron baddeleyaustralia71 + 71 + 71 = 213+ 3t9steve fleschunited states73 + 70 + 70 = 213+ 3t9david tomsunited states72 + 69 + 72 = 213+ 3t9camilo villegascolombia74 + 72 = 67 = 213+ 3\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT country FROM table_sql WHERE player = 'henrik stenson') = 'sweden' \n             AND (SELECT country FROM table_sql WHERE player = 'aaron baddeley') = 'australia' \n             AND (SELECT country FROM table_sql WHERE player = 'charlie wi') = 'south korea' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-726.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: in the final of katerina maleeva versus her opponent , the score was 6 - 2 , 7 - 6 (3)\nInput Table: isabel cueto\n\n\ndatetournamentsurfaceopponent_in_the_finalscore1988-07-04b\u00e5stad , swedenclaysandra cecchini7 - 5 , 6 - 11988-08-01athens , greececlaylaura golarsa6 - 0 , 6 - 11989-07-17estoril , portugalclaysandra cecchini7 - 6 (3) , 6 - 21989-07-31sofia , bulgariaclaykaterina maleeva6 - 2 , 7 - 6 (3)1990-07-09palermo , italyclaybarbara paulus6 - 2 , 6 - 3\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN score = '6 - 2 , 7 - 6 (3)' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE tournament = 'sofia , bulgaria' \nAND opponent_in_the_final = 'katerina maleeva';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-898.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: jim laker played in fewer matches than any of the australian players\nInput Table: 1948 ashes series\n\n\nplayerteammatcheswicketsaveragebest_bowlingray lindwallaustralia52719.626 / 20bill johnstonaustralia52723.335 / 36alec bedserengland51838.224 / 81keith milleraustralia51323.154 / 125ernie toshackaustralia41133.095 / 40norman yardleyengland5922.662 / 32jim lakerengland3952.444 / 138\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT matches FROM table_sql WHERE player = 'jim laker') < \n             (SELECT MIN(matches) FROM table_sql WHERE team = 'australia') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1138.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the home team st kilda played away team north melbourne , who had a score of 12.11 (83)\nInput Table: 1946 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddategeelong15.7 (97)melbourne21.14 (140)kardinia park115001946-07-13essendon16.24 (120)footscray14.8 (92)windy hill290001946-07-13collingwood15.23 (113)hawthorn11.14 (80)victoria park110001946-07-13carlton12.13 (85)south melbourne11.18 (84)princes park260001946-07-13st kilda10.14 (74)north melbourne12.11 (83)junction oval70001946-07-13richmond14.14 (98)fitzroy10.12 (72)punt road oval190001946-07-13\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE home_team = 'st kilda' \nAND away_team = 'north melbourne' \nAND away_team_score = '12.11 (83)';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-510.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the fourth elected incumbant sidney r yates was in 1964\nInput Table: united states house of representatives elections , 1974\n\n\ndistrictincumbentpartyfirst_electedresultcandidatesillinois 3robert p hanrahanrepublican1972-01-01lost re - election democratic gainmarty russo (d) 52.6% robert p hanrahan (r) 47.4%illinois 4ed derwinskirepublican1958-01-01re - electeded derwinski (r) 59.2% ronald a rodger (d) 40.8%illinois 6harold r collierrepublican1956-01-01retired republican holdhenry hyde (r) 53.4% edward v hanrahan (d) 46.6%illinois 9sidney r yatesdemocratic1964-01-01re - electedsidney r yates (d) unopposedillinois 10samuel h youngrepublican1972-01-01lost re - election democratic gainabner j mikva (d) 50.9% samuel h young (r) 49.1%illinois 12phil cranerepublican1969-01-01re - electedphil crane (r) 61.1% betty c spence (d) 38.9%illinois 19tom railsbackrepublican1966-01-01re - electedtom railsback (r) 65.3% jim gende (d) 34.7%illinois 20paul findleyrepublican1960-01-01re - electedpaul findley (r) 54.8% peter f mack (d) 45.2%illinois 23melvin pricedemocratic1944-01-01re - electedmelvin price (d) 80.5% scott randolph (r) 19.5%\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE first_elected = '1964-01-01' \nAND incumbent = 'sidney r yates';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1308.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: player fred couples has a score 72 + 67 + 71 = 210\nInput Table: 1988 u.s. open (golf)\n\n\nplaceplayercountryscoreto_par1curtis strangeunited states70 + 67 + 69 = 206- 7t2nick faldoengland72 + 67 + 68 = 207- 6t2bob gilderunited states68 + 69 + 70 = 207- 6t2scott simpsonunited states69 + 66 + 72 = 207- 6t5larry mizeunited states69 + 67 + 72 = 208- 5t5d a weibringunited states71 + 69 + 68 = 208- 57mark o'mearaunited states71 + 72 + 66 = 209- 48fred couplesunited states72 + 67 + 71 = 210- 39lanny wadkinsunited states70 + 71 + 70 = 211- 210ken greenunited states72 + 70 + 70 = 212- 1\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT score FROM table_sql WHERE player = 'fred couples') = '72 + 67 + 71 = 210' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-992.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: mike clattenburg directed one more episode than steve scaini\nInput Table: list of republic of doyle episodes\n\n\nUnnamed:_0titledirected_bywritten_byviewersoriginal_airdateprod_code1fathers and sonsmike clattenburgallan hawco , perry chafe and malcolm macrury9690002010-01-061012the return of the grievous angelsteve dimarcoallan hawco and avrum jacobson7150002010-01-131023duchess of georgemike clattenburgallan hawco , perry chafe and malcolm macrury6850002010-01-201035hit and rumsteve dimarcomatt maclennan5940002010-02-031056the one who got awaylarry mcleanjesse mckeown10120002010-02-101067the woman who knew too littlerobert liebermanjeremy boxen10530002010-03-031078the tell - tale safejerry ciccorittijohn callaghan and steve cochrane9860002010-03-101089he sleeps with the chipsphil earnshawperry chafe9080002010-03-1710910the pen is mightier than the doylerobert liebermansteve cochrane and avrum jacobson8970002010-03-2411011a horse dividedsteve scainijesse mckeown9020002010-03-31111\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE directed_by = 'mike clattenburg') > \n             (SELECT COUNT(*) FROM table_sql WHERE directed_by = 'steve scaini') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-145.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the final game score was 7 - 2 in two different games of the 2006 season\nInput Table: 2006 texas rangers season\n\n\ndateopponentscorelossattendancerecord9999-09-01indians7 - 2padilla (13 - 9)2377669 - 679999-09-02indians6 - 5volquez (1 - 4)4022269 - 689999-09-03indians5 - 2byrd1966770 - 689999-09-04athletics8 - 1zito2394971 - 689999-09-05athletics5 - 4saarloos2722572 - 689999-09-06athletics9 - 6rupe (0 - 1)1783872 - 699999-09-08mariners7 - 2millwood (14 - 10)2864672 - 709999-09-09mariners3 - 2rheinecker (4 - 6)3345472 - 719999-09-10mariners4 - 2huber3432173 - 719999-09-12tigers3 - 2mahay (1 - 3)2419673 - 729999-09-13tigers11 - 3verlander2467274 - 729999-09-14angels2 - 1volquez (1 - 5)2148874 - 739999-09-15angels2 - 1francisco (0 - 1)3078874 - 749999-09-16angels12 - 6lackey4019675 - 749999-09-17angels8 - 1santana2430376 - 749999-09-18mariners8 - 1hern\u00e1ndez1821477 - 749999-09-19mariners9 - 7wilson (2 - 3)1855177 - 759999-09-20mariners6 - 3tejeda (4 - 4)2600677 - 769999-09-22indians12 - 4byrd2628478 - 769999-09-23indians6 - 3padilla (14 - 10)3835178 - 779999-09-24indians11 - 6millwood (16 - 11)3661778 - 789999-09-25angels8 - 3volquez (1 - 6)3978178 - 799999-09-26angels5 - 2escobar3733979 - 799999-09-27angels6 - 5wilson (2 - 4)3803279 - 809999-09-29mariners6 - 5fruto3076680 - 809999-09-30mariners3 - 1millwood (16 - 12)2331080 - 819999-10-01mariners3 - 2tejeda (5 - 5)2836180 - 82\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 2 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE score = '7 - 2';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1929.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: mickael delage is the only person to appear in the mountain classification just one time\nInput Table: 2010 vuelta a espa\u00f1a\n\n\nstagewinnergeneral_classificationpoints_classificationmountains_classificationcombination_classificationteam_classification1team htc - columbiamark cavendishmark cavendish 1not awardedmark cavendishteam htc - columbia2yauheni hutarovichmark cavendishyauheni hutarovichmicka\u00ebl delagejavier ram\u00edrezteam htc - columbia3philippe gilbertphilippe gilbertphilippe gilbertseraf\u00edn mart\u00ednezseraf\u00edn mart\u00ednezteam htc - columbia4igor ant\u00f3nphilippe gilbertigor ant\u00f3nseraf\u00edn mart\u00ednezvincenzo nibalicaisse d'epargne5tyler farrarphilippe gilbertigor ant\u00f3nseraf\u00edn mart\u00ednezvincenzo nibalicaisse d'epargne6thor hushovdphilippe gilbertphilippe gilbertseraf\u00edn mart\u00ednezphilippe gilbertcaisse d'epargne7alessandro petacchiphilippe gilbertmark cavendishseraf\u00edn mart\u00ednezphilippe gilbertcaisse d'epargne8david moncouti\u00e9igor ant\u00f3nmark cavendishseraf\u00edn mart\u00ednezvincenzo nibalicaisse d'epargne9david l\u00f3pezigor ant\u00f3nmark cavendishdavid moncouti\u00e9vincenzo nibalicaisse d'epargne10imanol ervitijoaquim rodr\u00edguezmark cavendishdavid moncouti\u00e9david moncouti\u00e9caisse d'epargne11igor ant\u00f3nigor ant\u00f3nigor ant\u00f3ndavid moncouti\u00e9igor ant\u00f3ncaisse d'epargne12mark cavendishigor ant\u00f3nmark cavendishdavid moncouti\u00e9igor ant\u00f3ncaisse d'epargne13mark cavendishigor ant\u00f3nmark cavendishdavid moncouti\u00e9igor ant\u00f3ncaisse d'epargne14joaquim rodr\u00edguezvincenzo nibalimark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezcaisse d'epargne15carlos barredovincenzo nibalimark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezteam katusha16mikel nievejoaquim rodr\u00edguezmark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezteam katusha17peter velitsvincenzo nibalimark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezteam katusha18mark cavendishvincenzo nibalimark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezteam katusha19philippe gilbertvincenzo nibalimark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezteam katusha20ezequiel mosquera 2vincenzo nibalimark cavendishdavid moncouti\u00e9vincenzo nibaliteam katusha21tyler farrarvincenzo nibalimark cavendishdavid moncouti\u00e9vincenzo nibaliteam katusha\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 1 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE mountains_classification = 'micka\u00ebl delage';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1386.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: galloway & upper nithsdal winning party 2003 is conservative while that of paisley south is labour\nInput Table: scottish parliament general election , 2007\n\n\nrankconstituencywinning_party_2003swing_to_gainsnp_'s_place_2003result1galloway & upper nithsdaleconservative0.172ndcon hold2tweeddale , ettrick & lauderdaleliberal democrats1.012ndld hold3cumbernauld & kilsythlabour1.072ndlab hold4kilmarnock & loudounlabour1.922ndsnp gain5dundee westlabour2.132ndsnp gain6western isleslabour2.912ndsnp gain7glasgow govanlabour2.922ndsnp gain8aberdeen centrallabour2.962ndlab hold9linlithgowlabour3.562ndlab hold10west renfrewshirelabour4.412ndlab hold11paisley southlabour4.912ndlab hold\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT winning_party_2003 FROM table_sql WHERE constituency = 'galloway & upper nithsdale') = 'conservative' \n             AND (SELECT winning_party_2003 FROM table_sql WHERE constituency = 'paisley south') = 'labour' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1570.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: sergio garc\u00eda , p\u00e1draig harrington and charlie wi tied for 4th place with + 1 to par\nInput Table: 2008 pga championship\n\n\nplaceplayercountryscoreto_par1ben curtisunited states73 + 67 + 68 = 208- 2t2j b holmesunited states71 + 68 + 70 = 209- 1t2henrik stensonsweden71 + 70 + 68 = 209- 1t4sergio garc\u00edaspain69 + 73 + 69 = 211+ 1t4p\u00e1draig harringtonireland71 + 74 + 66 = 211+ 1t4charlie wisouth korea70 + 70 + 71 = 211+ 1t7andr\u00e9s romeroargentina69 + 78 + 65 = 212+ 2t7jeev milkha singhindia68 + 74 + 70 = 212+ 2t9aaron baddeleyaustralia71 + 71 + 71 = 213+ 3t9steve fleschunited states73 + 70 + 70 = 213+ 3t9david tomsunited states72 + 69 + 72 = 213+ 3t9camilo villegascolombia74 + 72 = 67 = 213+ 3\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE place = 't4' AND to_par = '+ 1') = 3 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-766.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: roger dutton / tony wright received 3 points for 8th place\nInput Table: 1972 isle of man tt\n\n\nplaceridercountrymachinespeedtimepoints1siegfried schauzu / wolfgang kalauchwest germanybmw91.85 mph1:13.57.2152heinz luthringshauser / jcusnikwest germanybmw91.70 mph1:14.04.6123gerry boret / nick boretunited kingdomkonig84.43 mph1:20.27.4104wklenk / nscheererwest germanybmw83.62 mph1:21.31.885barry dungworth / rwturringtonunited kingdombmw82.32 mph1:22.30.666roy hanks / jpmannunited kingdombsa80.07 mph1:24.49.657rwoodhouse / dwoodhouseunited kingdombsa79.83 mph1.25.05.4048roger dutton / tony wrightunited kingdombmw79.63 mph1.25.18.039george o'dell / bill boldisonunited kingdombsa79.60 mph1.25.20.2210jbarker / amacfadzeanunited kingdombsa79.52 mph1.25.28.21\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT points FROM table_sql WHERE place = 8 AND rider = 'roger dutton / tony wright') = 3 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1491.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: linfield was the opponent in venue a\nInput Table: 2003 - 04 rangers f.c. season\n\n\ndateopponentvenueresultattendance2003-07-16greuther f\u00fcrthn2 - 035002003-07-19vfb auerbacha5 - 125002003-07-19erzgebirge auea1 - 025002003-07-22jahn regensburga1 - 250002003-07-26evertonh2 - 3280002003-07-30linfielda3 - 0132842003-08-05arsenalh0 - 337000\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE opponent = 'linfield' \nAND venue = 'a';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1597.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: antonio pompa - baldi italy took the first postion in year 1999\nInput Table: cleveland international piano competition\n\n\nyearfirstsecondthirdfourth2013stanislav khristenko russiaarseny tarasevich - nikolaev russiafran\u00e7ois dumont francejiayan sun china2011alexander schimpf germanyalexei chernov russiaeric zuber usakyu yeon kim south korea2009martina filjak croatiadmitri levkovich canadawilliam youn south koreaevgeny brakhman russia2007alexander ghindin russiayaron kohlberg israelalexandre moutouzkine russiaran dank israel2005chu - fang huang chinasergey kuznetsov russiastanislav khristenko russiaspencer myer usa2003kotaro fukuma japansoyeon lee south koreakonstantin soukhovetski russiaandrius zlabys lithuania2001roberto plano italyminsoo sohn south korea\u00f6zg\u00fcr aydin turkeygilles vonsattel switzerland1999antonio pompa - baldi italyvassily primakov russiashoko inoue japansean botkin usa1997per tengstrand swedengulnora alimova uzbekistanning an chinadror biran israel1995margarita shevchenko russiamarina lomazov / ukraine / usadmitri teterin russiagiampaolo stuani italy1993amir katz israelnot awardedseizo azuma and japan yuko nakamichi japankatsunori ishii japan1991ilya itin russiaanders martinson usamarkus pawlik germanyjean - fran\u00e7ois bouvery france1989sergei babayan armenia ( ussr )nicholas angelich usamegumi kaneko japanpascal godart france1987thierry huillet franceasaf zohar israeljonathan bass usabeatrice hsin - chen long / taiwan / china1985daejin kim south koreabenedetto lupo italyh\u00e9l\u00e8ne jeanney franceneil rutman usa1983youngshin an south koreamayumi kameda japanst\u00e9phane lemelin canadaroy kogan usa1981philippe bianconi francedan riddle usar\u00e9my loumbrozo franceroy kogan usa1979edward newman usajean - yves thibaudet franceangela hewitt canadafrederick blum usa1977nathalie bera - tagrine francebarry salwen usadouglas montgomery usalaura silverman usa1975john owings usajulian martin usajohn - patrick millow franceroe van boskirk usa\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE year = 1999 \nAND first = 'antonio pompa - baldi italy';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1317.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: robert bauman was the republican incumbent who won the race in 1973\nInput Table: united states house of representatives elections , 1974\n\n\ndistrictincumbentpartyfirst_electedresultcandidatesmaryland 1robert baumanrepublican1973-01-01re - electedrobert bauman (r) 53.0% thomas j hatem (d) 47.0%maryland 2clarence longdemocratic1962-01-01re - electedclarence long (d) 77.1% john m seney (r) 22.9%maryland 4marjorie holtrepublican1972-01-01re - electedmarjorie holt (r) 58.1% fred l wineland (d) 41.9%maryland 6goodloe byrondemocratic1970-01-01re - electedgoodloe byron (d) 73.7% elton r wampler (r) 26.3%maryland 7parren mitchelldemocratic1970-01-01re - electedparren mitchell (d) unopposed\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE district = 'maryland 1' \nAND incumbent = 'robert bauman' \nAND party = 'republican' \nAND first_elected = '1973-01-01' \nAND result = 're - elected';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-820.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: kenny perry earned 170000 less than mark brooks\nInput Table: 1996 pga championship\n\n\nplaceplayercountryscoreto_parmoney1mark brooksunited states68 + 70 + 69 + 70 = 277- 114300002kenny perryunited states66 + 72 + 71 + 68 = 277- 11260000t3steve elkingtonaustralia67 + 74 + 67 + 70 = 278- 10140000t3tommy tollesunited states69 + 71 + 71 + 67 = 278- 10140000t5justin leonardunited states71 + 66 + 72 + 70 = 279- 986667t5jesper parneviksweden73 + 67 + 69 + 70 = 279- 986667t5vijay singhfiji69 + 69 + 69 + 72 = 279- 986667t8lee janzenunited states68 + 71 + 71 + 70 = 280- 857500t8per - ulrik johanssonsweden73 + 72 + 66 + 69 = 280- 857500t8phil mickelsonunited states67 + 67 + 74 + 72 = 280- 857500t8larry mizeunited states71 + 70 + 69 + 70 = 280- 857500t8frank nobilonew zealand69 + 72 + 71 + 68 = 280- 857500t8nick pricezimbabwe68 + 71 + 69 + 72 = 280- 857500\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT money FROM table_sql WHERE player = 'kenny perry') = \n             (SELECT money FROM table_sql WHERE player = 'mark brooks') - 170000 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-453.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the dolphins finished the regular season with a 12 - 4 record\nInput Table: 1983 miami dolphins season\n\n\nweekdateopponentresultattendance11983-09-04buffalo billsw 12 - 07871521983-09-11new england patriotsw 34 - 245934331983-09-19los angeles raidersl 27 - 145779641983-09-25kansas city chiefsw 14 - 65078551983-10-02new orleans saintsl 17 - 76648961983-10-09buffalo billsl 38 - 355994871983-10-16new york jetsw 32 - 145861581983-10-23baltimore coltsw 21 - 73234391983-10-30los angeles ramsw 30 - 1472175101983-11-06san francisco 49ersw 20 - 1757832111983-11-13new england patriotsl 17 - 660771121983-11-20baltimore coltsw 37 - 054482131983-11-28cincinnati bengalsw 38 - 1474506141983-12-04houston oilersw 24 - 1739434151983-12-10atlanta falconsw 31 - 2456725161983-12-16new york jetsw 34 - 1459975\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE result LIKE 'w%') = 12 \n             AND (SELECT COUNT(*) FROM table_sql WHERE result LIKE 'l%') = 4 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1110.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: steve gould is the lead in the city of winnipeg\nInput Table: 2009 canadian olympic curling trials\n\n\nskipthird_/_vice_skipsecondleadcitykerry burtnykdon walchukrichard daneaultgarth smithwinnipegpat simmonsgerry adamjeff sharpsteve laycockdavidsonjeff stoughtonkevin parkrob fowlersteve gouldwinnipegwayne middaughjon meadjohn eppingscott baileyislingtonbrad gushuemark nicholsryan fryjamie korabst john 'smike mcewenb j neufeldmatt wozniakdenni neufeldwinnipegjoel jordisonscott bitzaryn schmidtdean hickemoose jawbob urseljim cotterkevin folkrick sawatskykelownajean - michel m\u00e9nardmartin cr\u00eate\u00e9ric sylvainjean gagnonl\u00e9visted appelmantom appelmanbradon klassenbrendan melnykedmontongreg mcaulayken maskiewichdeane horningaaron watsonrichmondjason gunnlaugsonjustin richterbraden zawadatyler forrestbeausejour\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE lead = 'steve gould' \nAND city = 'winnipeg';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1601.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: during the 2007 - 08 minnesota wild season , the score was the same on february 27 and february 29\nInput Table: 2007 - 08 minnesota wild season\n\n\ndatevisitorscorehomedecisionattendancerecord01-02-9999minnesota4 - 1columbusbackstrom1852930 - 19 - 39999-02-05detroit3 - 2minnesotabackstrom1856830 - 19 - 401-02-07dallas1 - 0minnesotabackstrom1856830 - 20 - 49999-02-09ny islanders3 - 4minnesotabackstrom1856831 - 20 - 401-02-10minnesota2 - 1st louisharding1647732 - 20 - 401-02-12minnesota2 - 4edmontonharding1683932 - 21 - 401-02-14minnesota5 - 4vancouverbackstrom1863033 - 21 - 49999-02-17nashville4 - 5minnesotabackstrom1856834 - 21 - 49999-02-19vancouver3 - 2minnesotabackstrom1856834 - 21 - 59999-02-20minnesota0 - 3chicagoharding1781234 - 22 - 59999-02-24calgary2 - 1minnesotabackstrom1856834 - 23 - 59999-02-26minnesota1 - 4washingtonbackstrom1739134 - 24 - 59999-02-27minnesota3 - 2tampa baybackstrom1721135 - 24 - 59999-02-29minnesota3 - 2floridabackstrom1692736 - 24 - 5\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT score FROM table_sql WHERE date = '9999-02-27') = \n             (SELECT score FROM table_sql WHERE date = '9999-02-29') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-962.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the title of the episode that aired on march 31 , 2008 is , new york : secret societies\nInput Table: cities of the underworld\n\n\nproduction_noepisode_nooriginal_airdateepisode_titlehost152012008-01-28underground apocalypsedon wildman162022008-02-04vietnamdon wildman172032008-02-11a - bomb undergrounddon wildman182042008-02-25viking undergrounddon wildman192052008-03-03hitler 's last secretdon wildman202062008-03-10maya undergrounddon wildman212072008-03-17mob undergrounddon wildman222082008-03-24prophecies from belowdon wildman232092008-03-31new york : secret societiesdon wildman242102008-04-14washington , dc : seat of powerdon wildman252112008-04-21stalin 's secret lairdon wildman262122008-04-28katrina undergrounddon wildman272132008-05-05secret soviet basesdon wildman\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN episode_title = 'new york : secret societies' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE original_airdate = '2008-03-31';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1113.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: brendan melnyk is the lead and ted appelman is skip\nInput Table: 2009 canadian olympic curling trials\n\n\nskipthird_/_vice_skipsecondleadcitykerry burtnykdon walchukrichard daneaultgarth smithwinnipegpat simmonsgerry adamjeff sharpsteve laycockdavidsonjeff stoughtonkevin parkrob fowlersteve gouldwinnipegwayne middaughjon meadjohn eppingscott baileyislingtonbrad gushuemark nicholsryan fryjamie korabst john 'smike mcewenb j neufeldmatt wozniakdenni neufeldwinnipegjoel jordisonscott bitzaryn schmidtdean hickemoose jawbob urseljim cotterkevin folkrick sawatskykelownajean - michel m\u00e9nardmartin cr\u00eate\u00e9ric sylvainjean gagnonl\u00e9visted appelmantom appelmanbradon klassenbrendan melnykedmontongreg mcaulayken maskiewichdeane horningaaron watsonrichmondjason gunnlaugsonjustin richterbraden zawadatyler forrestbeausejour\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT lead FROM table_sql WHERE skip = 'ted appelman') = 'brendan melnyk' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-26.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: only two times was the attendance less than 20000 people and it was on august 4 and august 5\nInput Table: 1997 colorado rockies season\n\n\ndateopponentscorelossattendancerecord9999-08-01pirates7 - 6rinc\u00f3n (4 - 5)2265752 - 589999-08-02pirates6 - 5swift (4 - 5)3238852 - 599999-08-03pirates8 - 4reed (3 - 5)2498952 - 609999-08-04phillies7 - 3castillo (8 - 10)1523052 - 619999-08-05phillies4 - 2bottalico (2 - 4)1642853 - 619999-08-06mets4 - 0mlicki (5 - 8)2663354 - 619999-08-07mets12 - 4swift (4 - 6)2953654 - 629999-08-08pirates5 - 3lieber (6 - 12)4826255 - 629999-08-09pirates8 - 7rinc\u00f3n (4 - 6)4832356 - 629999-08-10pirates8 - 7wilkins (7 - 3)4801857 - 629999-08-12phillies5 - 0thomson (4 - 7)4822857 - 639999-08-13phillies12 - 8wright (6 - 8)4849157 - 649999-08-15mets6 - 2reed (10 - 6)4830858 - 649999-08-16mets7 - 5mcmichael (7 - 10)4831159 - 649999-08-17mets6 - 4mlicki (5 - 10)4844060 - 649999-08-19reds6 - 5wright (6 - 9)3172260 - 659999-08-20reds5 - 3white (1 - 1)2196861 - 659999-08-21astros10 - 4bailey (9 - 9)2296261 - 669999-08-22astros9 - 1thomson (5 - 8)3306161 - 679999-08-23astros6 - 3hudek (0 - 2)3237462 - 679999-08-24astros3 - 1wright (6 - 10)2891862 - 689999-08-25reds7 - 6castillo (10 - 11)4814362 - 699999-08-25reds6 - 4hutton (3 - 2)4808162 - 709999-08-26reds9 - 5mart\u00ednez (1 - 1)4806363 - 709999-08-27reds7 - 5remlinger (6 - 6)4803264 - 709999-08-28mariners9 - 5olivares (6 - 9)4842265 - 709999-08-29mariners6 - 5timlin (3 - 3)4817866 - 709999-08-30athletics4 - 3mohler (1 - 10)4830867 - 709999-08-31athletics10 - 4oquist (2 - 5)4804168 - 70\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE attendance < 20000) = 2 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1710.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: for the class vesuvius with wheel arrangement 2 - 4 - 0 , the quantity made was 32 and quantity preserved was 0\nInput Table: locomotives of the southern railway\n\n\nclasswheel_arrangementmanufactureryear_madequantity_madequantity_preservedyear_(s)_withdrawnjoseph hamilton beattie (1850 - 1871)joseph hamilton beattie (1850 - 1871)joseph hamilton beattie (1850 - 1871)joseph hamilton beattie (1850 - 1871)joseph hamilton beattie (1850 - 1871)joseph hamilton beattie (1850 - 1871)joseph hamilton beattie (1850 - 1871)hercules2 - 4 - 0nine elms works1851 - 18541501875 - 1884tartar2 - 2 - 2wtsharp brothers1852601871 - 1874sussex2 - 2 - 2wtnine elms works1852801871 - 1876canute2 - 2 - 2nine elms works1855 - 18591201875 - 1885saxon2 - 4 - 0nine elms works1855 - 18571201877 - 1885chaplin2 - 2 - 2wtnine elms works1856301876 - 1877minerva2 - 4 - 0wtnine elms works1856301874 - 1883nelson2 - 4 - 0wtnine elms works1858301882 - 1885nile2 - 4 - 0wtnine elms works1859301882tweed2 - 4 - 0nine elms works1858 - 1859601877 - 1879undine2 - 4 - 0nine elms works1859 - 601201884 - 1886clyde2 - 4 - 0nine elms works1859 - 18681301883 - 1899gem2 - 4 - 0nine elms works1862 - 1863601884 - 1885eagle2 - 4 - 0nine elms works1862301885 - 1886falcon2 - 4 - 0nine elms works1863 - 18671701882 - 18981772 - 4 - 0wtbeyer , peacock & co (82) nine elms works (3)1863 - 18758521886 - 1899 , 1962lion0 - 6 - 0nine elms works1863 - 18733801886 - 1900volcano2 - 4 - 0nine elms works1866 - 18731801886 - 18972210 - 6 - 0beyer , peacock & co1866 - 18732401891 - 19242312 - 4 - 0beyer , peacock & co1866601892 - 1899vesuvius2 - 4 - 0nine elms works1869 - 18753201893 - 1899\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT quantity_made FROM table_sql WHERE class = 'vesuvius' AND wheel_arrangement = '2 - 4 - 0') = 32 \n             AND (SELECT quantity_preserved FROM table_sql WHERE class = 'vesuvius' AND wheel_arrangement = '2 - 4 - 0') = 0 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1066.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there are two games that took place in the month of december\nInput Table: 1976 buffalo bills season\n\n\nweekdateopponentresultattendance11976-09-13miami dolphinsl 30 - 217768321976-09-19houston oilersl 13 - 36138431976-09-26tampa bay buccaneersw 14 - 94450541976-10-03kansas city chiefsw 50 - 175190951976-10-10new york jetsl 17 - 145911061976-10-17baltimore coltsl 31 - 137100971976-10-24new england patriotsl 26 - 224514481976-10-31new york jetsl 19 - 144128591976-11-07new england patriotsl 20 - 1061157101976-11-15dallas cowboysl 17 - 1051799111976-11-21san diego chargersl 34 - 1336539121976-11-25detroit lionsl 27 - 1466875131976-12-05miami dolphinsl 45 - 2743475141976-12-12baltimore coltsl 58 - 2050451\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 2 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE strftime('%m', date) = '12';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1992.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: a 2000 steam buggy themed coin by artist john mordon is priced at 59.95\nInput Table: royal canadian mint numismatic coins (2000s)\n\n\nyearthemeartistmintageissue_price2000steam buggyjohn mardon4436759.952000the bluenosej franklin wrightincluded in steam buggy59.952000the torontojohn mardonincluded in steam buggy59.952001the russell light fourjohn mardon4182859.952001the marco poloj franklin wrightincluded in the russell59.952001the scotiadon curleyincluded in the russell59.952002the gray - dortjohn mardon3594459.952002the william lawrencebonnie rossincluded in the gray - dort59.952002d - 10 locomotivedan fellincluded in the gray - dort59.952003hmcs bras dordon curley3199759.952003cnr fa - 1 diesel electricjohn mardonincluded in hmcs bras dor59.952003bricklin sv - 1brian hughesincluded in hmcs bras dor59.95\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE year = 2000 \nAND theme = 'steam buggy' \nAND artist = 'john mardon' \nAND issue_price = 59.95;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-748.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the yugoslavian national team scored 7 goals and allowed 3 against in the three 1982 world cup qualifying matches\nInput Table: yugoslavia national football team results\n\n\ndatecityopponentresultstype_of_game9999-03-22sarajevouruguay2:1friendly9999-03-30belgraderomania2:0balkan cup9999-04-26borovopoland2:1friendly9999-08-27bucharest , romaniaromania1:4balkan cup9999-09-10luxembourgluxembourg5:01982 wcq9999-09-27ljubljanadenmark2:11982 wcq9999-11-15torino , italyitaly0:21982 wcq\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT SUM(CAST(SUBSTR(results, 1, 1) AS INTEGER)) FROM table_sql WHERE type_of_game = '1982 wcq') = 7 \n             AND (SELECT SUM(CAST(SUBSTR(results, 3, 1) AS INTEGER)) FROM table_sql WHERE type_of_game = '1982 wcq') = 3 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1418.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: west germany had two of the top six but did not have anyone win a medal\nInput Table: 1976 world junior figure skating championships\n\n\nranknamenationsp_+_fspointsplaces1mark cockerellunited states1172.4211.02takashi murajapan2165.724.03brian pockarcanada3166.6223.04norbert schrammwest germany4159.840.05andrew bestwickunited kingdom5158.148.06stephan brilwest germany7155.7257.07patrice macrezfrance6151.7671.08pierre laminefrance8150.579.09shinji someyajapan10150.3474.510jozef sabov\u010d\u00edkczechoslovakia9148.8887.011daniel fuererswitzerland13146.1892.512gerald schranzaustria11143.04102.013helmut kristofics - binderaustria15137.32123.014michael pasfieldaustralia12136.6119.015francis demarteaubelgium14131.02140.016adrian vasileromania16127.74143.017miljan begovicyugoslavia17127.3143.018jeremy dowsonsouth africa18114.98166.019marc franquetbelgium19114.38167.0\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE nation = 'west germany' AND rank <= 6) = 2 \n             AND (SELECT COUNT(*) FROM table_sql WHERE nation = 'west germany' AND places <= 3) = 0 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-492.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: route 24 intersects with pleasant street turnpike street lindelof avenue\nInput Table: massachusetts route 139\n\n\ncountylocationstreet_namesmilepostroads_intersectednotesnorfolkstoughtonpleasant street turnpike street lindelof avenue3.0route 24route 24 exit 20norfolkweymouthanne street(no major junctions)(no major junctions)(no major junctions)plymouthrocklandnorth avenue plain street market street12.2route 123western terminus of route 123 / 139 concurrencyplymouthrocklandnorth avenue plain street market street12.8route 123eastern terminus of route 123 / 139 concurrencyplymouthhanoverhanover street rockland street columbia road17.9route 53northern terminus of route 53 / 139 concurrency\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE roads_intersected LIKE '%route 24%' \nAND street_names LIKE '%pleasant street%' \nAND street_names LIKE '%turnpike street%' \nAND street_names LIKE '%lindelof avenue%';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-974.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: nesheim bridge is in mcville\nInput Table: list of bridges on the national register of historic places in north dakota\n\n\nnamelistedlocationcountytypebeaver creek bridge1997-02-27finleysteelepratt through trusscaledonia bridge1997-02-27caledoniatraillpratt through trusscedar creek bridge1997-02-27haynesadamspratt through trusscolton 's crossing bridge1997-02-27lisbonransompratt through trusscrystal bridge1997-05-30crystalpembinaconcrete t - beam bridgeeastwood park bridge1975-04-21minotwardcantilever typeelliott bridge1997-02-27townermchenrypratt through trussfairview lift bridge1997-03-14cartwrightmckenzierailroad lift bridgegrace city bridge1997-02-27grace cityfosterpratt through trussgreat northern railway underpass1997-02-27stanleymountrailconcrete deck girder bridgeknife river bridge near stanton2001-04-25stantonmercerpratt through trusslisbon bridge1997-02-27lisbonransomsteel cantilever bean bridgemidland continental overpass1997-02-27jamestownstutsmansteel cantilever beam bridgemidway bridge1997-02-27johnstowngrand forkswarren bedstead bridgenesheim bridge1997-02-27mcvillenelsonpratt through trussnew rockford bridge1997-03-13new rockford closed to trafficeddywarren through truss bridgenorthwood bridge1997-02-27northwoodgrand forkspratt pony trussnorway bridge1997-02-27mayvilletraillpratt pony trussost valle bridge1997-02-27thompsongrand forkspratt through trussromness bridge1997-02-27cooperstowngriggspratt through trusssorlie memorial bridge1999-07-19grand forksgrand forksparker through truss bridgeviking bridge1997-02-27portlandtraillpratt through trusswest antelope bridge1997-02-27florabensonpratt pony truss bridgewest park bridge1997-02-27valley citybarnesconcrete false arch bridgewestgaard bridge1997-02-27voltairemchenrypratt pony through trussblanchard bridge1997-02-27blanchardtraillpratt through trussgoose river bridge1997-02-27hillsborotraillpratt through trussliberty memorial bridge1997-03-11 removed 2009-03-25bismarckburleighwarren - turner through trussporter elliott bridge1997-02-27hillsborotraillwarren through trussportland park bridge2004-09-23portlandtraillsteel through girderrainbow arch bridge2004-09-23valley citybarnesmarsh rainbow arch\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE name = 'nesheim bridge' \nAND location = 'mcville';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1725.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: when the game attendance was 38109 , kenny rogers was the winning pitcher\nInput Table: 2005 texas rangers season\n\n\ndatewinning_teamscorewinning_pitcherlosing_pitcherattendancelocation9999-05-20texas7 - 3kenny rogersbrandon backe38109arlington9999-05-21texas18 - 3chris youngezequiel astacio35781arlington9999-05-22texas2 - 0chan ho parkroy oswalt40583arlington9999-06-24houston5 - 2roy oswaltricardo rodr\u00edguez36199houston9999-06-25texas6 - 5chris youngbrandon backe41868houston\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE attendance = 38109 \nAND winning_pitcher = 'kenny rogers';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-402.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: secteur 6 lost by one against the enugu rangers\nInput Table: 1971 african cup of champions clubs\n\n\nteam_1aggteam_21st_leg2nd_legal - merrikh2 - 2 (5 - 4 pen)tele sc asmara9999-01-029999-01-01abaluhya united1 - 3great olympics9999-01-019999-01-01asc diaraf3 - 4stade malien9999-03-019999-01-01maseru united3 - 5mmm tamatave9999-01-029999-02-03as porto novo0 - 3victoria club mokanda9999-01-019999-01-02canon yaound\u00e99 - 4as solidarit\u00e99999-07-039999-01-02esp\u00e9rance1 - 0al - ahly (benghazi)9999-01-019999-01-01secteur 61 - 2enugu rangers9999-01-019999-01-01young africans2 - 0lavori publici9999-01-019999-01-01\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT agg FROM table_sql WHERE team_1 = 'secteur 6' AND team_2 = 'enugu rangers') = '1 - 2' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1052.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: on 7 may 1960 , a crowd of 9000 watched the away team , richmond , score 3.8 (26)\nInput Table: 1960 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddatenorth melbourne5.12 (42)richmond3.8 (26)arden street oval90001960-05-07melbourne16.14 (110)south melbourne6.10 (46)mcg231351960-05-07fitzroy5.11 (41)geelong8.7 (55)brunswick street oval138021960-05-07hawthorn6.9 (45)footscray6.17 (53)glenferrie oval160001960-05-07essendon11.10 (76)collingwood11.8 (74)windy hill300001960-05-07st kilda5.11 (41)carlton7.3 (45)junction oval187001960-05-07\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE date = '1960-05-07' \nAND crowd = 9000 \nAND away_team = 'richmond' \nAND away_team_score = '3.8 (26)';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-190.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there were 5 matches held in october of 1978\nInput Table: 1978 new zealand rugby union tour of britain and ireland\n\n\nopposing_teamagainstdatevenuestatuscambridge university121978-10-18grange road , cambridgetour matchcardiff71978-10-21cardiff arms park , cardifftour matchwest wales xv71978-10-25st helen 's , swanseatour matchlondon counties121978-10-28twickenham , londontour matchmunster121978-10-31thomond park , limericktour matchireland61978-11-04lansdowne road , dublintest matchulster71978-11-07ravenhill , belfasttour matchwales121978-11-01cardiff arms park , cardifftest matchsouth and south - west counties01978-11-15memorial ground , bristoltour matchmidland counties151978-11-18welford road , leicestertour matchcombined services61978-11-21aldershot military stadium , aldershottour matchengland61978-11-25twickenham , londontest matchmonmouthshire91978-11-29rodney parade , newporttour matchnorth of england61978-12-02birkenhead park , birkenheadtour matchnorth and midland of scotland31978-12-05linksfield stadium , aberdeentour matchscotland91978-12-09murrayfield , edinburghtest matchbridgend61978-12-13brewery field , bridgendtour matchbarbarians161978-12-16cardiff arms park , cardifftour match\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 5 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE strftime('%Y-%m', date) = '1978-10';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-767.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the 5th place bmw went at 82.32 mph\nInput Table: 1972 isle of man tt\n\n\nplaceridercountrymachinespeedtimepoints1siegfried schauzu / wolfgang kalauchwest germanybmw91.85 mph1:13.57.2152heinz luthringshauser / jcusnikwest germanybmw91.70 mph1:14.04.6123gerry boret / nick boretunited kingdomkonig84.43 mph1:20.27.4104wklenk / nscheererwest germanybmw83.62 mph1:21.31.885barry dungworth / rwturringtonunited kingdombmw82.32 mph1:22.30.666roy hanks / jpmannunited kingdombsa80.07 mph1:24.49.657rwoodhouse / dwoodhouseunited kingdombsa79.83 mph1.25.05.4048roger dutton / tony wrightunited kingdombmw79.63 mph1.25.18.039george o'dell / bill boldisonunited kingdombsa79.60 mph1.25.20.2210jbarker / amacfadzeanunited kingdombsa79.52 mph1.25.28.21\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT speed FROM table_sql WHERE place = 5 AND machine = 'bmw') = '82.32 mph' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1808.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the gold medalist for equestrian at the asian games has been different in every year they have occurred\nInput Table: equestrian at the asian games\n\n\nyearlocationgoldsilverbronze1982new delhinadia al - moutawaajamila al - moutawaabariaa salem al - sabbah1986seoultakashi tomurashuichi tokiryuzo okuno1994hiroshimakonoshin kuwahararyuzo okunonatya chantrasmi1998bangkokjin kannosohn bong - gakquzier ambak fathil2002busanmikaela mar\u00e3\u00ada jaworskilee jin - kyungtadayoshi hayashi2006dohaali yousuf al - rumaihijasmine chen - shao manjoo jung - hyun2010guangzhouramzy al duhamilatifa al maktomkhaled al - eid\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(DISTINCT gold) = COUNT(*) THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1587.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: stuart potts was the man of the match during the league / cup competition on the 22nd\nInput Table: 2008 - 09 guildford flames season\n\n\ndateopponentvenueresultattendancecompetitionman_of_the_match9999-01-01slough jetshomelost 2 - 31308league / cuplukas smital9999-01-02slough jetsawaylost 5 - 6 (ot)320leaguepaul dixon9999-01-08swindon wildcatsawaywon 6 - 3754league / cuplukas smital9999-01-09swindon wildcatshomewon 4 - 21568league / cupneil liddiard9999-01-15sheffield scimitarsawaywon 7 - 4364league / cuprick plant9999-01-16milton keynes lightninghomelost 2 - 41161league / cupdavid savage9999-01-19romford raidershomewon 6 - 21016league / cupalex mettam9999-01-22wightlink raidersawaylost 5 - 4509league / cupstuart potts9999-01-23telford tigershomewon 4 - 21368leaguealex mettam / mark williams9999-01-29romford raidershomewon 7 - 21238leaguemartin bouz9999-01-30bracknell beesawaywon 4 - 0not reportedleague / cupjoe watkins\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT man_of_the_match FROM table_sql WHERE date = '9999-01-22' AND competition = 'league / cup') = 'stuart potts' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1730.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the chicago bears were the opponents on october 16 1983\nInput Table: 1983 detroit lions season\n\n\nweekdateopponentresultattendance11983-09-04tampa bay buccaneersw 11 - 06215421983-09-11cleveland brownsl 31 - 266009531983-09-18atlanta falconsl 30 - 145462241983-09-25minnesota vikingsl 20 - 175825451983-10-02los angeles ramsl 21 - 104940361983-10-09green bay packersw 38 - 146773871983-10-16chicago bearsw 31 - 176670981983-10-23washington redskinsl 38 - 174318991983-10-30chicago bearsw 38 - 1758764101983-11-07new york giantsw 15 - 968985111983-11-13houston oilersl 27 - 1740660121983-11-20green bay packersw 23 - 20 ot50050131983-11-24pittsburgh steelersw 45 - 377724141983-12-05minnesota vikingsw 13 - 279169151983-12-11cincinnati bengalsl 17 - 945728161983-12-18tampa bay buccaneersw 23 - 2078392\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE date = '1983-10-16' \nAND opponent = 'chicago bears';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-15.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: cedar rapids is the site with the earliest date\nInput Table: iowa corn cy - hawk series\n\n\ndatesitesportwinning_teamseries2007-09-04cedar rapidsm golfiowa stateiowa state 2 - 02007-09-08des moinesvolleyballiowa stateiowa state 4 - 02007-09-09iowa cityw soccertieiowa state 5 - 12007-09-15amesfootballiowa stateiowa state 8 - 12007-11-10peoriam cross countryiowa stateiowa state 10 - 12007-11-10peoriaw cross countryiowaiowa state 10 - 32007-12-05amesw basketballiowa stateiowa state 12 - 32007-12-07amesw swimmingiowa stateiowa state 14 - 32007-12-08amesm basketballiowa stateiowa state 16 - 32007-12-09ameswrestlingiowaiowa state 16 - 52008-02-22amesw gymnasticsiowa stateiowa state 18 - 52008-03-07iowa cityw gymnasticsiowaiowa state 18 - 72008-04-01amessoftballiowaiowa state 18 - 9\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN site = 'cedar rapids' AND date = (SELECT MIN(date) FROM table_sql) THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1848.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: when the girls singles was lindaweni fanetri , the mixed doubles were wifqi windarto and debby susanto\nInput Table: indonesian national badminton championships\n\n\nyearboys_singlesgirls_singlesboys_doublesgirls_doublesmixed_doubles2001holvy de pauwmaria kristin yuliantihendra setiawan joko riyadililyana natsir natalia poluakanhendra setiawan greysia polii2002andre kurniawan tedjonofransisca ratnasariujang suherlan yoga ukikasahpurwati meiliana jauharimuhammad rijal meiliana jauhari2003alamsyah yunuswiwis meilyannafran kurniawan chandra kowipia zebadiah nitya krishinda maheswarifran kurniawan yulianti2004andre kurniawan tedjonopia zebadiahaditya dwi putra i made agungpia zebadiah nitya krishinda maheswarilingga lie yulianti2005achmad rivaibellaetrix manuputtyrio willianto davin prawidssalily siswanti shendy puspa irawatiabdul rahman richi puspita dili2006nugroho andi saputrosylvinna kurniawandanny bawa chrisnanta afiat yuris wirawanbellaetrix manuputty samantha lintangdanny bawa chrisnanta debby susanto2007nandang ariflindaweni fanetribudi hartono yohanes rendy sugiartoanneke feinya agustin wenny setiawatiwifqi windarto debby susanto2008hermansyahana rovitadidit juang indrianto seiko wahyu kusdiantosuci rizki andini tiara rosalia nuraidahirfan fadhilah weni anggraeni2009riyanto subagjaana rovitajones ralfy jansen dandi prabuditaayu pratiwi anggi widiadidit juang indrianto yayu rahayu2010shesar hiren rhustavitoganis nur rahmadanijones ralfy jansen dandi prabuditaaris budiharti dian fitrianijones ralfy jansen nurbeta kwanrico\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT mixed_doubles FROM table_sql WHERE girls_singles = 'lindaweni fanetri') = 'wifqi windarto debby susanto' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-27.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the attendance on august 26 and august 27 was 48063 and 48032\nInput Table: 1997 colorado rockies season\n\n\ndateopponentscorelossattendancerecord9999-08-01pirates7 - 6rinc\u00f3n (4 - 5)2265752 - 589999-08-02pirates6 - 5swift (4 - 5)3238852 - 599999-08-03pirates8 - 4reed (3 - 5)2498952 - 609999-08-04phillies7 - 3castillo (8 - 10)1523052 - 619999-08-05phillies4 - 2bottalico (2 - 4)1642853 - 619999-08-06mets4 - 0mlicki (5 - 8)2663354 - 619999-08-07mets12 - 4swift (4 - 6)2953654 - 629999-08-08pirates5 - 3lieber (6 - 12)4826255 - 629999-08-09pirates8 - 7rinc\u00f3n (4 - 6)4832356 - 629999-08-10pirates8 - 7wilkins (7 - 3)4801857 - 629999-08-12phillies5 - 0thomson (4 - 7)4822857 - 639999-08-13phillies12 - 8wright (6 - 8)4849157 - 649999-08-15mets6 - 2reed (10 - 6)4830858 - 649999-08-16mets7 - 5mcmichael (7 - 10)4831159 - 649999-08-17mets6 - 4mlicki (5 - 10)4844060 - 649999-08-19reds6 - 5wright (6 - 9)3172260 - 659999-08-20reds5 - 3white (1 - 1)2196861 - 659999-08-21astros10 - 4bailey (9 - 9)2296261 - 669999-08-22astros9 - 1thomson (5 - 8)3306161 - 679999-08-23astros6 - 3hudek (0 - 2)3237462 - 679999-08-24astros3 - 1wright (6 - 10)2891862 - 689999-08-25reds7 - 6castillo (10 - 11)4814362 - 699999-08-25reds6 - 4hutton (3 - 2)4808162 - 709999-08-26reds9 - 5mart\u00ednez (1 - 1)4806363 - 709999-08-27reds7 - 5remlinger (6 - 6)4803264 - 709999-08-28mariners9 - 5olivares (6 - 9)4842265 - 709999-08-29mariners6 - 5timlin (3 - 3)4817866 - 709999-08-30athletics4 - 3mohler (1 - 10)4830867 - 709999-08-31athletics10 - 4oquist (2 - 5)4804168 - 70\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT attendance FROM table_sql WHERE date = '9999-08-26') = 48063 \n             AND (SELECT attendance FROM table_sql WHERE date = '9999-08-27') = 48032 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-86.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the game with the lowest attendance happened on 11 february 2006\nInput Table: 2005 - 06 manchester united f.c. season\n\n\ndateopponentsh_/_aresult_f_-_aattendanceleague_position2005-08-13evertona2 - 0386104th2005-08-20aston villah1 - 0679344th2005-08-28newcastle uniteda2 - 0523274th2005-09-10manchester cityh1 - 1678394th2005-09-18liverpoola0 - 0449173rd2005-09-24blackburn roversh1 - 2677656th2005-10-01fulhama3 - 2218624th2005-10-15sunderlanda3 - 1390853rd2005-10-22tottenham hotspurh1 - 1678565th2005-10-29middlesbrougha1 - 4305797th2005-11-06chelseah1 - 0678644th2005-11-19charlton athletica3 - 1267303rd2005-11-27west ham uniteda2 - 1347552nd2005-12-03portsmouthh3 - 0676842nd2005-12-11evertonh1 - 1678313rd2005-12-14wigan athletich4 - 0677932nd2005-12-17aston villaa2 - 0371282nd2005-12-26west bromwich albionh3 - 0679722nd2005-12-28birmingham citya2 - 2284592nd2005-12-31bolton wanderersh4 - 1678582nd2006-01-03arsenala0 - 0383132nd2006-01-14manchester citya1 - 3471922nd2006-01-22liverpoolh1 - 0678742nd2006-02-01blackburn roversa3 - 4254842nd2006-02-04fulhamh4 - 2678442nd2006-02-11portsmoutha3 - 1202062nd2006-03-06wigan athletica2 - 1235242nd2006-03-12newcastle unitedh2 - 0678582nd2006-03-18west bromwich albiona2 - 1276232nd2006-03-26birmingham cityh3 - 0690702nd2006-03-29west ham unitedh1 - 0695222nd2006-04-01bolton wanderersa2 - 1277182nd2006-04-09arsenalh2 - 0709082nd2006-04-14sunderlandh0 - 0725192nd2006-04-17tottenham hotspura2 - 1361412nd2006-04-29chelseaa0 - 3422192nd2006-05-01middlesbroughh0 - 0695312nd2006-05-07charlton athletich4 - 0730062nd\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN attendance = (SELECT MIN(attendance) FROM table_sql) \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE date = '2006-02-11';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-477.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: western oval had footscray as it 's home team\nInput Table: 1927 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddatefootscray10.6 (66)melbourne10.13 (73)western oval110001927-09-10carlton15.16 (106)st kilda7.9 (51)princes park240001927-09-10richmond16.23 (119)hawthorn6.17 (53)punt road oval110001927-09-10south melbourne14.11 (95)geelong15.15 (105)lake oval150001927-09-10fitzroy5.13 (43)essendon14.10 (94)brunswick street oval110001927-09-10north melbourne7.14 (56)collingwood11.16 (82)arden street oval110001927-09-10\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE venue = 'western oval' \nAND home_team = 'footscray';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1494.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: two of the projects were proposed , but never listed and never completed\nInput Table: list of superfund sites in mississippi\n\n\ncerclis_idnamecountyproposedlistedconstruction_completedpartially_deleteddeletedmsd004006995american creosote works , incwinston2001-06-142001-09-139999-01-01--msd008154486chemfax , incharrison1993-06-239999-01-019999-01-01--msd046497012davis timber companylamar2000-05-112000-07-279999-01-01--msd980710941flowood siterankin1983-09-081984-09-211993-09-17-02 / 16 / 1996msd980840045newsom brothers / old reichhold chemicals , incmarion1984-10-151986-06-101997-08-08-09 / 27 / 2000msd065490930picayune wood treatingpearl river2004-03-082004-07-229999-01-01--msd056029648potter cocopiah1993-05-109999-01-019999-01-01--msd086556388sonford productsrankin2006-09-272007-03-079999-01-01--msd980601736walcotte chemical co warehouseswashington9999-01-019999-01-011982-12-30-12 / 30 / 1982\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 2 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE proposed != '9999-01-01' \nAND listed = '9999-01-01' \nAND construction_completed = '9999-01-01';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-376.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the home media center had no os x\nInput Table: comparison of upnp av media servers\n\n\nnamelicenseos_xunix_-_likewindowsweb_interface360 media servergplnoyesyesyesavia media playerpropnonononobrisamitpartialpartialnoyescoherencemitpartialpartialpartialyesdivxpropyesnoyesnoelgato eyeconnectpropyesnononofoobar2000propnonoyesnofuppesgplyesyesyesyesgeexbox usharegplnoyesnoyesgmediaservergplnoyesnonohome media centergplv2nonoyesyesisedora media serverpropyesnoyesyesjriver media centerpropnonoyesyeskooraroo mediapropyesyesyesyeslximediagplyesyesyesnomajestic media serverpropyesnononomediatombgplpartialyesnoyesminidlnagpl / bsdpartialyesyespartialmezzmopropnonoyesnomyihomepropyesyesyesnomythtv with upnpgplyesyesnoyesnullriver medialinkpropyesnononoplayonpropnonoyesyesplexpropyesyesyesyesps3 media servergplyesyesyesyespymedsmitpartialpartialnonorygellgplv2noyesnonorivetpropyesnononoserviiopropyesyesyesyessimplecenter premiumpropnonoyesyesskiftapropyesyesyesnosongbirdgplv2yesnoyesnotvblepropnonoyesnotversitypropnonoyesyestvmobilipropyesyesyesyestvsharepropnonoyesnotwonkyserverpropyesyesyesyesuniversal media servergplyesyesyesyeswindows media connectpropnonoyesnowild media serverpropyesyesyesyesxbmc media centergplyesyesyesyesxupnpdgplv2noyesnoyesyazsoft playbackpropyesnonononamelicenseos xunix - likewindowsweb interface\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT os_x FROM table_sql WHERE name = 'home media center') = 'no' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1850.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: in 2006 , the mixed doubles was danny bawa chrisnanta debby susanto and the boys singles was nugroho andi saputro\nInput Table: indonesian national badminton championships\n\n\nyearboys_singlesgirls_singlesboys_doublesgirls_doublesmixed_doubles2001holvy de pauwmaria kristin yuliantihendra setiawan joko riyadililyana natsir natalia poluakanhendra setiawan greysia polii2002andre kurniawan tedjonofransisca ratnasariujang suherlan yoga ukikasahpurwati meiliana jauharimuhammad rijal meiliana jauhari2003alamsyah yunuswiwis meilyannafran kurniawan chandra kowipia zebadiah nitya krishinda maheswarifran kurniawan yulianti2004andre kurniawan tedjonopia zebadiahaditya dwi putra i made agungpia zebadiah nitya krishinda maheswarilingga lie yulianti2005achmad rivaibellaetrix manuputtyrio willianto davin prawidssalily siswanti shendy puspa irawatiabdul rahman richi puspita dili2006nugroho andi saputrosylvinna kurniawandanny bawa chrisnanta afiat yuris wirawanbellaetrix manuputty samantha lintangdanny bawa chrisnanta debby susanto2007nandang ariflindaweni fanetribudi hartono yohanes rendy sugiartoanneke feinya agustin wenny setiawatiwifqi windarto debby susanto2008hermansyahana rovitadidit juang indrianto seiko wahyu kusdiantosuci rizki andini tiara rosalia nuraidahirfan fadhilah weni anggraeni2009riyanto subagjaana rovitajones ralfy jansen dandi prabuditaayu pratiwi anggi widiadidit juang indrianto yayu rahayu2010shesar hiren rhustavitoganis nur rahmadanijones ralfy jansen dandi prabuditaaris budiharti dian fitrianijones ralfy jansen nurbeta kwanrico\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT mixed_doubles FROM table_sql WHERE year = 2006) = 'danny bawa chrisnanta debby susanto' \n             AND (SELECT boys_singles FROM table_sql WHERE year = 2006) = 'nugroho andi saputro' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-886.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: john gadret on the ag2r prevoyance team scored 15 uci points\nInput Table: 2007 volta a catalunya\n\n\ncyclistcountryteamtimeuci_pointsvladimir karpetsrussiacaisse d'epargne9999-01-0150denis menchovrussiarabobank9999-01-0140michael rogersaustraliat - mobile team9999-01-0135christophe moreaufranceag2r pr\u00e9voyance9999-01-0130\u00f3scar sevillaspainrelax - gam9999-01-01n / afrancisco mancebospainrelax - gam9999-01-01n / ajohn gadretfranceag2r pr\u00e9voyance9999-01-0215marcos - antonio serranospainkarpin - galicia9999-01-01n / alaurens ten damnetherlandsunibetcom9999-01-015janez brajkovi\u010dsloveniadiscovery channel9999-01-022\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT uci_points FROM table_sql WHERE cyclist = 'john gadret' AND team = 'ag2r pr\u00e9voyance') = 15 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1253.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the philippines and macau have won the same number of gold and silver medals for wushu , but the philippines have won 4 more bronze medals\nInput Table: wushu at the asian games\n\n\nranknationgoldsilverbronzetotal1china (chn)4373532iran (iri)435123malaysia (mas)31594hong kong (hkg)294155thailand (tha)236116japan (jpn)165127philippines (phi)158148macau (mac)154109south korea (kor)1461110chinese taipei (tpe)13111511myanmar (mya)112412vietnam (vie)0971613indonesia (ina)022414laos (lao)015615india (ind)012316pakistan (pak)011217singapore (sin)005518mongolia (mgl)003319kazakhstan (kaz)002220yemen (yem)0011totaltotal606187208\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT gold FROM table_sql WHERE nation = 'philippines (phi)') = \n             (SELECT gold FROM table_sql WHERE nation = 'macau (mac)') \n        AND (SELECT silver FROM table_sql WHERE nation = 'philippines (phi)') = \n             (SELECT silver FROM table_sql WHERE nation = 'macau (mac)') \n        AND (SELECT bronze FROM table_sql WHERE nation = 'philippines (phi)') - \n             (SELECT bronze FROM table_sql WHERE nation = 'macau (mac)') = 4 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-234.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: globular cluster has less apparent magnitude than irregular galaxy\nInput Table: list of ngc objects (5001 - 6000)\n\n\nngc_numberobject_typeconstellationright_ascension_(_j2000_)declination_(_j2000_)apparent_magnitude5408irregular galaxycentaurus14h03 m21.0s degree22\u203244\u203314.05457spiral galaxyursa major14h03 m12.5s degree20\u203253\u20338.75466globular clusterbo\u00f6tes14h05 m27.4s degree32\u203204\u203310.55474spiral galaxyursa major14h05 m01.5s degree39\u203245\u203311.95477irregular galaxyursa major14h05 m33.1s degree27\u203240\u203314.5\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT apparent_magnitude FROM table_sql WHERE object_type = 'globular cluster') < \n             (SELECT apparent_magnitude FROM table_sql WHERE object_type = 'irregular galaxy') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-914.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the september 1st game against the mets resulted in a win 3 - 0. there were 19196 people in attendance\nInput Table: 1997 toronto blue jays season\n\n\ndateopponentscorelossattendancerecord9999-09-01mets3 - 0hentgen (14 - 9)1919665 - 719999-09-02mets8 - 5clemens (20 - 5)1763565 - 729999-09-03mets4 - 2quantrill (6 - 6)1451365 - 739999-09-04rangers6 - 2carpenter (1 - 7)2617865 - 749999-09-05rangers5 - 1pavlik (2 - 4)2712166 - 749999-09-06rangers2 - 1burkett (7 - 12)3123267 - 749999-09-07rangers4 - 0oliver (11 - 11)3021268 - 749999-09-08angels12 - 10james (4 - 5)2577569 - 749999-09-09angels2 - 0hill (7 - 12)2567470 - 749999-09-10athletics3 - 2plesac (1 - 4)476470 - 759999-09-11athletics8 - 7escobar (2 - 1)613570 - 769999-09-12mariners7 - 3clemens (21 - 6)3704470 - 779999-09-13mariners6 - 3ayala (10 - 5)5163171 - 779999-09-14mariners3 - 2risley (0 - 1)4547771 - 789999-09-15mariners7 - 3williams (8 - 14)4168471 - 799999-09-17red sox4 - 3quantrill (6 - 7)2364871 - 809999-09-18red sox3 - 2escobar (3 - 2)2799071 - 819999-09-19yankees3 - 0gooden (8 - 5)3119572 - 819999-09-20yankees4 - 3 (11)janzen (1 - 1)3833272 - 829999-09-21yankees5 - 4 (10)almanzar (0 - 1)4003872 - 839999-09-22yankees8 - 1hentgen (15 - 10)2338072 - 849999-09-23orioles3 - 2clemens (21 - 7)2927672 - 859999-09-24orioles9 - 3daal (1 - 1)2744372 - 869999-09-25orioles4 - 3mussina (15 - 8)2832473 - 869999-09-26red sox3 - 0henry (7 - 3)3415574 - 869999-09-27red sox12 - 5corsi (5 - 3)3740175 - 869999-09-28red sox3 - 2gordon (6 - 10)4025176 - 86\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE date = '9999-09-01' \nAND opponent = 'mets' \nAND score = '3 - 0' \nAND attendance = 19196;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-357.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: players in rounds higher than 4 , were from either canada or the united states\nInput Table: 2007 - 08 los angeles kings season\n\n\nroundplayernationalitynhl_teamcollege_/_junior_/_club_team_(league)1thomas hickey (d)canadalos angeles kingsseattle thunderbirds ( whl )2oscar moller (c)swedenlos angeles kingschilliwack bruins ( whl )2wayne simmonds (rw)canadalos angeles kingsowen sound attack ( whl )3bryan cameron (c)canadalos angeles kingsbelleville bulls ( ohl )4alec martinez (d)united stateslos angeles kingsmiami university ( ncaa )4dwight king (c)canadalos angeles kingslethbridge hurricanes ( whl )5linden rowat (g)canadalos angeles kingsregina pats ( whl )5joshua turnbull (c)united stateslos angeles kingswaterloo black hawks ( ushl )7josh kidd (d)canadalos angeles kingserie otters ( ohl )7matt fillier (lw)canadalos angeles kingsst john 's fog devils ( qmjhl )\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE round > 4 \nAND (nationality = 'canada' OR nationality = 'united states');\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1658.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: game 4 was on april 25\nInput Table: 2008 - 09 san antonio spurs season\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendanceseries19999-04-18dallasl 97 - 105 (ot)tim duncan (27)tim duncan (9)tony parker (8)at&t center 187970 - 129999-04-20dallasw 105 - 84 (ot)tony parker (38)tim duncan (11)tony parker (8)at&t center 187971 - 139999-04-23dallasl 67 - 88 (ot)tony parker (12)kurt thomas (10)tony parker (3)american airlines center 204911 - 249999-04-25dallasl 90 - 99 (ot)tony parker (43)tim duncan (10)tim duncan (7)american airlines center 208291 - 359999-04-28dallasl 93 - 106 (ot)tim duncan (31)tim duncan (12)tony parker (6)at&t center 208291 - 4\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE game = 4 \nAND date = '9999-04-25';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-288.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: clubs belenenses , benfica and sporting cp have lisbon as the city\nInput Table: 2004 - 05 primeira liga\n\n\nclubhead_coachcitystadium2003_-_2004_seasonacad\u00e9mica de coimbrajo\u00e3o carlos pereiracoimbraest\u00e1dio cidade de coimbra13th in the ligabelenensescarlos carvalhallisbonest\u00e1dio do restelo15th in the ligabenficagiovanni trapattonilisbonest\u00e1dio da luz2nd in the ligaboavistajaime pachecoportoest\u00e1dio do bessa - s\u00e9culo xxi8th in the ligabragajesualdo ferreirabragaest\u00e1dio municipal de braga - axa5th in the ligaestoril - praialitosestorilest\u00e1dio ant\u00f3nio coimbra da mota1st in the liga de honragil vicentelu\u00eds camposbarcelosest\u00e1dio cidade de barcelos12th in the ligauni\u00e3o de leiriav\u00edtor pontesleiriaest\u00e1dio dr magalh\u00e3es pessoa10th in the ligapenafielmanuel fernandespenafielest\u00e1dio municipal 25 de abril3rd in the liga de honramar\u00edtimomanuel cajudafunchalest\u00e1dio dos barreiros6th in the liganacionalcasemiro miorfunchalest\u00e1dio da madeira4th in the ligabeira - marmick wadsworthaveiroest\u00e1dio municipal de aveiro11th in the ligamoreirensev\u00edtor oliveiraguimar\u00e3esest\u00e1dio do moreirense9th in the ligaportoluigi delneriportoest\u00e1dio do drag\u00e3o1st in the ligasporting cpjos\u00e9 peseirolisbonest\u00e1dio jos\u00e9 alvalade - s\u00e9culo xxi3rd in the ligario avecarlos britovila do condeest\u00e1dio dos arcos7th in the ligavit\u00f3ria de guimar\u00e3esmanuel machadoguimar\u00e3esest\u00e1dio d afonso henriques14th in the ligavit\u00f3ria de set\u00fabaljos\u00e9 couceiroset\u00fabalest\u00e1dio do bonfim2nd in the liga de honra\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 3 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE city = 'lisbon' \nAND club IN ('belenenses', 'benfica', 'sporting cp');\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-345.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the game against new orleans didn't have the highest attendance\nInput Table: 2008 - 09 phoenix suns season\n\n\ngamedateteamlocation_attendancerecord759999-04-01houstonus airways center 1842241 - 34769999-04-03sacramentous airways center 1842242 - 3477'9999-04-05'dallasamerican airlines center 2030142 - 35789999-04-08new orleansnew orleans arena 1778143 - 3579'9999-04-10'memphisfedexforum 1590843 - 36809999-04-11minnesotatarget center 1847844 - 36819999-04-13memphisus airways center 1842245 - 3682'9999-04-15'golden stateus airways center46 - 36\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MAX(location_attendance) FROM table_sql) = (SELECT location_attendance FROM table_sql WHERE game = 78) \n        THEN 'FALSE' \n        ELSE 'TRUE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1175.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: shanghai pudong international airport ranked 3rd in total cargo with 2939157 metric tonnes\nInput Table: world 's busiest airports by cargo traffic\n\n\nrankairportcode_(iata_/_icao)total_cargo_(metric_tonnes)%_change1hong kong international airporthkg / vhhh40622612.2%2memphis international airportmem / kmem39165352.5%3shanghai pudong international airportpvg / zspd29391575.3%4incheon international airporticn / rksi24567243.3%5ted stevens anchorage international airportanc / panc24495513.7%6dubai international airportdxb / omdb22673653.1%7louisville international airportsdf / ksdf21877660.9%8paris - charles de gaulle airportcdg / lfpg21509506.5%9frankfurt airportfra / eddf20664326.7%10narita international airportnrt / rjaa20061733.1%11miami international airportmia / kmia19298894.9%12singapore changi airportsin / wsss18988503.0%13beijing capital international airportpek / zbaa17870276.0%14los angeles international airportlax / klax16883513.7%15taiwan taoyuan international airporttpe / rctp15777283.1%16london heathrow airportlhr / egll15562030.7%17o'hare international airportord / kord15121863.0%18amsterdam airport schipholams / eham15118242.4%19suvarnabhumi airportbkk / vtbs13454871.8%20john f kennedy international airportjfk / kjfk12836635.5%21guangzhou baiyun international airportcan / zggg12464675.6%22indianapolis international airportind / kind9321052.7%23tokyo international airporthnd / rjtt9096843.6%24shenzhen bao'an international airportszx / zgsz8549013.5%25leipzig / halle airportlej / eddp84609213.7%26doha international airportdoh / otbd8445324.5%27newark liberty international airportewr / kewr7437627.5%28cologne bonn airportcgn / eddk7300540.5%29kansai international airportkix / rjbb7231482.7%30kuala lumpur international airportkul / wmkk7022270.1%\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT rank FROM table_sql WHERE airport = 'shanghai pudong international airport') = 3 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-731.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the giants played 7 games within the month of september\nInput Table: 2008 arizona diamondbacks season\n\n\ndateopponentscorelossattendancerecord9999-09-01cardinals8 - 6mcclellan (2 - 7)3507570 - 679999-09-02cardinals8 - 2petit (3 - 4)2756870 - 689999-09-03cardinals4 - 3perez (2 - 2)2435071 - 689999-09-05dodgers7 - 0haren (14 - 8)5227071 - 699999-09-06dodgers7 - 2webb (19 - 7)4754371 - 709999-09-07dodgers5 - 3rauch (4 - 6)5413771 - 719999-09-08giants6 - 2petit (3 - 5)3025271 - 729999-09-09giants5 - 4rauch (4 - 7)3051871 - 739999-09-10giants4 - 3lyon (2 - 5)3099271 - 749999-09-12reds3 - 2harang (4 - 16)2904672 - 749999-09-13reds3 - 2 (10)pe\u00f1a (1 - 2)4507572 - 759999-09-14reds2 - 1 (10)rauch (4 - 8)2729772 - 769999-09-15giants3 - 1hennessey (1 - 2)2596973 - 769999-09-16giants2 - 0cain (8 - 13)3319574 - 769999-09-17giants7 - 6s\u00e1nchez (9 - 11)2261675 - 769999-09-18giants3 - 2lincecum (17 - 4)3432376 - 769999-09-19rockies3 - 2scherzer (0 - 3)4313776 - 779999-09-20rockies5 - 3fuentes (1 - 5)3828377 - 779999-09-21rockies13 - 4reynolds (2 - 8)3291578 - 779999-09-22cardinals4 - 2wellemeyer (12 - 9)4034979 - 779999-09-23cardinals7 - 4johnson (10 - 10)4001379 - 789999-09-24cardinals4 - 2scherzer (0 - 4)4002979 - 799999-09-25cardinals12 - 3rosales (1 - 1)4050279 - 809999-09-26rockies6 - 4grilli (3 - 3)3495080 - 809999-09-27rockies6 - 4corpas (3 - 4)3323481 - 809999-09-28rockies2 - 1vizca\u00edno (1 - 2)3590882 - 80\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 7 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE date LIKE '9999-09-%' \nAND opponent = 'giants';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1897.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: jerry mitchell is one of three nominees for a drama desk award\nInput Table: la cage aux folles (musical)\n\n\nyearawardcategorynomineeresult2005tony awardbest revival of a musicalbest revival of a musicalwon2005tony awardbest performance by a leading actor in a musicalgary beachnominated2005tony awardbest choreographyjerry mitchellwon2005tony awardbest costume designwilliam ivey longnominated2005drama desk awardoutstanding revival of a musicaloutstanding revival of a musicalwon2005drama desk awardoutstanding choreographyjerry mitchellwon2005drama desk awardoutstanding costume designwilliam ivey longnominated\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE year = 2005 AND award = 'drama desk award' AND nominee = 'jerry mitchell') <= 3 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1321.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: robert bauman is the incumbent for the republican party\nInput Table: united states house of representatives elections , 1974\n\n\ndistrictincumbentpartyfirst_electedresultcandidatesmaryland 1robert baumanrepublican1973-01-01re - electedrobert bauman (r) 53.0% thomas j hatem (d) 47.0%maryland 2clarence longdemocratic1962-01-01re - electedclarence long (d) 77.1% john m seney (r) 22.9%maryland 4marjorie holtrepublican1972-01-01re - electedmarjorie holt (r) 58.1% fred l wineland (d) 41.9%maryland 6goodloe byrondemocratic1970-01-01re - electedgoodloe byron (d) 73.7% elton r wampler (r) 26.3%maryland 7parren mitchelldemocratic1970-01-01re - electedparren mitchell (d) unopposed\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE incumbent = 'robert bauman' \nAND party = 'republican';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1633.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: 2012 set the record for the year with the highest score of 29 - 7. 2013 followed with 27 - 9\nInput Table: vcu rams men 's basketball\n\n\nyearrecordseedregionresults198018 - 1212eastl 72 - 86198124 - 55eastw 85 - 69 l 56 - 58 ot198324 - 75eastw 76 - 67 l 54 - 56198423 - 76eastw 70 - 69 l 63 - 78198526 - 62westw 81 - 65 l 59 - 63199624 - 912southeastl 51 - 58200423 - 813eastl 78 - 79200728 - 711westw 79 - 77 l 79 - 84 ot200924 - 1011eastl 64 - 65201128 - 1211southwestw 59 - 46 w 74 - 56 w 94 - 76 w 72 - 71 ot w 71 - 61 l 62 - 70201229 - 712midwestw 62 - 59 l 61 - 63201327 - 95southw 88 - 42 l 53 - 78\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT record FROM table_sql WHERE year = 2012) = '29 - 7' \n             AND (SELECT record FROM table_sql WHERE year = 2013) = '27 - 9' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1743.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the sla4h (m0) model has a release date of q2 2008\nInput Table: list of intel pentium dual - core microprocessors\n\n\nmodel_numbersspec_numberfrequencyl2_cachefsbmultvoltagetdpsocketrelease_datepart_number_(s)release_price_(_usd_)pentium dual - core t2310slaec (m0)1.47 ghz1 mb533 mt / s111.075 - 1.175v35 wsocket p2007-10-01lf80537 ge0201 m90pentium dual - core t2330sla4k (m0)1.6 ghz1 mb533 mt / s121.075 - 1.175v35 wsocket p2007-10-01lf80537 ge0251 mnoempentium dual - core t2370sla4j (m0)1.73 ghz1 mb533 mt / s131.075 - 1.175v35 wsocket p2007-10-01lf80537 ge0301 moempentium dual - core t2390sla4h (m0)1.87 ghz1 mb533 mt / s141.075 - 1.175v35 wsocket p2008-04-01lf80537 ge0361 moempentium dual - core t2410sla4 g (m0)2 ghz1 mb533 mt / s151.075 - 1.175v35 wsocket p2008-07-01lf80537 ge0411 moempentium dual - core t3200slavg (m0)2 ghz1 mb667 mt / s121.075 - 1.175v35 wsocket p2008-10-01lf80537 gf0411 moem\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT release_date FROM table_sql WHERE model_number = 'pentium dual - core t2390' AND sspec_number = 'sla4h (m0)') = '2008-04-01' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-989.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: march was the month that aired the most episodes with five\nInput Table: list of republic of doyle episodes\n\n\nUnnamed:_0titledirected_bywritten_byviewersoriginal_airdateprod_code1fathers and sonsmike clattenburgallan hawco , perry chafe and malcolm macrury9690002010-01-061012the return of the grievous angelsteve dimarcoallan hawco and avrum jacobson7150002010-01-131023duchess of georgemike clattenburgallan hawco , perry chafe and malcolm macrury6850002010-01-201035hit and rumsteve dimarcomatt maclennan5940002010-02-031056the one who got awaylarry mcleanjesse mckeown10120002010-02-101067the woman who knew too littlerobert liebermanjeremy boxen10530002010-03-031078the tell - tale safejerry ciccorittijohn callaghan and steve cochrane9860002010-03-101089he sleeps with the chipsphil earnshawperry chafe9080002010-03-1710910the pen is mightier than the doylerobert liebermansteve cochrane and avrum jacobson8970002010-03-2411011a horse dividedsteve scainijesse mckeown9020002010-03-31111\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE strftime('%m', original_airdate) = '03') = 5 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-700.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: pan wei - lun lost against chinatrust whales\nInput Table: 2007 uni - president lions season\n\n\ndateopponentscorelosssave9999-03-17la new bears4 - 5pan wei - lunhuang chun - chung9999-03-18la new bears4 - 1horacio estradatseng yi - cheng9999-03-22chinatrust whales7 - 9kao lung - weini fu - deh9999-03-23chinatrust whales4 - 5pan wei - lunmiguel saladin9999-03-24la new bears1 - 5jeriome robertson||30089999-03-25la new bears1 - 6rob cordemanshuang chun - chung9999-03-27brother elephantspostponed rescheduled for june 19postponed rescheduled for june 19postponed rescheduled for june 199999-03-28brother elephants0 - 4tsao chun - yangchuang wei - chuan9999-03-31macoto cobras11 - 5diegomar markwell||2275\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE opponent = 'chinatrust whales' \nAND loss = 'pan wei - lun';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-462.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: gene borek is from the united states\nInput Table: 1973 u.s. open (golf)\n\n\nplaceplayercountryscoreto_par1gary playersouth africa67 + 70 = 137- 52jim colbertunited states70 + 68 = 138- 4t3jack nicklausunited states71 + 69 = 140- 2t3johnny millerunited states71 + 69 = 140- 2t3bob charlesnew zealand71 + 69 = 140- 2t6gene borekunited states77 + 65 = 142et6julius borosunited states73 + 69 = 142et6tom weiskopfunited states73 + 69 = 142et6arnold palmerunited states71 + 71 = 142et6lee trevinounited states70 + 72 = 142e\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE player = 'gene borek' \nAND country = 'united states';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1695.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: katee shean and joshua allen danced the contemporary piece\nInput Table: so you think you can dance (u.s. season 4)\n\n\ncouplestylemusicchoreographer_(s)resultscourtney galiano mark kanemuraviennese waltzthe time of my life - david cookjason gilkisonkanemura eliminatedcourtney galiano mark kanemurajazzthe garden- mirahsonya tayehkanemura eliminatedkatee shean joshua allencontemporaryall by myself - celine diontyce dioriosafekatee shean joshua allenpaso doblefilet from le r\u00eavejason gilkisonsafechelsie hightower stephen twitch bossmamboahora me toca a mi- v\u00edctor manuelletony meredith melanie lapatin assistinghightower eliminatedchelsie hightower stephen twitch bosship - hopcontrol - vitamin string quartettabitha and napoleon d'umohightower eliminated\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE couple = 'katee shean joshua allen' \nAND style = 'contemporary';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1289.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: south korea earned no gold medals in the competition\nInput Table: 1967 world judo championships\n\n\nranknationgoldsilverbronzetotal1japan534122netherlands11133germany01233south korea01235soviet union00226great britain0011\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT gold FROM table_sql WHERE nation = 'south korea') = 0 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-147.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: in three different baseball games the final score was 8 - 1\nInput Table: 2006 texas rangers season\n\n\ndateopponentscorelossattendancerecord9999-09-01indians7 - 2padilla (13 - 9)2377669 - 679999-09-02indians6 - 5volquez (1 - 4)4022269 - 689999-09-03indians5 - 2byrd1966770 - 689999-09-04athletics8 - 1zito2394971 - 689999-09-05athletics5 - 4saarloos2722572 - 689999-09-06athletics9 - 6rupe (0 - 1)1783872 - 699999-09-08mariners7 - 2millwood (14 - 10)2864672 - 709999-09-09mariners3 - 2rheinecker (4 - 6)3345472 - 719999-09-10mariners4 - 2huber3432173 - 719999-09-12tigers3 - 2mahay (1 - 3)2419673 - 729999-09-13tigers11 - 3verlander2467274 - 729999-09-14angels2 - 1volquez (1 - 5)2148874 - 739999-09-15angels2 - 1francisco (0 - 1)3078874 - 749999-09-16angels12 - 6lackey4019675 - 749999-09-17angels8 - 1santana2430376 - 749999-09-18mariners8 - 1hern\u00e1ndez1821477 - 749999-09-19mariners9 - 7wilson (2 - 3)1855177 - 759999-09-20mariners6 - 3tejeda (4 - 4)2600677 - 769999-09-22indians12 - 4byrd2628478 - 769999-09-23indians6 - 3padilla (14 - 10)3835178 - 779999-09-24indians11 - 6millwood (16 - 11)3661778 - 789999-09-25angels8 - 3volquez (1 - 6)3978178 - 799999-09-26angels5 - 2escobar3733979 - 799999-09-27angels6 - 5wilson (2 - 4)3803279 - 809999-09-29mariners6 - 5fruto3076680 - 809999-09-30mariners3 - 1millwood (16 - 12)2331080 - 819999-10-01mariners3 - 2tejeda (5 - 5)2836180 - 82\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 3 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE score = '8 - 1';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-353.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: yi is the name when the royal house is ji and the state is cai\nInput Table: list of state leaders in 820s bc\n\n\nstatetypenametitleroyal_housefromcaisovereignyimarquisji837 bccaosovereignyoucount-835 bccaosovereigndaicount-826 bcchensovereignliduke-831 bcchusovereignxiong yan the youngerviscountmi837 bcchusovereignxiong shuangviscountmi827 bcchusovereignxiong xunviscountmi821 bcjinsovereignximarquisji840 bcjinsovereignxianmarquisji822 bclusovereignshendukeji854 bclusovereignwudukeji825 bcqisovereignwudukejiang850 bcqisovereignlidukejiang824 bcqinsovereignqin zhongrulerying845 bcqinsovereignzhuangdukeying822 bcsongsovereignhuiduke-830 bcweysovereignlimarquis-855 bcyansovereignhuimarquis-864 bcyansovereignlimarquis-826 bc\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE name = 'yi' \nAND royal_house = 'ji' \nAND state = 'cai';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1681.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: alabama was the opponent when they played at legion field birmingham , al\nInput Table: east carolina pirates football , 1990 - 99\n\n\ndateopponentsiteresultattendance9999-09-05virginia techlane stadium blacksburg , val3 - 38481349999-09-12chattanoogadowdy - ficklen stadium greenville , ncw31 - 0340289999-09-19ohiopeden stadium athens , ohw21 - 14191869999-10-03armydowdy - ficklen stadium greenville , ncw30 - 25406079999-10-10uabdowdy - ficklen stadium greenville , ncw26 - 7310029999-10-17alabamalegion field birmingham , all22 - 23800799999-10-24southern missmm roberts stadium hattiesburg , msl7 - 41240209999-10-31houstondowdy - ficklen stadium greenville , ncl31 - 34268219999-11-05cincinnatinippert stadium cincinnati , ohw24 - 21190989999-11-14louisvilledowdy - ficklen stadium greenville , ncl45 - 63262589999-11-21memphisliberty bowl memorial stadium memphis , tnw34 - 31160529999-01-01all times are in easternall times are in easternall times are in easternall times are in eastern\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE opponent = 'alabama' \nAND site = 'legion field birmingham , al';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-868.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the entrant was private on two occasions with the drivers being toni branca and philippe etancelin with tyres p and d\nInput Table: 1950 swiss grand prix\n\n\ndriverentrantconstructorchassisenginetyrenello paganiscuderia achille varzimaseratimaserati 4clt - 48maserati l4spjohnny claesecurie belgetalbot - lagotalbot - lago t26ctalbot l6dyves giraud - cabantousautomobiles talbot - darracq satalbot - lagotalbot - lago t26c - datalbot l6deug\u00e8ne martinautomobiles talbot - darracq satalbot - lagotalbot - lago t26c - datalbot l6dlouis rosierautomobiles talbot - darracq satalbot - lagotalbot - lago t26c - datalbot l6dluigi fagiolisa alfa romeoalfa romeoalfa romeo 158alfa romeo l8spjuan manuel fangiosa alfa romeoalfa romeoalfa romeo 158alfa romeo l8spnino farinasa alfa romeoalfa romeoalfa romeo 158alfa romeo l8spalberto ascariscuderia ferrariferrariferrari 125ferrari v12spraymond sommerscuderia ferrariferrariferrari 125ferrari v12spluigi villoresiscuderia ferrariferrariferrari 125ferrari v12sppeter whiteheadscuderia ferrariferrariferrari 125ferrari v12splouis chironofficine alfieri maseratimaseratimaserati 4clt - 48maserati l4spfranco rolofficine alfieri maseratimaseratimaserati 4clt - 48maserati l4spprince biraenrico plat\u00e9maseratimaserati 4clt - 48maserati l4sptoulo de graffenriedenrico plat\u00e9maseratimaserati 4clt - 48maserati l4spfelice bonettoscuderia milanomaseratimaserati milano 4clt - 50maserati l4spreg parnellscuderia ambrosianamaseratimaserati 4clt - 48maserati l4sdrudi fischerecurie espadonsva - fiatsva 1500fiat l4sptoni brancaprivatemaseratimaserati 4clmaserati l4spphilippe \u00e9tancelinprivatetalbot - lagotalbot - lago t26ctalbot l6dharry schellecurie bleuetalbot - lagotalbot - lago t26ctalbot l6d\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE entrant = 'private' AND driver = 'toni branca' AND tyre = 'p') = 1 \n             AND (SELECT COUNT(*) FROM table_sql WHERE entrant = 'private' AND driver = 'philippe \u00e9tancelin' AND tyre = 'd') = 1 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1014.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: st kilda was the away team on sunday , 13 february\nInput Table: 2000 ansett australia cup\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scoregroundcrowddateadelaide17.5 (107)melbourne19.11 (125)football park122399999-01-30geelong10.14 (74)st kilda11.12 (78)waverley park73949999-01-30st kilda9.12 (66)melbourne13.14 (92)waverley park105339999-02-05adelaide19.10 (124)geelong15.12 (102)football park113269999-02-06adelaide14.11 (95)st kilda15.12 (102)football park130869999-02-13geelong17.12 (114)melbourne11.16 (82)waverley park495201-14-9999\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE away_team = 'st kilda' \nAND date = '9999-02-13';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1644.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the princes park venue had more crowd than the junction oval menu\nInput Table: 1975 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddategeelong14.20 (104)melbourne14.14 (98)kardinia park133281975-06-07st kilda15.9 (99)north melbourne17.19 (121)moorabbin oval178111975-06-07richmond19.14 (128)essendon12.9 (81)mcg494691975-06-07hawthorn19.24 (138)collingwood13.11 (89)princes park238301975-06-07fitzroy15.7 (97)carlton16.10 (106)junction oval162491975-06-07footscray13.11 (89)south melbourne12.15 (87)vfl park140561975-06-07\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT crowd FROM table_sql WHERE venue = 'princes park') > \n             (SELECT crowd FROM table_sql WHERE venue = 'junction oval') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1589.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the wightlink raiders were the opponents at on away game on the 22nd\nInput Table: 2008 - 09 guildford flames season\n\n\ndateopponentvenueresultattendancecompetitionman_of_the_match9999-01-01slough jetshomelost 2 - 31308league / cuplukas smital9999-01-02slough jetsawaylost 5 - 6 (ot)320leaguepaul dixon9999-01-08swindon wildcatsawaywon 6 - 3754league / cuplukas smital9999-01-09swindon wildcatshomewon 4 - 21568league / cupneil liddiard9999-01-15sheffield scimitarsawaywon 7 - 4364league / cuprick plant9999-01-16milton keynes lightninghomelost 2 - 41161league / cupdavid savage9999-01-19romford raidershomewon 6 - 21016league / cupalex mettam9999-01-22wightlink raidersawaylost 5 - 4509league / cupstuart potts9999-01-23telford tigershomewon 4 - 21368leaguealex mettam / mark williams9999-01-29romford raidershomewon 7 - 21238leaguemartin bouz9999-01-30bracknell beesawaywon 4 - 0not reportedleague / cupjoe watkins\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE date = '9999-01-22' \nAND venue = 'away' \nAND opponent = 'wightlink raiders';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1417.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: mark cockerell finished with a better score than partice macrez\nInput Table: 1976 world junior figure skating championships\n\n\nranknamenationsp_+_fspointsplaces1mark cockerellunited states1172.4211.02takashi murajapan2165.724.03brian pockarcanada3166.6223.04norbert schrammwest germany4159.840.05andrew bestwickunited kingdom5158.148.06stephan brilwest germany7155.7257.07patrice macrezfrance6151.7671.08pierre laminefrance8150.579.09shinji someyajapan10150.3474.510jozef sabov\u010d\u00edkczechoslovakia9148.8887.011daniel fuererswitzerland13146.1892.512gerald schranzaustria11143.04102.013helmut kristofics - binderaustria15137.32123.014michael pasfieldaustralia12136.6119.015francis demarteaubelgium14131.02140.016adrian vasileromania16127.74143.017miljan begovicyugoslavia17127.3143.018jeremy dowsonsouth africa18114.98166.019marc franquetbelgium19114.38167.0\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT points FROM table_sql WHERE name = 'mark cockerell') > \n             (SELECT points FROM table_sql WHERE name = 'patrice macrez') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1372.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: iran , who ranks 1st in gdp in the middle east , ranks sixth in all of asia\nInput Table: list of asian and pacific countries by gdp (ppp)\n\n\nrank_mideastrank_asiarank_worldcountry2011_gdp_(ppp)_billions_of_usd1617iran930.2362923saudi arabia677.66331848united arab emirates261.18941950israel235.44652155qatar181.91262258kuwait150.00272360iraq127.34882666syria107.80392976oman81.005103083yemen63.344113184lebanon61.738123597jordan36.8971337104bahrain30.889\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT rank_asia FROM table_sql WHERE country = 'iran') = 6 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1183.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: on july 13th , set 3 was 12 - 25\nInput Table: 2002 fivb women 's volleyball world championship qualification\n\n\ndatescoreset_1set_2set_3total9999-07-130 - 39 - 2517 - 2512 - 2538 - 759999-07-133 - 025 - 2325 - 1025 - 1375 - 469999-07-143 - 025 - 1325 - 1025 - 1175 - 349999-07-141 - 325 - 2216 - 2515 - 2570 - 979999-07-150 - 316 - 2519 - 2518 - 2553 - 759999-07-153 - 025 - 2325 - 1625 - 1475 - 53\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT set_3 FROM table_sql WHERE date = '9999-07-13') = '12 - 25' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-2.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the wildcats lost one game in september and two games in november\nInput Table: 1947 kentucky wildcats football team\n\n\ngamedateopponentresultwildcats_pointsopponentsrecord19999-09-20ole missloss7140 - 129999-09-27cincinnatiwin2001 - 139999-10-04xavierwin2072 - 149999-10-119 georgiawin2603 - 1 , 2059999-10-1810 vanderbiltwin1404 - 1 , 1469999-10-25michigan statewin765 - 1 , 1379999-11-0118 alabamaloss0135 - 289999-11-08west virginiawin1566 - 299999-11-15evansvillewin3607 - 2109999-11-22tennesseeloss6137 - 3\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE result = 'loss' AND date LIKE '9999-09%') = 1 \n             AND (SELECT COUNT(*) FROM table_sql WHERE result = 'loss' AND date LIKE '9999-11%') = 2 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1026.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: windows live messenger version 14 and made by microsoft was relased on 2010 - 11 - 17 under the category of social networking\nInput Table: list of zune applications\n\n\ntitledevelopercategoryrelease_dateversionalarm clockmicrosoftutilities2010-12-161.1calculatormicrosoftutilities2009-09-011.0calendarmatchboxutilities2011-07-291.0.0.3chord findermicrosoftutilities2010-11-171.0drum machine hddino gamesutilities2010-10-201.0emailmicrosoftutilities2011-04-011.1.0.1facebookmatchboxsocial networking2010-12-161.4fan predictionihwy , incentertainment2011-06-231.0fingerpaintbabarogaentertainment2011-07-291.1levelmicrosoftutilities2011-06-231.0metronomedino gamesutilities2010-09-091.0msn moneymicrosoftutilities2010-07-291.0notesmicrosoftutilities2011-06-231.0pianomicrosoftentertainment2009-11-011.0shuffle by albummicrosoftutilities2011-02-181.1stopwatchmicrosoftutilities2010-08-051.1twittermatchboxsocial networking2010-12-161.6weathermicrosoftutilities2009-09-011.0windows live messengermicrosoftsocial networking2010-11-171.4zune readermicrosoftutilities2011-02-181.2\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE title = 'windows live messenger' AND version = '1.4' AND developer = 'microsoft' AND release_date = '2010-11-17' AND category = 'social networking') > 0 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1053.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: 3.8 (26) was the away team score against a home team that scored 5.12 (42)\nInput Table: 1960 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddatenorth melbourne5.12 (42)richmond3.8 (26)arden street oval90001960-05-07melbourne16.14 (110)south melbourne6.10 (46)mcg231351960-05-07fitzroy5.11 (41)geelong8.7 (55)brunswick street oval138021960-05-07hawthorn6.9 (45)footscray6.17 (53)glenferrie oval160001960-05-07essendon11.10 (76)collingwood11.8 (74)windy hill300001960-05-07st kilda5.11 (41)carlton7.3 (45)junction oval187001960-05-07\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT away_team_score FROM table_sql WHERE home_team_score = '5.12 (42)' AND away_team_score = '3.8 (26)') IS NOT NULL \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1982.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the match on 7 march 2001 had an attendance of 20503 , while the one on 21 february 2001 had 23266\nInput Table: 2000 - 01 sheffield wednesday f.c. season\n\n\ndateopponentvenueresultattendance2000-08-13wolverhampton wanderersa1 - 1190862000-08-19huddersfield townh2 - 3227042000-08-26grimsby towna1 - 077552000-08-28blackburn roversh1 - 1156462000-09-09wimbledonh0 - 5158562000-09-13nottingham foresth0 - 1157002000-09-16tranmere roversa0 - 293522000-09-23preston north endh1 - 3173792000-09-30gillinghama0 - 290992000-10-08west bromwich albionh1 - 2153382000-10-14portsmoutha1 - 2133762000-10-17burnleya0 - 1163722000-10-22birmingham cityh1 - 0146952000-10-25queens park rangersa2 - 1103532000-10-28fulhamh3 - 3175592000-11-04crystal palacea1 - 4153332000-11-07watforda3 - 1111662000-11-01norwich cityh3 - 2169562000-11-18barnsleya0 - 1199892000-11-25crewe alexandraa0 - 171032000-12-02queens park rangersh5 - 2217822000-12-09stockport countyh2 - 4163372000-12-16sheffield uniteda1 - 1251562000-12-23wolverhampton wanderersh0 - 1177872000-12-26bolton wanderersa0 - 2213162000-12-30huddersfield towna0 - 0189312001-01-01grimsby townh1 - 0170042001-01-13blackburn roversa0 - 2193082001-01-20bolton wanderersh0 - 3176382001-02-03watfordh2 - 3161342001-02-10wimbledona1 - 467412001-02-13tranmere roversh1 - 0154442001-02-21nottingham foresta1 - 0232662001-02-24preston north enda0 - 2143792001-03-03gillinghamh2 - 1187022001-03-07portsmouthh0 - 0205032001-03-10west bromwich albiona2 - 1186622001-03-17burnleyh2 - 0201842001-03-24birmingham citya2 - 1197332001-04-01sheffield unitedh1 - 2384332001-04-07stockport countya1 - 296662001-04-14crystal palaceh4 - 1198772001-04-16fulhama1 - 1175002001-04-21barnsleyh2 - 1234982001-04-28norwich citya0 - 1212412001-05-06crewe alexandrah0 - 028007\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT attendance FROM table_sql WHERE date = '2001-03-07') = 20503 \n             AND (SELECT attendance FROM table_sql WHERE date = '2001-02-21') = 23266 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-372.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the black knights lost to stanford , 67 - 14\nInput Table: 1975 army cadets football team\n\n\ngamedateopponentresultblack_knights_pointsopponentsrecord19999-09-13holy crosswin4471 - 029999-09-20lehighwin54322 - 039999-09-27villanovaloss0102 - 149999-10-04stanfordloss14672 - 259999-10-11dukeloss10212 - 369999-10-18pittsburghloss20522 - 479999-10-25penn stateloss0312 - 589999-11-01air forceloss3332 - 699999-11-08boston collegeloss0312 - 7109999-11-15vanderbiltloss14232 - 8\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT result FROM table_sql WHERE opponent = 'stanford') = 'loss' \n             AND (SELECT black_knights_points FROM table_sql WHERE opponent = 'stanford') = 14 \n             AND (SELECT opponents FROM table_sql WHERE opponent = 'stanford') = 67 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1619.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: 99000 is the number of resent points for 23 events\nInput Table: 2007 fedex cup playoffs\n\n\nUnnamed:_0playercountrypointseventsreset_points1tiger woodsunited states30574131000002vijay singhfiji1912923990003jim furykunited states1669119985004phil mickelsonunited states1603718980005kj choisouth korea1548521975006rory sabbatinisouth africa1354819972507zach johnsonunited states1334119970008charles howell iiiunited states1212621967509brandt snedekerunited states118702596500\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT reset_points FROM table_sql WHERE events = 23) = 99000 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1403.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: lleyton hewitt was a runner - up five times out of a total of 7\nInput Table: lleyton hewitt\n\n\noutcomeyearchampionshipsurfaceopponentscorerunner - up2000-01-01stuttgarthard (i)wayne ferreira6 - 7 (6 - 8) , 6 - 3 , 7 - 6 (7 - 5) , 6 - 7 (2 - 7) , 2 - 6winner2002-01-01indian wellshardtim henman6 - 1 , 6 - 2runner - up2002-01-01cincinnatihardcarlos moy\u00e15 - 7 , 6 - 7 (5 - 7)runner - up2002-01-01pariscarpet (i)marat safin6 - 7 (4 - 7) , 0 - 6 , 4 - 6winner2003-01-01indian wells (2)hardgustavo kuerten6 - 1 , 6 - 1runner - up2004-01-01cincinnati (2)hardandre agassi3 - 6 , 6 - 3 , 2 - 6runner - up2005-01-01indian wellshardroger federer2 - 6 , 4 - 6 , 4 - 6\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE outcome = 'runner - up') = 5 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-456.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the most points scored by the dolphins in a game was 38\nInput Table: 1983 miami dolphins season\n\n\nweekdateopponentresultattendance11983-09-04buffalo billsw 12 - 07871521983-09-11new england patriotsw 34 - 245934331983-09-19los angeles raidersl 27 - 145779641983-09-25kansas city chiefsw 14 - 65078551983-10-02new orleans saintsl 17 - 76648961983-10-09buffalo billsl 38 - 355994871983-10-16new york jetsw 32 - 145861581983-10-23baltimore coltsw 21 - 73234391983-10-30los angeles ramsw 30 - 1472175101983-11-06san francisco 49ersw 20 - 1757832111983-11-13new england patriotsl 17 - 660771121983-11-20baltimore coltsw 37 - 054482131983-11-28cincinnati bengalsw 38 - 1474506141983-12-04houston oilersw 24 - 1739434151983-12-10atlanta falconsw 31 - 2456725161983-12-16new york jetsw 34 - 1459975\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN MAX(CAST(SUBSTR(result, INSTR(result, ' ') + 1, INSTR(result, ' - ') - INSTR(result, ' ') - 1) AS INTEGER)) = 38 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-675.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: 67 + 68 + 70 = 205 was tiger wood 's score\nInput Table: 2002 u.s. open (golf)\n\n\nplaceplayercountryscoreto_par1tiger woodsunited states67 + 68 + 70 = 205- 52sergio garc\u00edaspain68 + 74 + 67 = 209- 1t3jeff maggertunited states69 + 73 + 68 = 210et3phil mickelsonunited states70 + 73 + 67 = 210et5robert allenbyaustralia74 + 70 + 67 = 211+ 1t5p\u00e1draig harringtonireland70 + 68 + 73 = 211+ 1t5billy mayfairunited states69 + 74 + 68 = 211+ 1t8nick faldoengland70 + 76 + 66 = 212+ 2t8justin leonardunited states73 + 71 + 68 = 212+ 2t10tom byrumunited states72 + 72 + 70 = 214+ 4t10davis love iiiunited states71 + 71 + 72 = 214+ 4t10scott mccarronunited states72 + 72 + 70 = 214+ 4\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT score FROM table_sql WHERE player = 'tiger woods') = '67 + 68 + 70 = 205' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-428.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: all about christmas eve was the title for season 11\nInput Table: will & grace (season 5)\n\n\nseriesseasontitledirected_bywritten_byoriginal_air_dateus_viewers_(millions)931and the horse he rode in onjames burrowsadam barr2002-09-2621.5942bacon and eggsjames burrowsalex herschlag2002-10-0320.6953the kid stays out of the picturejames burrowsjhoni marchinko2002-10-1020.2964humongous growthjames burrowskari lizer2002-10-1719.5975it 's the gay pumpkin , charlie brownjames burrowsgary janetti2002-10-3117.2986boardroom and a parked placejames burrowsgail lerner2002-11-0721.1997the needle and the omelet 's donejames burrowstracy poust & jon kinnally2002-11-1419.11008 - 9marry me a little , marry me a little morejames burrowsjeff greenstein & bill wrubel2002-11-2124.310110the honeymoon 's overjames burrowssally bradford2002-12-0519.310211all about christmas evejames burrowsadam barr2002-12-1216.210312field of queensjames burrowskatie palmer2003-01-0916.210413fagmalion part i : gay it forwardjames burrowstracy poust & jon kinnally2003-01-1616.010514fagmalion part ii : attack of the clonesjames burrowsgary janetti2003-01-3015.810615homojojames burrowsbill wrubel2003-02-0616.510716women and children firstjames burrowslaura kightlinger2003-02-1318.710817fagmalion part iii : bye , bye , beardyjames burrowsalex herschlag2003-02-2016.410918fagmalion part iv : the guy who loved mejames burrowsgail lerner2003-03-1315.011019sex , losers , and videotapejames burrowssteve gabriel2003-04-0315.011120leo unwrappedjames burrowssonja warfield2003-04-1714.711221dolls and dollsjames burrowskari lizer2003-04-2417.7\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE season = 11 \nAND title = 'all about christmas eve';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-19.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: wrestling is the sport with the latest date in 2007\nInput Table: iowa corn cy - hawk series\n\n\ndatesitesportwinning_teamseries2007-09-04cedar rapidsm golfiowa stateiowa state 2 - 02007-09-08des moinesvolleyballiowa stateiowa state 4 - 02007-09-09iowa cityw soccertieiowa state 5 - 12007-09-15amesfootballiowa stateiowa state 8 - 12007-11-10peoriam cross countryiowa stateiowa state 10 - 12007-11-10peoriaw cross countryiowaiowa state 10 - 32007-12-05amesw basketballiowa stateiowa state 12 - 32007-12-07amesw swimmingiowa stateiowa state 14 - 32007-12-08amesm basketballiowa stateiowa state 16 - 32007-12-09ameswrestlingiowaiowa state 16 - 52008-02-22amesw gymnasticsiowa stateiowa state 18 - 52008-03-07iowa cityw gymnasticsiowaiowa state 18 - 72008-04-01amessoftballiowaiowa state 18 - 9\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MAX(date) FROM table_sql WHERE sport = 'wrestling' AND date LIKE '2007%') = \n             (SELECT MAX(date) FROM table_sql WHERE date LIKE '2007%') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-582.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the reds in the 2005 milwaukee brewers season played them after the padres\nInput Table: 2005 milwaukee brewers season\n\n\ndateopponentscorelossattendancerecord9999-09-01padres5 - 6davis (1 - 1)2478565 - 699999-09-02padres12 - 2lawrence (7 - 14)1823166 - 699999-09-03padres1 - 6obermueller (1 - 3)3202266 - 709999-09-04padres3 - 2otsuka (1 - 6)2004267 - 709999-09-05reds6 - 1belisle (3 - 7)1614468 - 709999-09-06reds1 - 2 (10)de la rosa (2 - 2)1335168 - 719999-09-07reds14 - 5milton (7 - 14)1588669 - 719999-09-09astros7 - 4clemens (11 - 7)1813070 - 719999-09-10astros5 - 7ohka (10 - 8)2443770 - 729999-09-11astros4 - 2oswalt (17 - 12)1739271 - 729999-09-13diamondbacks3 - 1v\u00e3\u00a1zquez (10 - 15)2370872 - 729999-09-14diamondbacks1 - 2 (12)lehr (0 - 1)2379372 - 739999-09-15diamondbacks14 - 2estes (7 - 8)2074173 - 739999-09-16astros1 - 2eveland (1 - 1)3376773 - 749999-09-17astros0 - 7obermueller (1 - 4)3775673 - 759999-09-18astros1 - 6capuano (17 - 10)3505273 - 769999-09-20cubs5 - 3williams (5 - 9)3013674 - 769999-09-21cubs7 - 6van buren (0 - 2)3004975 - 769999-09-22cubs0 - 3helling (2 - 1)3113775 - 779999-09-23cardinals9 - 6carpenter (21 - 5)2247276 - 779999-09-24cardinals8 - 7mulder (16 - 8)3350677 - 779999-09-25cardinals0 - 2davis (11 - 11)2015077 - 789999-09-26reds12 - 9coffey (4 - 1)1441278 - 789999-09-27reds6 - 2claussen (10 - 10)2803179 - 789999-09-28reds4 - 11capuano (18 - 11)2118179 - 799999-09-29reds2 - 0milton (8 - 15)1317380 - 799999-09-30pirates6 - 5vogelsong (2 - 2)2092281 - 79\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE opponent = 'reds' AND date > (SELECT date FROM table_sql WHERE opponent = 'padres')) > 0 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-328.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the new orleans saints were the opponents for the first time in the 11th week\nInput Table: 1997 oakland raiders season\n\n\nweekdateopponentresulttv_timeattendance11997-08-31tennessee oilersl 24 - 21nbc 10:00 am3017121997-09-08kansas city chiefsl 28 - 27abc 6:00 pm6152331997-09-14atlanta falconsw 36 - 31nbc 10:00 am4792241997-09-21new york jetsl 23 - 22nbc 10:00 am7258651997-09-28st louis ramsw 35 - 17fox 1:15 pm4250661997-10-05san diego chargersl 25 - 10nbc 1:15 pm4364881997-10-19denver broncosw 28 - 25nbc 1:15 pm5700691997-10-26seattle seahawksl 45 - 34nbc 1:15 pm66264101997-11-02carolina panthersl 38 - 14nbc 10:00 am71064111997-11-09new orleans saintsl 13 - 10fox 1:15 pm40091121997-11-16san diego chargersw 38 - 13nbc 1:15 pm65714131997-11-24denver broncosl 31 - 3abc 6:00 pm75307141997-11-30miami dolphinsl 34 - 16nbc 1:15 pm50569151997-12-07kansas city chiefsl 30 - 0nbc 10:00 am76379161997-12-14seattle seahawksl 22 - 21nbc 1:15 pm40124171997-12-21jacksonville jaguarsl 20 - 9nbc 1:15 pm40032\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE week = 11 \nAND opponent = 'new orleans saints';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1238.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: given sentence : the production code for the episode directed by robert duncan mcneill is bcw404\nInput Table: list of white collar episodes\n\n\nno_in_seriesno_in_seasontitledirected_bywritten_byus_viewers_(million)original_air_dateproduction_code471wantedpaul holahanjeff eastin3.212012-07-10bcw401482most wantedpaul holahanmark goffman2.982012-07-17bcw402493diminishing returnsstefan schwartzjim campolongo3.012012-07-24bcw403504parting shotsrobert duncan mcneillalexandra mcnally2.822012-07-31bcw404515honor among thievesarlene sanfordjoe henderson2.932012-08-14bcw405526identity crisisdavid straitonchanning powell3.892012-08-21bcw406537compromising positionspaul holahanmatthew negrete3.362012-08-28bcw407548ancient historyrussell lee finedaniel shattuck3.382012-09-04bcw408559gloves offrenny harlinmark goffman3.82012-09-11bcw4095610vested interestrussell lee finejeff eastin3.412012-09-18bcw4105711family businesspaul holahanjoe henderson2.772013-01-22bcw4115812brass tacksanton cropperjim campolongo & alexandra mcnally2.612013-01-29bcw4125913empire citytim dekaychanning powell & daniel shattuck2.282013-02-05bcw4136014shoot the moonrussell lee finematthew negrete & bob derosa2.422013-02-19bcw4146115the originaljohn kretchmermark goffman2.122013-02-26bcw415\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT production_code FROM table_sql WHERE directed_by = 'robert duncan mcneill') = 'bcw404' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1618.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the united states is the home country of phil mickelson\nInput Table: 2007 fedex cup playoffs\n\n\nUnnamed:_0playercountrypointseventsreset_points1tiger woodsunited states30574131000002vijay singhfiji1912923990003jim furykunited states1669119985004phil mickelsonunited states1603718980005kj choisouth korea1548521975006rory sabbatinisouth africa1354819972507zach johnsonunited states1334119970008charles howell iiiunited states1212621967509brandt snedekerunited states118702596500\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE player = 'phil mickelson' \nAND country = 'united states';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1851.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: in 2007 , the girls doubles was anneke feinya agustin wenny setiawati and the mixed doubles was wifqi windarto debby susanto\nInput Table: indonesian national badminton championships\n\n\nyearboys_singlesgirls_singlesboys_doublesgirls_doublesmixed_doubles2001holvy de pauwmaria kristin yuliantihendra setiawan joko riyadililyana natsir natalia poluakanhendra setiawan greysia polii2002andre kurniawan tedjonofransisca ratnasariujang suherlan yoga ukikasahpurwati meiliana jauharimuhammad rijal meiliana jauhari2003alamsyah yunuswiwis meilyannafran kurniawan chandra kowipia zebadiah nitya krishinda maheswarifran kurniawan yulianti2004andre kurniawan tedjonopia zebadiahaditya dwi putra i made agungpia zebadiah nitya krishinda maheswarilingga lie yulianti2005achmad rivaibellaetrix manuputtyrio willianto davin prawidssalily siswanti shendy puspa irawatiabdul rahman richi puspita dili2006nugroho andi saputrosylvinna kurniawandanny bawa chrisnanta afiat yuris wirawanbellaetrix manuputty samantha lintangdanny bawa chrisnanta debby susanto2007nandang ariflindaweni fanetribudi hartono yohanes rendy sugiartoanneke feinya agustin wenny setiawatiwifqi windarto debby susanto2008hermansyahana rovitadidit juang indrianto seiko wahyu kusdiantosuci rizki andini tiara rosalia nuraidahirfan fadhilah weni anggraeni2009riyanto subagjaana rovitajones ralfy jansen dandi prabuditaayu pratiwi anggi widiadidit juang indrianto yayu rahayu2010shesar hiren rhustavitoganis nur rahmadanijones ralfy jansen dandi prabuditaaris budiharti dian fitrianijones ralfy jansen nurbeta kwanrico\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT girls_doubles FROM table_sql WHERE year = 2007) = 'anneke feinya agustin wenny setiawati' \n             AND (SELECT mixed_doubles FROM table_sql WHERE year = 2007) = 'wifqi windarto debby susanto' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1767.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: only one person has been a member of the party of labour of albania political party and been elected\nInput Table: list of prime ministers of albania\n\n\nnameborn_-_diedterm_startterm_endpolitical_partyprime ministers 1991 onwards1991-01-011991-01-011991-01-01prime ministers 1991 onwardsfatos nano (1st time)9999-01-011991-02-221991-06-05party of labour of albaniaylli bufi9999-01-011991-06-051991-12-10socialist party of albaniavilson ahmeti9999-01-011991-12-101992-04-13non - partyaleksand\u00ebr meksi9999-01-011992-04-131997-03-11democratic party of albaniabashkim fino9999-01-011997-03-111997-07-24socialist party of albaniafatos nano (2nd time)9999-01-011997-07-241998-10-02socialist party of albaniapandeli majko (1st time)9999-01-011998-10-021999-10-29socialist party of albaniailir meta9999-01-011999-10-292002-02-22socialist party of albaniapandeli majko (2nd time)9999-01-012002-02-222002-07-31socialist party of albaniafatos nano (3rd time)9999-01-012002-07-312005-09-11socialist party of albaniasali berisha1944-01-012005-09-112013-09-15democratic party of albaniaedi rama9999-01-012013-09-159999-01-01socialist party of albania\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 1 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE political_party = 'party of labour of albania' \nAND term_start != term_end;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-305.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the score was 2 - 2 when the away team was brighton and hove albion\nInput Table: 1990 - 91 fa cup\n\n\ntie_nohome_teamscoreaway_teamdate1liverpool2 - 2brighton & hove albion1991-01-26replaybrighton & hove albion2 - 3liverpool1991-01-302notts county2 - 0oldham athletic1991-01-263crewe alexandra1 - 0rotherham united1991-01-264luton town1 - 1west ham united1991-01-26replaywest ham united5 - 0luton town1991-01-305woking0 - 1everton1991-01-276shrewsbury town1 - 0wimbledon1991-01-267newcastle united2 - 2nottingham forest1991-02-13replaynottingham forest3 - 0newcastle united1991-02-188tottenham hotspur4 - 2oxford united1991-01-269coventry city1 - 1southampton1991-01-26replaysouthampton2 - 0coventry city1991-01-2910portsmouth5 - 1bournemouth1991-01-2611manchester united1 - 0bolton wanderers1991-01-2612norwich city3 - 1swindon town1991-01-2613millwall4 - 4sheffield wednesday1991-01-26replaysheffield wednesday2 - 0millwall1991-01-3014port vale1 - 2manchester city1991-01-2615arsenal0 - 0leeds united1991-01-27replayleeds united1 - 1arsenal1991-01-30replayarsenal0 - 0leeds united1991-02-13replayleeds united1 - 2arsenal1991-02-1616cambridge united2 - 0middlesbrough1991-01-26\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE score = '2 - 2' \nAND away_team = 'brighton & hove albion';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-808.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: netherlands and romania had games on june 1 and june 3 , respectively , in 1998\nInput Table: 1998 in paraguayan football\n\n\ndatevenuescorecompreport1998-02-08estadio defensores del chaco asunci\u00f3n , paraguay4 - 0f4501998-03-14qualcomm stadium san diego , united states2 - 2f4511998-03-18estadio ol\u00edmpico universitario mexico city , mexico1 - 1f4521998-03-28yale bowl new haven , united states1 - 1f4531998-04-22stadio ennio tardini parma , italy3 - 1f4541998-05-17olympic stadium tokyo , japan1 - 1kirin cup4551998-05-21kobe universiade memorial stadium kobe , japan1 - 0kirin cup4561998-06-01philips stadion eindhoven , netherlands5 - 1f4571998-06-03steaua stadium bucharest , romania3 - 2f4581998-06-06king baudouin stadium brussels , belgium1 - 0f4591998-06-12stade de la mosson montpellier , france0 - 0world cupreport1998-06-19stade geoffroy - guichard saint - \u00e9tienne , france0 - 0world cupreport1998-06-24stade de toulouse toulouse , france1 - 3world cupreport1998-06-28stade f\u00e9lix bollaert lens , france0 - 0 ( 1 - 0 aet )world cupreport\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE date = '1998-06-01' AND (venue LIKE '%eindhoven%' OR venue LIKE '%netherlands%')) > 0 \n             AND (SELECT COUNT(*) FROM table_sql WHERE date = '1998-06-03' AND (venue LIKE '%bucharest%' OR venue LIKE '%romania%')) > 0 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-225.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: neil labute was nominated for best play in 2009\nInput Table: reasons to be pretty\n\n\nyearaward_ceremonycategorynomineeresult2009tony awardbest playneil labutenominated2009tony awardbest performance by a leading actor in a playthomas sadoskinominated2009tony awardbest performance by a featured actress in a playmarin irelandnominated2009drama desk awardoutstanding playoutstanding playnominated2009drama desk awardoutstanding actor in a playthomas sadoskinominated2009drama desk awardoutstanding director of a playterry kinneynominated2009theatre world awardtheatre world awardmarin irelandwon\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE year = 2009 \nAND category = 'best play' \nAND nominee = 'neil labute' \nAND result = 'nominated';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1647.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: all the matches was on the same date\nInput Table: 1975 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddategeelong14.20 (104)melbourne14.14 (98)kardinia park133281975-06-07st kilda15.9 (99)north melbourne17.19 (121)moorabbin oval178111975-06-07richmond19.14 (128)essendon12.9 (81)mcg494691975-06-07hawthorn19.24 (138)collingwood13.11 (89)princes park238301975-06-07fitzroy15.7 (97)carlton16.10 (106)junction oval162491975-06-07footscray13.11 (89)south melbourne12.15 (87)vfl park140561975-06-07\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(DISTINCT date) = 1 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1753.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the 49ers tied two out of fourteen games in the 1947 season\nInput Table: 1947 san francisco 49ers season\n\n\nweekdateopponentresultscorerecord11947-08-31brooklyn dodgersw23 - 71 - 021947-09-07los angeles donsw17 - 142 - 031947-09-14baltimore coltsw14 - 73 - 041947-09-21new york yankeesl21 - 163 - 151947-09-28buffalo billsw41 - 244 - 161947-10-05baltimore coltst28 - 284 - 1 - 171947-10-12chicago rocketsw42 - 285 - 1 - 181947-10-26cleveland brownsl14 - 75 - 2 - 191947-11-02los angeles donsw26 - 166 - 2 - 1101947-11-09new york yankeesl24 - 166 - 3 - 1111947-11-16cleveland brownsl37 - 146 - 4 - 1121947-11-21chicago rocketsw41 - 167 - 4 - 1131947-11-27brooklyn dodgersw21 - 78 - 4 - 1141947-12-07buffalo billst21 - 218 - 4 - 2\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE result = 't') = 2 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-3.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the wildcats played two games in september , four games in october , and four games in november\nInput Table: 1947 kentucky wildcats football team\n\n\ngamedateopponentresultwildcats_pointsopponentsrecord19999-09-20ole missloss7140 - 129999-09-27cincinnatiwin2001 - 139999-10-04xavierwin2072 - 149999-10-119 georgiawin2603 - 1 , 2059999-10-1810 vanderbiltwin1404 - 1 , 1469999-10-25michigan statewin765 - 1 , 1379999-11-0118 alabamaloss0135 - 289999-11-08west virginiawin1566 - 299999-11-15evansvillewin3607 - 2109999-11-22tennesseeloss6137 - 3\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE strftime('%m', date) = '09') = 2 \n             AND (SELECT COUNT(*) FROM table_sql WHERE strftime('%m', date) = '10') = 4 \n             AND (SELECT COUNT(*) FROM table_sql WHERE strftime('%m', date) = '11') = 4 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-896.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: ray lindwall took the same number of wickets as bill johnston but had a better bowling average\nInput Table: 1948 ashes series\n\n\nplayerteammatcheswicketsaveragebest_bowlingray lindwallaustralia52719.626 / 20bill johnstonaustralia52723.335 / 36alec bedserengland51838.224 / 81keith milleraustralia51323.154 / 125ernie toshackaustralia41133.095 / 40norman yardleyengland5922.662 / 32jim lakerengland3952.444 / 138\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT wickets FROM table_sql WHERE player = 'ray lindwall') = \n             (SELECT wickets FROM table_sql WHERE player = 'bill johnston') \n             AND (SELECT average FROM table_sql WHERE player = 'ray lindwall') < \n             (SELECT average FROM table_sql WHERE player = 'bill johnston') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-238.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: spiral galaxy has two ngc numbers in the list\nInput Table: list of ngc objects (5001 - 6000)\n\n\nngc_numberobject_typeconstellationright_ascension_(_j2000_)declination_(_j2000_)apparent_magnitude5408irregular galaxycentaurus14h03 m21.0s degree22\u203244\u203314.05457spiral galaxyursa major14h03 m12.5s degree20\u203253\u20338.75466globular clusterbo\u00f6tes14h05 m27.4s degree32\u203204\u203310.55474spiral galaxyursa major14h05 m01.5s degree39\u203245\u203311.95477irregular galaxyursa major14h05 m33.1s degree27\u203240\u203314.5\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 2 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE object_type = 'spiral galaxy';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-951.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the at90s1200 chip has a frequency of 12 mhz\nInput Table: none\n\n\nchipflash_sizeeepromsramfrequencypackageat90s12001k64012pdip - 20at90s23132k12812810pdip - 20at90s / ls23232k12812810pdip - 8at90s / ls23432k12812810pdip - 8at90s44144k2562568pdip - 40at90s / ls44344k2562568pdip - 40at90s85158k5125128pdip - 40at90s / ls85358k5125128pdip - 40\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT frequency FROM table_sql WHERE chip = 'at90s1200') = 12 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1614.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: on october 9 j\u00e9r\u00f4me pineau was the series leader\nInput Table: 2008 french road cycling cup\n\n\ndateeventwinnerteamseries_leader9999-02-24tour du haut vardavide rebellin ( ita )gerolsteinerrinaldo nocentini ( ita )9999-03-23cholet - pays de loirejanek tombak ( est )mitsubishi - jartazirinaldo nocentini ( ita )9999-04-06grand prix de rennesmikhaylo khalilov ( ukr )ceramica flaminia - bossini doccejimmy casper ( fra )'9999-04-15'paris - camembertalejandro valverde ( esp )caisse d'epargnej\u00e9r\u00f4me pineau ( fra )0000-04-17grand prix de denainedvald boasson hagen ( nor )team high roadjimmy casper ( fra )9999-04-19tour du finist\u00e8redavid lelay ( fra )bretagne - armor luxjimmy casper ( fra )9999-04-20tro - bro l\u00e9onfr\u00e9d\u00e9ric guesdon ( fra )fran\u00e7aise des jeuxjimmy casper ( fra )9999-05-04troph\u00e9e des grimpeursdavid lelay ( fra )bretagne - armor luxdavid lelay ( fra )9999-05-31grand prix de plumelec - morbihanthomas voeckler ( fra )bouygues t\u00e9l\u00e9comdavid lelay ( fra )9999-08-03polynormandearnaud g\u00e9rard ( fra )fran\u00e7aise des jeuxj\u00e9r\u00f4me pineau ( fra )9999-08-31chteauroux classicanthony ravard ( fra )agritubelj\u00e9r\u00f4me pineau ( fra )9999-09-21grand prix d'isbergueswilliam bonnet ( fra )cr\u00e9dit agricolej\u00e9r\u00f4me pineau ( fra )9999-10-05tour de vend\u00e9ekoldo fern\u00e1ndez ( esp )euskaltel - euskadij\u00e9r\u00f4me pineau ( fra )9999-10-09paris - bourgesbernhard eisel ( aut )team columbiaj\u00e9r\u00f4me pineau ( fra )\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT series_leader FROM table_sql WHERE date = '9999-10-09') = 'j\u00e9r\u00f4me pineau ( fra )' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1849.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: when the girls double was ayu pratiwi and anggi widia , the boys doubles was jones ralfy jansen and dandi prabudita\nInput Table: indonesian national badminton championships\n\n\nyearboys_singlesgirls_singlesboys_doublesgirls_doublesmixed_doubles2001holvy de pauwmaria kristin yuliantihendra setiawan joko riyadililyana natsir natalia poluakanhendra setiawan greysia polii2002andre kurniawan tedjonofransisca ratnasariujang suherlan yoga ukikasahpurwati meiliana jauharimuhammad rijal meiliana jauhari2003alamsyah yunuswiwis meilyannafran kurniawan chandra kowipia zebadiah nitya krishinda maheswarifran kurniawan yulianti2004andre kurniawan tedjonopia zebadiahaditya dwi putra i made agungpia zebadiah nitya krishinda maheswarilingga lie yulianti2005achmad rivaibellaetrix manuputtyrio willianto davin prawidssalily siswanti shendy puspa irawatiabdul rahman richi puspita dili2006nugroho andi saputrosylvinna kurniawandanny bawa chrisnanta afiat yuris wirawanbellaetrix manuputty samantha lintangdanny bawa chrisnanta debby susanto2007nandang ariflindaweni fanetribudi hartono yohanes rendy sugiartoanneke feinya agustin wenny setiawatiwifqi windarto debby susanto2008hermansyahana rovitadidit juang indrianto seiko wahyu kusdiantosuci rizki andini tiara rosalia nuraidahirfan fadhilah weni anggraeni2009riyanto subagjaana rovitajones ralfy jansen dandi prabuditaayu pratiwi anggi widiadidit juang indrianto yayu rahayu2010shesar hiren rhustavitoganis nur rahmadanijones ralfy jansen dandi prabuditaaris budiharti dian fitrianijones ralfy jansen nurbeta kwanrico\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT boys_doubles FROM table_sql WHERE girls_doubles = 'ayu pratiwi anggi widia') = 'jones ralfy jansen dandi prabudita' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1384.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: dundee west has lower swing to gain points than western isles\nInput Table: scottish parliament general election , 2007\n\n\nrankconstituencywinning_party_2003swing_to_gainsnp_'s_place_2003result1galloway & upper nithsdaleconservative0.172ndcon hold2tweeddale , ettrick & lauderdaleliberal democrats1.012ndld hold3cumbernauld & kilsythlabour1.072ndlab hold4kilmarnock & loudounlabour1.922ndsnp gain5dundee westlabour2.132ndsnp gain6western isleslabour2.912ndsnp gain7glasgow govanlabour2.922ndsnp gain8aberdeen centrallabour2.962ndlab hold9linlithgowlabour3.562ndlab hold10west renfrewshirelabour4.412ndlab hold11paisley southlabour4.912ndlab hold\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT swing_to_gain FROM table_sql WHERE constituency = 'dundee west') < \n             (SELECT swing_to_gain FROM table_sql WHERE constituency = 'western isles') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1495.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there were two projects in rankin county , sonford products and flowood site\nInput Table: list of superfund sites in mississippi\n\n\ncerclis_idnamecountyproposedlistedconstruction_completedpartially_deleteddeletedmsd004006995american creosote works , incwinston2001-06-142001-09-139999-01-01--msd008154486chemfax , incharrison1993-06-239999-01-019999-01-01--msd046497012davis timber companylamar2000-05-112000-07-279999-01-01--msd980710941flowood siterankin1983-09-081984-09-211993-09-17-02 / 16 / 1996msd980840045newsom brothers / old reichhold chemicals , incmarion1984-10-151986-06-101997-08-08-09 / 27 / 2000msd065490930picayune wood treatingpearl river2004-03-082004-07-229999-01-01--msd056029648potter cocopiah1993-05-109999-01-019999-01-01--msd086556388sonford productsrankin2006-09-272007-03-079999-01-01--msd980601736walcotte chemical co warehouseswashington9999-01-019999-01-011982-12-30-12 / 30 / 1982\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 2 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE county = 'rankin' \nAND (name = 'sonford products' OR name = 'flowood site');\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1449.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: republican paul findley was first elected in 1960\nInput Table: united states house of representatives elections , 1980\n\n\ndistrictincumbentpartyfirst_electedresultcandidatesillinois 2morgan f murphydemocratic1970-01-01retired democratic holdgus savage (d) 88.2% marsha a harris (r) 11.8%illinois 6henry hyderepublican1974-01-01re - electedhenry hyde (r) 67.0% mario reymond reda (d) 33.0%illinois 7cardiss collinsdemocratic1973-01-01re - electedcardiss collins (d) 85.1% ruth r hooper (r) 14.9%illinois 12phil cranerepublican1969-01-01re - electedphil crane (r) 74.1% david mccartney (d) 25.9%illinois 13robert mccloryrepublican1962-01-01re - electedrobert mcclory (r) 71.7% michael reese (d) 28.3%illinois 15tom corcoranrepublican1976-01-01re - electedtom corcoran (r) 76.7% john p quillin (d) 23.3%illinois 19tom railsbackrepublican1966-01-01re - electedtom railsback (r) 73.4% thomas j hand (d) 26.6%illinois 20paul findleyrepublican1960-01-01re - electedpaul findley (r) 56.0% david robinson (d) 44.0%\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE first_elected = '1960-01-01' \nAND party = 'republican' \nAND incumbent = 'paul findley';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1309.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: mark o'meara had a score of 71 + 72 + 66 = 209\nInput Table: 1988 u.s. open (golf)\n\n\nplaceplayercountryscoreto_par1curtis strangeunited states70 + 67 + 69 = 206- 7t2nick faldoengland72 + 67 + 68 = 207- 6t2bob gilderunited states68 + 69 + 70 = 207- 6t2scott simpsonunited states69 + 66 + 72 = 207- 6t5larry mizeunited states69 + 67 + 72 = 208- 5t5d a weibringunited states71 + 69 + 68 = 208- 57mark o'mearaunited states71 + 72 + 66 = 209- 48fred couplesunited states72 + 67 + 71 = 210- 39lanny wadkinsunited states70 + 71 + 70 = 211- 210ken greenunited states72 + 70 + 70 = 212- 1\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT score FROM table_sql WHERE player = \"mark o'meara\") = \"71 + 72 + 66 = 209\" \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-173.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the years 1972 - 1976 have a rank of 1\nInput Table: none\n\n\nrankplayeryearsgamesreb_avgtotal_rebounds1jim nowers1972-01-01 - 1976-01-011129.410482kenny sanders1985-01-01 - 1989-01-011079.610263will thomas2004-01-01 - 2008-01-011317.69934george evans1997-01-01 - 2001-01-011168.29535robert dykes1987-01-01 - 1991-01-011227.59256andre gaddy1977-01-01 - 1982-01-01989.39167jai lewis2002-01-01 - 2006-01-011257.28958rob rose1982-01-01 - 1986-01-011137.18059herb estes1973-01-01 - 1976-01-01809.273410jesse young1999-01-01 - 2003-01-011156.2708\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT rank FROM table_sql WHERE years = '1972-01-01 - 1976-01-01') = 1 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-493.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: 12.8 is one of the mileposts listed for the location rockland\nInput Table: massachusetts route 139\n\n\ncountylocationstreet_namesmilepostroads_intersectednotesnorfolkstoughtonpleasant street turnpike street lindelof avenue3.0route 24route 24 exit 20norfolkweymouthanne street(no major junctions)(no major junctions)(no major junctions)plymouthrocklandnorth avenue plain street market street12.2route 123western terminus of route 123 / 139 concurrencyplymouthrocklandnorth avenue plain street market street12.8route 123eastern terminus of route 123 / 139 concurrencyplymouthhanoverhanover street rockland street columbia road17.9route 53northern terminus of route 53 / 139 concurrency\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE location = 'rockland' \nAND milepost = 12.8;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-294.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the score on 15 / 04 / 07 in super league xii was 52 - 22\nInput Table: 2007 bradford bulls season\n\n\ndatehome_teamscoreaway_teamgoalsattendancecompetition2007-11-02bradford18 - 14huddersfield giantsdeacon 3 / 412130super league xii0007-02-18warrington wolves20 - 36bradforddeacon 6 / 712607super league xii2007-02-24bradford32 - 28wigan warriorsdeacon 6 / 612798super league xii2007-02-03st helens34 - 22bradforddeacon 3 / 411793super league xii2007-11-03bradford56 - 18salford city redsdeacon 8 / 1010640super league xii0007-03-17harlequins rl22 - 36bradforddeacon 6 / 64011super league xii2007-03-25bradford22 - 29catalans dragonsdeacon 3 / 411298super league xii2007-03-30bradford24 - 16castleford tigersdeacon 4 / 46748rugby league challenge cup2007-05-04bradford14 - 18leeds rhinosdeacon 3 / 516706super league xii2007-09-04wakefield trinity wildcats24 - 36bradforddeacon 6 / 79106super league xii2007-04-15bradford52 - 22hull krdeacon 8 / 910881super league xii2007-04-20hull fc22 - 32bradforddeacon 4 / 612767super league xii2007-04-29bradford36 - 24warrington wolvesdeacon 3 / 3 , i harris 3 / 5 ,11200super league xii2007-06-05bradford38 - 42leeds rhinosdeacon 7 / 726667super league xii0007-05-13wakefield trinity wildcats4 - 14bradforddeacon 1 / 33568rugby league challenge cup0007-05-18huddersfield giants36 - 12bradfordi harris 2 / 28667super league xii2007-05-27bradford44 - 18harlequins rldeacon 6 / 810418super league xii2007-02-06catalans dragons20 - 28bradforddeacon 4 / 57555super league xii2007-10-06bradford52 - 20huddersfield giantsdeacon 8 / 107811rugby league challenge cup0007-06-17bradford34 - 8hull fcdeacon 4 / 6 , vainikolo 1 / 111557super league xii2007-06-29leeds rhinos14 - 38bradforddeacon 7 / 722000super league xii2007-06-07wigan warriors25 - 18bradforddeacon 5 / 515107super league xii0007-07-13bradford10 - 4st helensdeacon 3 / 311217super league xii2007-07-21salford city reds14 - 10bradforddeacon 1 / 23438super league xii2007-07-28bradford16 - 35st helensdeacon 1 / 314316rugby league challenge cup2007-05-08bradford38 - 24wakefield trinity wildcatsburgess 5 / 810701super league xii2007-12-08hull kr10 - 28bradfordi harris 4 / 56695super league xii0007-08-19huddersfield giants26 - 22bradfordharris 5 / 56824super league xii2007-09-02bradford16 - 16leeds rhinosdeacon 2 / 418000super league xii2007-09-09bradford40 - 8catalans dragonsiestyn harris (6 / 7)9350super league xii2007-09-14hull fc20 - 10bradfordi harris (1 / 2)14409super league xii2007-09-21bradford30 - 31wigan warriorsi harris (5 / 6)9000super league xii\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT score FROM table_sql WHERE date = '2007-04-15' AND competition = 'super league xii') = '52 - 22' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-42.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: kenneth ferrie and geoff ogilvy of australia were the only players to score a + 1 to par\nInput Table: 2006 u.s. open (golf)\n\n\nplaceplayercountryscoreto_par1steve strickerunited states70 + 69 = 139- 12colin montgomeriescotland69 + 71 = 140et3kenneth ferrieengland71 + 70 = 141+ 1t3geoff ogilvyaustralia71 + 70 = 141+ 1t5jim furykunited states70 + 72 = 142+ 2t5p\u00e1draig harringtonireland70 + 72 = 142+ 2t7jason dufnerunited states72 + 71 = 143+ 3t7graeme mcdowellnorthern ireland71 + 72 = 143+ 3t7phil mickelsonunited states70 + 73 = 143+ 3t7arron oberholserunited states75 + 68 = 143+ 3\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 2 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE to_par = '+ 1';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-69.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: joliette township has a geo id of 3806741020\nInput Table: list of townships in north dakota\n\n\ntownshipcountypop_(2010)land_(_sqmi_)water_(sqmi)latitudelongitudegeo_idansi_codejacksonsargent3335.8090.046.066276- 97.94553038081404601036797james hillmountrail3231.824.24348.423125- 102.42993438061405001037048james river valleydickey4028.5970.046.246641- 98.18832938021405401036767jankelogan2835.9950.16346.415512- 99.13170138047406201037193jeffersonpierce4535.0691.12548.232149- 100.18237038069407001759556jim river valleystutsman3834.1341.74647.112388- 98.77847838093407801036484johnsonwells3635.2990.90847.377745- 99.45867738103408201037137johnstowngrand forks7936.1990.048.151362- 97.44903338035409401036624joliettepembina6770.0440.77148.796545- 97.21722738067410201036723\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE township = 'joliette' \nAND geo_id = 3806741020;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1870.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the solheim cup was hosted outside of the united states six times from 1990 - 2013\nInput Table: solheim cup\n\n\nyearvenuewinning_teamscoreusa_captaineurope_captain2013-01-01colorado golf club , colorado , usaeurope18 - 10meg mallonliselotte neumann2011-01-01killeen castle golf resort , irelandeurope15 - 13rosie jonesalison nicholas2009-01-01rich harvest farms , illinois , usaunited states16 - 12beth danielalison nicholas2007-01-01halmstad gk , swedenunited states16 - 12betsy kinghelen alfredsson2005-01-01crooked stick golf club , indiana , usaunited states15\u00bd - 12\u00bdnancy lopezcatrin nilsmark2003-01-01barseb\u00e4ck golf & country club , swedeneurope17\u00bd - 10\u00bdpatty sheehancatrin nilsmark2002-01-01interlachen country club , minnesota , usaunited states15\u00bd - 12\u00bdpatty sheehandale reid2000-01-01loch lomond golf club , scotlandeurope14\u00bd - 11\u00bdpat bradleydale reid1998-01-01muirfield village , ohio , usaunited states16 - 12judy rankinpia nilsson1996-01-01st pierre golf & country club , walesunited states17 - 11judy rankinmickey walker1994-01-01the greenbrier , west virginia , usaunited states13 - 7joanne carnermickey walker1992-01-01dalmahoy country club , scotlandeurope11\u00bd - 6\u00bdkathy whitworthmickey walker1990-01-01lake nona golf & country club , florida , usaunited states11\u00bd - 4\u00bdkathy whitworthmickey walker\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 6 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE year BETWEEN 1990 AND 2013 \nAND venue NOT LIKE '%usa%';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1458.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the new york jets played the denver broncos before the miami dolphins during the 1993 season\nInput Table: 1993 new york jets season\n\n\nweekdateopponentresultgame_siteattendance11993-09-05denver broncosl 26 - 20the meadowlands6813021993-09-12miami dolphinsw 24 - 14joe robbie stadium7031441993-09-26new england patriotsw 45 - 7the meadowlands6483651993-10-03philadelphia eaglesl 35 - 30the meadowlands7259361993-10-10los angeles raidersl 24 - 20los angeles memorial coliseum4162781993-10-24buffalo billsl 19 - 10the meadowlands7154191993-10-31new york giantsw 10 - 6giants stadium71659101993-11-07miami dolphinsw 27 - 10the meadowlands71306111993-11-14indianapolis coltsw 31 - 17rca dome47351121993-11-21cincinnati bengalsw 17 - 12the meadowlands64264131993-11-28new england patriotsw 6 - 0foxboro stadium42810141993-12-05indianapolis coltsl 9 - 6the meadowlands45799151993-12-11washington redskinsw 3 - 0robert f kennedy memorial stadium47970161993-12-18dallas cowboysl 28 - 7the meadowlands73233171993-12-26buffalo billsl 16 - 14rich stadium70817181994-01-02houston oilersl 24 - 0houston astrodome61040\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT week FROM table_sql WHERE opponent = 'denver broncos') < \n             (SELECT week FROM table_sql WHERE opponent = 'miami dolphins') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1648.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: kardinia park has less crowd than moorabbin oval\nInput Table: 1975 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddategeelong14.20 (104)melbourne14.14 (98)kardinia park133281975-06-07st kilda15.9 (99)north melbourne17.19 (121)moorabbin oval178111975-06-07richmond19.14 (128)essendon12.9 (81)mcg494691975-06-07hawthorn19.24 (138)collingwood13.11 (89)princes park238301975-06-07fitzroy15.7 (97)carlton16.10 (106)junction oval162491975-06-07footscray13.11 (89)south melbourne12.15 (87)vfl park140561975-06-07\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT crowd FROM table_sql WHERE venue = 'kardinia park') < \n             (SELECT crowd FROM table_sql WHERE venue = 'moorabbin oval') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-758.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the pole vault record was set on the 26th of august 2005\nInput Table: memorial van damme\n\n\neventrecordathletenationalitydate100 m10.72 ( - 0.3 m / s)shelly - ann fraser - prycejamaica2013-09-06200 m21.64 ( + 0.8 m / s)merlene otteyjamaica1991-09-13400 m48.83sanya richardsunited states2009-09-04800 m1:55.16pamela jelimokenya2008-09-061000 m2:28.98svetlana masterkovarussia1996-08-231500 m3:55.33s\u00fcreyya ayhanturkey2003-09-05mile4:17.75maryam yusuf jamalbahrain2007-09-142000 m5:30.19gelete burkaethiopia2009-09-043000 m8:24.81 +meseret defarethiopia2007-09-14two miles8:58.58meseret defarethiopia2007-09-145000 m14:25.43vivian cheruiyotkenya2008-09-06100 m hurdles12.42 ( - 0.3 m / s)yordanka donkovabulgaria1986-09-05400 m hurdles53.43nezha bidouanemorocco1998-08-283000 m steeplechase9:15.06milcah chemoskenya2013-09-06high jump2.05 manna chicherovarussia2011-09-16pole vault4.93 myelena isinbayevarussia2005-08-26long jump7.25 m ( + 1.7 m / s)heike drechslergermany1991-09-13triple jump15.14 m ( + 0.3 m / s)tatyana lebedevarussia2003-09-05shot put20.57 mnatalya lisovskayasoviet union1987-09-11discus throw69.84 mtsvetanka christovabulgaria1986-09-05javelin throw72.18 m ( old design ) 67.76 m ( current design )fatima whitbread trine hattestadunited kingdom norway1986-09-054100 m relay42.97united statesunited states1988-08-19\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT date FROM table_sql WHERE event = 'pole vault' AND record = '4.93 m') = '2005-08-26' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1927.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: caisse d'epargne had the most team classification wins with eleven\nInput Table: 2010 vuelta a espa\u00f1a\n\n\nstagewinnergeneral_classificationpoints_classificationmountains_classificationcombination_classificationteam_classification1team htc - columbiamark cavendishmark cavendish 1not awardedmark cavendishteam htc - columbia2yauheni hutarovichmark cavendishyauheni hutarovichmicka\u00ebl delagejavier ram\u00edrezteam htc - columbia3philippe gilbertphilippe gilbertphilippe gilbertseraf\u00edn mart\u00ednezseraf\u00edn mart\u00ednezteam htc - columbia4igor ant\u00f3nphilippe gilbertigor ant\u00f3nseraf\u00edn mart\u00ednezvincenzo nibalicaisse d'epargne5tyler farrarphilippe gilbertigor ant\u00f3nseraf\u00edn mart\u00ednezvincenzo nibalicaisse d'epargne6thor hushovdphilippe gilbertphilippe gilbertseraf\u00edn mart\u00ednezphilippe gilbertcaisse d'epargne7alessandro petacchiphilippe gilbertmark cavendishseraf\u00edn mart\u00ednezphilippe gilbertcaisse d'epargne8david moncouti\u00e9igor ant\u00f3nmark cavendishseraf\u00edn mart\u00ednezvincenzo nibalicaisse d'epargne9david l\u00f3pezigor ant\u00f3nmark cavendishdavid moncouti\u00e9vincenzo nibalicaisse d'epargne10imanol ervitijoaquim rodr\u00edguezmark cavendishdavid moncouti\u00e9david moncouti\u00e9caisse d'epargne11igor ant\u00f3nigor ant\u00f3nigor ant\u00f3ndavid moncouti\u00e9igor ant\u00f3ncaisse d'epargne12mark cavendishigor ant\u00f3nmark cavendishdavid moncouti\u00e9igor ant\u00f3ncaisse d'epargne13mark cavendishigor ant\u00f3nmark cavendishdavid moncouti\u00e9igor ant\u00f3ncaisse d'epargne14joaquim rodr\u00edguezvincenzo nibalimark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezcaisse d'epargne15carlos barredovincenzo nibalimark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezteam katusha16mikel nievejoaquim rodr\u00edguezmark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezteam katusha17peter velitsvincenzo nibalimark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezteam katusha18mark cavendishvincenzo nibalimark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezteam katusha19philippe gilbertvincenzo nibalimark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezteam katusha20ezequiel mosquera 2vincenzo nibalimark cavendishdavid moncouti\u00e9vincenzo nibaliteam katusha21tyler farrarvincenzo nibalimark cavendishdavid moncouti\u00e9vincenzo nibaliteam katusha\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE team_classification = \"caisse d'epargne\") = 11 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-990.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there were two episodes in the series that were directed by mike clattenburg\nInput Table: list of republic of doyle episodes\n\n\nUnnamed:_0titledirected_bywritten_byviewersoriginal_airdateprod_code1fathers and sonsmike clattenburgallan hawco , perry chafe and malcolm macrury9690002010-01-061012the return of the grievous angelsteve dimarcoallan hawco and avrum jacobson7150002010-01-131023duchess of georgemike clattenburgallan hawco , perry chafe and malcolm macrury6850002010-01-201035hit and rumsteve dimarcomatt maclennan5940002010-02-031056the one who got awaylarry mcleanjesse mckeown10120002010-02-101067the woman who knew too littlerobert liebermanjeremy boxen10530002010-03-031078the tell - tale safejerry ciccorittijohn callaghan and steve cochrane9860002010-03-101089he sleeps with the chipsphil earnshawperry chafe9080002010-03-1710910the pen is mightier than the doylerobert liebermansteve cochrane and avrum jacobson8970002010-03-2411011a horse dividedsteve scainijesse mckeown9020002010-03-31111\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 2 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE directed_by = 'mike clattenburg';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-692.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: week 6 was when the october 17 , 2004 game was played\nInput Table: 2004 cleveland browns season\n\n\nweekdateopponentresultstadiumrecordattendance12004-09-12baltimore ravensw 20 - 3cleveland browns stadium1 - 073068.022004-09-19dallas cowboysl 12 - 19texas stadium1 - 163119.032004-09-26new york giantsl 10 - 27giants stadium1 - 278521.042004-10-03washington redskinsw 17 - 13cleveland browns stadium2 - 273348.052004-10-10pittsburgh steelersl 23 - 34heinz field2 - 363609.062004-10-17cincinnati bengalsw 34 - 17cleveland browns stadium3 - 373263.072004-10-24philadelphia eaglesl 31 - 34cleveland browns stadium3 - 473394.089999-01-01----nan92004-11-07baltimore ravensl 13 - 27m&t bank stadium3 - 569781.0102004-11-14pittsburgh steelersl 10 - 24cleveland browns stadium3 - 673703.0112004-11-21new york jetsl 7 - 10cleveland browns stadium3 - 772547.0122004-11-28cincinnati bengalsl 48 - 58paul brown stadium3 - 865677.0132004-12-05new england patriotsl 15 - 42cleveland browns stadium3 - 973028.0142004-12-12buffalo billsl 7 - 37ralph wilson stadium3 - 1072330.0152004-12-19san diego chargersl 0 - 21cleveland browns stadium3 - 1172489.0162004-12-26miami dolphinsl 7 - 10pro player stadium3 - 1273169.0172005-01-02houston texansw 22 - 14reliant stadium4 - 1270724.0\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE week = 6 \nAND date = '2004-10-17';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-57.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: joe germanese was the 27th pick\nInput Table: 2008 mls superdraft\n\n\npickmls_teamplayerpositionaffiliation15san jose earthquakesshea salinasmfurman carolina dynamo16new york red bullseric brunnerdohio state michigan bucks17real salt lakealex nimofgeneration adidas18new england revolutionmichael videiramduke cary railhawks u23 's19fc dallaseric avilamuc santa barbara ventura county fusion20columbus crewgeorge jostenm / fgonzaga michigan bucks21los angeles galaxyely allenf / mwashington22columbus crewricardo pierre - louisflee university cape cod crusaders23kansas city wizardsyomby williamdold dominion hampton roads piranhas24dc unitedandrew jacobsonmcalifornia25kansas city wizardsjonathan leathersdfurman atlanta silverbacks u23 's26chicago firepeter lowrym / fsanta clara san jose frogs27new england revolutionjoe germanesemduke cary railhawks u23 's28toronto fcbrian edwardsgkwake forest\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT pick FROM table_sql WHERE player = 'joe germanese') = 27 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-58.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: jonathan leathers was picked 25th\nInput Table: 2008 mls superdraft\n\n\npickmls_teamplayerpositionaffiliation15san jose earthquakesshea salinasmfurman carolina dynamo16new york red bullseric brunnerdohio state michigan bucks17real salt lakealex nimofgeneration adidas18new england revolutionmichael videiramduke cary railhawks u23 's19fc dallaseric avilamuc santa barbara ventura county fusion20columbus crewgeorge jostenm / fgonzaga michigan bucks21los angeles galaxyely allenf / mwashington22columbus crewricardo pierre - louisflee university cape cod crusaders23kansas city wizardsyomby williamdold dominion hampton roads piranhas24dc unitedandrew jacobsonmcalifornia25kansas city wizardsjonathan leathersdfurman atlanta silverbacks u23 's26chicago firepeter lowrym / fsanta clara san jose frogs27new england revolutionjoe germanesemduke cary railhawks u23 's28toronto fcbrian edwardsgkwake forest\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT pick FROM table_sql WHERE player = 'jonathan leathers') = 25 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-1067.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the largest attendance was at the game that took place on september 13 , 1976\nInput Table: 1976 buffalo bills season\n\n\nweekdateopponentresultattendance11976-09-13miami dolphinsl 30 - 217768321976-09-19houston oilersl 13 - 36138431976-09-26tampa bay buccaneersw 14 - 94450541976-10-03kansas city chiefsw 50 - 175190951976-10-10new york jetsl 17 - 145911061976-10-17baltimore coltsl 31 - 137100971976-10-24new england patriotsl 26 - 224514481976-10-31new york jetsl 19 - 144128591976-11-07new england patriotsl 20 - 1061157101976-11-15dallas cowboysl 17 - 1051799111976-11-21san diego chargersl 34 - 1336539121976-11-25detroit lionsl 27 - 1466875131976-12-05miami dolphinsl 45 - 2743475141976-12-12baltimore coltsl 58 - 2050451\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN attendance = (SELECT MAX(attendance) FROM table_sql) \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE date = '1976-09-13';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-4.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the most the wildcats outscored an opponent is by 36 points\nInput Table: 1947 kentucky wildcats football team\n\n\ngamedateopponentresultwildcats_pointsopponentsrecord19999-09-20ole missloss7140 - 129999-09-27cincinnatiwin2001 - 139999-10-04xavierwin2072 - 149999-10-119 georgiawin2603 - 1 , 2059999-10-1810 vanderbiltwin1404 - 1 , 1469999-10-25michigan statewin765 - 1 , 1379999-11-0118 alabamaloss0135 - 289999-11-08west virginiawin1566 - 299999-11-15evansvillewin3607 - 2109999-11-22tennesseeloss6137 - 3\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MAX(wildcats_points - opponents) FROM table_sql) >= 36 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-664.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: three of the total games featured had an attendance in the 3000s\nInput Table: 2008 - 09 bradford city a.f.c. season\n\n\ngamedateopponentvenueresultattendance12008-08-09notts countyhome2 - 11403822008-08-16macclesfield townaway2 - 0255632008-08-23rochdalehome2 - 01315442008-08-30aldershot townaway2 - 3380552008-09-06port valeaway2 - 0727362008-09-13exeter cityhome4 - 11268372008-09-20bournemouthhome1 - 31282482008-09-27shrewsbury townaway0 - 2651792008-10-04luton townhome1 - 113083102008-10-11accrington stanleyaway3 - 23012112008-10-18gillinghamhome2 - 212432122008-10-21darlingtonaway1 - 23034132008-10-24grimsby townaway3 - 14470142008-10-28buryhome1 - 012830152008-11-01barnethome3 - 312510162008-11-15wycombe wanderersaway0 - 15002172008-11-22rotherham unitedaway2 - 04586182008-11-25chesterfieldhome3 - 212145192008-12-06dagenham & redbridgehome1 - 112145202008-12-13brentfordaway1 - 24339212008-12-20chester cityhome0 - 012092222008-12-26lincoln cityaway0 - 06156232008-12-28morecambehome4 - 013105242009-01-03shrewsbury townhome0 - 012877252009-01-17accrington stanleyhome1 - 112172262009-01-24luton townaway3 - 36053272009-01-27buryaway0 - 14112282009-01-31grimsby townhome2 - 012816292009-02-07gillinghamaway2 - 04866302009-02-14wycombe wanderershome1 - 012689312009-02-17darlingtonhome0 - 012782322009-02-21barnetaway1 - 42445332009-02-28notts countyaway1 - 35138342009-03-01macclesfield townhome1 - 011908352009-03-07aldershot townhome5 - 012465362009-03-10rochdaleaway0 - 35157372009-03-14exeter cityaway0 - 15253382009-03-17bournemouthaway1 - 44847392009-03-21port valehome0 - 112436402009-03-28chester cityaway0 - 02735412009-04-04brentfordhome1 - 112832422009-04-10morecambeaway1 - 24546432009-04-13lincoln cityhome1 - 112932\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 3 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE attendance BETWEEN 3000 AND 3999;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-361.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: more players were drafted from usc than from clemson\nInput Table: indianapolis colts draft history\n\n\nroundpickoverallnamepositioncollege155curtis dickeyrunning backtexas a&m12424derrick hatchettcornerbacktexas2432ray donaldsoncentergeorgia22351tim foleyoffensive tacklenotre dame4588ray butlerwide receiverusc66144chris footecenterusc75170wes robertsdefensive endtcu82195ken walteroffensive tackletexas tech96227mark brightrunning backtemple105254larry stewartoffensive tacklemaryland113280ed whitleytight endkansas state126311randy bielskiplacekickertowson1219324marvin simsfullbackclemson\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE college = 'usc') > \n             (SELECT COUNT(*) FROM table_sql WHERE college = 'clemson') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-512.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the player from portugal is ranked number 1\nInput Table: rowing at the 2008 summer olympics - men 's lightweight double sculls\n\n\nrankrowerscountrytimenotes1pedro fraga , nuno mendesportugal6:39.07sa / b2eyder batista , yunior perezcuba6:40.15sa / b3kazushige ura , daisaku takedajapan6:43.03sc / d4zsolt hirling , tam\u00e3\u00a1s vargahungary6:50.48sc / d5devender kumar khandwal , manjeet singhindia7:02.06sc / d6jang kang - eun , kim hong - kyunsouth korea7:12.17sc / d\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN rank = 1 AND country = 'portugal' THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-324.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: william f goodling was one of six republican incumbents to be re - elected\nInput Table: united states house of representatives elections , 1994\n\n\ndistrictincumbentpartyfirst_electedstatusopponentpennsylvania4ron klinkdemocratic1992-01-01re - electedron klink (d) 64.2% ed peglow (r) 35.8%pennsylvania5william f clinger , jrrepublican1978-01-01re - electedwilliam f clinger , jr (r) unopposedpennsylvania7curt weldonrepublican1986-01-01re - electedcurt weldon (r) 69.7% sara r nichols (d) 30.3%pennsylvania9bud shusterrepublican1972-01-01re - electedbud shuster (r) unopposedpennsylvania12john murthademocratic1974-01-01re - electedjohn murtha (d) 68.9% bill choby (r) 31.1%pennsylvania17george gekasrepublican1982-01-01re - electedgeorge gekas (r) unopposedpennsylvania18rick santorumrepublican1990-01-01retired to run for us senate democratic gainmichael f doyle (d) 54.8% john mccarty (r) 45.2%pennsylvania19william f goodlingrepublican1974-01-01re - electedwilliam f goodling (r) unopposed\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 1 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE incumbent = 'william f goodling' \nAND party = 'republican' \nAND status = 're - elected';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-528.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: north melbourne home team recorded an home score of 9.14 (68) while south melbourne recorded an home score of 7.8 (50)\nInput Table: 1961 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddatenorth melbourne9.14 (68)st kilda11.16 (82)arden street oval130001961-06-03hawthorn10.13 (73)richmond8.12 (60)glenferrie oval150001961-06-03collingwood18.11 (119)essendon8.10 (58)victoria park282901961-06-03geelong13.13 (91)footscray4.14 (38)kardinia park186831961-06-03south melbourne7.8 (50)fitzroy17.15 (117)lake oval145001961-06-03melbourne15.14 (104)carlton11.13 (79)mcg496781961-06-03\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT home_team_score FROM table_sql WHERE home_team = 'north melbourne') = '9.14 (68)' \n             AND (SELECT home_team_score FROM table_sql WHERE home_team = 'south melbourne') = '7.8 (50)' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TP/test-464.html": {
        "method": "Text2SQL",
        "subfolder": "TP",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "True",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the player in second place has a score of 70 + 68 = 138\nInput Table: 1973 u.s. open (golf)\n\n\nplaceplayercountryscoreto_par1gary playersouth africa67 + 70 = 137- 52jim colbertunited states70 + 68 = 138- 4t3jack nicklausunited states71 + 69 = 140- 2t3johnny millerunited states71 + 69 = 140- 2t3bob charlesnew zealand71 + 69 = 140- 2t6gene borekunited states77 + 65 = 142et6julius borosunited states73 + 69 = 142et6tom weiskopfunited states73 + 69 = 142et6arnold palmerunited states71 + 71 = 142et6lee trevinounited states70 + 72 = 142e\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT score FROM table_sql WHERE place = 2) = '70 + 68 = 138' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-611.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the nets' only win came at the air canada centre\nInput Table: 2010 - 11 new jersey nets season\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord759999-04-01philadelphial 90 - 115 (ot)brandan wright (15)brandan wright (11)deron williams (7)wells fargo center 1669523 - 52769999-04-03miamil 94 - 108 (ot)deron williams (18)travis outlaw (9)deron williams (9)prudential center 1871123 - 5377'9999-04-05'minnesotaw 107 - 105 (ot)brook lopez (30)brook lopez (12)deron williams (21)prudential center 1346124 - 53789999-04-06detroitl 109 - 116 (ot)brook lopez (39)brook lopez (7)jordan farmar (11)the palace of auburn hills 1455424 - 54799999-04-08new yorkl 93 - 116 (ot)brook lopez (27)jordan farmar (8)jordan farmar (9)prudential center 1802324 - 5580'9999-04-10'torontol 92 - 99 (ot)brook lopez (35)brook lopez (11)jordan farmar (7)air canada centre 1775524 - 56819999-04-11charlottel 103 - 105 (ot)brook lopez (31)dan gadzuric (8)jordan farmar (9)prudential center 1385324 - 57\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE team = 'new jersey nets' AND location_attendance = 'air canada centre' AND score = 'w 107 - 105 (ot)') = 1 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-769.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the bmw has less than 6 points with a speed of 82.32 mph\nInput Table: 1972 isle of man tt\n\n\nplaceridercountrymachinespeedtimepoints1siegfried schauzu / wolfgang kalauchwest germanybmw91.85 mph1:13.57.2152heinz luthringshauser / jcusnikwest germanybmw91.70 mph1:14.04.6123gerry boret / nick boretunited kingdomkonig84.43 mph1:20.27.4104wklenk / nscheererwest germanybmw83.62 mph1:21.31.885barry dungworth / rwturringtonunited kingdombmw82.32 mph1:22.30.666roy hanks / jpmannunited kingdombsa80.07 mph1:24.49.657rwoodhouse / dwoodhouseunited kingdombsa79.83 mph1.25.05.4048roger dutton / tony wrightunited kingdombmw79.63 mph1.25.18.039george o'dell / bill boldisonunited kingdombsa79.60 mph1.25.20.2210jbarker / amacfadzeanunited kingdombsa79.52 mph1.25.28.21\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT points FROM table_sql WHERE machine = 'bmw' AND speed = '82.32 mph') < 6 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-639.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: bell media owns three separate radio stations like the cbc\nInput Table: media in kelowna\n\n\nfrequencycall_signbrandingformatowner1150 amckfram 1150news / talkastral media00 88.9 fmcbtk - fmcbc radio onepublic news / talkcanadian broadcasting corporation00 89.7 fmcbu - fm - 3cbc radio 2public musiccanadian broadcasting corporation00 90.5 fmcbuf - fm - 2premi\u00e8re cha\u00eenepublic news / talkcanadian broadcasting corporation00 96.3 fmckko - fmk96.3classic rocksun country cablevision00 99.9 fmchsu - fm99.9 sun fmcontemporary hits radiobell media0 101.5 fmcilk - fm101.5 ez rockadult contemporarybell media0 103.1 fmckqq - fmq103hot adult contemporaryjim pattison group0 103.9 fmcjui - fm103.9 the juiceadult hitsvista broadcast group0 104.7 fmcklz - fmpower 104active rockjim pattison group\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE owner = 'bell media') = 3 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-773.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: when the attendance was 62170 , the opponent was at dallas cowboys , for week 10\nInput Table: 2000 cincinnati bengals season\n\n\nweekdateopponentresultattendance22000-09-10cleveland brownsl 24 - 76400632000-09-17jacksonville jaguarsl 13 - 04565342000-09-24baltimore ravensl 37 - 06848152000-10-01miami dolphinsl 31 - 166153562000-10-08tennessee titansl 23 - 146340672000-10-15pittsburgh steelersl 15 - 05432882000-10-22denver broncosw 31 - 216160392000-10-29cleveland brownsw 12 - 373118102000-11-05baltimore ravensl 27 - 754759112000-11-12dallas cowboysl 23 - 662170122000-11-19new england patriotsl 16 - 1360292132000-11-26pittsburgh steelersl 48 - 2863925142000-12-03arizona cardinalsw 24 - 1350289152000-12-10tennessee titansl 35 - 368498162000-12-17jacksonville jaguarsw 17 - 1450469172000-12-24philadelphia eaglesl 16 - 764902\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT opponent FROM table_sql WHERE attendance = 62170 AND week = 10) = 'dallas cowboys' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-278.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the toronto blue jays lost three consecutive games between the 25th and the 28th may 1991\nInput Table: 1991 toronto blue jays season\n\n\ndateopponentscorelossattendancerecord9999-05-01rangers3 - 0key (4 - 1)3343912 - 109999-05-02royals3 - 1appier (1 - 4)2289613 - 109999-05-03royals5 - 1davis (2 - 2)2080914 - 109999-05-04royals6 - 5boucher (0 - 2)2262814 - 119999-05-05royals3 - 0gordon (1 - 2)2258815 - 119999-05-07rangers3 - 2key (4 - 2)4462215 - 129999-05-08rangers4 - 2ryan (3 - 3)4321116 - 129999-05-09white sox2 - 0p\u00e3rez (1 - 2)4723617 - 129999-05-10white sox5 - 3 (12)fraser (0 - 1)5019817 - 139999-05-11white sox5 - 2hough (0 - 2)5020618 - 139999-05-12white sox4 - 2hibbard (2 - 1)5010819 - 139999-05-13royals4 - 2davis (2 - 4)4427520 - 139999-05-14royals4 - 1gubicza (0 - 1)4335721 - 139999-05-15royals6 - 4boucher (0 - 3)5011321 - 149999-05-17white sox5 - 3timlin (3 - 1)3009521 - 159999-05-18white sox9 - 2hibbard (2 - 2)3486122 - 159999-05-19white sox5 - 4timlin (3 - 2)4101522 - 169999-05-20athletics1 - 0welch (4 - 3)2463123 - 169999-05-21athletics11 - 7dressendorfer (3 - 3)2273824 - 169999-05-22athletics2 - 1stieb (4 - 3)3402824 - 179999-05-24angels3 - 2finley (7 - 2)2640825 - 179999-05-25angels5 - 0stottlemyre (5 - 1)3673225 - 189999-05-26angels6 - 2wells (5 - 4)4530725 - 199999-05-28athletics8 - 4acker (1 - 2)5029925 - 209999-05-29athletics8 - 3slusarski (1 - 2)5026226 - 209999-05-30athletics8 - 6ward (0 - 2)5027126 - 219999-05-31angels5 - 1langston (6 - 2)5025227 - 21\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE date BETWEEN '1991-05-25' AND '1991-05-28' AND loss = 'lost') = 3 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-203.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the average of all the home team scores is less than 12\nInput Table: 1972 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddatefootscray14.7 (91)st kilda9.11 (65)western oval186551972-07-15fitzroy16.14 (110)north melbourne9.12 (66)junction oval70071972-07-15essendon13.12 (90)richmond17.9 (111)windy hill222511972-07-15carlton20.8 (128)south melbourne8.15 (63)princes park144651972-07-15hawthorn19.14 (128)geelong15.8 (98)glenferrie oval124251972-07-15collingwood10.13 (73)melbourne8.10 (58)vfl park308831972-07-15\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN AVG(home_team_score) < 12 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1192.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: alfredo binda was the race leader for 15 races in the 1933 giro d'italia\nInput Table: 1933 giro d'italia\n\n\ndatecoursedistancewinnerrace_leader9999-05-06milan to turin-learco guerra ( ita )learco guerra ( ita )9999-05-07turin to genoa-alfredo binda ( ita )alfredo binda ( ita )9999-05-08genoa to pisa-learco guerra ( ita )alfredo binda ( ita )9999-05-09rest dayrest dayrest dayrest day9999-05-10pisa to florence-giuseppe olmo ( ita )alfredo binda ( ita )9999-05-11florence to grosseto-learco guerra ( ita )jef demuysere ( bel )9999-05-12grosseto to rome-mario cipriani ( ita )jef demuysere ( bel )9999-05-13rest dayrest dayrest dayrest day9999-05-14rome to naples-gerard loncke ( bel )jef demuysere ( bel )9999-05-15naples to foggia-alfredo binda ( ita )alfredo binda ( ita )9999-05-16rest dayrest dayrest dayrest day9999-05-17foggia to chieti-alfredo binda ( ita )alfredo binda ( ita )9999-05-18chieti to ascoli piceno-alfredo binda ( ita )alfredo binda ( ita )9999-05-19rest dayrest dayrest dayrest day9999-05-20ascoli piceno to riccione-fernand cornez ( fra )alfredo binda ( ita )9999-05-21riccione to bologna-giuseppe olmo ( ita )alfredo binda ( ita )9999-05-22bologna to ferrara-alfredo binda ( ita )alfredo binda ( ita )9999-05-23rest dayrest dayrest dayrest day9999-05-24ferrara to udine-ettore meini ( ita )alfredo binda ( ita )9999-05-25udine to bassano del grappa-ettore meini ( ita )alfredo binda ( ita )9999-05-26bassano del grappa to bolzano-gerard loncke ( bel )alfredo binda ( ita )9999-05-27rest dayrest dayrest dayrest day9999-05-28bolzano to milan-alfredo binda ( ita )alfredo binda ( ita )2023-09-20-km (mi)-km (mi)\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 15 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE race_leader = 'alfredo binda ( ita )';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-188.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there were four teams that scored exactly 12 against cambridge university\nInput Table: 1978 new zealand rugby union tour of britain and ireland\n\n\nopposing_teamagainstdatevenuestatuscambridge university121978-10-18grange road , cambridgetour matchcardiff71978-10-21cardiff arms park , cardifftour matchwest wales xv71978-10-25st helen 's , swanseatour matchlondon counties121978-10-28twickenham , londontour matchmunster121978-10-31thomond park , limericktour matchireland61978-11-04lansdowne road , dublintest matchulster71978-11-07ravenhill , belfasttour matchwales121978-11-01cardiff arms park , cardifftest matchsouth and south - west counties01978-11-15memorial ground , bristoltour matchmidland counties151978-11-18welford road , leicestertour matchcombined services61978-11-21aldershot military stadium , aldershottour matchengland61978-11-25twickenham , londontest matchmonmouthshire91978-11-29rodney parade , newporttour matchnorth of england61978-12-02birkenhead park , birkenheadtour matchnorth and midland of scotland31978-12-05linksfield stadium , aberdeentour matchscotland91978-12-09murrayfield , edinburghtest matchbridgend61978-12-13brewery field , bridgendtour matchbarbarians161978-12-16cardiff arms park , cardifftour match\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 4 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE against = 12 \nAND opposing_team = 'cambridge university';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1196.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: learco guerra was the race leader for the first race of the 1933 giro d'italia , and] became race leader again for the rest of the circuit\nInput Table: 1933 giro d'italia\n\n\ndatecoursedistancewinnerrace_leader9999-05-06milan to turin-learco guerra ( ita )learco guerra ( ita )9999-05-07turin to genoa-alfredo binda ( ita )alfredo binda ( ita )9999-05-08genoa to pisa-learco guerra ( ita )alfredo binda ( ita )9999-05-09rest dayrest dayrest dayrest day9999-05-10pisa to florence-giuseppe olmo ( ita )alfredo binda ( ita )9999-05-11florence to grosseto-learco guerra ( ita )jef demuysere ( bel )9999-05-12grosseto to rome-mario cipriani ( ita )jef demuysere ( bel )9999-05-13rest dayrest dayrest dayrest day9999-05-14rome to naples-gerard loncke ( bel )jef demuysere ( bel )9999-05-15naples to foggia-alfredo binda ( ita )alfredo binda ( ita )9999-05-16rest dayrest dayrest dayrest day9999-05-17foggia to chieti-alfredo binda ( ita )alfredo binda ( ita )9999-05-18chieti to ascoli piceno-alfredo binda ( ita )alfredo binda ( ita )9999-05-19rest dayrest dayrest dayrest day9999-05-20ascoli piceno to riccione-fernand cornez ( fra )alfredo binda ( ita )9999-05-21riccione to bologna-giuseppe olmo ( ita )alfredo binda ( ita )9999-05-22bologna to ferrara-alfredo binda ( ita )alfredo binda ( ita )9999-05-23rest dayrest dayrest dayrest day9999-05-24ferrara to udine-ettore meini ( ita )alfredo binda ( ita )9999-05-25udine to bassano del grappa-ettore meini ( ita )alfredo binda ( ita )9999-05-26bassano del grappa to bolzano-gerard loncke ( bel )alfredo binda ( ita )9999-05-27rest dayrest dayrest dayrest day9999-05-28bolzano to milan-alfredo binda ( ita )alfredo binda ( ita )2023-09-20-km (mi)-km (mi)\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT race_leader FROM table_sql WHERE date = '9999-05-06') = 'learco guerra ( ita )' \n             AND (SELECT race_leader FROM table_sql WHERE date > '9999-05-06') = 'learco guerra ( ita )' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1761.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the size of the crowd when essendon was the away team was 25158\nInput Table: 1954 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddatecollingwood12.13 (85)st kilda7.15 (57)victoria park165001954-07-31carlton9.11 (65)richmond6.10 (46)princes park258631954-07-31melbourne16.14 (110)hawthorn5.3 (33)mcg267081954-07-31south melbourne6.5 (41)footscray11.12 (78)lake oval195001954-07-31north melbourne8.19 (67)fitzroy8.6 (54)arden street oval110001954-07-31geelong16.14 (110)essendon11.10 (76)kardinia park281581954-07-31\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT crowd FROM table_sql WHERE away_team = 'essendon') = 25158 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-142.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: australia received 0 gold medals and more than 1 bronze\nInput Table: 2003 world taekwondo championships\n\n\nranknationgoldsilverbronzetotal1south korea802102iran22153chinese taipei20134united states12365spain11356china11137greece10238croatia02139france020210germany012311canada011211denmark011113cuba010113great britain010113mexico010116azerbaijan004417thailand002218australia001118austria001118belarus001118kazakhstan001118morocco001118philippines001118turkey001118venezuela0011totaltotal16163264\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT gold FROM table_sql WHERE nation = 'australia') = 0 \n             AND (SELECT bronze FROM table_sql WHERE nation = 'australia') > 1 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1854.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: in 2009 , the mixed double consists of didit juang indrianto and yayu rahayu and hermansyah is the boys singles\nInput Table: indonesian national badminton championships\n\n\nyearboys_singlesgirls_singlesboys_doublesgirls_doublesmixed_doubles2001holvy de pauwmaria kristin yuliantihendra setiawan joko riyadililyana natsir natalia poluakanhendra setiawan greysia polii2002andre kurniawan tedjonofransisca ratnasariujang suherlan yoga ukikasahpurwati meiliana jauharimuhammad rijal meiliana jauhari2003alamsyah yunuswiwis meilyannafran kurniawan chandra kowipia zebadiah nitya krishinda maheswarifran kurniawan yulianti2004andre kurniawan tedjonopia zebadiahaditya dwi putra i made agungpia zebadiah nitya krishinda maheswarilingga lie yulianti2005achmad rivaibellaetrix manuputtyrio willianto davin prawidssalily siswanti shendy puspa irawatiabdul rahman richi puspita dili2006nugroho andi saputrosylvinna kurniawandanny bawa chrisnanta afiat yuris wirawanbellaetrix manuputty samantha lintangdanny bawa chrisnanta debby susanto2007nandang ariflindaweni fanetribudi hartono yohanes rendy sugiartoanneke feinya agustin wenny setiawatiwifqi windarto debby susanto2008hermansyahana rovitadidit juang indrianto seiko wahyu kusdiantosuci rizki andini tiara rosalia nuraidahirfan fadhilah weni anggraeni2009riyanto subagjaana rovitajones ralfy jansen dandi prabuditaayu pratiwi anggi widiadidit juang indrianto yayu rahayu2010shesar hiren rhustavitoganis nur rahmadanijones ralfy jansen dandi prabuditaaris budiharti dian fitrianijones ralfy jansen nurbeta kwanrico\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT mixed_doubles FROM table_sql WHERE year = 2009) = 'didit juang indrianto yayu rahayu' \n             AND (SELECT boys_singles FROM table_sql WHERE year = 2009) = 'hermansyah' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-310.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: 1 - 0 was the score the home team was bolton wanderers\nInput Table: 1990 - 91 fa cup\n\n\ntie_nohome_teamscoreaway_teamdate1liverpool2 - 2brighton & hove albion1991-01-26replaybrighton & hove albion2 - 3liverpool1991-01-302notts county2 - 0oldham athletic1991-01-263crewe alexandra1 - 0rotherham united1991-01-264luton town1 - 1west ham united1991-01-26replaywest ham united5 - 0luton town1991-01-305woking0 - 1everton1991-01-276shrewsbury town1 - 0wimbledon1991-01-267newcastle united2 - 2nottingham forest1991-02-13replaynottingham forest3 - 0newcastle united1991-02-188tottenham hotspur4 - 2oxford united1991-01-269coventry city1 - 1southampton1991-01-26replaysouthampton2 - 0coventry city1991-01-2910portsmouth5 - 1bournemouth1991-01-2611manchester united1 - 0bolton wanderers1991-01-2612norwich city3 - 1swindon town1991-01-2613millwall4 - 4sheffield wednesday1991-01-26replaysheffield wednesday2 - 0millwall1991-01-3014port vale1 - 2manchester city1991-01-2615arsenal0 - 0leeds united1991-01-27replayleeds united1 - 1arsenal1991-01-30replayarsenal0 - 0leeds united1991-02-13replayleeds united1 - 2arsenal1991-02-1616cambridge united2 - 0middlesbrough1991-01-26\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT score FROM table_sql WHERE home_team = 'bolton wanderers') = '1 - 0' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-137.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the toronto maple leafs are the opponent listed with 63 , 66 , and 69 points\nInput Table: none\n\n\ngamemarchopponentscorerecordpoints639999-01-04detroit red wings2 - 224 - 28 - 1159649999-01-06california golden seals4 - 424 - 28 - 1260659999-01-07minnesota north stars1 - 324 - 29 - 1260669999-01-10pittsburgh penguins2 - 224 - 29 - 1361679999-01-12new york rangers2 - 724 - 30 - 1361689999-01-13toronto maple leafs3 - 225 - 30 - 1363699999-01-18new york rangers2 - 126 - 30 - 1365709999-01-20boston bruins3 - 526 - 31 - 1365719999-01-21toronto maple leafs1 - 126 - 31 - 1466729999-01-24montreal canadiens3 - 526 - 32 - 1466739999-01-25minnesota north stars2 - 226 - 32 - 1567749999-01-27chicago black hawks1 - 326 - 33 - 1567759999-01-28pittsburgh penguins3 - 127 - 33 - 1569\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 3 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE opponent = 'toronto maple leafs' \nAND points IN (63, 66, 69);\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-831.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: in the 1981 open championship no player finished under par except isao aoki\nInput Table: 1981 open championship\n\n\nplaceplayercountryscoreto_part1vicente fern\u00e3\u00a1ndezargentina70et1nick jobengland70et3isao aokijapan71+ 1t3david grahamaustralia71+ 1t3tony jacklinengland71+ 1t3johnny millerunited states71+ 1t3simon owennew zealand71+ 1t3hal sutton (a)united states71+ 1t9howard clarkengland72+ 2t9ben crenshawunited states72+ 2t9david jaggerengland72+ 2t9mark jamesengland72+ 2t9greg normanaustralia72+ 2t9arnold palmerunited states72+ 2t9bill rogersunited states72+ 2t9sam torrancescotland72+ 2\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE to_par < 'e' \nAND player != 'isao aoki' \nAND place != 't1';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1143.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: essendon was the away team which played against footscray\nInput Table: 1946 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddategeelong15.7 (97)melbourne21.14 (140)kardinia park115001946-07-13essendon16.24 (120)footscray14.8 (92)windy hill290001946-07-13collingwood15.23 (113)hawthorn11.14 (80)victoria park110001946-07-13carlton12.13 (85)south melbourne11.18 (84)princes park260001946-07-13st kilda10.14 (74)north melbourne12.11 (83)junction oval70001946-07-13richmond14.14 (98)fitzroy10.12 (72)punt road oval190001946-07-13\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE away_team = 'essendon' \nAND home_team = 'footscray';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-452.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: two home teams had the same scores as the away teams that they were playing\nInput Table: 1938 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddategeelong11.23 (89)hawthorn6.13 (49)corio oval70001938-06-18fitzroy16.12 (108)south melbourne8.8 (56)brunswick street oval120001938-06-18st kilda14.12 (96)melbourne16.16 (112)junction oval140001938-06-18richmond15.14 (104)essendon15.9 (99)punt road oval200001938-06-18footscray13.9 (87)collingwood10.5 (65)western oval180001938-06-18north melbourne11.5 (71)carlton16.25 (121)arden street oval130001938-06-18\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT home_team_score FROM table_sql WHERE home_team = away_team AND home_team_score = away_team_score) IS NOT NULL \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-194.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: all 5 matches held in october of 1978 took place after the 25th of the month\nInput Table: 1978 new zealand rugby union tour of britain and ireland\n\n\nopposing_teamagainstdatevenuestatuscambridge university121978-10-18grange road , cambridgetour matchcardiff71978-10-21cardiff arms park , cardifftour matchwest wales xv71978-10-25st helen 's , swanseatour matchlondon counties121978-10-28twickenham , londontour matchmunster121978-10-31thomond park , limericktour matchireland61978-11-04lansdowne road , dublintest matchulster71978-11-07ravenhill , belfasttour matchwales121978-11-01cardiff arms park , cardifftest matchsouth and south - west counties01978-11-15memorial ground , bristoltour matchmidland counties151978-11-18welford road , leicestertour matchcombined services61978-11-21aldershot military stadium , aldershottour matchengland61978-11-25twickenham , londontest matchmonmouthshire91978-11-29rodney parade , newporttour matchnorth of england61978-12-02birkenhead park , birkenheadtour matchnorth and midland of scotland31978-12-05linksfield stadium , aberdeentour matchscotland91978-12-09murrayfield , edinburghtest matchbridgend61978-12-13brewery field , bridgendtour matchbarbarians161978-12-16cardiff arms park , cardifftour match\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE strftime('%Y-%m-%d', date) > '1978-10-25' \nAND strftime('%Y-%m', date) = '1978-10';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1477.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the total number of high assists (8) for g payton occurred at the game on march 10\nInput Table: 1991 - 92 seattle supersonics season\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord589999-03-01cleveland cavaliersw 113 - 107e johnson , r pierce (22)b benjamin , m cage (14)r pierce (6)seattle center coliseum 1364732 - 26599999-03-03denver nuggetsw 111 - 92s kemp (21)s kemp (13)g payton (9)seattle center coliseum 986533 - 26609999-03-05phoenix sunsl 105 - 118r pierce (23)s kemp (19)g payton (12)arizona veterans memorial coliseum 1449633 - 27619999-03-07new jersey netsw 109 - 98r pierce (27)m cage (13)n mcmillan (7)seattle center coliseum 1341934 - 27620000-03-08portland trail blazersl 97 - 109r pierce (28)r pierce (10)g payton (7)memorial coliseum 1288834 - 28639999-03-10detroit pistonsl 92 - 98g payton (19)s kemp (9)n mcmillan (5)seattle center coliseum 1309834 - 29649999-03-11los angeles clippersw 104 - 96r pierce (19)b benjamin , m cage (6)g payton (9)los angeles memorial sports arena 1091235 - 296501-03-15dallas mavericksw 109 - 100r pierce (23)s kemp (15)g payton (8)seattle center coliseum 1216336 - 29660000-03-17golden state warriorsl 107 - 119r pierce (24)s kemp (15)r pierce (5)seattle center coliseum 1316336 - 30679999-03-19houston rocketsw 112 - 91r pierce (22)m cage , s kemp (14)g payton (11)the summit 1512237 - 30689999-03-21san antonio spursl 96 - 101e johnson (23)s kemp (13)d barros , m cage , n mcmillan (4)hemisfair arena 1605737 - 31699999-03-22dallas mavericksw 113 - 105e johnson (31)s kemp (17)n mcmillan (8)reunion arena 1434538 - 31709999-03-24houston rocketsw 128 - 106d mckey (23)m cage , s kemp (11)n mcmillan , g payton (7)seattle center coliseum 1137739 - 31719999-03-27milwaukee bucksw 96 - 95e johnson (21)n mcmillan (7)n mcmillan (6)seattle center coliseum 1145040 - 31729999-03-28new york knicksl 87 - 92s kemp (27)s kemp (12)n mcmillan (6)seattle center coliseum 1481240 - 32\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT high_assists FROM table_sql WHERE date = '9999-03-10' AND team = 'seattle supersonics') = 8 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-953.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: at90s1200 is the chip with the smallest frequency of more than 12 mhz\nInput Table: none\n\n\nchipflash_sizeeepromsramfrequencypackageat90s12001k64012pdip - 20at90s23132k12812810pdip - 20at90s / ls23232k12812810pdip - 8at90s / ls23432k12812810pdip - 8at90s44144k2562568pdip - 40at90s / ls44344k2562568pdip - 40at90s85158k5125128pdip - 40at90s / ls85358k5125128pdip - 40\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT chip FROM table_sql WHERE frequency > 12 ORDER BY frequency ASC LIMIT 1) = 'at90s1200' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-547.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the first episode for dea agent was vengeance\nInput Table: list of csi : miami characters\n\n\ncharacterpositionactorfirst_episodefinal_episodedurationfinal_episode_countdr tom lomanmedical examinerchristian clemenson9999-01-019999-01-0108x03 - 10x1952maxine valeradna technicianboti bliss9999-01-019999-01-0102x01 - 08x1176dan cooperav technicianbrendan fehr9999-01-019999-01-0104x01 - 06x1635tyler jensonav technicianbrian pothYYYY-MM-DD9999-10-0701x19 - 03x2429aaron peterstrace technicianarmando kennedy9999-01-019999-01-0103x07 - 04x2516cynthia wellsqd technicianbrooke bloom9999-01-012023-09-2002x16 - 05x1814jake berkeleydetectivejohnny whitworth9999-01-012022-01-0105x02 - 08x2112john hagendetectiveholt mccallany9999-01-019999-10-0701x17 - 03x2411adelle sevilladetectivewanda de jesus9999-01-019999-01-0101x03 - 01x1710rebecca nevinsasachristina chang9999-01-019999-01-0103x06 - 08x2310joseph kaylefingerprints technicianleslie odom , jr9999-01-019999-01-0102x05 - 03x20 , 04x22 - 04x249aaron jessopofficerjoel west9999-01-019999-01-0102x20 - 04x258sam belmontestrace technicianchristian de la fuente9999-01-012022-01-0102x03 - 03x057peter elliottsecret service agentmichael b silver9999-01-019999-01-0102x17 - 05x037monica westasabellamy young9999-01-019999-01-0104x10 - 04x256glen colefbi agentmark rolston9999-01-019999-01-0104x25 - 06x123bob keatondea agentmax martini9999-01-019999-01-0102x08 , 03x20 - 03x223mac taylornypd csigary sinise9999-01-019999-01-0102x23 , 04x072stella bonaseranypd csimelina kanakaredes9999-01-019999-01-0102x231aiden burnnypd csivanessa ferlito9999-01-019999-01-0102x231danny messernypd csicarmine giovinazzo9999-01-019999-01-0102x231sheldon hawkesnypd medical examinerhill harper9999-01-019999-01-0102x231\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT first_episode FROM table_sql WHERE character = 'bob keaton' AND position = 'dea agent') = 'vengeance' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1931.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: stage 1 was the only stage where a team classification wasn't awarded\nInput Table: 2010 vuelta a espa\u00f1a\n\n\nstagewinnergeneral_classificationpoints_classificationmountains_classificationcombination_classificationteam_classification1team htc - columbiamark cavendishmark cavendish 1not awardedmark cavendishteam htc - columbia2yauheni hutarovichmark cavendishyauheni hutarovichmicka\u00ebl delagejavier ram\u00edrezteam htc - columbia3philippe gilbertphilippe gilbertphilippe gilbertseraf\u00edn mart\u00ednezseraf\u00edn mart\u00ednezteam htc - columbia4igor ant\u00f3nphilippe gilbertigor ant\u00f3nseraf\u00edn mart\u00ednezvincenzo nibalicaisse d'epargne5tyler farrarphilippe gilbertigor ant\u00f3nseraf\u00edn mart\u00ednezvincenzo nibalicaisse d'epargne6thor hushovdphilippe gilbertphilippe gilbertseraf\u00edn mart\u00ednezphilippe gilbertcaisse d'epargne7alessandro petacchiphilippe gilbertmark cavendishseraf\u00edn mart\u00ednezphilippe gilbertcaisse d'epargne8david moncouti\u00e9igor ant\u00f3nmark cavendishseraf\u00edn mart\u00ednezvincenzo nibalicaisse d'epargne9david l\u00f3pezigor ant\u00f3nmark cavendishdavid moncouti\u00e9vincenzo nibalicaisse d'epargne10imanol ervitijoaquim rodr\u00edguezmark cavendishdavid moncouti\u00e9david moncouti\u00e9caisse d'epargne11igor ant\u00f3nigor ant\u00f3nigor ant\u00f3ndavid moncouti\u00e9igor ant\u00f3ncaisse d'epargne12mark cavendishigor ant\u00f3nmark cavendishdavid moncouti\u00e9igor ant\u00f3ncaisse d'epargne13mark cavendishigor ant\u00f3nmark cavendishdavid moncouti\u00e9igor ant\u00f3ncaisse d'epargne14joaquim rodr\u00edguezvincenzo nibalimark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezcaisse d'epargne15carlos barredovincenzo nibalimark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezteam katusha16mikel nievejoaquim rodr\u00edguezmark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezteam katusha17peter velitsvincenzo nibalimark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezteam katusha18mark cavendishvincenzo nibalimark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezteam katusha19philippe gilbertvincenzo nibalimark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezteam katusha20ezequiel mosquera 2vincenzo nibalimark cavendishdavid moncouti\u00e9vincenzo nibaliteam katusha21tyler farrarvincenzo nibalimark cavendishdavid moncouti\u00e9vincenzo nibaliteam katusha\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT team_classification FROM table_sql WHERE stage = 1) = 'not awarded' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-33.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: when the score was 4 - 5 , the athletics record went 53 - 32 against the colorado rockies\nInput Table: 1997 colorado rockies season\n\n\ndateopponentscorelossattendancerecord9999-08-01pirates7 - 6rinc\u00f3n (4 - 5)2265752 - 589999-08-02pirates6 - 5swift (4 - 5)3238852 - 599999-08-03pirates8 - 4reed (3 - 5)2498952 - 609999-08-04phillies7 - 3castillo (8 - 10)1523052 - 619999-08-05phillies4 - 2bottalico (2 - 4)1642853 - 619999-08-06mets4 - 0mlicki (5 - 8)2663354 - 619999-08-07mets12 - 4swift (4 - 6)2953654 - 629999-08-08pirates5 - 3lieber (6 - 12)4826255 - 629999-08-09pirates8 - 7rinc\u00f3n (4 - 6)4832356 - 629999-08-10pirates8 - 7wilkins (7 - 3)4801857 - 629999-08-12phillies5 - 0thomson (4 - 7)4822857 - 639999-08-13phillies12 - 8wright (6 - 8)4849157 - 649999-08-15mets6 - 2reed (10 - 6)4830858 - 649999-08-16mets7 - 5mcmichael (7 - 10)4831159 - 649999-08-17mets6 - 4mlicki (5 - 10)4844060 - 649999-08-19reds6 - 5wright (6 - 9)3172260 - 659999-08-20reds5 - 3white (1 - 1)2196861 - 659999-08-21astros10 - 4bailey (9 - 9)2296261 - 669999-08-22astros9 - 1thomson (5 - 8)3306161 - 679999-08-23astros6 - 3hudek (0 - 2)3237462 - 679999-08-24astros3 - 1wright (6 - 10)2891862 - 689999-08-25reds7 - 6castillo (10 - 11)4814362 - 699999-08-25reds6 - 4hutton (3 - 2)4808162 - 709999-08-26reds9 - 5mart\u00ednez (1 - 1)4806363 - 709999-08-27reds7 - 5remlinger (6 - 6)4803264 - 709999-08-28mariners9 - 5olivares (6 - 9)4842265 - 709999-08-29mariners6 - 5timlin (3 - 3)4817866 - 709999-08-30athletics4 - 3mohler (1 - 10)4830867 - 709999-08-31athletics10 - 4oquist (2 - 5)4804168 - 70\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT record FROM table_sql WHERE score = '4 - 5' AND opponent = 'athletics') = '53 - 32' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-997.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: steve scaini directed one more episode than mike clattenburg\nInput Table: list of republic of doyle episodes\n\n\nUnnamed:_0titledirected_bywritten_byviewersoriginal_airdateprod_code1fathers and sonsmike clattenburgallan hawco , perry chafe and malcolm macrury9690002010-01-061012the return of the grievous angelsteve dimarcoallan hawco and avrum jacobson7150002010-01-131023duchess of georgemike clattenburgallan hawco , perry chafe and malcolm macrury6850002010-01-201035hit and rumsteve dimarcomatt maclennan5940002010-02-031056the one who got awaylarry mcleanjesse mckeown10120002010-02-101067the woman who knew too littlerobert liebermanjeremy boxen10530002010-03-031078the tell - tale safejerry ciccorittijohn callaghan and steve cochrane9860002010-03-101089he sleeps with the chipsphil earnshawperry chafe9080002010-03-1710910the pen is mightier than the doylerobert liebermansteve cochrane and avrum jacobson8970002010-03-2411011a horse dividedsteve scainijesse mckeown9020002010-03-31111\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE directed_by = 'steve scaini') > \n             (SELECT COUNT(*) FROM table_sql WHERE directed_by = 'mike clattenburg') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-833.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: england , australia and the united states had the same number of players in the 1981 open championship with five each\nInput Table: 1981 open championship\n\n\nplaceplayercountryscoreto_part1vicente fern\u00e3\u00a1ndezargentina70et1nick jobengland70et3isao aokijapan71+ 1t3david grahamaustralia71+ 1t3tony jacklinengland71+ 1t3johnny millerunited states71+ 1t3simon owennew zealand71+ 1t3hal sutton (a)united states71+ 1t9howard clarkengland72+ 2t9ben crenshawunited states72+ 2t9david jaggerengland72+ 2t9mark jamesengland72+ 2t9greg normanaustralia72+ 2t9arnold palmerunited states72+ 2t9bill rogersunited states72+ 2t9sam torrancescotland72+ 2\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(DISTINCT country) FROM table_sql WHERE country IN ('england', 'australia', 'united states')) = 3 \n             AND (SELECT COUNT(DISTINCT player) FROM table_sql WHERE country IN ('england', 'australia', 'united states')) = 5 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-212.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: jeremy mayfield was the driver with 200 laps in 1997\nInput Table: pocono 400\n\n\nyeardatedriverteammanufacturerlaps-race_timeaverage_speed_(mph)report1982-01-019999-06-06bobby allisondigard motorsportsbuick200500 (804.672)4:24:08113.579report1983-01-019999-06-12bobby allisondigard motorsportsbuick200500 (804.672)3:53:13128.636report1984-01-019999-06-10cale yarboroughranier - lundychevrolet200500 (804.672)3:37:08138.164report1985-01-019999-06-09bill elliottmelling racingford200500 (804.672)3:35:48138.974report1986-01-019999-06-08tim richmondhendrick motorsportschevrolet200500 (804.672)4:24:50113.279report1987-01-019999-06-14tim richmondhendrick motorsportschevrolet200500 (804.672)4:05:57122.166report1988-01-019999-06-19geoffrey bodinehendrick motorsportschevrolet200500 (804.672)3:58:21126.147report1989-01-019999-06-18terry labontejunior johnson & associatesford200500 (804.672)3:48:27131.32report1990-01-019999-06-17harry gantleo jackson racingoldsmobile200500 (804.672)4:08:25120.6report1991-01-019999-06-16darrell waltripdarwal , incchevrolet200500 (804.672)4:04:34122.666report1992-01-019999-06-14alan kulwickiak racingford200500 (804.672)3:28:18144.023report1993-01-019999-06-13kyle pettysabco racingpontiac200500 (804.672)3:37:23138.005report1994-01-019999-06-12rusty wallacepenske racingford200500 (804.672)3:52:55128.801report1995-01-019999-06-11terry labontehendrick motorsportschevrolet200500 (804.672)3:37:50137.72report1996-01-019999-06-16jeff gordonhendrick motorsportschevrolet200500 (804.672)3:35:40139.104report1997-01-019999-06-08jeff gordonhendrick motorsportschevrolet200500 (804.672)3:34:33139.828report1998-01-019999-06-21jeremy mayfieldpenske racingford200500 (804.672)4:14:39117.809report1999-01-019999-06-20bobby labontejoe gibbs racingpontiac200500 (804.672)4:12:19118.898report2000-01-019999-06-19jeremy mayfieldpenske racingford200500 (804.672)3:34:41139.741report2001-01-019999-06-17ricky ruddrobert yates racingford200500 (804.672)3:43:14134.389report2002-01-019999-06-09dale jarrettrobert yates racingford200500 (804.672)3:29:10143.426report2003-01-019999-06-08tony stewartjoe gibbs racingchevrolet200500 (804.672)3:42:24134.892report2004-01-019999-06-13jimmie johnsonhendrick motorsportschevrolet200500 (804.672)4:27:33112.129report2005-01-019999-06-12carl edwardsroush racingford201502.5 (808.695)3:53:24129.177report2006-01-019999-06-11denny hamlinjoe gibbs racingchevrolet200500 (804.672)3:47:52131.656report2007-01-019999-06-10jeff gordonhendrick motorsportschevrolet106265 (426.476)1:57:15135.608report2008-01-019999-06-08kasey kahnegillett evernham motorsportsdodge200500 (804.672)3:59:36125.209report2009-01-019999-06-07tony stewartstewart - haas racingchevrolet200500 (804.672)3:36:35138.515report2010-01-019999-06-06denny hamlinjoe gibbs racingtoyota204510 (820.765)3:44:30136.303report2011-01-019999-06-12jeff gordonhendrick motorsportschevrolet200500 (804.672)3:26:21145.384report2012-01-019999-06-10joey loganojoe gibbs racingtoyota160400 (643.737)3:03:12131.004report\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE year = 1997 \nAND driver = 'jeremy mayfield' \nAND laps = 200;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-186.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there was 13 tour matches in the last 3 months of 1978\nInput Table: 1978 new zealand rugby union tour of britain and ireland\n\n\nopposing_teamagainstdatevenuestatuscambridge university121978-10-18grange road , cambridgetour matchcardiff71978-10-21cardiff arms park , cardifftour matchwest wales xv71978-10-25st helen 's , swanseatour matchlondon counties121978-10-28twickenham , londontour matchmunster121978-10-31thomond park , limericktour matchireland61978-11-04lansdowne road , dublintest matchulster71978-11-07ravenhill , belfasttour matchwales121978-11-01cardiff arms park , cardifftest matchsouth and south - west counties01978-11-15memorial ground , bristoltour matchmidland counties151978-11-18welford road , leicestertour matchcombined services61978-11-21aldershot military stadium , aldershottour matchengland61978-11-25twickenham , londontest matchmonmouthshire91978-11-29rodney parade , newporttour matchnorth of england61978-12-02birkenhead park , birkenheadtour matchnorth and midland of scotland31978-12-05linksfield stadium , aberdeentour matchscotland91978-12-09murrayfield , edinburghtest matchbridgend61978-12-13brewery field , bridgendtour matchbarbarians161978-12-16cardiff arms park , cardifftour match\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 13 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE date >= '1978-10-01' \nAND date <= '1978-12-31' \nAND status = 'tour match';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1780.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the life expectancy in 1995 - 2000 is less than 61.5 and the imr is exactly 27\nInput Table: none\n\n\nperiodlive_births_per_yeardeaths_per_yearnatural_change_per_yearcbrcdrnctfrimrlife_expectancy_totallife_expectancy_maleslife_expectancy_females1950-01-01 - 1955-01-012 572 000900 0001 672 00044.115.528.66.1513550.949.252.61955-01-01 - 1960-01-012 918 000947 0001 971 00043.214.029.16.1512253.351.555.21960-01-01 - 1965-01-013 303 000986 0002 317 00042.212.629.66.1510955.753.857.69999-01-01 - 1970-01-013 330 000998 0002 332 00037.011.125.95.3810057.655.759.61970-01-01 - 1975-01-013 441 0001 014 0002 427 00033.79.923.84.729159.557.361.81975-01-01 - 1980-01-013 741 0001 043 0002 698 00032.59.023.54.317961.559.263.91980-01-01 - 1985-01-013 974 0001 064 0002 910 00030.88.222.63.86363.460.466.81985-01-01 - 1990-01-013 757 0001 055 0002 702 00026.37.418.93.15265.361.969.11990-01-01 - 1995-01-013 519 0001 058 0002 461 00022.66.815.82.64367.363.671.21995-01-01 - 2000-01-013 624 0001 086 0002 538 00021.56.515.12.453469.365.573.32000-01-01 - 2005-01-013 572 0001 147 0002 425 00019.86.413.42.252770.967.274.8\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT life_expectancy_total FROM table_sql WHERE period = '1995-01-01 - 2000-01-01') < 61.5 \n             AND (SELECT imr FROM table_sql WHERE period = '1995-01-01 - 2000-01-01') = 27 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1353.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: when the record was 4 - 5 , the opponent was yankees on april 11\nInput Table: 1989 toronto blue jays season\n\n\ndateopponentscorelossattendancerecord9999-04-03royals4 - 3gubicza (0 - 1)385951 - 0'9999-04-05'royals2 - 1stottlemyre (0 - 1)171261 - 19999-04-06royals3 - 2ward (0 - 1)188831 - 2'9999-04-07'rangers10 - 9guante (1 - 1)229142 - 29999-04-08rangers5 - 4key (1 - 1)260732 - 39999-04-09rangers3 - 2henke (0 - 1)194982 - 4'9999-04-10'yankees8 - 0hawkins (0 - 2)171923 - 49999-04-11yankees11 - 6 (10)righetti (0 - 1)202774 - 4'9999-04-12'yankees5 - 3castillo (1 - 1)179004 - 59999-04-14royals3 - 0leibrandt (0 - 1)460285 - 5'9999-04-15'royals10 - 5ward (0 - 2)252475 - 6'9999-04-16'royals15 - 8saberhagen (1 - 1)352106 - 60000-04-17yankees7 - 2flanagan (0 - 1)232606 - 79999-04-18yankees2 - 0musselman (0 - 1)250406 - 89999-04-19yankees4 - 2key (2 - 2)264716 - 99999-04-21rangers6 - 3brown (1 - 1)221867 - 99999-04-22rangers4 - 2hough (2 - 1)272788 - 99999-04-23rangers4 - 1stottlemyre (0 - 2)314738 - 109999-04-24athletics5 - 4henke (1 - 2)250998 - 119999-04-25athletics3 - 1cerutti (0 - 1)124378 - 129999-04-26mariners7 - 6wells (1 - 1)73998 - 139999-04-27mariners6 - 1dunne (0 - 1)86009 - 139999-04-28angels9 - 0stottlemyre (0 - 3)309589 - 149999-04-29angels4 - 3 (10)ward (1 - 3)499069 - 159999-04-30angels1 - 0 (11)henke (1 - 3)311259 - 16\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE record = '4 - 5' \nAND opponent = 'yankees' \nAND date = '9999-04-12';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-451.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: no game on the 18th of june drew a crowd of more fewer than 20000\nInput Table: 1938 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddategeelong11.23 (89)hawthorn6.13 (49)corio oval70001938-06-18fitzroy16.12 (108)south melbourne8.8 (56)brunswick street oval120001938-06-18st kilda14.12 (96)melbourne16.16 (112)junction oval140001938-06-18richmond15.14 (104)essendon15.9 (99)punt road oval200001938-06-18footscray13.9 (87)collingwood10.5 (65)western oval180001938-06-18north melbourne11.5 (71)carlton16.25 (121)arden street oval130001938-06-18\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE date = '1938-06-18' \nAND crowd < 20000;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-825.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: kenny perry earned 170000 more than mark brooks\nInput Table: 1996 pga championship\n\n\nplaceplayercountryscoreto_parmoney1mark brooksunited states68 + 70 + 69 + 70 = 277- 114300002kenny perryunited states66 + 72 + 71 + 68 = 277- 11260000t3steve elkingtonaustralia67 + 74 + 67 + 70 = 278- 10140000t3tommy tollesunited states69 + 71 + 71 + 67 = 278- 10140000t5justin leonardunited states71 + 66 + 72 + 70 = 279- 986667t5jesper parneviksweden73 + 67 + 69 + 70 = 279- 986667t5vijay singhfiji69 + 69 + 69 + 72 = 279- 986667t8lee janzenunited states68 + 71 + 71 + 70 = 280- 857500t8per - ulrik johanssonsweden73 + 72 + 66 + 69 = 280- 857500t8phil mickelsonunited states67 + 67 + 74 + 72 = 280- 857500t8larry mizeunited states71 + 70 + 69 + 70 = 280- 857500t8frank nobilonew zealand69 + 72 + 71 + 68 = 280- 857500t8nick pricezimbabwe68 + 71 + 69 + 72 = 280- 857500\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT money FROM table_sql WHERE player = 'kenny perry') - \n             (SELECT money FROM table_sql WHERE player = 'mark brooks') > 170000 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1249.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: 66189 people attended the game with a record of 6 - 1 on week 8\nInput Table: 2001 st. louis rams season\n\n\nweekdateopponentresultrecordtv_timeattendance12001-09-09philadelphia eaglesw 20 - 17 (ot)1 - 0fox 3:15 pm66243.022001-09-23san francisco 49ersw 30 - 262 - 0fox 3:15 pm67536.032001-09-30miami dolphinsw 42 - 103 - 0cbs 12:00 pm66046.042001-10-08detroit lionsw 35 - 04 - 0abc 8:00 pm77765.052001-10-14new york giantsw 15 - 145 - 0fox 12:00 pm65992.062001-10-21new york jetsw 34 - 146 - 0fox 12:00 pm78766.072001-10-28new orleans saintsl 34 - 316 - 1fox 12:00 pm66189.089999-01-01----nan92001-11-11carolina panthersw 48 - 147 - 1fox 12:00 pm66069.0102001-11-18new england patriotsw 24 - 178 - 1espn 7:30 pm60292.0112001-11-26tampa bay buccaneersl 24 - 178 - 2abc 8:00 pm66198.0122001-12-02atlanta falconsw 35 - 69 - 2fox 3:15 pm60787.0132001-12-09san francisco 49ersw 27 - 1410 - 2fox 12:00 pm66218.0142001-12-17new orleans saintsw 34 - 2111 - 2abc 8:00 pm70332.0152001-12-23carolina panthersw 38 - 3212 - 2fox 12:00 pm72438.0162001-12-30indianapolis coltsw 42 - 1713 - 2cbs 12:00 pm66084.0172002-01-06atlanta falconsw 31 - 1314 - 2fox 3:15 pm66033.0\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 1 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE week = 8 \nAND attendance = 66189.0 \nAND record = '6 - 1';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1652.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: all of the matches were on different dates\nInput Table: 1975 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddategeelong14.20 (104)melbourne14.14 (98)kardinia park133281975-06-07st kilda15.9 (99)north melbourne17.19 (121)moorabbin oval178111975-06-07richmond19.14 (128)essendon12.9 (81)mcg494691975-06-07hawthorn19.24 (138)collingwood13.11 (89)princes park238301975-06-07fitzroy15.7 (97)carlton16.10 (106)junction oval162491975-06-07footscray13.11 (89)south melbourne12.15 (87)vfl park140561975-06-07\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(DISTINCT date) = COUNT(*) THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-2020.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the hurricanes only won 50% of their games in 2007 and did not get promoted to a higher division\nInput Table: dundee hurricanes\n\n\nseasondivisionwinslossestiesfinal_positionnotes2003bafl division 2 north6404 / 11-2004bafl division 2 north6211 / 3-2005bafl division 2 scottish5502 / 4-2006bafl division 2 scottish3402 / 3-2007bafl division 2 north9101 / 6promoted to division 1 north2008bafl division 1 north5233 / 6-2009bafl division 1 north2615 / 7-\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT CAST(wins AS FLOAT) / (wins + losses + ties) FROM table_sql WHERE season = 2007) = 0.5 \n             AND (SELECT final_position FROM table_sql WHERE season = 2007) NOT LIKE '%promoted%' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1596.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the man of the match against the slough jets on the 2nd was lukas smital\nInput Table: 2008 - 09 guildford flames season\n\n\ndateopponentvenueresultattendancecompetitionman_of_the_match9999-01-01slough jetshomelost 2 - 31308league / cuplukas smital9999-01-02slough jetsawaylost 5 - 6 (ot)320leaguepaul dixon9999-01-08swindon wildcatsawaywon 6 - 3754league / cuplukas smital9999-01-09swindon wildcatshomewon 4 - 21568league / cupneil liddiard9999-01-15sheffield scimitarsawaywon 7 - 4364league / cuprick plant9999-01-16milton keynes lightninghomelost 2 - 41161league / cupdavid savage9999-01-19romford raidershomewon 6 - 21016league / cupalex mettam9999-01-22wightlink raidersawaylost 5 - 4509league / cupstuart potts9999-01-23telford tigershomewon 4 - 21368leaguealex mettam / mark williams9999-01-29romford raidershomewon 7 - 21238leaguemartin bouz9999-01-30bracknell beesawaywon 4 - 0not reportedleague / cupjoe watkins\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT man_of_the_match FROM table_sql WHERE date = '9999-01-02' AND opponent = 'slough jets') = 'lukas smital' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-835.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: in the 1981 open championship no one player achieved their position alone , except argentina\nInput Table: 1981 open championship\n\n\nplaceplayercountryscoreto_part1vicente fern\u00e3\u00a1ndezargentina70et1nick jobengland70et3isao aokijapan71+ 1t3david grahamaustralia71+ 1t3tony jacklinengland71+ 1t3johnny millerunited states71+ 1t3simon owennew zealand71+ 1t3hal sutton (a)united states71+ 1t9howard clarkengland72+ 2t9ben crenshawunited states72+ 2t9david jaggerengland72+ 2t9mark jamesengland72+ 2t9greg normanaustralia72+ 2t9arnold palmerunited states72+ 2t9bill rogersunited states72+ 2t9sam torrancescotland72+ 2\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(DISTINCT place) = 1 AND country = 'argentina' THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1624.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: daniel palladino directed directed one episode than amy sherman - palladino did\nInput Table: list of gilmore girls episodes\n\n\nno-titledirectorwriter_(s)original_air_dateprod_codeus_viewers_(million)661ballrooms and biscottiamy sherman - palladinoamy sherman - palladino2003-09-231761515.2672the lorelais' first day at yalechris longdaniel palladino2003-09-301761523.9683the hobbit , the sofa and digger stilesmatthew diamondamy sherman - palladino2003-10-071761534.9694chicken or beefchris longjane espenson2003-10-141761545.5705the fundamental things applyneema barnettejohn stephens2003-10-211761555.5716an affair to remembermatthew diamondamy sherman - palladino2003-10-281761565.2727the festival of living artchris longdaniel palladino2003-11-041761574.7738die , jerktom mooredaniel palladino2003-11-111761584.9749ted koppel 's big night outjamie babbitamy sherman - palladino2003-11-181761595.27510the nanny and the professorpeter lauerscott kaufer2004-01-201761604.17611in the clamor and the clangormichael grossmansheila r lawrence , janet leahy2004-01-271761614.47712a family matterkenny ortegadaniel palladino2004-02-031761624.97914the incredible sinking lorelaisstephen clancyamy sherman - palladino , daniel palladino2004-02-171761644.88015scene in a mallchris longdaniel palladino2004-02-241761654.88116the reigning lorelaimarita grabiakjane espenson2004-03-021761665.08217girls in bikinis , boys doin' the twistjamie babbitamy sherman - palladino2004-04-131761674.58318tick , tick , tick , boom!daniel palladinodaniel palladino2004-04-201761684.28419afterboommichael zinbergsheila r lawrence2004-04-271761694.38520luke can see her facematthew diamondamy sherman - palladino , daniel palladino2004-05-041761704.28621last week fights , this week tightschris longdaniel palladino2004-05-111761714.6\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE director = 'daniel palladino') > \n             (SELECT COUNT(*) FROM table_sql WHERE director = 'amy sherman - palladino') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1135.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: tommy smith has he highest number of league goals\nInput Table: 1979 - 80 huddersfield town f.c. season\n\n\nnamepositionleague_appsleague_goalsfa_cup_appsfa_cup_goalsleague_cup_appsleague_cup_goalstotal_appstotal_goalsjim branagandf00000 (1)00 (1)0malcolm browndf4622041523david cowlingmf39 (1)10104044 (1)10peter fletcherfw30 (8)17203135 (8)18keith hanveydf3320040392peter hartmf4641140515ian holmesmf6 (4)3004110 (4)4steve kindonfw22 (1)14000022 (1)14mick laverickmf4542040514bernard purdiedf18 (4)0200020 (4)0andy rankingk2400000240ian robinsfw452520425127fred robinsondf3012040361tommy smithfw00001010brian stantonmf4192000439alan starlinggk2202040280dave suttondf4662041527chris toppingdf1302000150\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MAX(league_goals) FROM table_sql) = (SELECT league_goals FROM table_sql WHERE name = 'tommy smith') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-406.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the young africans scored zero points in the 1971 african cup of champions clubs\nInput Table: 1971 african cup of champions clubs\n\n\nteam_1aggteam_21st_leg2nd_legal - merrikh2 - 2 (5 - 4 pen)tele sc asmara9999-01-029999-01-01abaluhya united1 - 3great olympics9999-01-019999-01-01asc diaraf3 - 4stade malien9999-03-019999-01-01maseru united3 - 5mmm tamatave9999-01-029999-02-03as porto novo0 - 3victoria club mokanda9999-01-019999-01-02canon yaound\u00e99 - 4as solidarit\u00e99999-07-039999-01-02esp\u00e9rance1 - 0al - ahly (benghazi)9999-01-019999-01-01secteur 61 - 2enugu rangers9999-01-019999-01-01young africans2 - 0lavori publici9999-01-019999-01-01\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE team_1 = 'young africans' AND agg = '0 - 0') > 0 \n             OR (SELECT COUNT(*) FROM table_sql WHERE team_2 = 'young africans' AND agg = '0 - 0') > 0 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1045.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the first record was recorded after november 1965\nInput Table: list of sumo record holders\n\n\nnametotalfirstlasthighest_rankkotonishiki341990-09-011999-09-01sekiwakekai\u014d321994-05-012000-07-01\u014dzekimus\u014dyama311994-03-012000-09-01\u014dzekihasegawa301965-11-011974-09-01sekiwakekotomitsuki302001-01-012007-07-01\u014dzekiakinoshima271988-11-012000-09-01sekiwaketakamiyama271969-11-011982-09-01sekiwaketakat\u014driki261991-05-012000-05-01sekiwakewakanosato262000-11-012005-09-01sekiwakedaikirin221966-11-011970-09-01\u014dzekitochiazuma ii221997-07-012005-01-01\u014dzekikisenosato222006-07-012011-09-01\u014dzeki\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MIN(first) FROM table_sql) > '1965-11-01' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1893.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: nelson is not the province for the electorate of collingwood\nInput Table: 3rd new zealand parliament\n\n\nmemberelectorateprovincemps_termelection_datealfred creykeavoncanterburyfirst1861-01-01frederick weldcheviotcanterburythird1861-01-01andrew richmondcollingwoodnelsonfirst1861-04-01isaac cooksonkaiapoicanterburysecond1861-07-01herbert curtismotuekanelsonsecond1861-05-01william foxrangitikiwellingtonsecond1861-04-01alfred saunderswaimeamarlboroughfirst1861-01-01\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT province FROM table_sql WHERE electorate = 'collingwood') != 'nelson' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1573.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: henrik stenson is from australia , aaron baddeley is from south korea , and charlie wi is from sweden\nInput Table: 2008 pga championship\n\n\nplaceplayercountryscoreto_par1ben curtisunited states73 + 67 + 68 = 208- 2t2j b holmesunited states71 + 68 + 70 = 209- 1t2henrik stensonsweden71 + 70 + 68 = 209- 1t4sergio garc\u00edaspain69 + 73 + 69 = 211+ 1t4p\u00e1draig harringtonireland71 + 74 + 66 = 211+ 1t4charlie wisouth korea70 + 70 + 71 = 211+ 1t7andr\u00e9s romeroargentina69 + 78 + 65 = 212+ 2t7jeev milkha singhindia68 + 74 + 70 = 212+ 2t9aaron baddeleyaustralia71 + 71 + 71 = 213+ 3t9steve fleschunited states73 + 70 + 70 = 213+ 3t9david tomsunited states72 + 69 + 72 = 213+ 3t9camilo villegascolombia74 + 72 = 67 = 213+ 3\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT country FROM table_sql WHERE player = 'henrik stenson') = 'sweden' \n             AND (SELECT country FROM table_sql WHERE player = 'aaron baddeley') = 'south korea' \n             AND (SELECT country FROM table_sql WHERE player = 'charlie wi') = 'sweden' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1612.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the total number scored of the team positioned higher than 10 is zero\nInput Table: 2005 in paraguayan football\n\n\npositionteamplayedwinsdrawslossesscoredconcededpoints1cerro porte\u00f1o1810623015362guaran\u00ed189452118313nacional1893625223043 de febrero18774241728512 de octubre186842222266tacuary1841132419237libertad184772123198sportivo luque\u00f1o183872022179general caballero zc1827916281310olimpia18279102713\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT SUM(scored) FROM table_sql WHERE position < 10) = 0 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-685.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: nick faldo is a player from ireland\nInput Table: 2002 u.s. open (golf)\n\n\nplaceplayercountryscoreto_par1tiger woodsunited states67 + 68 + 70 = 205- 52sergio garc\u00edaspain68 + 74 + 67 = 209- 1t3jeff maggertunited states69 + 73 + 68 = 210et3phil mickelsonunited states70 + 73 + 67 = 210et5robert allenbyaustralia74 + 70 + 67 = 211+ 1t5p\u00e1draig harringtonireland70 + 68 + 73 = 211+ 1t5billy mayfairunited states69 + 74 + 68 = 211+ 1t8nick faldoengland70 + 76 + 66 = 212+ 2t8justin leonardunited states73 + 71 + 68 = 212+ 2t10tom byrumunited states72 + 72 + 70 = 214+ 4t10davis love iiiunited states71 + 71 + 72 = 214+ 4t10scott mccarronunited states72 + 72 + 70 = 214+ 4\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT player FROM table_sql WHERE player = 'nick faldo' AND country = 'ireland') IS NOT NULL \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1980.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: only ten cleveland brown 's quarterbacks have won more than 30 games\nInput Table: list of cleveland browns starting quarterbacks\n\n\nquarterbackuniform_no_(s)games_startedwinslossestieswinning_pctsipe , brian1711257550589.0kosar , bernie1910553511595.0ryan , frank137652222697.0graham , otto60 , 147157131810.0couch , tim25922370373.0nelsen , bill165134161676.0phipps , mike155124252490.0plum , milt165133162667.0anderson , derek33416180471.0testaverde , vinny123116150516.0mcdonald , paul16218130381.0mccoy , colt12216150286.0frye , charlie9196130316.0weeden , brandon3195140263.0o'connell , tommy15141031750.0holcomb , kelly1012480333.0quinn , brady1012390250.0ninowski , jim15 , 1111560455.0dilfer , trent811470364.0garcia , jeff510370300.0danielson , gary188530625.0tomczak , mike188440500.0pederson , doug188170125.0pagel , mike107250286.0wallace , seneca67160143.0ratterman , george12 , 165230400.0philcox , todd175230400.0delhomme , jake174220500.0mays , dave104130250.0zeier , eric104130250.0mccown , luke1240400.0parilli , babe183120333.0rypien , mark113210667.0dorsey , ken1130300.0hoyer , brian633001.0strock , don1222001.0christensen , jeff112110500.0detmer , ty1120200.0campbell , jason172110500.0gault , don1111001.0lane , gary1510100.0dawson , len1811001.0wynn , spergon1310100.0luck , terry710100.0cureton , will1610100.0gradkowski , bruce710100.0lewis , thaddeus910100.0\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE wins > 30) = 10 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-802.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the number of players from canada outnumber the number of players from the united states\nInput Table: 2004 - 05 philadelphia flyers season\n\n\nroundplayerpositionnationalitycollege_/_junior_/_club_team_(league)3rob bellamyright wingunited statesnew england jr coyotes ( ejhl )4r j andersondefenseunited statescentennial high school (minn)4david laliberteright wingcanadaprince edward island rocket ( qmjhl )5chris zarbdefenseunited statestri - city storm ( ushl )5gino piselliniright wingunited statesplymouth whalers ( ohl )6ladislav scurkocenterslovakiaspi\u0161sk\u00e1 nov\u00e1 ves (slovakia)6frederik cabanacentercanadahalifax mooseheads (qmjhl)8martin houlegoaltendercanadacape breton screaming eagles (qmjhl)8travis gawryletzdefensecanadatrail smoke eaters ( bchl )9triston grantleft wingcanadavancouver giants ( whl )9john cartercenterunited statesbrewster bulldogs (emjhl)\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE nationality = 'canada') > \n             (SELECT COUNT(*) FROM table_sql WHERE nationality = 'united states') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-2013.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: collingwood had a home team score 3.00 points higher than that of carlton\nInput Table: 1954 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddategeelong13.12 (90)hawthorn7.6 (48)kardinia park168701954-08-14collingwood12.16 (88)south melbourne13.12 (90)victoria park185561954-08-14carlton10.16 (76)essendon11.14 (80)princes park297441954-08-14richmond10.18 (78)melbourne15.4 (94)punt road oval240001954-08-14north melbourne9.14 (68)footscray9.14 (68)arden street oval220001954-08-14st kilda13.14 (92)fitzroy9.15 (69)junction oval115001954-08-14\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT home_team_score FROM table_sql WHERE home_team = 'collingwood') - \n             (SELECT home_team_score FROM table_sql WHERE home_team = 'carlton') > 3.00 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-90.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the last game of the season happened on 11 february 2006\nInput Table: 2005 - 06 manchester united f.c. season\n\n\ndateopponentsh_/_aresult_f_-_aattendanceleague_position2005-08-13evertona2 - 0386104th2005-08-20aston villah1 - 0679344th2005-08-28newcastle uniteda2 - 0523274th2005-09-10manchester cityh1 - 1678394th2005-09-18liverpoola0 - 0449173rd2005-09-24blackburn roversh1 - 2677656th2005-10-01fulhama3 - 2218624th2005-10-15sunderlanda3 - 1390853rd2005-10-22tottenham hotspurh1 - 1678565th2005-10-29middlesbrougha1 - 4305797th2005-11-06chelseah1 - 0678644th2005-11-19charlton athletica3 - 1267303rd2005-11-27west ham uniteda2 - 1347552nd2005-12-03portsmouthh3 - 0676842nd2005-12-11evertonh1 - 1678313rd2005-12-14wigan athletich4 - 0677932nd2005-12-17aston villaa2 - 0371282nd2005-12-26west bromwich albionh3 - 0679722nd2005-12-28birmingham citya2 - 2284592nd2005-12-31bolton wanderersh4 - 1678582nd2006-01-03arsenala0 - 0383132nd2006-01-14manchester citya1 - 3471922nd2006-01-22liverpoolh1 - 0678742nd2006-02-01blackburn roversa3 - 4254842nd2006-02-04fulhamh4 - 2678442nd2006-02-11portsmoutha3 - 1202062nd2006-03-06wigan athletica2 - 1235242nd2006-03-12newcastle unitedh2 - 0678582nd2006-03-18west bromwich albiona2 - 1276232nd2006-03-26birmingham cityh3 - 0690702nd2006-03-29west ham unitedh1 - 0695222nd2006-04-01bolton wanderersa2 - 1277182nd2006-04-09arsenalh2 - 0709082nd2006-04-14sunderlandh0 - 0725192nd2006-04-17tottenham hotspura2 - 1361412nd2006-04-29chelseaa0 - 3422192nd2006-05-01middlesbroughh0 - 0695312nd2006-05-07charlton athletich4 - 0730062nd\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MAX(date) FROM table_sql) = '2006-02-11' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-358.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: canada and the united states are the two nationalities of players with rounds lower than four\nInput Table: 2007 - 08 los angeles kings season\n\n\nroundplayernationalitynhl_teamcollege_/_junior_/_club_team_(league)1thomas hickey (d)canadalos angeles kingsseattle thunderbirds ( whl )2oscar moller (c)swedenlos angeles kingschilliwack bruins ( whl )2wayne simmonds (rw)canadalos angeles kingsowen sound attack ( whl )3bryan cameron (c)canadalos angeles kingsbelleville bulls ( ohl )4alec martinez (d)united stateslos angeles kingsmiami university ( ncaa )4dwight king (c)canadalos angeles kingslethbridge hurricanes ( whl )5linden rowat (g)canadalos angeles kingsregina pats ( whl )5joshua turnbull (c)united stateslos angeles kingswaterloo black hawks ( ushl )7josh kidd (d)canadalos angeles kingserie otters ( ohl )7matt fillier (lw)canadalos angeles kingsst john 's fog devils ( qmjhl )\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 2 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE round < 4 \nAND nationality IN ('canada', 'united states');\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-880.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: annika s\u00f6renstam and catriona matthew won with the lowest number of strokes\nInput Table: women 's british open\n\n\nyeardatesvenuechampioncountryscoreto_parmargin_of_victoryrunner_(s)_-_uppursewinner_'s_share20139999-08-01old course at st andrewsstacy lewisunited states280- 82 strokesna yeon choi hee young park275000040258320129999-09-13royal liverpool golf clubjiyai shinsouth korea279- 99 strokesinbee park275000042865020119999-07-28carnoustie golf linksyani tsengtaiwan272- 164 strokesbrittany lang250000039213320109999-07-29 - 9999-08-01royal birkdale golf clubyani tsengtaiwan277- 111 strokekatherine hull250000040871420099999-07-30 - 9999-08-02royal lytham & st annes golf clubcatriona matthewscotland285- 33 strokeskarrie webb220000033500020089999-07-31 - 9999-08-03sunningdale golf clubjiyai shinsouth korea270- 183 strokesyani tseng210000031446420079999-08-02old course at st andrewslorena ochoamexico287- 54 strokesmaria hjorth jee young lee200000032051220069999-08-03royal lytham & st annes golf clubsherri steinhauerunited states281- 73 strokessophie gustafson cristie kerr180000030544020059999-07-28royal birkdale golf clubjeong jangsouth korea272- 164 strokessophie gustafson180000028020820049999-07-29 - 9999-08-01sunningdale golf clubkaren stupplesengland269- 195 strokesrachel hetherington160000029088020039999-07-31 - 9999-08-03royal lytham & st annes golf clubannika s\u00f6renstamsweden278- 101 strokese ri pak160000025488020029999-08-08turnberry - ailsa coursekarrie webbaustralia273- 152 strokesmichelle ellis paula mart\u00ed150000023638320019999-08-02sunningdale golf clubse ri paksouth korea277- 112 strokesmi hyun kim1500000221650\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT score FROM table_sql WHERE champion = 'annika s\u00f6renstam') = \n             (SELECT MIN(score) FROM table_sql) \n             AND (SELECT score FROM table_sql WHERE champion = 'catriona matthew') = \n             (SELECT MIN(score) FROM table_sql) \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1306.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the semifinal first leg recorded attendance less than 50000\nInput Table: 2002 - 03 manchester united f.c. season\n\n\ndateroundopponentsresult_f_-_aattendance2002-11-05round 3leicester city2 - 0478482002-12-03round 4burnley2 - 0220342002-12-17round 5chelsea1 - 0579852003-01-07semi - final first legblackburn rovers1 - 1627402003-01-22semi - final second legblackburn rovers3 - 1290482003-03-02finalliverpool0 - 274500\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT attendance FROM table_sql WHERE round = 'semi - final first leg') < 50000 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-821.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: kenny perry is the player who earned the most money\nInput Table: 1996 pga championship\n\n\nplaceplayercountryscoreto_parmoney1mark brooksunited states68 + 70 + 69 + 70 = 277- 114300002kenny perryunited states66 + 72 + 71 + 68 = 277- 11260000t3steve elkingtonaustralia67 + 74 + 67 + 70 = 278- 10140000t3tommy tollesunited states69 + 71 + 71 + 67 = 278- 10140000t5justin leonardunited states71 + 66 + 72 + 70 = 279- 986667t5jesper parneviksweden73 + 67 + 69 + 70 = 279- 986667t5vijay singhfiji69 + 69 + 69 + 72 = 279- 986667t8lee janzenunited states68 + 71 + 71 + 70 = 280- 857500t8per - ulrik johanssonsweden73 + 72 + 66 + 69 = 280- 857500t8phil mickelsonunited states67 + 67 + 74 + 72 = 280- 857500t8larry mizeunited states71 + 70 + 69 + 70 = 280- 857500t8frank nobilonew zealand69 + 72 + 71 + 68 = 280- 857500t8nick pricezimbabwe68 + 71 + 69 + 72 = 280- 857500\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MAX(money) FROM table_sql) = (SELECT money FROM table_sql WHERE player = 'kenny perry') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1572.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: charlie wi and aaron baddeley are from the united states\nInput Table: 2008 pga championship\n\n\nplaceplayercountryscoreto_par1ben curtisunited states73 + 67 + 68 = 208- 2t2j b holmesunited states71 + 68 + 70 = 209- 1t2henrik stensonsweden71 + 70 + 68 = 209- 1t4sergio garc\u00edaspain69 + 73 + 69 = 211+ 1t4p\u00e1draig harringtonireland71 + 74 + 66 = 211+ 1t4charlie wisouth korea70 + 70 + 71 = 211+ 1t7andr\u00e9s romeroargentina69 + 78 + 65 = 212+ 2t7jeev milkha singhindia68 + 74 + 70 = 212+ 2t9aaron baddeleyaustralia71 + 71 + 71 = 213+ 3t9steve fleschunited states73 + 70 + 70 = 213+ 3t9david tomsunited states72 + 69 + 72 = 213+ 3t9camilo villegascolombia74 + 72 = 67 = 213+ 3\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE (player = 'charlie wi' OR player = 'aaron baddeley') AND country = 'united states') = 2 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1824.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: when michael beade was the highest scorer , the score was w 97 - 92 (ot)\nInput Table: 2008 - 09 miami heat season\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord759999-04-01dallasl 96 - 98 (ot)dwyane wade (23)jermaine o'neal , udonis haslem (7)dwyane wade (6)american airlines center 2002139 - 36769999-04-03charlottew 97 - 92 (ot)dwyane wade (27)daequan cook (7)dwyane wade (10)time warner cable arena 1956840 - 36779999-04-04washingtonw 118 - 104 (ot)dwyane wade (33)jermaine o'neal , jamaal magloire (6)dwyane wade (8)verizon center 2017341 - 3678'9999-04-07'new orleansl 87 - 93 (ot)dwyane wade (32)jamaal magloire (10)dwyane wade (6)american airlines arena 1960041 - 3779'9999-04-10'bostonl 98 - 105 (ot)dwyane wade (31)michael beasley (13)dwyane wade (9)td banknorth garden 1862441 - 3880'9999-04-12'new yorkw 122 - 105 (ot)dwyane wade (55)michael beasley (16)mario chalmers (9)american airlines arena 1960042 - 38819999-04-14atlantal 79 - 81 (ot)michael beasley (23)michael beasley (13)chris quinn (7)philips arena42 - 3982'9999-04-15'detroitw 102 - 96 (ot)chris quinn (26)dorell wright (10)mario chalmers (10)american airlines arena43 - 39\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN score = 'w 97 - 92 (ot)' AND high_points = 'michael beasley (27)' THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1997.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the artist with a mintage of 41828 is bonnie ross\nInput Table: royal canadian mint numismatic coins (2000s)\n\n\nyearthemeartistmintageissue_price2000steam buggyjohn mardon4436759.952000the bluenosej franklin wrightincluded in steam buggy59.952000the torontojohn mardonincluded in steam buggy59.952001the russell light fourjohn mardon4182859.952001the marco poloj franklin wrightincluded in the russell59.952001the scotiadon curleyincluded in the russell59.952002the gray - dortjohn mardon3594459.952002the william lawrencebonnie rossincluded in the gray - dort59.952002d - 10 locomotivedan fellincluded in the gray - dort59.952003hmcs bras dordon curley3199759.952003cnr fa - 1 diesel electricjohn mardonincluded in hmcs bras dor59.952003bricklin sv - 1brian hughesincluded in hmcs bras dor59.95\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT artist FROM table_sql WHERE mintage = 41828) = 'bonnie ross' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1676.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the results were counted in bhind district three times and five times in datia\nInput Table: bhind (lok sabha constituency)\n\n\nconstituency_numbernamereserved_for_(_sc_/_st_/_none)districtnumber_of_electorates_(2009)9aternonebhind17733410bhindnonebhind19718311laharnonebhind20583912mehgaonnonebhind21064913gohadscbhind16689320sewdanonedatia13016121bhanderscdatia13960022datianonedatia143593total :total :total :total :1371252\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE district = 'bhind') = 3 \n             AND (SELECT COUNT(*) FROM table_sql WHERE district = 'datia') = 5 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-977.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the grace city bridge is a concrete deck girder bridge in stanley\nInput Table: list of bridges on the national register of historic places in north dakota\n\n\nnamelistedlocationcountytypebeaver creek bridge1997-02-27finleysteelepratt through trusscaledonia bridge1997-02-27caledoniatraillpratt through trusscedar creek bridge1997-02-27haynesadamspratt through trusscolton 's crossing bridge1997-02-27lisbonransompratt through trusscrystal bridge1997-05-30crystalpembinaconcrete t - beam bridgeeastwood park bridge1975-04-21minotwardcantilever typeelliott bridge1997-02-27townermchenrypratt through trussfairview lift bridge1997-03-14cartwrightmckenzierailroad lift bridgegrace city bridge1997-02-27grace cityfosterpratt through trussgreat northern railway underpass1997-02-27stanleymountrailconcrete deck girder bridgeknife river bridge near stanton2001-04-25stantonmercerpratt through trusslisbon bridge1997-02-27lisbonransomsteel cantilever bean bridgemidland continental overpass1997-02-27jamestownstutsmansteel cantilever beam bridgemidway bridge1997-02-27johnstowngrand forkswarren bedstead bridgenesheim bridge1997-02-27mcvillenelsonpratt through trussnew rockford bridge1997-03-13new rockford closed to trafficeddywarren through truss bridgenorthwood bridge1997-02-27northwoodgrand forkspratt pony trussnorway bridge1997-02-27mayvilletraillpratt pony trussost valle bridge1997-02-27thompsongrand forkspratt through trussromness bridge1997-02-27cooperstowngriggspratt through trusssorlie memorial bridge1999-07-19grand forksgrand forksparker through truss bridgeviking bridge1997-02-27portlandtraillpratt through trusswest antelope bridge1997-02-27florabensonpratt pony truss bridgewest park bridge1997-02-27valley citybarnesconcrete false arch bridgewestgaard bridge1997-02-27voltairemchenrypratt pony through trussblanchard bridge1997-02-27blanchardtraillpratt through trussgoose river bridge1997-02-27hillsborotraillpratt through trussliberty memorial bridge1997-03-11 removed 2009-03-25bismarckburleighwarren - turner through trussporter elliott bridge1997-02-27hillsborotraillwarren through trussportland park bridge2004-09-23portlandtraillsteel through girderrainbow arch bridge2004-09-23valley citybarnesmarsh rainbow arch\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT type FROM table_sql WHERE name = 'grace city bridge') = 'concrete deck girder bridge' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1217.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: four players scored three goals total , and all four are in league 4\nInput Table: 2008 - 09 r.s.c. anderlecht season\n\n\nplayerleaguetitle_playoffsuper_cuptotalmbark boussoufa110011tom de sutter9009guillaume gillet8009marcin wasilewski8008jonathan legear5107nicol\u00e1s frutos6006thomas chatelle4004roland juh\u00e1sz4004stanislav vl\u010dek4004lucas biglia2003dmitri bulykin3003jan pol\u00e1k2003mat\u00edas su\u00e1rez1013jelle van damme3003oleksandr iakovenko2002hern\u00e1n losada1002v\u00edctor bern\u00e1rdez1001bart goor1001nemanja rni\u01070001\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 4 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE total = 3 \nAND league = 4;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1195.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: ettore meini won three races in a row , on may 24th , 25th and 26th , during the 1933 giro d'italia\nInput Table: 1933 giro d'italia\n\n\ndatecoursedistancewinnerrace_leader9999-05-06milan to turin-learco guerra ( ita )learco guerra ( ita )9999-05-07turin to genoa-alfredo binda ( ita )alfredo binda ( ita )9999-05-08genoa to pisa-learco guerra ( ita )alfredo binda ( ita )9999-05-09rest dayrest dayrest dayrest day9999-05-10pisa to florence-giuseppe olmo ( ita )alfredo binda ( ita )9999-05-11florence to grosseto-learco guerra ( ita )jef demuysere ( bel )9999-05-12grosseto to rome-mario cipriani ( ita )jef demuysere ( bel )9999-05-13rest dayrest dayrest dayrest day9999-05-14rome to naples-gerard loncke ( bel )jef demuysere ( bel )9999-05-15naples to foggia-alfredo binda ( ita )alfredo binda ( ita )9999-05-16rest dayrest dayrest dayrest day9999-05-17foggia to chieti-alfredo binda ( ita )alfredo binda ( ita )9999-05-18chieti to ascoli piceno-alfredo binda ( ita )alfredo binda ( ita )9999-05-19rest dayrest dayrest dayrest day9999-05-20ascoli piceno to riccione-fernand cornez ( fra )alfredo binda ( ita )9999-05-21riccione to bologna-giuseppe olmo ( ita )alfredo binda ( ita )9999-05-22bologna to ferrara-alfredo binda ( ita )alfredo binda ( ita )9999-05-23rest dayrest dayrest dayrest day9999-05-24ferrara to udine-ettore meini ( ita )alfredo binda ( ita )9999-05-25udine to bassano del grappa-ettore meini ( ita )alfredo binda ( ita )9999-05-26bassano del grappa to bolzano-gerard loncke ( bel )alfredo binda ( ita )9999-05-27rest dayrest dayrest dayrest day9999-05-28bolzano to milan-alfredo binda ( ita )alfredo binda ( ita )2023-09-20-km (mi)-km (mi)\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE winner = 'ettore meini' AND date = '9999-05-24') = 1 \n             AND (SELECT COUNT(*) FROM table_sql WHERE winner = 'ettore meini' AND date = '9999-05-25') = 1 \n             AND (SELECT COUNT(*) FROM table_sql WHERE winner = 'ettore meini' AND date = '9999-05-26') = 1 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-686.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: tiger woods score was less than 205\nInput Table: 2002 u.s. open (golf)\n\n\nplaceplayercountryscoreto_par1tiger woodsunited states67 + 68 + 70 = 205- 52sergio garc\u00edaspain68 + 74 + 67 = 209- 1t3jeff maggertunited states69 + 73 + 68 = 210et3phil mickelsonunited states70 + 73 + 67 = 210et5robert allenbyaustralia74 + 70 + 67 = 211+ 1t5p\u00e1draig harringtonireland70 + 68 + 73 = 211+ 1t5billy mayfairunited states69 + 74 + 68 = 211+ 1t8nick faldoengland70 + 76 + 66 = 212+ 2t8justin leonardunited states73 + 71 + 68 = 212+ 2t10tom byrumunited states72 + 72 + 70 = 214+ 4t10davis love iiiunited states71 + 71 + 72 = 214+ 4t10scott mccarronunited states72 + 72 + 70 = 214+ 4\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT score FROM table_sql WHERE player = 'tiger woods') < 205 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1194.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: in the 1933 giro d'italia , gerard loncke won the race on may 25th , despite alfredo binda being the race leader\nInput Table: 1933 giro d'italia\n\n\ndatecoursedistancewinnerrace_leader9999-05-06milan to turin-learco guerra ( ita )learco guerra ( ita )9999-05-07turin to genoa-alfredo binda ( ita )alfredo binda ( ita )9999-05-08genoa to pisa-learco guerra ( ita )alfredo binda ( ita )9999-05-09rest dayrest dayrest dayrest day9999-05-10pisa to florence-giuseppe olmo ( ita )alfredo binda ( ita )9999-05-11florence to grosseto-learco guerra ( ita )jef demuysere ( bel )9999-05-12grosseto to rome-mario cipriani ( ita )jef demuysere ( bel )9999-05-13rest dayrest dayrest dayrest day9999-05-14rome to naples-gerard loncke ( bel )jef demuysere ( bel )9999-05-15naples to foggia-alfredo binda ( ita )alfredo binda ( ita )9999-05-16rest dayrest dayrest dayrest day9999-05-17foggia to chieti-alfredo binda ( ita )alfredo binda ( ita )9999-05-18chieti to ascoli piceno-alfredo binda ( ita )alfredo binda ( ita )9999-05-19rest dayrest dayrest dayrest day9999-05-20ascoli piceno to riccione-fernand cornez ( fra )alfredo binda ( ita )9999-05-21riccione to bologna-giuseppe olmo ( ita )alfredo binda ( ita )9999-05-22bologna to ferrara-alfredo binda ( ita )alfredo binda ( ita )9999-05-23rest dayrest dayrest dayrest day9999-05-24ferrara to udine-ettore meini ( ita )alfredo binda ( ita )9999-05-25udine to bassano del grappa-ettore meini ( ita )alfredo binda ( ita )9999-05-26bassano del grappa to bolzano-gerard loncke ( bel )alfredo binda ( ita )9999-05-27rest dayrest dayrest dayrest day9999-05-28bolzano to milan-alfredo binda ( ita )alfredo binda ( ita )2023-09-20-km (mi)-km (mi)\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT winner FROM table_sql WHERE date = '1933-05-25') = 'gerard loncke ( bel )' \n             AND (SELECT race_leader FROM table_sql WHERE date = '1933-05-25') = 'alfredo binda ( ita )' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1444.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the final ables for the game at giants stadium when chicago bears were the visiting team was 26 - 21\nInput Table: nbc sunday night football results (2006 - present)\n\n\ndatevisiting_teamfinal_scorehost_teamstadium9999-09-07miami dolphins17 - 28pittsburgh steelersheinz field9999-09-10indianapolis colts26 - 21new york giantsgiants stadium9999-09-17washington redskins10 - 27dallas cowboystexas stadium9999-09-24denver broncos17 - 7new england patriotsgillette stadium9999-10-01seattle seahawks6 - 37chicago bearssoldier field9999-10-08pittsburgh steelers13 - 23san diego chargersqualcomm stadium9999-10-15oakland raiders3 - 13denver broncosinvesco field at mile high9999-10-29dallas cowboys35 - 14carolina panthersbank of america stadium9999-11-05indianapolis colts27 - 20new england patriotsgillette stadium9999-11-12chicago bears38 - 20new york giantsgiants stadium9999-11-19san diego chargers35 - 27denver broncosinvesco field at mile high9999-11-26philadelphia eagles21 - 45indianapolis coltsrca dome9999-12-03seattle seahawks23 - 20denver broncosinvesco field at mile high9999-12-10new orleans saints42 - 17dallas cowboystexas stadium9999-12-17kansas city chiefs9 - 20san diego chargersqualcomm stadium9999-12-25philadelphia eagles23 - 7dallas cowboystexas stadium9999-12-31green bay packers26 - 7chicago bearssoldier field0001-01-06kansas city chiefs8 - 23indianapolis coltsrca dome0001-01-06dallas cowboys20 - 21seattle seahawksqwest field\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT final_score FROM table_sql WHERE visiting_team = 'chicago bears' AND stadium = 'giants stadium') = '26 - 21' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1791.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the result with incumbent cecil r king , district california 10 is re - elected\nInput Table: united states house of representatives elections , 1942\n\n\ndistrictincumbentpartyfirst_electedresultcandidatescalifornia 2harry lane englebrightrepublican1926-01-01re - electedharry lane englebright (r) unopposedcalifornia 4thomas rolphrepublican1940-01-01re - electedthomas rolph (r) 98.3% archie brown ( w / i ) 1.7%california 7john h tolandemocratic1934-01-01re - electedjohn h tolan (d) unopposedcalifornia 9bertrand w gearhartrepublican1934-01-01re - electedbertrand w gearhart (r) unopposedcalifornia 10alfred j elliottdemocratic1937-01-01re - electedalfred j elliott (d) unopposedcalifornia 17cecil r kingdemocratic1942-08-25re - electedcecil r king (d) unopposedcalifornia 22none (district created)none (district created)9999-01-01new seat republican gainjohn j phillips (r) 57.6% n e west (d) 42.4%\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE district = 'california 10' \nAND incumbent = 'cecil r king' \nAND result = 're - elected';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1935.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: mar cavendish consecutively won 5 stages\nInput Table: 2010 vuelta a espa\u00f1a\n\n\nstagewinnergeneral_classificationpoints_classificationmountains_classificationcombination_classificationteam_classification1team htc - columbiamark cavendishmark cavendish 1not awardedmark cavendishteam htc - columbia2yauheni hutarovichmark cavendishyauheni hutarovichmicka\u00ebl delagejavier ram\u00edrezteam htc - columbia3philippe gilbertphilippe gilbertphilippe gilbertseraf\u00edn mart\u00ednezseraf\u00edn mart\u00ednezteam htc - columbia4igor ant\u00f3nphilippe gilbertigor ant\u00f3nseraf\u00edn mart\u00ednezvincenzo nibalicaisse d'epargne5tyler farrarphilippe gilbertigor ant\u00f3nseraf\u00edn mart\u00ednezvincenzo nibalicaisse d'epargne6thor hushovdphilippe gilbertphilippe gilbertseraf\u00edn mart\u00ednezphilippe gilbertcaisse d'epargne7alessandro petacchiphilippe gilbertmark cavendishseraf\u00edn mart\u00ednezphilippe gilbertcaisse d'epargne8david moncouti\u00e9igor ant\u00f3nmark cavendishseraf\u00edn mart\u00ednezvincenzo nibalicaisse d'epargne9david l\u00f3pezigor ant\u00f3nmark cavendishdavid moncouti\u00e9vincenzo nibalicaisse d'epargne10imanol ervitijoaquim rodr\u00edguezmark cavendishdavid moncouti\u00e9david moncouti\u00e9caisse d'epargne11igor ant\u00f3nigor ant\u00f3nigor ant\u00f3ndavid moncouti\u00e9igor ant\u00f3ncaisse d'epargne12mark cavendishigor ant\u00f3nmark cavendishdavid moncouti\u00e9igor ant\u00f3ncaisse d'epargne13mark cavendishigor ant\u00f3nmark cavendishdavid moncouti\u00e9igor ant\u00f3ncaisse d'epargne14joaquim rodr\u00edguezvincenzo nibalimark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezcaisse d'epargne15carlos barredovincenzo nibalimark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezteam katusha16mikel nievejoaquim rodr\u00edguezmark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezteam katusha17peter velitsvincenzo nibalimark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezteam katusha18mark cavendishvincenzo nibalimark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezteam katusha19philippe gilbertvincenzo nibalimark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezteam katusha20ezequiel mosquera 2vincenzo nibalimark cavendishdavid moncouti\u00e9vincenzo nibaliteam katusha21tyler farrarvincenzo nibalimark cavendishdavid moncouti\u00e9vincenzo nibaliteam katusha\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE winner = 'mark cavendish') >= 5 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1804.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: daniel uberti was sacked on 29 december 2008 and replaced by carlos de toro on 29 december 2008\nInput Table: primera divisi\u00f3n de f\u00fatbol profesional apertura 2008\n\n\nteamoutgoing_managermanner_of_departuredate_of_vacancyreplaced_bydate_of_appointmentposition_in_tablenejapamauricio cienfuegosmutual consent2008-08-14daniel uberti2008-09-0510thfirpogerardo reinososacked2008-08-25oscar benitez2008-09-027thbalboagustavo de simonesacked2008-08-30roberto gamarra2008-09-0510thalianzapablo centronesacked2008-09-14carlos jurado2008-09-165thfirpooscar ben\u00edtezsacked2008-12-09agust\u00edn castillo2008-12-23post - season (6th)\u00e1guilaagust\u00edn castillosacked2008-12-15pablo centrone2008-12-24post - season (semifinals)fasnelson anchetasacked2008-12-27roberto gamarra2009-01-01post - season (semifinals)nejapadaniel ubertisacked2008-12-29nelson ancheta2008-12-29post - season (10th)balboaroberto gamarramutual consent2009-01-01carlos de toro2009-01-16post - season (7th)\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE outgoing_manager = 'daniel uberti' AND manner_of_departure = 'sacked' AND date_of_vacancy = '2008-12-29' AND replaced_by = 'carlos de toro' AND date_of_appointment = '2008-12-29') > 0 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-7.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the wildcats loss one game in november and two games in september\nInput Table: 1947 kentucky wildcats football team\n\n\ngamedateopponentresultwildcats_pointsopponentsrecord19999-09-20ole missloss7140 - 129999-09-27cincinnatiwin2001 - 139999-10-04xavierwin2072 - 149999-10-119 georgiawin2603 - 1 , 2059999-10-1810 vanderbiltwin1404 - 1 , 1469999-10-25michigan statewin765 - 1 , 1379999-11-0118 alabamaloss0135 - 289999-11-08west virginiawin1566 - 299999-11-15evansvillewin3607 - 2109999-11-22tennesseeloss6137 - 3\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE result = 'loss' AND strftime('%m', date) = '11') = 1 \n             AND (SELECT COUNT(*) FROM table_sql WHERE result = 'loss' AND strftime('%m', date) = '09') = 2 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-899.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: alec bedser had the best bowling average of any england player\nInput Table: 1948 ashes series\n\n\nplayerteammatcheswicketsaveragebest_bowlingray lindwallaustralia52719.626 / 20bill johnstonaustralia52723.335 / 36alec bedserengland51838.224 / 81keith milleraustralia51323.154 / 125ernie toshackaustralia41133.095 / 40norman yardleyengland5922.662 / 32jim lakerengland3952.444 / 138\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT average FROM table_sql WHERE team = 'england') = \n             (SELECT MIN(average) FROM table_sql WHERE team = 'england') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-995.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there were two episodes in the series that were directed by perry chafe\nInput Table: list of republic of doyle episodes\n\n\nUnnamed:_0titledirected_bywritten_byviewersoriginal_airdateprod_code1fathers and sonsmike clattenburgallan hawco , perry chafe and malcolm macrury9690002010-01-061012the return of the grievous angelsteve dimarcoallan hawco and avrum jacobson7150002010-01-131023duchess of georgemike clattenburgallan hawco , perry chafe and malcolm macrury6850002010-01-201035hit and rumsteve dimarcomatt maclennan5940002010-02-031056the one who got awaylarry mcleanjesse mckeown10120002010-02-101067the woman who knew too littlerobert liebermanjeremy boxen10530002010-03-031078the tell - tale safejerry ciccorittijohn callaghan and steve cochrane9860002010-03-101089he sleeps with the chipsphil earnshawperry chafe9080002010-03-1710910the pen is mightier than the doylerobert liebermansteve cochrane and avrum jacobson8970002010-03-2411011a horse dividedsteve scainijesse mckeown9020002010-03-31111\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 2 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE directed_by = 'perry chafe';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1649.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the princes park venue had just as much crowd as the junction oval menu\nInput Table: 1975 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddategeelong14.20 (104)melbourne14.14 (98)kardinia park133281975-06-07st kilda15.9 (99)north melbourne17.19 (121)moorabbin oval178111975-06-07richmond19.14 (128)essendon12.9 (81)mcg494691975-06-07hawthorn19.24 (138)collingwood13.11 (89)princes park238301975-06-07fitzroy15.7 (97)carlton16.10 (106)junction oval162491975-06-07footscray13.11 (89)south melbourne12.15 (87)vfl park140561975-06-07\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT crowd FROM table_sql WHERE venue = 'princes park') = \n             (SELECT crowd FROM table_sql WHERE venue = 'junction oval') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-795.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: danish thomas bj\u00f8rn ranked lower than tiger woods\nInput Table: 1998 open championship\n\n\nplaceplayercountryscoreto_par1brian wattsunited states68 + 69 + 73 = 210et2jim furykunited states70 + 70 + 72 = 212+ 2t2mark o'mearaunited states72 + 68 + 72 = 212+ 2t2jesper parneviksweden68 + 72 + 72 = 212+ 25justin rose (a)england72 + 66 + 75 = 213+ 3t6thomas bj\u00e3rndenmark68 + 71 + 76 = 215+ 5t6brad faxonunited states67 + 74 + 74 = 215+ 5t6john hustonunited states65 + 77 + 73 = 215+ 5t6tiger woodsunited states65 + 73 + 77 = 215+ 5t10david duvalunited states70 + 71 + 75 = 216+ 6t10costantino roccaitaly72 + 74 + 70 = 216+ 6t10raymond russellscotland68 + 73 + 75 = 216+ 6t10katsuyoshi tomorijapan75 + 71 + 70 = 216+ 6\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT place FROM table_sql WHERE player = 'thomas bj\u00e3rn') > \n             (SELECT place FROM table_sql WHERE player = 'tiger woods') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-440.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: john love has the highest position at 25 on grid following howden ganley at 16 with dave charlton in the 1st postion\nInput Table: 1971 south african grand prix\n\n\ndriverconstructorlapstime_/_retiredgridmario andrettiferrari791:47:35.54jackie stewarttyrrell - ford79+ 20.91clay regazzoniferrari79+ 31.43reine wiselllotus - ford79+ 1:09.414chris amonmatra78+ 1 lap2denny hulmemclaren - ford78+ 1 lap7brian redmansurtees - ford78+ 1 lap17jacky ickxferrari78+ 1 lap8graham hillbrabham - ford77+ 2 laps19ronnie petersonmarch - ford77+ 2 laps13henri pescarolomarch - ford77+ 2 laps18rolf stommelensurtees - ford77+ 2 laps15andrea de adamichmarch - alfa romeo75+ 4 laps22emerson fittipaldilotus - ford58engine5john surteessurtees - ford56gearbox6fran\u00e7ois ceverttyrrell - ford45accident9howden ganleybrm42physical24pedro rodr\u00edguezbrm33overheating10dave charltonbrabham - ford31engine16jo siffertbrm31overheating12john lovemarch - ford30differential21jackie pretoriusbrabham - ford22engine20peter gethinmclaren - ford7fuel leak11jo bonniermclaren - ford5suspension23alex soler - roigmarch - ford5engine25\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT grid FROM table_sql WHERE driver = 'john love') = 25 \n             AND (SELECT grid FROM table_sql WHERE driver = 'howden ganley') = 16 \n             AND (SELECT grid FROM table_sql WHERE driver = 'dave charlton') = 1 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1141.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: st kilda was the away team when the home team scored 12.11 (83)\nInput Table: 1946 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddategeelong15.7 (97)melbourne21.14 (140)kardinia park115001946-07-13essendon16.24 (120)footscray14.8 (92)windy hill290001946-07-13collingwood15.23 (113)hawthorn11.14 (80)victoria park110001946-07-13carlton12.13 (85)south melbourne11.18 (84)princes park260001946-07-13st kilda10.14 (74)north melbourne12.11 (83)junction oval70001946-07-13richmond14.14 (98)fitzroy10.12 (72)punt road oval190001946-07-13\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE home_team_score = '12.11 (83)' \nAND away_team = 'st kilda';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1912.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: over three teams have the same number of goals scored against them\nInput Table: 1940 in brazilian football\n\n\npositionteampointsplayedagainstdifference1flamengo1381282fluminense13815103corinthians981544palestra it\u00e1lia881935portuguesa7823- 106botafogo682507vasco da gama6819- 28am\u00e9rica6825- 109s\u00e3o paulo4824- 13\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(DISTINCT against) = 1 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1733.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: week 9 was before october 30 , 1983\nInput Table: 1983 detroit lions season\n\n\nweekdateopponentresultattendance11983-09-04tampa bay buccaneersw 11 - 06215421983-09-11cleveland brownsl 31 - 266009531983-09-18atlanta falconsl 30 - 145462241983-09-25minnesota vikingsl 20 - 175825451983-10-02los angeles ramsl 21 - 104940361983-10-09green bay packersw 38 - 146773871983-10-16chicago bearsw 31 - 176670981983-10-23washington redskinsl 38 - 174318991983-10-30chicago bearsw 38 - 1758764101983-11-07new york giantsw 15 - 968985111983-11-13houston oilersl 27 - 1740660121983-11-20green bay packersw 23 - 20 ot50050131983-11-24pittsburgh steelersw 45 - 377724141983-12-05minnesota vikingsw 13 - 279169151983-12-11cincinnati bengalsl 17 - 945728161983-12-18tampa bay buccaneersw 23 - 2078392\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT date FROM table_sql WHERE week = 9) < '1983-10-30' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-449.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there were no home teams that scored more than 11\nInput Table: 1938 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddategeelong11.23 (89)hawthorn6.13 (49)corio oval70001938-06-18fitzroy16.12 (108)south melbourne8.8 (56)brunswick street oval120001938-06-18st kilda14.12 (96)melbourne16.16 (112)junction oval140001938-06-18richmond15.14 (104)essendon15.9 (99)punt road oval200001938-06-18footscray13.9 (87)collingwood10.5 (65)western oval180001938-06-18north melbourne11.5 (71)carlton16.25 (121)arden street oval130001938-06-18\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE home_team_score > '11';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-382.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: gpl is the license for jriver media center\nInput Table: comparison of upnp av media servers\n\n\nnamelicenseos_xunix_-_likewindowsweb_interface360 media servergplnoyesyesyesavia media playerpropnonononobrisamitpartialpartialnoyescoherencemitpartialpartialpartialyesdivxpropyesnoyesnoelgato eyeconnectpropyesnononofoobar2000propnonoyesnofuppesgplyesyesyesyesgeexbox usharegplnoyesnoyesgmediaservergplnoyesnonohome media centergplv2nonoyesyesisedora media serverpropyesnoyesyesjriver media centerpropnonoyesyeskooraroo mediapropyesyesyesyeslximediagplyesyesyesnomajestic media serverpropyesnononomediatombgplpartialyesnoyesminidlnagpl / bsdpartialyesyespartialmezzmopropnonoyesnomyihomepropyesyesyesnomythtv with upnpgplyesyesnoyesnullriver medialinkpropyesnononoplayonpropnonoyesyesplexpropyesyesyesyesps3 media servergplyesyesyesyespymedsmitpartialpartialnonorygellgplv2noyesnonorivetpropyesnononoserviiopropyesyesyesyessimplecenter premiumpropnonoyesyesskiftapropyesyesyesnosongbirdgplv2yesnoyesnotvblepropnonoyesnotversitypropnonoyesyestvmobilipropyesyesyesyestvsharepropnonoyesnotwonkyserverpropyesyesyesyesuniversal media servergplyesyesyesyeswindows media connectpropnonoyesnowild media serverpropyesyesyesyesxbmc media centergplyesyesyesyesxupnpdgplv2noyesnoyesyazsoft playbackpropyesnonononamelicenseos xunix - likewindowsweb interface\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN license = 'gpl' AND name = 'jriver media center' THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-750.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the yugoslavian national team suffered its worst outcome losing 2:1 in the balken cup against poland on march 22\nInput Table: yugoslavia national football team results\n\n\ndatecityopponentresultstype_of_game9999-03-22sarajevouruguay2:1friendly9999-03-30belgraderomania2:0balkan cup9999-04-26borovopoland2:1friendly9999-08-27bucharest , romaniaromania1:4balkan cup9999-09-10luxembourgluxembourg5:01982 wcq9999-09-27ljubljanadenmark2:11982 wcq9999-11-15torino , italyitaly0:21982 wcq\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT results FROM table_sql WHERE type_of_game = 'balkan cup' AND opponent = 'poland' AND date = '9999-03-22') = '2:1' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1336.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: stephen jackson led the team in points for less than half the games\nInput Table: 2009 - 10 charlotte bobcats season\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord4701-02-9999portlandl 79 - 98 (ot)raymond felton (23)gerald wallace (10)stephen jackson (4)rose garden 2010624 - 23489999-02-03la lakersl 97 - 99 (ot)stephen jackson (30)nazr mohammed (17)boris diaw (5)staples center 1899724 - 24499999-02-06new orleansl 99 - 104 (ot)stephen jackson (26)boris diaw (8)raymond felton (7)time warner cable arena 1916424 - 25509999-02-09washingtonw 94 - 92 (ot)stephen jackson (22)nazr mohammed (10)raymond felton (5)time warner cable arena 1237625 - 255101-02-10minnesotaw 93 - 92 (ot)stephen jackson (33)nazr mohammed (20)dj augustin (7)target center 1335226 - 255201-02-16new jerseyl 94 - 103 (ot)gerald wallace (21)gerald wallace , boris diaw (10)stephen jackson (5)time warner cable arena 1371226 - 26539999-02-19clevelandw 110 - 93 (ot)stephen jackson (29)tyrus thomas (12)boris diaw (9)time warner cable arena 1956827 - 26549999-02-20milwaukeel 88 - 93 (ot)stephen jackson (35)tyrus thomas (11)stephen jackson (5)bradley center 1717427 - 27559999-02-22la clippersl 94 - 98 (ot)gerald wallace (32)gerald wallace (12)boris diaw , raymond felton (9)staples center 1589227 - 28569999-02-24utahl 93 - 102 (ot)gerald wallace (27)gerald wallace (8)raymond felton (5)energysolutions arena 1991127 - 29\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE high_points > (SELECT MAX(high_points) FROM table_sql) / 2 AND team = 'charlotte bobcats') < (SELECT COUNT(*) FROM table_sql WHERE team = 'charlotte bobcats') / 2 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1305.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the match played on 7th january recorded a attendance grater than 70000\nInput Table: 2002 - 03 manchester united f.c. season\n\n\ndateroundopponentsresult_f_-_aattendance2002-11-05round 3leicester city2 - 0478482002-12-03round 4burnley2 - 0220342002-12-17round 5chelsea1 - 0579852003-01-07semi - final first legblackburn rovers1 - 1627402003-01-22semi - final second legblackburn rovers3 - 1290482003-03-02finalliverpool0 - 274500\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT attendance FROM table_sql WHERE date = '2003-01-07') > 70000 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1492.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the venue that linfield was the opponent b\nInput Table: 2003 - 04 rangers f.c. season\n\n\ndateopponentvenueresultattendance2003-07-16greuther f\u00fcrthn2 - 035002003-07-19vfb auerbacha5 - 125002003-07-19erzgebirge auea1 - 025002003-07-22jahn regensburga1 - 250002003-07-26evertonh2 - 3280002003-07-30linfielda3 - 0132842003-08-05arsenalh0 - 337000\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE opponent = 'linfield' \nAND venue = 'b';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-689.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: tiger woods scores a 211 placing 5th\nInput Table: 2002 u.s. open (golf)\n\n\nplaceplayercountryscoreto_par1tiger woodsunited states67 + 68 + 70 = 205- 52sergio garc\u00edaspain68 + 74 + 67 = 209- 1t3jeff maggertunited states69 + 73 + 68 = 210et3phil mickelsonunited states70 + 73 + 67 = 210et5robert allenbyaustralia74 + 70 + 67 = 211+ 1t5p\u00e1draig harringtonireland70 + 68 + 73 = 211+ 1t5billy mayfairunited states69 + 74 + 68 = 211+ 1t8nick faldoengland70 + 76 + 66 = 212+ 2t8justin leonardunited states73 + 71 + 68 = 212+ 2t10tom byrumunited states72 + 72 + 70 = 214+ 4t10davis love iiiunited states71 + 71 + 72 = 214+ 4t10scott mccarronunited states72 + 72 + 70 = 214+ 4\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT to_par FROM table_sql WHERE player = 'tiger woods') = -5 \n             AND (SELECT place FROM table_sql WHERE player = 'tiger woods') = 5 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-834.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: in the 1981 open championship the winning score was 72 , with two players tying for this score , isao aoki and david graham\nInput Table: 1981 open championship\n\n\nplaceplayercountryscoreto_part1vicente fern\u00e3\u00a1ndezargentina70et1nick jobengland70et3isao aokijapan71+ 1t3david grahamaustralia71+ 1t3tony jacklinengland71+ 1t3johnny millerunited states71+ 1t3simon owennew zealand71+ 1t3hal sutton (a)united states71+ 1t9howard clarkengland72+ 2t9ben crenshawunited states72+ 2t9david jaggerengland72+ 2t9mark jamesengland72+ 2t9greg normanaustralia72+ 2t9arnold palmerunited states72+ 2t9bill rogersunited states72+ 2t9sam torrancescotland72+ 2\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE score = 72) = 2 \n             AND (SELECT COUNT(*) FROM table_sql WHERE score = 72 AND player = 'isao aoki') = 1 \n             AND (SELECT COUNT(*) FROM table_sql WHERE score = 72 AND player = 'david graham') = 1 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-356.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: when the from is 830 bc , the state is wey\nInput Table: list of state leaders in 820s bc\n\n\nstatetypenametitleroyal_housefromcaisovereignyimarquisji837 bccaosovereignyoucount-835 bccaosovereigndaicount-826 bcchensovereignliduke-831 bcchusovereignxiong yan the youngerviscountmi837 bcchusovereignxiong shuangviscountmi827 bcchusovereignxiong xunviscountmi821 bcjinsovereignximarquisji840 bcjinsovereignxianmarquisji822 bclusovereignshendukeji854 bclusovereignwudukeji825 bcqisovereignwudukejiang850 bcqisovereignlidukejiang824 bcqinsovereignqin zhongrulerying845 bcqinsovereignzhuangdukeying822 bcsongsovereignhuiduke-830 bcweysovereignlimarquis-855 bcyansovereignhuimarquis-864 bcyansovereignlimarquis-826 bc\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN state = 'wey' AND \"from\" = '830 bc' THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-619.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: one episode is titled the expulsion\nInput Table: none\n\n\nepisodeseriesepisode_titleoriginal_air_dateproduction_code271return to genesis2008-04-05201282the suspension2008-04-06202293a team reinvented2008-04-12203304the new captain2008-04-13204315the homecoming2008-04-19205326netherball rules!2008-04-20206337doubts within2008-04-26207348rocket 's decent2008-04-27208359the all - stars2008-05-032093610rocket vs sinedd2008-05-042103711the champions stumble2008-05-102113812last stand2008-05-112123913fluxless2008-05-172134014new order2008-07-262144115revelations2008-07-272154216new rules2008-08-022164317open doors2008-08-032174418warren steps in2008-08-092184519the technodroid v3s2008-08-102194620the fallen star2008-08-162204721coach artegor2008-08-172214822rocket , the midfielder2008-08-232224923destiny2008-08-242235024final preparations2008-08-312245125a team unravels2008-08-31225\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE episode_title = 'the expulsion';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1311.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: larry mize and scott simpson are tied for 5th place\nInput Table: 1988 u.s. open (golf)\n\n\nplaceplayercountryscoreto_par1curtis strangeunited states70 + 67 + 69 = 206- 7t2nick faldoengland72 + 67 + 68 = 207- 6t2bob gilderunited states68 + 69 + 70 = 207- 6t2scott simpsonunited states69 + 66 + 72 = 207- 6t5larry mizeunited states69 + 67 + 72 = 208- 5t5d a weibringunited states71 + 69 + 68 = 208- 57mark o'mearaunited states71 + 72 + 66 = 209- 48fred couplesunited states72 + 67 + 71 = 210- 39lanny wadkinsunited states70 + 71 + 70 = 211- 210ken greenunited states72 + 70 + 70 = 212- 1\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT place FROM table_sql WHERE player = 'larry mize') = (SELECT place FROM table_sql WHERE player = 'scott simpson') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1660.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: game 4 had a location attendance of at&t center 20491 and the series was 1 - 1\nInput Table: 2008 - 09 san antonio spurs season\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendanceseries19999-04-18dallasl 97 - 105 (ot)tim duncan (27)tim duncan (9)tony parker (8)at&t center 187970 - 129999-04-20dallasw 105 - 84 (ot)tony parker (38)tim duncan (11)tony parker (8)at&t center 187971 - 139999-04-23dallasl 67 - 88 (ot)tony parker (12)kurt thomas (10)tony parker (3)american airlines center 204911 - 249999-04-25dallasl 90 - 99 (ot)tony parker (43)tim duncan (10)tim duncan (7)american airlines center 208291 - 359999-04-28dallasl 93 - 106 (ot)tim duncan (31)tim duncan (12)tony parker (6)at&t center 208291 - 4\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE game = 4 \nAND location_attendance = 'at&t center 20491' \nAND series = '1 - 1';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-373.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the black knights lost to penn state , whose record was 2 - 1 , on september 27th\nInput Table: 1975 army cadets football team\n\n\ngamedateopponentresultblack_knights_pointsopponentsrecord19999-09-13holy crosswin4471 - 029999-09-20lehighwin54322 - 039999-09-27villanovaloss0102 - 149999-10-04stanfordloss14672 - 259999-10-11dukeloss10212 - 369999-10-18pittsburghloss20522 - 479999-10-25penn stateloss0312 - 589999-11-01air forceloss3332 - 699999-11-08boston collegeloss0312 - 7109999-11-15vanderbiltloss14232 - 8\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT record FROM table_sql WHERE opponent = 'penn state' AND date = '9999-09-27') = '2 - 1' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1888.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the average services is less than 7 , when year is greater than 2003 , when industry is less than 1465 , and when regional gva is greater than 9432\nInput Table: none\n\n\nyearregional_gvaagricultureindustryservices199547531111103632200065841013025277200382011113746816200589781114657502200794321115657856\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT AVG(services) FROM table_sql WHERE year > 2003 AND industry < 1465 AND regional_gva > 9432) < 7 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1756.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the 49ers last opponent of the season was the brooklyn dodgers\nInput Table: 1947 san francisco 49ers season\n\n\nweekdateopponentresultscorerecord11947-08-31brooklyn dodgersw23 - 71 - 021947-09-07los angeles donsw17 - 142 - 031947-09-14baltimore coltsw14 - 73 - 041947-09-21new york yankeesl21 - 163 - 151947-09-28buffalo billsw41 - 244 - 161947-10-05baltimore coltst28 - 284 - 1 - 171947-10-12chicago rocketsw42 - 285 - 1 - 181947-10-26cleveland brownsl14 - 75 - 2 - 191947-11-02los angeles donsw26 - 166 - 2 - 1101947-11-09new york yankeesl24 - 166 - 3 - 1111947-11-16cleveland brownsl37 - 146 - 4 - 1121947-11-21chicago rocketsw41 - 167 - 4 - 1131947-11-27brooklyn dodgersw21 - 78 - 4 - 1141947-12-07buffalo billst21 - 218 - 4 - 2\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN opponent = 'brooklyn dodgers' AND week = (SELECT MAX(week) FROM table_sql) \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1932.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: caisse d'epargne had the least team classifications with 3\nInput Table: 2010 vuelta a espa\u00f1a\n\n\nstagewinnergeneral_classificationpoints_classificationmountains_classificationcombination_classificationteam_classification1team htc - columbiamark cavendishmark cavendish 1not awardedmark cavendishteam htc - columbia2yauheni hutarovichmark cavendishyauheni hutarovichmicka\u00ebl delagejavier ram\u00edrezteam htc - columbia3philippe gilbertphilippe gilbertphilippe gilbertseraf\u00edn mart\u00ednezseraf\u00edn mart\u00ednezteam htc - columbia4igor ant\u00f3nphilippe gilbertigor ant\u00f3nseraf\u00edn mart\u00ednezvincenzo nibalicaisse d'epargne5tyler farrarphilippe gilbertigor ant\u00f3nseraf\u00edn mart\u00ednezvincenzo nibalicaisse d'epargne6thor hushovdphilippe gilbertphilippe gilbertseraf\u00edn mart\u00ednezphilippe gilbertcaisse d'epargne7alessandro petacchiphilippe gilbertmark cavendishseraf\u00edn mart\u00ednezphilippe gilbertcaisse d'epargne8david moncouti\u00e9igor ant\u00f3nmark cavendishseraf\u00edn mart\u00ednezvincenzo nibalicaisse d'epargne9david l\u00f3pezigor ant\u00f3nmark cavendishdavid moncouti\u00e9vincenzo nibalicaisse d'epargne10imanol ervitijoaquim rodr\u00edguezmark cavendishdavid moncouti\u00e9david moncouti\u00e9caisse d'epargne11igor ant\u00f3nigor ant\u00f3nigor ant\u00f3ndavid moncouti\u00e9igor ant\u00f3ncaisse d'epargne12mark cavendishigor ant\u00f3nmark cavendishdavid moncouti\u00e9igor ant\u00f3ncaisse d'epargne13mark cavendishigor ant\u00f3nmark cavendishdavid moncouti\u00e9igor ant\u00f3ncaisse d'epargne14joaquim rodr\u00edguezvincenzo nibalimark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezcaisse d'epargne15carlos barredovincenzo nibalimark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezteam katusha16mikel nievejoaquim rodr\u00edguezmark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezteam katusha17peter velitsvincenzo nibalimark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezteam katusha18mark cavendishvincenzo nibalimark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezteam katusha19philippe gilbertvincenzo nibalimark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezteam katusha20ezequiel mosquera 2vincenzo nibalimark cavendishdavid moncouti\u00e9vincenzo nibaliteam katusha21tyler farrarvincenzo nibalimark cavendishdavid moncouti\u00e9vincenzo nibaliteam katusha\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE team_classification = \"caisse d'epargne\") = 3 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1638.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: w 59 - 46 w 74 - 56 w 94 - 76 w 72 - 71 ot w 71 - 61 i 62 - 70 results has the record of 27 - 9\nInput Table: vcu rams men 's basketball\n\n\nyearrecordseedregionresults198018 - 1212eastl 72 - 86198124 - 55eastw 85 - 69 l 56 - 58 ot198324 - 75eastw 76 - 67 l 54 - 56198423 - 76eastw 70 - 69 l 63 - 78198526 - 62westw 81 - 65 l 59 - 63199624 - 912southeastl 51 - 58200423 - 813eastl 78 - 79200728 - 711westw 79 - 77 l 79 - 84 ot200924 - 1011eastl 64 - 65201128 - 1211southwestw 59 - 46 w 74 - 56 w 94 - 76 w 72 - 71 ot w 71 - 61 l 62 - 70201229 - 712midwestw 62 - 59 l 61 - 63201327 - 95southw 88 - 42 l 53 - 78\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN results = 'w 59 - 46 w 74 - 56 w 94 - 76 w 72 - 71 ot w 71 - 61 l 62 - 70' \n             AND record = '27 - 9' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1969.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: before october 15 , carrier dome 11747 was the location attendance where will bynum (5) did the high assists played\nInput Table: 2010 - 11 detroit pistons season\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord19999-10-05miamil 89 - 105 (ot)ben gordon (17)ben gordon , charlie villanueva (5)rodney stuckey (5)american airlines arena 196000 - 129999-10-08milwaukeew 115 - 110 (ot)austin daye (21)austin daye (7)will bynum (9)the palace of auburn hills 128211 - 139999-10-11atlantaw 94 - 85 (ot)rodney stuckey (16)greg monroe (7)richard hamilton (7)the palace of auburn hills 105912 - 149999-10-13dallasl 96 - 101 (ot)austin daye (16)ben wallace , jason maxiell (8)rodney stuckey (6)van andel arena 102072 - 259999-10-15minnesotal 88 - 99 (ot)austin daye (18)austin daye (11)will bynum (5)carrier dome 117472 - 369999-10-16charlottel 94 - 97 (ot)rodney stuckey (25)greg monroe (8)rodney stuckey , will bynum (5)colonial life arena 68472 - 479999-10-19washingtonw 98 - 92 (ot)rodney stuckey (34)ben wallace (11)rodney stuckey (7)huntington center 64243 - 4\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT location_attendance FROM table_sql WHERE date < '9999-10-15' AND location_attendance = 'carrier dome 11747') IS NOT NULL \n             AND (SELECT high_assists FROM table_sql WHERE date < '9999-10-15' AND location_attendance = 'carrier dome 11747') = 5 \n             AND (SELECT team FROM table_sql WHERE date < '9999-10-15' AND location_attendance = 'carrier dome 11747' AND high_assists = 5) = 'will bynum' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-148.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: in the 2006 season the texas mariners played the angels nine times\nInput Table: 2006 texas rangers season\n\n\ndateopponentscorelossattendancerecord9999-09-01indians7 - 2padilla (13 - 9)2377669 - 679999-09-02indians6 - 5volquez (1 - 4)4022269 - 689999-09-03indians5 - 2byrd1966770 - 689999-09-04athletics8 - 1zito2394971 - 689999-09-05athletics5 - 4saarloos2722572 - 689999-09-06athletics9 - 6rupe (0 - 1)1783872 - 699999-09-08mariners7 - 2millwood (14 - 10)2864672 - 709999-09-09mariners3 - 2rheinecker (4 - 6)3345472 - 719999-09-10mariners4 - 2huber3432173 - 719999-09-12tigers3 - 2mahay (1 - 3)2419673 - 729999-09-13tigers11 - 3verlander2467274 - 729999-09-14angels2 - 1volquez (1 - 5)2148874 - 739999-09-15angels2 - 1francisco (0 - 1)3078874 - 749999-09-16angels12 - 6lackey4019675 - 749999-09-17angels8 - 1santana2430376 - 749999-09-18mariners8 - 1hern\u00e1ndez1821477 - 749999-09-19mariners9 - 7wilson (2 - 3)1855177 - 759999-09-20mariners6 - 3tejeda (4 - 4)2600677 - 769999-09-22indians12 - 4byrd2628478 - 769999-09-23indians6 - 3padilla (14 - 10)3835178 - 779999-09-24indians11 - 6millwood (16 - 11)3661778 - 789999-09-25angels8 - 3volquez (1 - 6)3978178 - 799999-09-26angels5 - 2escobar3733979 - 799999-09-27angels6 - 5wilson (2 - 4)3803279 - 809999-09-29mariners6 - 5fruto3076680 - 809999-09-30mariners3 - 1millwood (16 - 12)2331080 - 819999-10-01mariners3 - 2tejeda (5 - 5)2836180 - 82\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 9 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE opponent = 'angels' \nAND date LIKE '2006%' \nAND (record LIKE '%- 7%' OR record LIKE '%- 8%');\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1036.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the score was 5 - 4 on february 24\nInput Table: 2003 - 04 philadelphia flyers season\n\n\ngamefebruaryopponentscorerecordpoints549999-01-02tampa bay lightning1 - 226 - 12 - 11 - 568559999-01-04washington capitals5 - 127 - 12 - 11 - 570569999-01-05atlanta thrashers5 - 128 - 12 - 11 - 572579999-01-10new jersey devils4 - 129 - 12 - 11 - 574589999-01-12new york rangers2 - 130 - 12 - 11 - 576599999-01-14new york rangers6 - 231 - 12 - 11 - 578609999-01-16san jose sharks2 - 531 - 13 - 11 - 578619999-01-17tampa bay lightning2 - 531 - 14 - 11 - 578629999-01-19boston bruins3 - 431 - 15 - 11 - 578639999-01-21atlanta thrashers5 - 432 - 15 - 11 - 580649999-01-24chicago blackhawks3 - 133 - 15 - 11 - 582659999-01-26ottawa senators1 - 1 ot33 - 15 - 12 - 583669999-01-28boston bruins2 - 3 ot33 - 15 - 12 - 684679999-01-29detroit red wings2 - 433 - 16 - 12 - 684\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT score FROM table_sql WHERE february = '2003-04-24' AND score = '5 - 4') IS NOT NULL \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1164.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there were two instances where there was a tie for most rebounds by detroit pistons players during this period of the 2010 - 2011 season\nInput Table: 2010 - 11 detroit pistons season\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord629999-03-01milwaukeel 90 - 92 (ot)rodney stuckey (25)greg monroe , charlie villanueva (9)rodney stuckey (5)bradley center 1136422 - 40639999-03-02minnesotal 105 - 116 (ot)austin daye (22)greg monroe (11)rodney stuckey (10)the palace of auburn hills 1312222 - 41649999-03-06washingtonw 113 - 102 (ot)tayshaun prince (20)greg monroe , rodney stuckey (7)rodney stuckey (9)the palace of auburn hills 1750623 - 41659999-03-09san antoniol 104 - 111 (ot)richard hamilton (20)greg monroe (10)tracy mcgrady (9)at&t center 1858123 - 42669999-03-11oklahoma cityl 94 - 104 (ot)richard hamilton (20)greg monroe (10)greg monroe , rodney stuckey (6)oklahoma city arena 1820323 - 43679999-03-12denverl 101 - 131 (ot)chris wilcox (21)austin daye , ben gordon , greg monroe (6)will bynum (10)pepsi center 1915523 - 44689999-03-16torontow 107 - 93 (ot)richard hamilton (24)greg monroe (10)rodney stuckey (14)the palace of auburn hills 1516624 - 44699999-03-18new yorkw 99 - 95 (ot)tayshaun prince (16)chris wilcox (12)will bynum (5)the palace of auburn hills 2207625 - 44709999-03-20atlantal 96 - 104 (ot)rodney stuckey (22)greg monroe (10)rodney stuckey (8)philips arena 1758025 - 45719999-03-23miamil 94 - 100 (ot)richard hamilton (27)greg monroe (12)rodney stuckey (6)the palace of auburn hills 2207625 - 46729999-03-25clevelandl 91 - 97 (ot)richard hamilton , tayshaun prince (15)chris wilcox , greg monroe (8)rodney stuckey (4)quicken loans arena 1990725 - 47739999-03-26indianaw 100 - 88 (ot)richard hamilton (23)greg monroe (13)richard hamilton , rodney stuckey (6)the palace of auburn hills 1921626 - 47\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 2 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE high_rebounds = (SELECT MAX(high_rebounds) FROM table_sql WHERE team = 'detroit pistons') \nAND record = '2010 - 2011';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1463.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the new york jets played the miami dolphins before denver broncos during the 1993 season\nInput Table: 1993 new york jets season\n\n\nweekdateopponentresultgame_siteattendance11993-09-05denver broncosl 26 - 20the meadowlands6813021993-09-12miami dolphinsw 24 - 14joe robbie stadium7031441993-09-26new england patriotsw 45 - 7the meadowlands6483651993-10-03philadelphia eaglesl 35 - 30the meadowlands7259361993-10-10los angeles raidersl 24 - 20los angeles memorial coliseum4162781993-10-24buffalo billsl 19 - 10the meadowlands7154191993-10-31new york giantsw 10 - 6giants stadium71659101993-11-07miami dolphinsw 27 - 10the meadowlands71306111993-11-14indianapolis coltsw 31 - 17rca dome47351121993-11-21cincinnati bengalsw 17 - 12the meadowlands64264131993-11-28new england patriotsw 6 - 0foxboro stadium42810141993-12-05indianapolis coltsl 9 - 6the meadowlands45799151993-12-11washington redskinsw 3 - 0robert f kennedy memorial stadium47970161993-12-18dallas cowboysl 28 - 7the meadowlands73233171993-12-26buffalo billsl 16 - 14rich stadium70817181994-01-02houston oilersl 24 - 0houston astrodome61040\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT week FROM table_sql WHERE opponent = 'miami dolphins') < \n             (SELECT week FROM table_sql WHERE opponent = 'denver broncos') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1873.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the us last won the solheim cup in 2009 , which was one of seven titles since 1990\nInput Table: solheim cup\n\n\nyearvenuewinning_teamscoreusa_captaineurope_captain2013-01-01colorado golf club , colorado , usaeurope18 - 10meg mallonliselotte neumann2011-01-01killeen castle golf resort , irelandeurope15 - 13rosie jonesalison nicholas2009-01-01rich harvest farms , illinois , usaunited states16 - 12beth danielalison nicholas2007-01-01halmstad gk , swedenunited states16 - 12betsy kinghelen alfredsson2005-01-01crooked stick golf club , indiana , usaunited states15\u00bd - 12\u00bdnancy lopezcatrin nilsmark2003-01-01barseb\u00e4ck golf & country club , swedeneurope17\u00bd - 10\u00bdpatty sheehancatrin nilsmark2002-01-01interlachen country club , minnesota , usaunited states15\u00bd - 12\u00bdpatty sheehandale reid2000-01-01loch lomond golf club , scotlandeurope14\u00bd - 11\u00bdpat bradleydale reid1998-01-01muirfield village , ohio , usaunited states16 - 12judy rankinpia nilsson1996-01-01st pierre golf & country club , walesunited states17 - 11judy rankinmickey walker1994-01-01the greenbrier , west virginia , usaunited states13 - 7joanne carnermickey walker1992-01-01dalmahoy country club , scotlandeurope11\u00bd - 6\u00bdkathy whitworthmickey walker1990-01-01lake nona golf & country club , florida , usaunited states11\u00bd - 4\u00bdkathy whitworthmickey walker\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT winning_team FROM table_sql WHERE year = 2009) = 'united states' \n             AND (SELECT COUNT(*) FROM table_sql WHERE year >= 1990 AND winning_team = 'united states') = 7 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1232.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the lions finished with a record of 4 wins and 8 losses\nInput Table: 1976 detroit lions season\n\n\nweekdateopponentresultattendance11976-09-12chicago bearsl 10 - 35412521976-09-19atlanta falconsw 24 - 105084031976-09-26minnesota vikingsl 10 - 97729241976-10-03green bay packersl 24 - 145504151976-10-10new england patriotsw 30 - 106017461976-10-17washington redskinsl 20 - 74590871976-10-24seattle seahawksw 41 - 146128081976-10-31green bay packersw 27 - 67499291976-11-07minnesota vikingsl 31 - 2346735101976-11-14new orleans saintsl 17 - 1642048111976-11-21chicago bearsw 14 - 1078042121976-11-25buffalo billsw 27 - 1466875131976-12-05new york giantsl 24 - 1066069141976-12-11los angeles ramsl 20 - 1773470\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE result = 'w') = 4 \n             AND (SELECT COUNT(*) FROM table_sql WHERE result = 'l') = 8 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1705.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: 83% is the total of all shot pct occurrences when the value of blank ends is 8\nInput Table: 2005 tim hortons brier\n\n\nlocaleskipwlpfpaends_wonends_lostblank_endsstolen_endsshot_pctalbertarandy ferbey92905848437986%manitobarandy dutiaume8377694744101379%nova scotiashawn adams8380604741161383%quebecjean - michel m\u00e3nard747769544081580%british columbiadeane horning6572654745181280%ontariowayne middaugh657562424610782%newfoundland and labradorbrad gushue6576694845131079%saskatchewanpat simmons656661434512980%prince edward islandrod macdonald476785415112579%northern ontariomike jakubo38648641489679%new brunswickwade blanchard385683414517878%\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT SUM(shot_pct) FROM table_sql WHERE blank_ends = 8) = 83 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1137.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: two other players apart from peter hart have fa cup goals\nInput Table: 1979 - 80 huddersfield town f.c. season\n\n\nnamepositionleague_appsleague_goalsfa_cup_appsfa_cup_goalsleague_cup_appsleague_cup_goalstotal_appstotal_goalsjim branagandf00000 (1)00 (1)0malcolm browndf4622041523david cowlingmf39 (1)10104044 (1)10peter fletcherfw30 (8)17203135 (8)18keith hanveydf3320040392peter hartmf4641140515ian holmesmf6 (4)3004110 (4)4steve kindonfw22 (1)14000022 (1)14mick laverickmf4542040514bernard purdiedf18 (4)0200020 (4)0andy rankingk2400000240ian robinsfw452520425127fred robinsondf3012040361tommy smithfw00001010brian stantonmf4192000439alan starlinggk2202040280dave suttondf4662041527chris toppingdf1302000150\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE fa_cup_goals > 0 AND name != 'peter hart') >= 2 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-280.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the toronto blue jays played the angels three times in may during the 1991 season\nInput Table: 1991 toronto blue jays season\n\n\ndateopponentscorelossattendancerecord9999-05-01rangers3 - 0key (4 - 1)3343912 - 109999-05-02royals3 - 1appier (1 - 4)2289613 - 109999-05-03royals5 - 1davis (2 - 2)2080914 - 109999-05-04royals6 - 5boucher (0 - 2)2262814 - 119999-05-05royals3 - 0gordon (1 - 2)2258815 - 119999-05-07rangers3 - 2key (4 - 2)4462215 - 129999-05-08rangers4 - 2ryan (3 - 3)4321116 - 129999-05-09white sox2 - 0p\u00e3rez (1 - 2)4723617 - 129999-05-10white sox5 - 3 (12)fraser (0 - 1)5019817 - 139999-05-11white sox5 - 2hough (0 - 2)5020618 - 139999-05-12white sox4 - 2hibbard (2 - 1)5010819 - 139999-05-13royals4 - 2davis (2 - 4)4427520 - 139999-05-14royals4 - 1gubicza (0 - 1)4335721 - 139999-05-15royals6 - 4boucher (0 - 3)5011321 - 149999-05-17white sox5 - 3timlin (3 - 1)3009521 - 159999-05-18white sox9 - 2hibbard (2 - 2)3486122 - 159999-05-19white sox5 - 4timlin (3 - 2)4101522 - 169999-05-20athletics1 - 0welch (4 - 3)2463123 - 169999-05-21athletics11 - 7dressendorfer (3 - 3)2273824 - 169999-05-22athletics2 - 1stieb (4 - 3)3402824 - 179999-05-24angels3 - 2finley (7 - 2)2640825 - 179999-05-25angels5 - 0stottlemyre (5 - 1)3673225 - 189999-05-26angels6 - 2wells (5 - 4)4530725 - 199999-05-28athletics8 - 4acker (1 - 2)5029925 - 209999-05-29athletics8 - 3slusarski (1 - 2)5026226 - 209999-05-30athletics8 - 6ward (0 - 2)5027126 - 219999-05-31angels5 - 1langston (6 - 2)5025227 - 21\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 3 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE opponent = 'angels' \nAND date LIKE '9999-05%' \nAND record LIKE '% - %';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1901.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: jerry mitchell won two tony awards\nInput Table: la cage aux folles (musical)\n\n\nyearawardcategorynomineeresult2005tony awardbest revival of a musicalbest revival of a musicalwon2005tony awardbest performance by a leading actor in a musicalgary beachnominated2005tony awardbest choreographyjerry mitchellwon2005tony awardbest costume designwilliam ivey longnominated2005drama desk awardoutstanding revival of a musicaloutstanding revival of a musicalwon2005drama desk awardoutstanding choreographyjerry mitchellwon2005drama desk awardoutstanding costume designwilliam ivey longnominated\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 2 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE award = 'tony award' \nAND nominee = 'jerry mitchell' \nAND result = 'won';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1424.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: pierre lamine beat shinji someya by more than a point\nInput Table: 1976 world junior figure skating championships\n\n\nranknamenationsp_+_fspointsplaces1mark cockerellunited states1172.4211.02takashi murajapan2165.724.03brian pockarcanada3166.6223.04norbert schrammwest germany4159.840.05andrew bestwickunited kingdom5158.148.06stephan brilwest germany7155.7257.07patrice macrezfrance6151.7671.08pierre laminefrance8150.579.09shinji someyajapan10150.3474.510jozef sabov\u010d\u00edkczechoslovakia9148.8887.011daniel fuererswitzerland13146.1892.512gerald schranzaustria11143.04102.013helmut kristofics - binderaustria15137.32123.014michael pasfieldaustralia12136.6119.015francis demarteaubelgium14131.02140.016adrian vasileromania16127.74143.017miljan begovicyugoslavia17127.3143.018jeremy dowsonsouth africa18114.98166.019marc franquetbelgium19114.38167.0\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT points FROM table_sql WHERE name = 'pierre lamine') - \n             (SELECT points FROM table_sql WHERE name = 'shinji someya') > 1 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-829.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: in the 1981 open championship the winning score was 72 , with two players tying for this score\nInput Table: 1981 open championship\n\n\nplaceplayercountryscoreto_part1vicente fern\u00e3\u00a1ndezargentina70et1nick jobengland70et3isao aokijapan71+ 1t3david grahamaustralia71+ 1t3tony jacklinengland71+ 1t3johnny millerunited states71+ 1t3simon owennew zealand71+ 1t3hal sutton (a)united states71+ 1t9howard clarkengland72+ 2t9ben crenshawunited states72+ 2t9david jaggerengland72+ 2t9mark jamesengland72+ 2t9greg normanaustralia72+ 2t9arnold palmerunited states72+ 2t9bill rogersunited states72+ 2t9sam torrancescotland72+ 2\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 2 AND score = 72 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE score = 72;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1380.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there is 1 mideast rank and 1 asian rank\nInput Table: list of asian and pacific countries by gdp (ppp)\n\n\nrank_mideastrank_asiarank_worldcountry2011_gdp_(ppp)_billions_of_usd1617iran930.2362923saudi arabia677.66331848united arab emirates261.18941950israel235.44652155qatar181.91262258kuwait150.00272360iraq127.34882666syria107.80392976oman81.005103083yemen63.344113184lebanon61.738123597jordan36.8971337104bahrain30.889\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 1 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE rank_mideast IS NOT NULL \nAND rank_asia IS NOT NULL;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1328.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: robert bauman is the democratic incumbent for maryland district 7\nInput Table: united states house of representatives elections , 1974\n\n\ndistrictincumbentpartyfirst_electedresultcandidatesmaryland 1robert baumanrepublican1973-01-01re - electedrobert bauman (r) 53.0% thomas j hatem (d) 47.0%maryland 2clarence longdemocratic1962-01-01re - electedclarence long (d) 77.1% john m seney (r) 22.9%maryland 4marjorie holtrepublican1972-01-01re - electedmarjorie holt (r) 58.1% fred l wineland (d) 41.9%maryland 6goodloe byrondemocratic1970-01-01re - electedgoodloe byron (d) 73.7% elton r wampler (r) 26.3%maryland 7parren mitchelldemocratic1970-01-01re - electedparren mitchell (d) unopposed\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE district = 'maryland 7' \nAND incumbent = 'robert bauman' \nAND party = 'democratic';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1234.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the chicago bears defeated the lions in both games they played\nInput Table: 1976 detroit lions season\n\n\nweekdateopponentresultattendance11976-09-12chicago bearsl 10 - 35412521976-09-19atlanta falconsw 24 - 105084031976-09-26minnesota vikingsl 10 - 97729241976-10-03green bay packersl 24 - 145504151976-10-10new england patriotsw 30 - 106017461976-10-17washington redskinsl 20 - 74590871976-10-24seattle seahawksw 41 - 146128081976-10-31green bay packersw 27 - 67499291976-11-07minnesota vikingsl 31 - 2346735101976-11-14new orleans saintsl 17 - 1642048111976-11-21chicago bearsw 14 - 1078042121976-11-25buffalo billsw 27 - 1466875131976-12-05new york giantsl 24 - 1066069141976-12-11los angeles ramsl 20 - 1773470\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 2 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE opponent = 'chicago bears' \nAND result LIKE 'w%';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-289.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: rio ave 's head coach was carlos brito and club sporting cp has carlos brito as well\nInput Table: 2004 - 05 primeira liga\n\n\nclubhead_coachcitystadium2003_-_2004_seasonacad\u00e9mica de coimbrajo\u00e3o carlos pereiracoimbraest\u00e1dio cidade de coimbra13th in the ligabelenensescarlos carvalhallisbonest\u00e1dio do restelo15th in the ligabenficagiovanni trapattonilisbonest\u00e1dio da luz2nd in the ligaboavistajaime pachecoportoest\u00e1dio do bessa - s\u00e9culo xxi8th in the ligabragajesualdo ferreirabragaest\u00e1dio municipal de braga - axa5th in the ligaestoril - praialitosestorilest\u00e1dio ant\u00f3nio coimbra da mota1st in the liga de honragil vicentelu\u00eds camposbarcelosest\u00e1dio cidade de barcelos12th in the ligauni\u00e3o de leiriav\u00edtor pontesleiriaest\u00e1dio dr magalh\u00e3es pessoa10th in the ligapenafielmanuel fernandespenafielest\u00e1dio municipal 25 de abril3rd in the liga de honramar\u00edtimomanuel cajudafunchalest\u00e1dio dos barreiros6th in the liganacionalcasemiro miorfunchalest\u00e1dio da madeira4th in the ligabeira - marmick wadsworthaveiroest\u00e1dio municipal de aveiro11th in the ligamoreirensev\u00edtor oliveiraguimar\u00e3esest\u00e1dio do moreirense9th in the ligaportoluigi delneriportoest\u00e1dio do drag\u00e3o1st in the ligasporting cpjos\u00e9 peseirolisbonest\u00e1dio jos\u00e9 alvalade - s\u00e9culo xxi3rd in the ligario avecarlos britovila do condeest\u00e1dio dos arcos7th in the ligavit\u00f3ria de guimar\u00e3esmanuel machadoguimar\u00e3esest\u00e1dio d afonso henriques14th in the ligavit\u00f3ria de set\u00fabaljos\u00e9 couceiroset\u00fabalest\u00e1dio do bonfim2nd in the liga de honra\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT head_coach FROM table_sql WHERE club = 'rio ave') = \n             (SELECT head_coach FROM table_sql WHERE club = 'sporting cp') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-499.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: track 23 has a title : just a little bit\nInput Table: walk a mile in my shoes : the essential '70s masters\n\n\ntrackrecordedoriginal_issuesong_titletime11971-05-15wonderful world of christmasmerry christmas , baby9999-01-0121971-05-20previously unreleasedi shall be released9999-01-0131971-05-16elvisdon't think twice , it 's all right9999-01-0141971-05-19elvisit 's still here9999-01-0151971-05-19elvisi'll take you home again , kathleen9999-01-0161971-05-19elvisi will be true9999-01-0171971-06-10previously unreleasedmy way9999-01-0181972-03-27previously unreleasedfor the good times9999-01-0191973-07-22raised on rockjust a little bit9999-01-01101973-07-21previously unreleasedit 's diff 'rent now9999-01-01111973-09-23raised on rockare you sincere9999-01-01121973-12-10good timesi got a feelin' in my body9999-01-01131973-12-11promised landyou asked me to9999-01-01141973-12-13good timesgood time charlie 's got the blues9999-01-01151973-12-14good timestalk about the good times9999-01-01161975-03-11previously unreleasedtiger man9999-01-01171975-03-10todayi can help9999-01-01181975-03-11todaysusan when she tried9999-01-01191975-03-11todayshake a hand9999-01-01201976-02-01unreleased alternate takeshe thinks i still care9999-01-01211976-02-05from elvis presley boulevarddanny boy9999-01-01221976-02-01from elvis presley boulevardlove coming down9999-01-01231976-10-30moody bluehe'll have to go9999-01-01\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE track = 23 \nAND song_title = 'just a little bit';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-903.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: jim laker played in more matches than any of the australian players\nInput Table: 1948 ashes series\n\n\nplayerteammatcheswicketsaveragebest_bowlingray lindwallaustralia52719.626 / 20bill johnstonaustralia52723.335 / 36alec bedserengland51838.224 / 81keith milleraustralia51323.154 / 125ernie toshackaustralia41133.095 / 40norman yardleyengland5922.662 / 32jim lakerengland3952.444 / 138\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT matches FROM table_sql WHERE player = 'jim laker') > \n             (SELECT MAX(matches) FROM table_sql WHERE team = 'australia') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-82.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: manchester united has been 2nd in league position since 17 november 2005\nInput Table: 2005 - 06 manchester united f.c. season\n\n\ndateopponentsh_/_aresult_f_-_aattendanceleague_position2005-08-13evertona2 - 0386104th2005-08-20aston villah1 - 0679344th2005-08-28newcastle uniteda2 - 0523274th2005-09-10manchester cityh1 - 1678394th2005-09-18liverpoola0 - 0449173rd2005-09-24blackburn roversh1 - 2677656th2005-10-01fulhama3 - 2218624th2005-10-15sunderlanda3 - 1390853rd2005-10-22tottenham hotspurh1 - 1678565th2005-10-29middlesbrougha1 - 4305797th2005-11-06chelseah1 - 0678644th2005-11-19charlton athletica3 - 1267303rd2005-11-27west ham uniteda2 - 1347552nd2005-12-03portsmouthh3 - 0676842nd2005-12-11evertonh1 - 1678313rd2005-12-14wigan athletich4 - 0677932nd2005-12-17aston villaa2 - 0371282nd2005-12-26west bromwich albionh3 - 0679722nd2005-12-28birmingham citya2 - 2284592nd2005-12-31bolton wanderersh4 - 1678582nd2006-01-03arsenala0 - 0383132nd2006-01-14manchester citya1 - 3471922nd2006-01-22liverpoolh1 - 0678742nd2006-02-01blackburn roversa3 - 4254842nd2006-02-04fulhamh4 - 2678442nd2006-02-11portsmoutha3 - 1202062nd2006-03-06wigan athletica2 - 1235242nd2006-03-12newcastle unitedh2 - 0678582nd2006-03-18west bromwich albiona2 - 1276232nd2006-03-26birmingham cityh3 - 0690702nd2006-03-29west ham unitedh1 - 0695222nd2006-04-01bolton wanderersa2 - 1277182nd2006-04-09arsenalh2 - 0709082nd2006-04-14sunderlandh0 - 0725192nd2006-04-17tottenham hotspura2 - 1361412nd2006-04-29chelseaa0 - 3422192nd2006-05-01middlesbroughh0 - 0695312nd2006-05-07charlton athletich4 - 0730062nd\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT league_position FROM table_sql WHERE date >= '2005-11-17') = '2nd' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-221.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the volume 's 2 , 4 , and 5 have 2 discs and 3 episodes\nInput Table: none\n\n\nvolumediscsepisodesregion_1region_2region_41142006-01-312007-02-192007-03-152142006-03-282007-06-042007-07-053142006-05-302007-09-032008-03-134142006-07-182008-02-182008-06-195142006-09-192008-05-262009-03-05\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE (volume = 2 OR volume = 4 OR volume = 5) \nAND discs = 2 \nAND episodes = 3;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1220.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: guillaume gillet scored three times as much as each of the other two players in the uefa champions league tournament\nInput Table: 2008 - 09 r.s.c. anderlecht season\n\n\nplayerleaguetitle_playoffsuper_cuptotalmbark boussoufa110011tom de sutter9009guillaume gillet8009marcin wasilewski8008jonathan legear5107nicol\u00e1s frutos6006thomas chatelle4004roland juh\u00e1sz4004stanislav vl\u010dek4004lucas biglia2003dmitri bulykin3003jan pol\u00e1k2003mat\u00edas su\u00e1rez1013jelle van damme3003oleksandr iakovenko2002hern\u00e1n losada1002v\u00edctor bern\u00e1rdez1001bart goor1001nemanja rni\u01070001\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT total FROM table_sql WHERE player = 'guillaume gillet' AND league = 'uefa champions league') = \n             3 * (SELECT total FROM table_sql WHERE player = 'mbark boussoufa' AND league = 'uefa champions league') \n             AND (SELECT total FROM table_sql WHERE player = 'guillaume gillet' AND league = 'uefa champions league') = \n             3 * (SELECT total FROM table_sql WHERE player = 'tom de sutter' AND league = 'uefa champions league') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1686.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: alabama was the opponent when the attendance was 81079\nInput Table: east carolina pirates football , 1990 - 99\n\n\ndateopponentsiteresultattendance9999-09-05virginia techlane stadium blacksburg , val3 - 38481349999-09-12chattanoogadowdy - ficklen stadium greenville , ncw31 - 0340289999-09-19ohiopeden stadium athens , ohw21 - 14191869999-10-03armydowdy - ficklen stadium greenville , ncw30 - 25406079999-10-10uabdowdy - ficklen stadium greenville , ncw26 - 7310029999-10-17alabamalegion field birmingham , all22 - 23800799999-10-24southern missmm roberts stadium hattiesburg , msl7 - 41240209999-10-31houstondowdy - ficklen stadium greenville , ncl31 - 34268219999-11-05cincinnatinippert stadium cincinnati , ohw24 - 21190989999-11-14louisvilledowdy - ficklen stadium greenville , ncl45 - 63262589999-11-21memphisliberty bowl memorial stadium memphis , tnw34 - 31160529999-01-01all times are in easternall times are in easternall times are in easternall times are in eastern\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT opponent FROM table_sql WHERE attendance = 81079) = 'alabama' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1462.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the new york jets took three more wins over losses during the 1993 season\nInput Table: 1993 new york jets season\n\n\nweekdateopponentresultgame_siteattendance11993-09-05denver broncosl 26 - 20the meadowlands6813021993-09-12miami dolphinsw 24 - 14joe robbie stadium7031441993-09-26new england patriotsw 45 - 7the meadowlands6483651993-10-03philadelphia eaglesl 35 - 30the meadowlands7259361993-10-10los angeles raidersl 24 - 20los angeles memorial coliseum4162781993-10-24buffalo billsl 19 - 10the meadowlands7154191993-10-31new york giantsw 10 - 6giants stadium71659101993-11-07miami dolphinsw 27 - 10the meadowlands71306111993-11-14indianapolis coltsw 31 - 17rca dome47351121993-11-21cincinnati bengalsw 17 - 12the meadowlands64264131993-11-28new england patriotsw 6 - 0foxboro stadium42810141993-12-05indianapolis coltsl 9 - 6the meadowlands45799151993-12-11washington redskinsw 3 - 0robert f kennedy memorial stadium47970161993-12-18dallas cowboysl 28 - 7the meadowlands73233171993-12-26buffalo billsl 16 - 14rich stadium70817181994-01-02houston oilersl 24 - 0houston astrodome61040\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE result = 'w') - (SELECT COUNT(*) FROM table_sql WHERE result = 'l') = 3 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1382.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: ukraine has the most gold medals\nInput Table: 2006 - 07 isu junior grand prix\n\n\nranknationgoldsilverbronzetotal1united states24128442russia556163canada127104japan14385estonia12145italy03146south korea00337france01127ukraine01128spain01018china01018czech republic0011\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT gold FROM table_sql WHERE nation = 'ukraine') > \n             (SELECT gold FROM table_sql WHERE nation != 'ukraine') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-228.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: before 2009 was the only year that reasons to be pretty had a nominee at the drama desk award ceremony\nInput Table: reasons to be pretty\n\n\nyearaward_ceremonycategorynomineeresult2009tony awardbest playneil labutenominated2009tony awardbest performance by a leading actor in a playthomas sadoskinominated2009tony awardbest performance by a featured actress in a playmarin irelandnominated2009drama desk awardoutstanding playoutstanding playnominated2009drama desk awardoutstanding actor in a playthomas sadoskinominated2009drama desk awardoutstanding director of a playterry kinneynominated2009theatre world awardtheatre world awardmarin irelandwon\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) > 0 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE year < 2009 \nAND award_ceremony = 'drama desk award';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1783.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there was a tfr of 2.45 in the period where the imr was 43\nInput Table: none\n\n\nperiodlive_births_per_yeardeaths_per_yearnatural_change_per_yearcbrcdrnctfrimrlife_expectancy_totallife_expectancy_maleslife_expectancy_females1950-01-01 - 1955-01-012 572 000900 0001 672 00044.115.528.66.1513550.949.252.61955-01-01 - 1960-01-012 918 000947 0001 971 00043.214.029.16.1512253.351.555.21960-01-01 - 1965-01-013 303 000986 0002 317 00042.212.629.66.1510955.753.857.69999-01-01 - 1970-01-013 330 000998 0002 332 00037.011.125.95.3810057.655.759.61970-01-01 - 1975-01-013 441 0001 014 0002 427 00033.79.923.84.729159.557.361.81975-01-01 - 1980-01-013 741 0001 043 0002 698 00032.59.023.54.317961.559.263.91980-01-01 - 1985-01-013 974 0001 064 0002 910 00030.88.222.63.86363.460.466.81985-01-01 - 1990-01-013 757 0001 055 0002 702 00026.37.418.93.15265.361.969.11990-01-01 - 1995-01-013 519 0001 058 0002 461 00022.66.815.82.64367.363.671.21995-01-01 - 2000-01-013 624 0001 086 0002 538 00021.56.515.12.453469.365.573.32000-01-01 - 2005-01-013 572 0001 147 0002 425 00019.86.413.42.252770.967.274.8\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT tfr FROM table_sql WHERE imr = 43) = 2.45 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-381.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: gpl is the license for rygel\nInput Table: comparison of upnp av media servers\n\n\nnamelicenseos_xunix_-_likewindowsweb_interface360 media servergplnoyesyesyesavia media playerpropnonononobrisamitpartialpartialnoyescoherencemitpartialpartialpartialyesdivxpropyesnoyesnoelgato eyeconnectpropyesnononofoobar2000propnonoyesnofuppesgplyesyesyesyesgeexbox usharegplnoyesnoyesgmediaservergplnoyesnonohome media centergplv2nonoyesyesisedora media serverpropyesnoyesyesjriver media centerpropnonoyesyeskooraroo mediapropyesyesyesyeslximediagplyesyesyesnomajestic media serverpropyesnononomediatombgplpartialyesnoyesminidlnagpl / bsdpartialyesyespartialmezzmopropnonoyesnomyihomepropyesyesyesnomythtv with upnpgplyesyesnoyesnullriver medialinkpropyesnononoplayonpropnonoyesyesplexpropyesyesyesyesps3 media servergplyesyesyesyespymedsmitpartialpartialnonorygellgplv2noyesnonorivetpropyesnononoserviiopropyesyesyesyessimplecenter premiumpropnonoyesyesskiftapropyesyesyesnosongbirdgplv2yesnoyesnotvblepropnonoyesnotversitypropnonoyesyestvmobilipropyesyesyesyestvsharepropnonoyesnotwonkyserverpropyesyesyesyesuniversal media servergplyesyesyesyeswindows media connectpropnonoyesnowild media serverpropyesyesyesyesxbmc media centergplyesyesyesyesxupnpdgplv2noyesnoyesyazsoft playbackpropyesnonononamelicenseos xunix - likewindowsweb interface\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN license = 'gpl' AND name = 'rygel' THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-138.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the chicago black hawks are the only opponent with 63 points\nInput Table: none\n\n\ngamemarchopponentscorerecordpoints639999-01-04detroit red wings2 - 224 - 28 - 1159649999-01-06california golden seals4 - 424 - 28 - 1260659999-01-07minnesota north stars1 - 324 - 29 - 1260669999-01-10pittsburgh penguins2 - 224 - 29 - 1361679999-01-12new york rangers2 - 724 - 30 - 1361689999-01-13toronto maple leafs3 - 225 - 30 - 1363699999-01-18new york rangers2 - 126 - 30 - 1365709999-01-20boston bruins3 - 526 - 31 - 1365719999-01-21toronto maple leafs1 - 126 - 31 - 1466729999-01-24montreal canadiens3 - 526 - 32 - 1466739999-01-25minnesota north stars2 - 226 - 32 - 1567749999-01-27chicago black hawks1 - 326 - 33 - 1567759999-01-28pittsburgh penguins3 - 127 - 33 - 1569\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 1 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE points = 63 \nAND opponent = 'chicago black hawks';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-413.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the least laps for christian danner when the grid is 5 , is 43\nInput Table: 1987 hungarian grand prix\n\n\ndriverconstructorlapstime_/_retiredgridnelson piquetwilliams - honda761:59:26.7933ayrton sennalotus - honda76+ 37.7276alain prostmclaren - tag76+ 1:27.4564thierry boutsenbenetton - ford75+ 1 lap7riccardo patresebrabham - bmw75+ 1 lap10derek warwickarrows - megatron74+ 2 laps9jonathan palmertyrrell - ford74+ 2 laps16eddie cheeverarrows - megatron74+ 2 laps11philippe streifftyrrell - ford74+ 2 laps14ivan capellimarch - ford74+ 2 laps18alessandro nanniniminardi - motori moderni73+ 3 laps20piercarlo ghinzaniligier - megatron73+ 3 laps25pascal fabreags - ford71+ 5 laps26nigel mansellwilliams - honda70wheel1alex caffiosella - alfa romeo64fuel system21ren\u00e9 arnouxligier - megatron57electrical19philippe alliotlola - ford48accident15martin brundlezakspeed45turbo22michele alboretoferrari43engine5andrea de cesarisbrabham - bmw43gearbox13stefan johanssonmclaren - tag14gearbox8teo fabibenetton - ford14gearbox12adri\u00e1n camposminardi - motori moderni14spun off24gerhard bergerferrari13differential2christian dannerzakspeed3engine23satoru nakajimalotus - honda1drive - shaft17\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT laps FROM table_sql WHERE driver = 'christian danner' AND grid = 5) = 43 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1953.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the boston celtics lost more games than they won in the 1984 - 1985 season\nInput Table: 1984 - 85 boston celtics season\n\n\ngamedateopponentscorelocationrecord339999-01-02new jersey nets110 - 95brendan byrne arena27 - 6349999-01-04new york knicks105 - 94boston garden28 - 6359999-01-07new york knicks108 - 97madison square garden29 - 6369999-01-09chicago bulls111 - 108boston garden30 - 6379999-01-11washington bullets103 - 101boston garden31 - 6389999-01-12atlanta hawks119 - 111the omni32 - 6399999-01-16los angeles lakers104 - 102boston garden33 - 6409999-01-18indiana pacers86 - 91market square arena33 - 7419999-01-20philadelphia 76ers113 - 97boston garden34 - 7429999-01-23seattle supersonics97 - 107boston garden34 - 8439999-01-25indiana pacers125 - 94boston garden35 - 8449999-01-27portland trail blazers128 - 127boston garden36 - 8459999-01-29detroit pistons131 - 130hartford civic center37 - 8469999-01-30philadelphia 76ers104 - 122the spectrum37 - 9\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE record LIKE '%-%' AND SUBSTR(record, 1, INSTR(record, '-') - 1) < SUBSTR(record, INSTR(record, '-') + 1)) > \n             (SELECT COUNT(*) FROM table_sql WHERE record LIKE '%-%' AND SUBSTR(record, 1, INSTR(record, '-') - 1) > SUBSTR(record, INSTR(record, '-') + 1)) \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1827.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: richmond , with the home team score of 9.10 (64) , was away team melbourne 's home team opponent\nInput Table: 1943 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddatehawthorn13.10 (88)south melbourne7.14 (56)glenferrie oval150001943-08-21collingwood16.17 (113)fitzroy9.9 (63)victoria park65001943-08-21carlton15.23 (113)north melbourne7.5 (47)princes park80001943-08-21richmond15.19 (109)melbourne12.13 (85)punt road oval90001943-08-21footscray9.10 (64)essendon6.15 (51)western oval60001943-08-21\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT home_team_score FROM table_sql WHERE home_team = 'richmond' AND away_team = 'melbourne') = '9.10 (64)' \n             AND (SELECT venue FROM table_sql WHERE home_team = 'richmond' AND away_team = 'melbourne') = 'punt road oval' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-937.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the game on february 4th had new jersey as the home team\nInput Table: none\n\n\ndatevisitorscorehomerecord9999-02-03ny islanders7 - 2new jersey11 - 32 - 119999-02-05new jersey4 - 5washington11 - 33 - 119999-02-06vancouver4 - 4new jersey11 - 33 - 129999-02-09new jersey4 - 5chicago11 - 34 - 1201-02-12new jersey1 - 5st louis11 - 35 - 1201-02-15minnesota3 - 2new jersey11 - 36 - 129999-02-20new jersey0 - 3philadelphia11 - 37 - 1201-02-21buffalo4 - 4new jersey11 - 37 - 139999-02-24detroit1 - 4new jersey12 - 37 - 139999-02-26new jersey4 - 5pittsburgh12 - 38 - 139999-02-27new jersey2 - 6buffalo12 - 39 - 13\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE date = '9999-02-04' \nAND home = 'new jersey';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-311.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: 5 was the tie no before the away team was woking\nInput Table: 1990 - 91 fa cup\n\n\ntie_nohome_teamscoreaway_teamdate1liverpool2 - 2brighton & hove albion1991-01-26replaybrighton & hove albion2 - 3liverpool1991-01-302notts county2 - 0oldham athletic1991-01-263crewe alexandra1 - 0rotherham united1991-01-264luton town1 - 1west ham united1991-01-26replaywest ham united5 - 0luton town1991-01-305woking0 - 1everton1991-01-276shrewsbury town1 - 0wimbledon1991-01-267newcastle united2 - 2nottingham forest1991-02-13replaynottingham forest3 - 0newcastle united1991-02-188tottenham hotspur4 - 2oxford united1991-01-269coventry city1 - 1southampton1991-01-26replaysouthampton2 - 0coventry city1991-01-2910portsmouth5 - 1bournemouth1991-01-2611manchester united1 - 0bolton wanderers1991-01-2612norwich city3 - 1swindon town1991-01-2613millwall4 - 4sheffield wednesday1991-01-26replaysheffield wednesday2 - 0millwall1991-01-3014port vale1 - 2manchester city1991-01-2615arsenal0 - 0leeds united1991-01-27replayleeds united1 - 1arsenal1991-01-30replayarsenal0 - 0leeds united1991-02-13replayleeds united1 - 2arsenal1991-02-1616cambridge united2 - 0middlesbrough1991-01-26\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT tie_no FROM table_sql WHERE away_team = 'woking') = 5 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1758.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the 49ers lost two out of fourteen games int eh 1947 season\nInput Table: 1947 san francisco 49ers season\n\n\nweekdateopponentresultscorerecord11947-08-31brooklyn dodgersw23 - 71 - 021947-09-07los angeles donsw17 - 142 - 031947-09-14baltimore coltsw14 - 73 - 041947-09-21new york yankeesl21 - 163 - 151947-09-28buffalo billsw41 - 244 - 161947-10-05baltimore coltst28 - 284 - 1 - 171947-10-12chicago rocketsw42 - 285 - 1 - 181947-10-26cleveland brownsl14 - 75 - 2 - 191947-11-02los angeles donsw26 - 166 - 2 - 1101947-11-09new york yankeesl24 - 166 - 3 - 1111947-11-16cleveland brownsl37 - 146 - 4 - 1121947-11-21chicago rocketsw41 - 167 - 4 - 1131947-11-27brooklyn dodgersw21 - 78 - 4 - 1141947-12-07buffalo billst21 - 218 - 4 - 2\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE result = 'l') = 2 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1185.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the set 2 of 16 - 25 was on 15 jul\nInput Table: 2002 fivb women 's volleyball world championship qualification\n\n\ndatescoreset_1set_2set_3total9999-07-130 - 39 - 2517 - 2512 - 2538 - 759999-07-133 - 025 - 2325 - 1025 - 1375 - 469999-07-143 - 025 - 1325 - 1025 - 1175 - 349999-07-141 - 325 - 2216 - 2515 - 2570 - 979999-07-150 - 316 - 2519 - 2518 - 2553 - 759999-07-153 - 025 - 2325 - 1625 - 1475 - 53\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE set_2 = '16 - 25' \nAND date = '9999-07-15';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-509.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the surface for the opponent roger federer was clay after july 13 , 2003\nInput Table: ji\u0159\u00ed nov\u00e1k\n\n\ndatetournamentsurfaceopponentscore1996-01-14auckland , new zealandhardbrett steven6 - 4 , 6 - 41998-11-01mexico city , mexicoclayxavier malisse6 - 3 , 6 - 32001-05-06munich , germanyclayantony dupuis6 - 4 , 7 - 52001-07-15gstaad , switzerlandclayjuan carlos ferrero6 - 1 , 6 - 7 (5 - 7) , 7 - 52003-07-13gstaad , switzerlandclayroger federer5 - 7 , 6 - 3 , 6 - 3 , 1 - 6 , 6 - 32004-10-10tokyo , japanhardtaylor dent5 - 7 , 6 - 1 , 6 - 32004-11-03basel , switzerlandcarpet (i)david nalbandian5 - 7 , 6 - 3 , 6 - 4 , 1 - 6 , 6 - 2\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT surface FROM table_sql WHERE opponent = 'roger federer' AND date > '2003-07-13') = 'clay' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1736.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the buffalo bills played before week 7 in tulane stadium at the dallas cowboys\nInput Table: 1970 new york giants season\n\n\nweekdateopponentresultgame_siteattendance11970-09-19chicago bearsl 24 - 16yankee stadium6293621970-09-27dallas cowboysl 28 - 10cotton bowl5723631970-10-04new orleans saintsl 14 - 10tulane stadium6912641970-10-11philadelphia eaglesw 30 - 23yankee stadium6282051970-10-18boston patriotsw 16 - 0harvard stadium3909161970-10-25st louis cardinalsw 35 - 17yankee stadium6298471970-11-01new york jetsw 22 - 10shea stadium6390381970-11-08dallas cowboysw 23 - 20yankee stadium6293891970-11-15washington redskinsw 35 - 33yankee stadium62915101970-11-23philadelphia eaglesl 23 - 20franklin field59117111970-11-29washington redskinsw 27 - 24robert f kennedy memorial stadium50415121970-12-06buffalo billsw 20 - 6yankee stadium62870131970-12-13st louis cardinalsw 34 - 17busch memorial stadium50845141970-12-20los angeles ramsl 31 - 3yankee stadium62870\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE opponent = 'buffalo bills' AND week < 7 AND game_site = 'tulane stadium') > 0 \n             AND (SELECT COUNT(*) FROM table_sql WHERE opponent = 'dallas cowboys' AND week < 7 AND game_site = 'tulane stadium') > 0 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1299.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: robert garrett and james connolly both represented different countries\nInput Table: list of multiple olympic medalists\n\n\nmedal_countdateathletenationsportrecord_medal_event11896-04-06james connollyunited statesathleticstriple jump g11896-04-06alexandre tuff\u00e8refranceathleticstriple jump s11896-04-06ioannis persakisgreeceathleticstriple jump b11896-04-06robert garrettunited statesathleticsdiscus g11896-04-06panagiotis paraskevopoulosgreeceathleticsdiscus s11896-04-06sotirios versisgreeceathleticsdiscus b21896-04-07robert garrettunited statesathleticslong jump s21896-04-07james connollyunited statesathleticslong jump b31896-04-07robert garrettunited statesathleticsshot put g31896-04-09carl schuhmanngermanygymnasticsvault g31896-04-09hermann weing\u00e4rtnergermanygymnasticsvault b41896-04-09hermann weing\u00e4rtnergermanygymnasticspommel horse s51896-04-09hermann weing\u00e4rtnergermanygymnasticsrings s61896-04-09hermann weing\u00e4rtnergermanygymnasticshorizontal bar g61900-07-16robert garrettunited statesathleticsstanding triple jump b61904-09-03ray ewryunited statesathleticsstanding triple jump g71908-07-20ray ewryunited statesathleticsstanding long jump g81908-07-23ray ewryunited statesathleticsstanding high jump g81920-07-29carl osburnunited statesshootingteam 300 m / 600 m military rifle , prone g91920-07-30carl osburnunited statesshooting300 m military rifle , standing g101920-07-31carl osburnunited statesshootingteam free rifle g111924-06-27carl osburnunited statesshooting600 m free rifle s111928-08-03paavo nurmifinlandathletics5000 m s121928-08-04paavo nurmifinlandathletics3000 m steeplechase s121960-09-02edoardo mangiarottiitalyfencingteam foil s131960-09-09edoardo mangiarottiitalyfencingteam \u00e9p\u00e9e g131964-10-21larisa latyninasoviet uniongymnasticsteam g141964-10-21larisa latyninasoviet uniongymnasticsall - around s151964-10-22larisa latyninasoviet uniongymnasticsvault s161964-10-22larisa latyninasoviet uniongymnasticsuneven bars b171964-10-23larisa latyninasoviet uniongymnasticsbalance beam b181964-10-23larisa latyninasoviet uniongymnasticsfloor exercise g182012-07-31michael phelpsunited statesswimming200 m butterfly s192012-07-31michael phelpsunited statesswimming4 x 200 m freestyle g202012-08-02michael phelpsunited statesswimming200 m individual medley g212012-08-03michael phelpsunited statesswimming100 m butterfly g222012-08-04michael phelpsunited statesswimming4 100 m medley relay g\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(DISTINCT nation) FROM table_sql WHERE athlete = 'robert garrett') > 1 \n             AND (SELECT COUNT(DISTINCT nation) FROM table_sql WHERE athlete = 'james connolly') > 1 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-220.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the volume that has 1 disc , 4 episodes , and a region 1 of may 30 , 2006 is volume 5\nInput Table: none\n\n\nvolumediscsepisodesregion_1region_2region_41142006-01-312007-02-192007-03-152142006-03-282007-06-042007-07-053142006-05-302007-09-032008-03-134142006-07-182008-02-182008-06-195142006-09-192008-05-262009-03-05\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN volume = 5 AND discs = 1 AND episodes = 4 AND region_1 = '2006-05-30' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1687.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: uab was the opponent when the attendance was 33002\nInput Table: east carolina pirates football , 1990 - 99\n\n\ndateopponentsiteresultattendance9999-09-05virginia techlane stadium blacksburg , val3 - 38481349999-09-12chattanoogadowdy - ficklen stadium greenville , ncw31 - 0340289999-09-19ohiopeden stadium athens , ohw21 - 14191869999-10-03armydowdy - ficklen stadium greenville , ncw30 - 25406079999-10-10uabdowdy - ficklen stadium greenville , ncw26 - 7310029999-10-17alabamalegion field birmingham , all22 - 23800799999-10-24southern missmm roberts stadium hattiesburg , msl7 - 41240209999-10-31houstondowdy - ficklen stadium greenville , ncl31 - 34268219999-11-05cincinnatinippert stadium cincinnati , ohw24 - 21190989999-11-14louisvilledowdy - ficklen stadium greenville , ncl45 - 63262589999-11-21memphisliberty bowl memorial stadium memphis , tnw34 - 31160529999-01-01all times are in easternall times are in easternall times are in easternall times are in eastern\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE opponent = 'uab' \nAND attendance = 33002;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-687.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: justin leonard score less than 212 which put him tied for the 8th place\nInput Table: 2002 u.s. open (golf)\n\n\nplaceplayercountryscoreto_par1tiger woodsunited states67 + 68 + 70 = 205- 52sergio garc\u00edaspain68 + 74 + 67 = 209- 1t3jeff maggertunited states69 + 73 + 68 = 210et3phil mickelsonunited states70 + 73 + 67 = 210et5robert allenbyaustralia74 + 70 + 67 = 211+ 1t5p\u00e1draig harringtonireland70 + 68 + 73 = 211+ 1t5billy mayfairunited states69 + 74 + 68 = 211+ 1t8nick faldoengland70 + 76 + 66 = 212+ 2t8justin leonardunited states73 + 71 + 68 = 212+ 2t10tom byrumunited states72 + 72 + 70 = 214+ 4t10davis love iiiunited states71 + 71 + 72 = 214+ 4t10scott mccarronunited states72 + 72 + 70 = 214+ 4\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT score FROM table_sql WHERE player = 'justin leonard') < 212 \n             AND (SELECT place FROM table_sql WHERE player = 'justin leonard') = 't8' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-2012.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the home team score equals the away team score at the game taking place at junction oval\nInput Table: 1954 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddategeelong13.12 (90)hawthorn7.6 (48)kardinia park168701954-08-14collingwood12.16 (88)south melbourne13.12 (90)victoria park185561954-08-14carlton10.16 (76)essendon11.14 (80)princes park297441954-08-14richmond10.18 (78)melbourne15.4 (94)punt road oval240001954-08-14north melbourne9.14 (68)footscray9.14 (68)arden street oval220001954-08-14st kilda13.14 (92)fitzroy9.15 (69)junction oval115001954-08-14\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT home_team_score FROM table_sql WHERE venue = 'junction oval') = \n             (SELECT away_team_score FROM table_sql WHERE venue = 'junction oval') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-854.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: team brazil , team australia , and team england are three of the clubs that participated in the 2008 season\nInput Table: list of superleague formula football clubs\n\n\nnofootball_clubcontinentassociated_football_clubseasonsracing_drivers3ac milaneuropeac milan2008 2009 2010robert doornbos giorgio pantano yelmer buurman4ac sparta pragueeuropeac sparta prague2011filip salaquarda5team luxembourgeuropenone2011fr\u00e9d\u00e9ric vervisch6team new zealandoceanianone2011earl bamber7team japanasianone2011duncan tappy8 1 (in 2011)rsc anderlechteuropersc anderlecht2008 2009 2010 2011craig dolby yelmer buurman davide rigon neel jani8team netherlandseuropenone2011robert doornbos10fc basel 1893europefc basel2008 2009 2010max wissel max wissel max wissel12 24 (in 2010)beijing guoanasiabeijing guoan fc2008 2010davide rigon john martin14team brazils americanone2011ant\u00f4nio pizzonia17rangers fceuroperangers fc2008 2009ryan dalziel , james walker john martin24fc midtjyllandeuropefc midtjylland2009kasper andersen24team australiaoceanianone2011john martin31team englandeuropenone2011craig dolby\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 3 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE seasons LIKE '%2008%' \nAND (football_club = 'team brazil' OR football_club = 'team australia' OR football_club = 'team england');\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1924.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: 4 - 1 was the 1st leg for 2004\nInput Table: copa san isidro de curuguaty\n\n\nyearwinnerrunners_-_upaggregate1st_leg2nd_leg1956trinidadliga central4 - 22 - 12 - 11959fray bentosvilleta7 - 13 - 04 - 11963coloniaypacara\u00ed3 - 30 - 13 - 21966tacuaremb\u00f3coronel oviedo4 - 12 - 02 - 11978federaci\u00f3n misioneramelo4 - 01 - 03 - 01980federaci\u00f3n misioneratacuaremb\u00f35 - 5 , 3 - 2 p2 - 13 - 41982maldonadovillarrica1 - 1 , 4 - 3 p1 - 00 - 11984san pedrorocha4 - 31 - 33 - 01988paysand\u00faparanaense4 - 31 - 23 - 11990ypacara\u00edflorida2 - 11 - 01 - 11992liga del sudminas6 - 12 - 04 - 11994maldonadocaaguaz\u00fa9 - 24 - 05 - 21996paranaensemaldonado interior3 - 32 - 21 - 11998itaugu\u00e1melo4 - 31 - 13 - 22000san jos\u00e9 liga mayorcarapegu\u00e12 - 2 , 4 - 2 p1 - 11 - 12002limpiodurazno5 - 45 - 40 - 02004san jos\u00e9 de los arroyosdurazno4 - 30 - 24 - 12006piray\u00famaldonado liga mayor3 - 3 , 4 - 2 p1 - 22 - 12008colonia departamentalcaaguaz\u00fa4 - 23 - 11 - 12008liga caacupe\u00f1aartigas3 - 11 - 12 - 0\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN aggregate LIKE '4 - 1%' AND year = 2004 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1640.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: in 1980 they finished with a record of 18 - 12 and received the 11 seed\nInput Table: vcu rams men 's basketball\n\n\nyearrecordseedregionresults198018 - 1212eastl 72 - 86198124 - 55eastw 85 - 69 l 56 - 58 ot198324 - 75eastw 76 - 67 l 54 - 56198423 - 76eastw 70 - 69 l 63 - 78198526 - 62westw 81 - 65 l 59 - 63199624 - 912southeastl 51 - 58200423 - 813eastl 78 - 79200728 - 711westw 79 - 77 l 79 - 84 ot200924 - 1011eastl 64 - 65201128 - 1211southwestw 59 - 46 w 74 - 56 w 94 - 76 w 72 - 71 ot w 71 - 61 l 62 - 70201229 - 712midwestw 62 - 59 l 61 - 63201327 - 95southw 88 - 42 l 53 - 78\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT record FROM table_sql WHERE year = 1980) = '18 - 12' \n             AND (SELECT seed FROM table_sql WHERE year = 1980) = 11 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1823.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: verizon center 20173 for the location and attendance when the record is 49 - 36%\nInput Table: 2008 - 09 miami heat season\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord759999-04-01dallasl 96 - 98 (ot)dwyane wade (23)jermaine o'neal , udonis haslem (7)dwyane wade (6)american airlines center 2002139 - 36769999-04-03charlottew 97 - 92 (ot)dwyane wade (27)daequan cook (7)dwyane wade (10)time warner cable arena 1956840 - 36779999-04-04washingtonw 118 - 104 (ot)dwyane wade (33)jermaine o'neal , jamaal magloire (6)dwyane wade (8)verizon center 2017341 - 3678'9999-04-07'new orleansl 87 - 93 (ot)dwyane wade (32)jamaal magloire (10)dwyane wade (6)american airlines arena 1960041 - 3779'9999-04-10'bostonl 98 - 105 (ot)dwyane wade (31)michael beasley (13)dwyane wade (9)td banknorth garden 1862441 - 3880'9999-04-12'new yorkw 122 - 105 (ot)dwyane wade (55)michael beasley (16)mario chalmers (9)american airlines arena 1960042 - 38819999-04-14atlantal 79 - 81 (ot)michael beasley (23)michael beasley (13)chris quinn (7)philips arena42 - 3982'9999-04-15'detroitw 102 - 96 (ot)chris quinn (26)dorell wright (10)mario chalmers (10)american airlines arena43 - 39\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN location_attendance = 'verizon center 20173' AND record = '49 - 36' THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-979.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the westgaard bridge is a pratt pony through truss bridge in traill county\nInput Table: list of bridges on the national register of historic places in north dakota\n\n\nnamelistedlocationcountytypebeaver creek bridge1997-02-27finleysteelepratt through trusscaledonia bridge1997-02-27caledoniatraillpratt through trusscedar creek bridge1997-02-27haynesadamspratt through trusscolton 's crossing bridge1997-02-27lisbonransompratt through trusscrystal bridge1997-05-30crystalpembinaconcrete t - beam bridgeeastwood park bridge1975-04-21minotwardcantilever typeelliott bridge1997-02-27townermchenrypratt through trussfairview lift bridge1997-03-14cartwrightmckenzierailroad lift bridgegrace city bridge1997-02-27grace cityfosterpratt through trussgreat northern railway underpass1997-02-27stanleymountrailconcrete deck girder bridgeknife river bridge near stanton2001-04-25stantonmercerpratt through trusslisbon bridge1997-02-27lisbonransomsteel cantilever bean bridgemidland continental overpass1997-02-27jamestownstutsmansteel cantilever beam bridgemidway bridge1997-02-27johnstowngrand forkswarren bedstead bridgenesheim bridge1997-02-27mcvillenelsonpratt through trussnew rockford bridge1997-03-13new rockford closed to trafficeddywarren through truss bridgenorthwood bridge1997-02-27northwoodgrand forkspratt pony trussnorway bridge1997-02-27mayvilletraillpratt pony trussost valle bridge1997-02-27thompsongrand forkspratt through trussromness bridge1997-02-27cooperstowngriggspratt through trusssorlie memorial bridge1999-07-19grand forksgrand forksparker through truss bridgeviking bridge1997-02-27portlandtraillpratt through trusswest antelope bridge1997-02-27florabensonpratt pony truss bridgewest park bridge1997-02-27valley citybarnesconcrete false arch bridgewestgaard bridge1997-02-27voltairemchenrypratt pony through trussblanchard bridge1997-02-27blanchardtraillpratt through trussgoose river bridge1997-02-27hillsborotraillpratt through trussliberty memorial bridge1997-03-11 removed 2009-03-25bismarckburleighwarren - turner through trussporter elliott bridge1997-02-27hillsborotraillwarren through trussportland park bridge2004-09-23portlandtraillsteel through girderrainbow arch bridge2004-09-23valley citybarnesmarsh rainbow arch\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT type FROM table_sql WHERE name = 'westgaard bridge' AND county = 'traill') = 'pratt pony through truss' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1024.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: kings island opened before 1999\nInput Table: drop tower : scream zone\n\n\nparktower_heightdrop_heightspeedmodelopenedheight_requirementcanada 's wonderland230feet200feet62 mphgiant drop1997-01-01inches (cm)carowinds174feet100feet56 mphgiant drop1996-03-01inches (cm)california 's great america224feet207feet62 mphgiant drop1996-03-01inches (cm)kings dominion305feet272feet72 mphgyro drop2003-03-22inches (cm)kings island315feet264feet67 mphgyro drop1999-01-01inches (cm)\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT opened FROM table_sql WHERE park = 'kings island') < '1999-01-01' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1853.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: in 2010 , the girls doubles were ayu pratiwi and anggi widia and the boys doubles were jones ralfy jansen and dandi prabudita\nInput Table: indonesian national badminton championships\n\n\nyearboys_singlesgirls_singlesboys_doublesgirls_doublesmixed_doubles2001holvy de pauwmaria kristin yuliantihendra setiawan joko riyadililyana natsir natalia poluakanhendra setiawan greysia polii2002andre kurniawan tedjonofransisca ratnasariujang suherlan yoga ukikasahpurwati meiliana jauharimuhammad rijal meiliana jauhari2003alamsyah yunuswiwis meilyannafran kurniawan chandra kowipia zebadiah nitya krishinda maheswarifran kurniawan yulianti2004andre kurniawan tedjonopia zebadiahaditya dwi putra i made agungpia zebadiah nitya krishinda maheswarilingga lie yulianti2005achmad rivaibellaetrix manuputtyrio willianto davin prawidssalily siswanti shendy puspa irawatiabdul rahman richi puspita dili2006nugroho andi saputrosylvinna kurniawandanny bawa chrisnanta afiat yuris wirawanbellaetrix manuputty samantha lintangdanny bawa chrisnanta debby susanto2007nandang ariflindaweni fanetribudi hartono yohanes rendy sugiartoanneke feinya agustin wenny setiawatiwifqi windarto debby susanto2008hermansyahana rovitadidit juang indrianto seiko wahyu kusdiantosuci rizki andini tiara rosalia nuraidahirfan fadhilah weni anggraeni2009riyanto subagjaana rovitajones ralfy jansen dandi prabuditaayu pratiwi anggi widiadidit juang indrianto yayu rahayu2010shesar hiren rhustavitoganis nur rahmadanijones ralfy jansen dandi prabuditaaris budiharti dian fitrianijones ralfy jansen nurbeta kwanrico\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT girls_doubles FROM table_sql WHERE year = 2010) = 'ayu pratiwi anggi widia' \n             AND (SELECT boys_doubles FROM table_sql WHERE year = 2010) = 'jones ralfy jansen dandi prabudita' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-191.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: all 4 test matches took place in october of 1978\nInput Table: 1978 new zealand rugby union tour of britain and ireland\n\n\nopposing_teamagainstdatevenuestatuscambridge university121978-10-18grange road , cambridgetour matchcardiff71978-10-21cardiff arms park , cardifftour matchwest wales xv71978-10-25st helen 's , swanseatour matchlondon counties121978-10-28twickenham , londontour matchmunster121978-10-31thomond park , limericktour matchireland61978-11-04lansdowne road , dublintest matchulster71978-11-07ravenhill , belfasttour matchwales121978-11-01cardiff arms park , cardifftest matchsouth and south - west counties01978-11-15memorial ground , bristoltour matchmidland counties151978-11-18welford road , leicestertour matchcombined services61978-11-21aldershot military stadium , aldershottour matchengland61978-11-25twickenham , londontest matchmonmouthshire91978-11-29rodney parade , newporttour matchnorth of england61978-12-02birkenhead park , birkenheadtour matchnorth and midland of scotland31978-12-05linksfield stadium , aberdeentour matchscotland91978-12-09murrayfield , edinburghtest matchbridgend61978-12-13brewery field , bridgendtour matchbarbarians161978-12-16cardiff arms park , cardifftour match\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 4 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE strftime('%Y-%m', date) = '1978-10' \nAND status = 'test match';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1599.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: antonio pompa - baldi italy was first in 1999 and 2000\nInput Table: cleveland international piano competition\n\n\nyearfirstsecondthirdfourth2013stanislav khristenko russiaarseny tarasevich - nikolaev russiafran\u00e7ois dumont francejiayan sun china2011alexander schimpf germanyalexei chernov russiaeric zuber usakyu yeon kim south korea2009martina filjak croatiadmitri levkovich canadawilliam youn south koreaevgeny brakhman russia2007alexander ghindin russiayaron kohlberg israelalexandre moutouzkine russiaran dank israel2005chu - fang huang chinasergey kuznetsov russiastanislav khristenko russiaspencer myer usa2003kotaro fukuma japansoyeon lee south koreakonstantin soukhovetski russiaandrius zlabys lithuania2001roberto plano italyminsoo sohn south korea\u00f6zg\u00fcr aydin turkeygilles vonsattel switzerland1999antonio pompa - baldi italyvassily primakov russiashoko inoue japansean botkin usa1997per tengstrand swedengulnora alimova uzbekistanning an chinadror biran israel1995margarita shevchenko russiamarina lomazov / ukraine / usadmitri teterin russiagiampaolo stuani italy1993amir katz israelnot awardedseizo azuma and japan yuko nakamichi japankatsunori ishii japan1991ilya itin russiaanders martinson usamarkus pawlik germanyjean - fran\u00e7ois bouvery france1989sergei babayan armenia ( ussr )nicholas angelich usamegumi kaneko japanpascal godart france1987thierry huillet franceasaf zohar israeljonathan bass usabeatrice hsin - chen long / taiwan / china1985daejin kim south koreabenedetto lupo italyh\u00e9l\u00e8ne jeanney franceneil rutman usa1983youngshin an south koreamayumi kameda japanst\u00e9phane lemelin canadaroy kogan usa1981philippe bianconi francedan riddle usar\u00e9my loumbrozo franceroy kogan usa1979edward newman usajean - yves thibaudet franceangela hewitt canadafrederick blum usa1977nathalie bera - tagrine francebarry salwen usadouglas montgomery usalaura silverman usa1975john owings usajulian martin usajohn - patrick millow franceroe van boskirk usa\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT first FROM table_sql WHERE year = 1999) = 'antonio pompa - baldi italy' \n             AND (SELECT first FROM table_sql WHERE year = 2000) = 'antonio pompa - baldi italy' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1285.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: paulo costa of por is retiring at the end of the season\nInput Table: 2008 - 09 apoel f.c. season\n\n\nnatnamemoving_totypetransfer_windowtransfer_feesourcegremachlasretiredretirementsummer-contragrcypmakridesmetalurh donetskend of contractsummerfreekerkidanetser\u010dorovi\u0107ael limassolloan returnsummer--cyploukaael limassolend of contractsummerfreekerkidanetgrekapsislevadiakosend of contractsummerfree-cypdaskalakisaek larnacaend of contractsummerfreeapoelnetbraz\u00e9 carlostrofensecontract terminationsummerfreeapoelfccomcycypvourkoudoxa katokopialoansummerfree-cyppanayiotoudigenis morphouloansummerfree-mkdnikolovskiaep paphosmutual consentwinterfree-cyppapathanasiouermis aradippouloanwinterfree-porpaulo costaanorthosis famagustamutual consent loan returnwinterfreeapoelfccomcy\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE name = 'paulo costa' \nAND nat = 'por' \nAND type = 'retirement' \nAND transfer_window = 'end of season';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-300.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: standard li\u00e8ge had a match against hamburg as team 1\nInput Table: 2009 - 10 uefa europa league\n\n\nteam_1aggteam_21st_leg2nd_leghamburg6 - 5anderlecht3 - 13 - 4rubin kazan2 - 3wolfsburg1 - 11 - 2 ( aet )atl\u00e9tico madrid2 - 2 ( a )sporting cp0 - 02 - 2benfica3 - 2marseille1 - 12 - 1panathinaikos1 - 4standard li\u00e8ge1 - 30 - 1lille1 - 3liverpool1 - 00 - 3juventus4 - 5fulham3 - 11 - 4valencia5 - 5 ( a )werder bremen1 - 14 - 4\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE team_1 = 'standard li\u00e8ge' \nAND team_2 = 'hamburg';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-172.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the aircraft bell 212 twin huey was a trainer type\nInput Table: uruguayan air force\n\n\naircraftorigintypeversionsin_servicecessna a - 37 dragonflyunited statesattack / fightera - 37b12 (16 delivered)fma ia 58 pucar\u00e3\u00a1argentinaattacka - 585 (6 delivered)lockheed c - 130 herculesunited statestransport / utilityc - 130b2embraer emb 110 bandeirantebraziltransport / utilityc - 953beechcraft twin bonanzaunited statestransport / utilityd501casa c - 212 aviocarspaintransportc - 212 - 2002embraer emb 120 brasiliabraziltransportemb 1201cessna 206 stationairunited statesutility / liaisonu206h10beechcraft b58 baronunited statestrainer / liaisonb - 582british aerospace 125united kingdomvip transport700a 600a2aermacchi sf260italytrainert - 260 eu12pilatus pc - 7 turbo trainerswitzerlandtrainer- 925 (6 delivered)cessna t - 41 mescalerounited statestrainert - 41d7aerospatiale as 365 dauphinfranceliaison / transportas 3651bell 212 twin hueyunited statestransport / utilitybell 2124bell uh - 1 iroquoisunited statestransport / utilityuh - 1h13\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT type FROM table_sql WHERE aircraft = 'bell 212 twin huey') = 'trainer' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-936.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: on february 27 the score of the game with new jersey as the home team was 1 - 4\nInput Table: none\n\n\ndatevisitorscorehomerecord9999-02-03ny islanders7 - 2new jersey11 - 32 - 119999-02-05new jersey4 - 5washington11 - 33 - 119999-02-06vancouver4 - 4new jersey11 - 33 - 129999-02-09new jersey4 - 5chicago11 - 34 - 1201-02-12new jersey1 - 5st louis11 - 35 - 1201-02-15minnesota3 - 2new jersey11 - 36 - 129999-02-20new jersey0 - 3philadelphia11 - 37 - 1201-02-21buffalo4 - 4new jersey11 - 37 - 139999-02-24detroit1 - 4new jersey12 - 37 - 139999-02-26new jersey4 - 5pittsburgh12 - 38 - 139999-02-27new jersey2 - 6buffalo12 - 39 - 13\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT score FROM table_sql WHERE date = '9999-02-27' AND home = 'new jersey') = '1 - 4' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-763.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the record for the 400 m event before september 4 , 2009 is over 48.83\nInput Table: memorial van damme\n\n\neventrecordathletenationalitydate100 m10.72 ( - 0.3 m / s)shelly - ann fraser - prycejamaica2013-09-06200 m21.64 ( + 0.8 m / s)merlene otteyjamaica1991-09-13400 m48.83sanya richardsunited states2009-09-04800 m1:55.16pamela jelimokenya2008-09-061000 m2:28.98svetlana masterkovarussia1996-08-231500 m3:55.33s\u00fcreyya ayhanturkey2003-09-05mile4:17.75maryam yusuf jamalbahrain2007-09-142000 m5:30.19gelete burkaethiopia2009-09-043000 m8:24.81 +meseret defarethiopia2007-09-14two miles8:58.58meseret defarethiopia2007-09-145000 m14:25.43vivian cheruiyotkenya2008-09-06100 m hurdles12.42 ( - 0.3 m / s)yordanka donkovabulgaria1986-09-05400 m hurdles53.43nezha bidouanemorocco1998-08-283000 m steeplechase9:15.06milcah chemoskenya2013-09-06high jump2.05 manna chicherovarussia2011-09-16pole vault4.93 myelena isinbayevarussia2005-08-26long jump7.25 m ( + 1.7 m / s)heike drechslergermany1991-09-13triple jump15.14 m ( + 0.3 m / s)tatyana lebedevarussia2003-09-05shot put20.57 mnatalya lisovskayasoviet union1987-09-11discus throw69.84 mtsvetanka christovabulgaria1986-09-05javelin throw72.18 m ( old design ) 67.76 m ( current design )fatima whitbread trine hattestadunited kingdom norway1986-09-054100 m relay42.97united statesunited states1988-08-19\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT record FROM table_sql WHERE event = '400 m' AND date < '2009-09-04') > 48.83 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1083.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: by late january detroit was the lowest scoring team\nInput Table: 2003 - 04 detroit red wings season\n\n\ndatevisitorscorehomedecisionattendancerecord0002-01-01detroit4 - 1carolinajoseph1705324 - 12 - 4 - 10001-01-03anaheim1 - 3detroitlegace2006625 - 12 - 4 - 10000-01-05nashville0 - 6detroitjoseph2006626 - 12 - 4 - 10001-01-07boston3 - 0detroitjoseph2006626 - 13 - 4 - 10000-01-10detroit1 - 2bostonjoseph1756526 - 13 - 4 - 29999-01-14chicago2 - 4detroitlegace2006627 - 13 - 4 - 20000-01-16phoenix3 - 3detroitjoseph2006627 - 13 - 5 - 29999-01-19detroit1 - 2san josejoseph1736127 - 14 - 5 - 29999-01-21detroit2 - 2anaheimlegace1717427 - 14 - 6 - 29999-01-22detroit5 - 4los angelesjoseph1811828 - 14 - 6 - 29999-01-24detroit2 - 5phoenixjoseph1901928 - 15 - 6 - 29999-01-26detroit2 - 2dallaslegace1853228 - 15 - 7 - 29999-01-29new jersey2 - 5detroitjoseph2006629 - 15 - 7 - 29999-01-31carolina4 - 4detroitlegace2006630 - 15 - 8 - 2\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MIN(score) FROM table_sql WHERE date >= '2003-01-01' AND date <= '2003-01-31') = \n             (SELECT MIN(score) FROM table_sql WHERE date >= '2003-01-01' AND date <= '2003-01-31' AND home = 'detroit') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-610.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: travis outlaw led the team in both points and rebounds in a single game 3 different times\nInput Table: 2010 - 11 new jersey nets season\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord759999-04-01philadelphial 90 - 115 (ot)brandan wright (15)brandan wright (11)deron williams (7)wells fargo center 1669523 - 52769999-04-03miamil 94 - 108 (ot)deron williams (18)travis outlaw (9)deron williams (9)prudential center 1871123 - 5377'9999-04-05'minnesotaw 107 - 105 (ot)brook lopez (30)brook lopez (12)deron williams (21)prudential center 1346124 - 53789999-04-06detroitl 109 - 116 (ot)brook lopez (39)brook lopez (7)jordan farmar (11)the palace of auburn hills 1455424 - 54799999-04-08new yorkl 93 - 116 (ot)brook lopez (27)jordan farmar (8)jordan farmar (9)prudential center 1802324 - 5580'9999-04-10'torontol 92 - 99 (ot)brook lopez (35)brook lopez (11)jordan farmar (7)air canada centre 1775524 - 56819999-04-11charlottel 103 - 105 (ot)brook lopez (31)dan gadzuric (8)jordan farmar (9)prudential center 1385324 - 57\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE high_points = (SELECT MAX(high_points) FROM table_sql) AND high_rebounds = (SELECT MAX(high_rebounds) FROM table_sql)) >= 3 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-810.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the games on june 18 and 28 , 1998 both had a score of 1 - 1\nInput Table: 1998 in paraguayan football\n\n\ndatevenuescorecompreport1998-02-08estadio defensores del chaco asunci\u00f3n , paraguay4 - 0f4501998-03-14qualcomm stadium san diego , united states2 - 2f4511998-03-18estadio ol\u00edmpico universitario mexico city , mexico1 - 1f4521998-03-28yale bowl new haven , united states1 - 1f4531998-04-22stadio ennio tardini parma , italy3 - 1f4541998-05-17olympic stadium tokyo , japan1 - 1kirin cup4551998-05-21kobe universiade memorial stadium kobe , japan1 - 0kirin cup4561998-06-01philips stadion eindhoven , netherlands5 - 1f4571998-06-03steaua stadium bucharest , romania3 - 2f4581998-06-06king baudouin stadium brussels , belgium1 - 0f4591998-06-12stade de la mosson montpellier , france0 - 0world cupreport1998-06-19stade geoffroy - guichard saint - \u00e9tienne , france0 - 0world cupreport1998-06-24stade de toulouse toulouse , france1 - 3world cupreport1998-06-28stade f\u00e9lix bollaert lens , france0 - 0 ( 1 - 0 aet )world cupreport\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT score FROM table_sql WHERE date = '1998-06-18') = '1 - 1' \n             AND (SELECT score FROM table_sql WHERE date = '1998-06-28') = '1 - 1' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1605.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: during the 2007 - 08 minnesota wild season , the decision was backstrom eleven times more than it was harding\nInput Table: 2007 - 08 minnesota wild season\n\n\ndatevisitorscorehomedecisionattendancerecord01-02-9999minnesota4 - 1columbusbackstrom1852930 - 19 - 39999-02-05detroit3 - 2minnesotabackstrom1856830 - 19 - 401-02-07dallas1 - 0minnesotabackstrom1856830 - 20 - 49999-02-09ny islanders3 - 4minnesotabackstrom1856831 - 20 - 401-02-10minnesota2 - 1st louisharding1647732 - 20 - 401-02-12minnesota2 - 4edmontonharding1683932 - 21 - 401-02-14minnesota5 - 4vancouverbackstrom1863033 - 21 - 49999-02-17nashville4 - 5minnesotabackstrom1856834 - 21 - 49999-02-19vancouver3 - 2minnesotabackstrom1856834 - 21 - 59999-02-20minnesota0 - 3chicagoharding1781234 - 22 - 59999-02-24calgary2 - 1minnesotabackstrom1856834 - 23 - 59999-02-26minnesota1 - 4washingtonbackstrom1739134 - 24 - 59999-02-27minnesota3 - 2tampa baybackstrom1721135 - 24 - 59999-02-29minnesota3 - 2floridabackstrom1692736 - 24 - 5\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE decision = 'backstrom') = 11 * (SELECT COUNT(*) FROM table_sql WHERE decision = 'harding') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1327.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: robert bauman is the incumbent for maryland district 2\nInput Table: united states house of representatives elections , 1974\n\n\ndistrictincumbentpartyfirst_electedresultcandidatesmaryland 1robert baumanrepublican1973-01-01re - electedrobert bauman (r) 53.0% thomas j hatem (d) 47.0%maryland 2clarence longdemocratic1962-01-01re - electedclarence long (d) 77.1% john m seney (r) 22.9%maryland 4marjorie holtrepublican1972-01-01re - electedmarjorie holt (r) 58.1% fred l wineland (d) 41.9%maryland 6goodloe byrondemocratic1970-01-01re - electedgoodloe byron (d) 73.7% elton r wampler (r) 26.3%maryland 7parren mitchelldemocratic1970-01-01re - electedparren mitchell (d) unopposed\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE district = 'maryland 2' \nAND incumbent = 'robert bauman';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-281.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the toronto blue jays lost two of the last three games they played in may 1991\nInput Table: 1991 toronto blue jays season\n\n\ndateopponentscorelossattendancerecord9999-05-01rangers3 - 0key (4 - 1)3343912 - 109999-05-02royals3 - 1appier (1 - 4)2289613 - 109999-05-03royals5 - 1davis (2 - 2)2080914 - 109999-05-04royals6 - 5boucher (0 - 2)2262814 - 119999-05-05royals3 - 0gordon (1 - 2)2258815 - 119999-05-07rangers3 - 2key (4 - 2)4462215 - 129999-05-08rangers4 - 2ryan (3 - 3)4321116 - 129999-05-09white sox2 - 0p\u00e3rez (1 - 2)4723617 - 129999-05-10white sox5 - 3 (12)fraser (0 - 1)5019817 - 139999-05-11white sox5 - 2hough (0 - 2)5020618 - 139999-05-12white sox4 - 2hibbard (2 - 1)5010819 - 139999-05-13royals4 - 2davis (2 - 4)4427520 - 139999-05-14royals4 - 1gubicza (0 - 1)4335721 - 139999-05-15royals6 - 4boucher (0 - 3)5011321 - 149999-05-17white sox5 - 3timlin (3 - 1)3009521 - 159999-05-18white sox9 - 2hibbard (2 - 2)3486122 - 159999-05-19white sox5 - 4timlin (3 - 2)4101522 - 169999-05-20athletics1 - 0welch (4 - 3)2463123 - 169999-05-21athletics11 - 7dressendorfer (3 - 3)2273824 - 169999-05-22athletics2 - 1stieb (4 - 3)3402824 - 179999-05-24angels3 - 2finley (7 - 2)2640825 - 179999-05-25angels5 - 0stottlemyre (5 - 1)3673225 - 189999-05-26angels6 - 2wells (5 - 4)4530725 - 199999-05-28athletics8 - 4acker (1 - 2)5029925 - 209999-05-29athletics8 - 3slusarski (1 - 2)5026226 - 209999-05-30athletics8 - 6ward (0 - 2)5027126 - 219999-05-31angels5 - 1langston (6 - 2)5025227 - 21\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT loss FROM table_sql WHERE date = '9999-05-29') = 'lost' \n             AND (SELECT loss FROM table_sql WHERE date = '9999-05-30') = 'lost' \n             AND (SELECT loss FROM table_sql WHERE date = '9999-05-31') = 'won' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1521.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the home town of cody zeller is wichita , ks\nInput Table: usa today all - usa high school basketball team\n\n\nplayerheightschoolhometowncollegekhem birch6 - 9notre dame prepmontreal , qc , canadapittsburgh / unlvperry ellis6 - 8wichita heights high schoolwichita , kskansasmyles mack5 - 9st anthony high schooljersey city , njrutgersshabazz muhammad6 - 6bishop gorman high schoollas vegas , nvuclacody zeller6 - 11washington high schoolwashington , inindiana\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN hometown = 'wichita , ks' THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE player = 'cody zeller';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1772.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: only one person has been a member of the socialist party of albania\nInput Table: list of prime ministers of albania\n\n\nnameborn_-_diedterm_startterm_endpolitical_partyprime ministers 1991 onwards1991-01-011991-01-011991-01-01prime ministers 1991 onwardsfatos nano (1st time)9999-01-011991-02-221991-06-05party of labour of albaniaylli bufi9999-01-011991-06-051991-12-10socialist party of albaniavilson ahmeti9999-01-011991-12-101992-04-13non - partyaleksand\u00ebr meksi9999-01-011992-04-131997-03-11democratic party of albaniabashkim fino9999-01-011997-03-111997-07-24socialist party of albaniafatos nano (2nd time)9999-01-011997-07-241998-10-02socialist party of albaniapandeli majko (1st time)9999-01-011998-10-021999-10-29socialist party of albaniailir meta9999-01-011999-10-292002-02-22socialist party of albaniapandeli majko (2nd time)9999-01-012002-02-222002-07-31socialist party of albaniafatos nano (3rd time)9999-01-012002-07-312005-09-11socialist party of albaniasali berisha1944-01-012005-09-112013-09-15democratic party of albaniaedi rama9999-01-012013-09-159999-01-01socialist party of albania\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(DISTINCT name) = 1 AND political_party = 'socialist party of albania' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE political_party = 'socialist party of albania';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1621.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: 99012 is the lowest reset points where the events is 56\nInput Table: 2007 fedex cup playoffs\n\n\nUnnamed:_0playercountrypointseventsreset_points1tiger woodsunited states30574131000002vijay singhfiji1912923990003jim furykunited states1669119985004phil mickelsonunited states1603718980005kj choisouth korea1548521975006rory sabbatinisouth africa1354819972507zach johnsonunited states1334119970008charles howell iiiunited states1212621967509brandt snedekerunited states118702596500\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT reset_points FROM table_sql WHERE events = 56) = 99012 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-104.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: t7 is the place of player peter oosterhuis , who has 10875\nInput Table: 1975 u.s. open (golf)\n\n\nplaceplayercountryscoreto_parmoneyt1lou grahamunited states74 + 72 + 68 + 73 = 287+ 3playofft1john mahaffeyunited states73 + 71 + 72 + 71 = 287+ 3playofft3frank beardunited states74 + 69 + 67 + 78 = 288+ 410875t3ben crenshawunited states70 + 68 + 76 + 74 = 288+ 410875t3hale irwinunited states74 + 71 + 73 + 70 = 288+ 410875t3bob murphyunited states74 + 73 + 72 + 69 = 288+ 410875t7jack nicklausunited states72 + 70 + 75 + 72 = 289+ 57500t7peter oosterhuisengland69 + 73 + 72 + 75 = 289+ 57500t9pat fitzsimonsunited states67 + 73 + 73 + 77 = 290+ 65000t9arnold palmerunited states69 + 75 + 73 + 73 = 290+ 65000t9tom watsonunited states67 + 68 + 78 + 77 = 290+ 65000\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT place FROM table_sql WHERE player = 'peter oosterhuis') = 't7' \n             AND (SELECT money FROM table_sql WHERE player = 'peter oosterhuis') = 10875 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1242.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the production code for the episode directed by robert duncan mcneill is bcw403\nInput Table: list of white collar episodes\n\n\nno_in_seriesno_in_seasontitledirected_bywritten_byus_viewers_(million)original_air_dateproduction_code471wantedpaul holahanjeff eastin3.212012-07-10bcw401482most wantedpaul holahanmark goffman2.982012-07-17bcw402493diminishing returnsstefan schwartzjim campolongo3.012012-07-24bcw403504parting shotsrobert duncan mcneillalexandra mcnally2.822012-07-31bcw404515honor among thievesarlene sanfordjoe henderson2.932012-08-14bcw405526identity crisisdavid straitonchanning powell3.892012-08-21bcw406537compromising positionspaul holahanmatthew negrete3.362012-08-28bcw407548ancient historyrussell lee finedaniel shattuck3.382012-09-04bcw408559gloves offrenny harlinmark goffman3.82012-09-11bcw4095610vested interestrussell lee finejeff eastin3.412012-09-18bcw4105711family businesspaul holahanjoe henderson2.772013-01-22bcw4115812brass tacksanton cropperjim campolongo & alexandra mcnally2.612013-01-29bcw4125913empire citytim dekaychanning powell & daniel shattuck2.282013-02-05bcw4136014shoot the moonrussell lee finematthew negrete & bob derosa2.422013-02-19bcw4146115the originaljohn kretchmermark goffman2.122013-02-26bcw415\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT production_code FROM table_sql WHERE directed_by = 'robert duncan mcneill') = 'bcw403' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1146.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: season 6.0 has q245 as its format\nInput Table: none\n\n\nepisodeseasonformattitleoriginal_airdate2171h75lost smurf1988-09-102182h76archives of evil1988-09-102193q143bigmouth 's roommate / bungling babysitters1988-09-172204q144clockwork 's powerplay / clumsy in command1988-09-172215h77don smurfo 's uninvited guests1988-09-242226q145denisa 's greedy doll / denisa 's slumber party1988-09-242237q146grandpa 's nemesis / grandpa 's walking stick1988-10-012248h78a house for nanny1988-10-012259q147it 's a smurfy life / land of lost and found1988-10-0822610h79long live brainy1988-10-0822711h80a maze of mirrors1988-10-1522812q148memory melons / nanny 's way1988-10-1522913q149pappy 's puppy / shutterbug smurfs1988-10-2223014q150smoogle sings the blues / a smurf for denisa1988-10-2223115h81smurf the presses1988-10-2923216h82stealing grandpa 's thunder1988-10-29\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN format = 'q245' AND season = 6.0 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1519.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: player shabazz muhammad stands 6 - 11 in height and is from jersey city , nj\nInput Table: usa today all - usa high school basketball team\n\n\nplayerheightschoolhometowncollegekhem birch6 - 9notre dame prepmontreal , qc , canadapittsburgh / unlvperry ellis6 - 8wichita heights high schoolwichita , kskansasmyles mack5 - 9st anthony high schooljersey city , njrutgersshabazz muhammad6 - 6bishop gorman high schoollas vegas , nvuclacody zeller6 - 11washington high schoolwashington , inindiana\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN height = '6 - 11' AND hometown = 'jersey city , nj' THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE player = 'shabazz muhammad';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1464.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the new york jets had 992 more people in attendance in their second game against the new england patriots then from their first game played against them during the 1993 season\nInput Table: 1993 new york jets season\n\n\nweekdateopponentresultgame_siteattendance11993-09-05denver broncosl 26 - 20the meadowlands6813021993-09-12miami dolphinsw 24 - 14joe robbie stadium7031441993-09-26new england patriotsw 45 - 7the meadowlands6483651993-10-03philadelphia eaglesl 35 - 30the meadowlands7259361993-10-10los angeles raidersl 24 - 20los angeles memorial coliseum4162781993-10-24buffalo billsl 19 - 10the meadowlands7154191993-10-31new york giantsw 10 - 6giants stadium71659101993-11-07miami dolphinsw 27 - 10the meadowlands71306111993-11-14indianapolis coltsw 31 - 17rca dome47351121993-11-21cincinnati bengalsw 17 - 12the meadowlands64264131993-11-28new england patriotsw 6 - 0foxboro stadium42810141993-12-05indianapolis coltsl 9 - 6the meadowlands45799151993-12-11washington redskinsw 3 - 0robert f kennedy memorial stadium47970161993-12-18dallas cowboysl 28 - 7the meadowlands73233171993-12-26buffalo billsl 16 - 14rich stadium70817181994-01-02houston oilersl 24 - 0houston astrodome61040\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT attendance FROM table_sql WHERE opponent = 'new england patriots' AND week = 2) - \n             (SELECT attendance FROM table_sql WHERE opponent = 'new england patriots' AND week = 1) = 992 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1528.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the home team score when the vfl played at princes park was 21.18 (144)\nInput Table: 1969 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddategeelong16.14 (110)hawthorn14.11 (95)kardinia park315691969-08-23collingwood19.15 (129)south melbourne6.22 (58)victoria park194281969-08-23carlton20.7 (127)richmond24.12 (156)princes park276571969-08-23st kilda21.18 (144)north melbourne8.10 (58)moorabbin oval111091969-08-23melbourne14.13 (97)fitzroy14.15 (99)mcg177901969-08-23footscray14.10 (94)essendon12.10 (82)western oval160431969-08-23\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN home_team_score = '21.18 (144)' AND venue = 'princes park' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE venue = 'princes park';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-873.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the entrant was private on two occasions with the drivers were harry schell and johnny claes\nInput Table: 1950 swiss grand prix\n\n\ndriverentrantconstructorchassisenginetyrenello paganiscuderia achille varzimaseratimaserati 4clt - 48maserati l4spjohnny claesecurie belgetalbot - lagotalbot - lago t26ctalbot l6dyves giraud - cabantousautomobiles talbot - darracq satalbot - lagotalbot - lago t26c - datalbot l6deug\u00e8ne martinautomobiles talbot - darracq satalbot - lagotalbot - lago t26c - datalbot l6dlouis rosierautomobiles talbot - darracq satalbot - lagotalbot - lago t26c - datalbot l6dluigi fagiolisa alfa romeoalfa romeoalfa romeo 158alfa romeo l8spjuan manuel fangiosa alfa romeoalfa romeoalfa romeo 158alfa romeo l8spnino farinasa alfa romeoalfa romeoalfa romeo 158alfa romeo l8spalberto ascariscuderia ferrariferrariferrari 125ferrari v12spraymond sommerscuderia ferrariferrariferrari 125ferrari v12spluigi villoresiscuderia ferrariferrariferrari 125ferrari v12sppeter whiteheadscuderia ferrariferrariferrari 125ferrari v12splouis chironofficine alfieri maseratimaseratimaserati 4clt - 48maserati l4spfranco rolofficine alfieri maseratimaseratimaserati 4clt - 48maserati l4spprince biraenrico plat\u00e9maseratimaserati 4clt - 48maserati l4sptoulo de graffenriedenrico plat\u00e9maseratimaserati 4clt - 48maserati l4spfelice bonettoscuderia milanomaseratimaserati milano 4clt - 50maserati l4spreg parnellscuderia ambrosianamaseratimaserati 4clt - 48maserati l4sdrudi fischerecurie espadonsva - fiatsva 1500fiat l4sptoni brancaprivatemaseratimaserati 4clmaserati l4spphilippe \u00e9tancelinprivatetalbot - lagotalbot - lago t26ctalbot l6dharry schellecurie bleuetalbot - lagotalbot - lago t26ctalbot l6d\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 2 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE (entrant = 'private' AND driver = 'harry schell') \nOR (entrant = 'private' AND driver = 'johnny claes');\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-20.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: ames is the site with the earliest date\nInput Table: iowa corn cy - hawk series\n\n\ndatesitesportwinning_teamseries2007-09-04cedar rapidsm golfiowa stateiowa state 2 - 02007-09-08des moinesvolleyballiowa stateiowa state 4 - 02007-09-09iowa cityw soccertieiowa state 5 - 12007-09-15amesfootballiowa stateiowa state 8 - 12007-11-10peoriam cross countryiowa stateiowa state 10 - 12007-11-10peoriaw cross countryiowaiowa state 10 - 32007-12-05amesw basketballiowa stateiowa state 12 - 32007-12-07amesw swimmingiowa stateiowa state 14 - 32007-12-08amesm basketballiowa stateiowa state 16 - 32007-12-09ameswrestlingiowaiowa state 16 - 52008-02-22amesw gymnasticsiowa stateiowa state 18 - 52008-03-07iowa cityw gymnasticsiowaiowa state 18 - 72008-04-01amessoftballiowaiowa state 18 - 9\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN site = 'ames' AND date = (SELECT MIN(date) FROM table_sql) THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1510.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: fukusy\u016b no purop\u014dzu had the 2nd most recent broadcast date\nInput Table: tsuki no koibito\n\n\nUnnamed:_0episode_titleromanized_titletranslation_of_titlebroadcast_dateratingsep 1\u304a\u307e\u3048\u304c\u6b32\u3057\u3044omae ga hosiii want you2010-05-1022.4%ep 2\u3042\u308a\u3048\u306a\u3044\u30ad\u30b9arienai kisuthe unthinkable kiss2010-05-1719.2%ep 3\u5fa9\u8b90\u306e\u30d7\u30ed\u30dd\u30fc\u30bafukusy\u016b no purop\u014dzuthe proposal out of revenge2010-05-2415.6%ep 4\u3053\u3093\u306a\u306b\u597d\u304d\u3060\u3063\u305f\u3093\u3060\u2026konna ni suki dattanda\u2026that 's how much i liked you2010-05-3115.5%ep 5\u597d\u304d\u3068\u8a00\u3048\u305f\u3089\u3044\u3044\u306e\u306bsuki to ietara iinoniif only i could say , i like you2010-06-0717.4%ep 6\u6700\u7d42\u7ae0\u5e8f\u5e55\u30fb\u5225\u308csaish\u016bsh\u014djomakuwakarea prologue of final chapter , farewell2010-06-1413.4%\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MAX(broadcast_date) FROM table_sql) = (SELECT MAX(broadcast_date) FROM table_sql WHERE episode_title = '\u5fa9\u8b90\u306e\u30d7\u30ed\u30dd\u30fc\u30ba') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1326.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the candidates for the maryland district 7 were incumbent goodloe byron and elton r wampler\nInput Table: united states house of representatives elections , 1974\n\n\ndistrictincumbentpartyfirst_electedresultcandidatesmaryland 1robert baumanrepublican1973-01-01re - electedrobert bauman (r) 53.0% thomas j hatem (d) 47.0%maryland 2clarence longdemocratic1962-01-01re - electedclarence long (d) 77.1% john m seney (r) 22.9%maryland 4marjorie holtrepublican1972-01-01re - electedmarjorie holt (r) 58.1% fred l wineland (d) 41.9%maryland 6goodloe byrondemocratic1970-01-01re - electedgoodloe byron (d) 73.7% elton r wampler (r) 26.3%maryland 7parren mitchelldemocratic1970-01-01re - electedparren mitchell (d) unopposed\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 1 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE district = 'maryland 7' \nAND candidates LIKE '%goodloe byron%' \nAND candidates LIKE '%elton r wampler%';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1114.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: martin cr\u00eate is listed as a skip for winnipeg\nInput Table: 2009 canadian olympic curling trials\n\n\nskipthird_/_vice_skipsecondleadcitykerry burtnykdon walchukrichard daneaultgarth smithwinnipegpat simmonsgerry adamjeff sharpsteve laycockdavidsonjeff stoughtonkevin parkrob fowlersteve gouldwinnipegwayne middaughjon meadjohn eppingscott baileyislingtonbrad gushuemark nicholsryan fryjamie korabst john 'smike mcewenb j neufeldmatt wozniakdenni neufeldwinnipegjoel jordisonscott bitzaryn schmidtdean hickemoose jawbob urseljim cotterkevin folkrick sawatskykelownajean - michel m\u00e9nardmartin cr\u00eate\u00e9ric sylvainjean gagnonl\u00e9visted appelmantom appelmanbradon klassenbrendan melnykedmontongreg mcaulayken maskiewichdeane horningaaron watsonrichmondjason gunnlaugsonjustin richterbraden zawadatyler forrestbeausejour\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE skip = 'martin cr\u00eate' \nAND city = 'winnipeg';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1313.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: mark o' meara is the second player with 71 + 72 + 66 = 209 as the score\nInput Table: 1988 u.s. open (golf)\n\n\nplaceplayercountryscoreto_par1curtis strangeunited states70 + 67 + 69 = 206- 7t2nick faldoengland72 + 67 + 68 = 207- 6t2bob gilderunited states68 + 69 + 70 = 207- 6t2scott simpsonunited states69 + 66 + 72 = 207- 6t5larry mizeunited states69 + 67 + 72 = 208- 5t5d a weibringunited states71 + 69 + 68 = 208- 57mark o'mearaunited states71 + 72 + 66 = 209- 48fred couplesunited states72 + 67 + 71 = 210- 39lanny wadkinsunited states70 + 71 + 70 = 211- 210ken greenunited states72 + 70 + 70 = 212- 1\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE player = \"mark o'meara\" AND score = \"71 + 72 + 66 = 209\") = 2 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1454.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: in 1974 republican phil crane beat henry hyde who was a democrat\nInput Table: united states house of representatives elections , 1980\n\n\ndistrictincumbentpartyfirst_electedresultcandidatesillinois 2morgan f murphydemocratic1970-01-01retired democratic holdgus savage (d) 88.2% marsha a harris (r) 11.8%illinois 6henry hyderepublican1974-01-01re - electedhenry hyde (r) 67.0% mario reymond reda (d) 33.0%illinois 7cardiss collinsdemocratic1973-01-01re - electedcardiss collins (d) 85.1% ruth r hooper (r) 14.9%illinois 12phil cranerepublican1969-01-01re - electedphil crane (r) 74.1% david mccartney (d) 25.9%illinois 13robert mccloryrepublican1962-01-01re - electedrobert mcclory (r) 71.7% michael reese (d) 28.3%illinois 15tom corcoranrepublican1976-01-01re - electedtom corcoran (r) 76.7% john p quillin (d) 23.3%illinois 19tom railsbackrepublican1966-01-01re - electedtom railsback (r) 73.4% thomas j hand (d) 26.6%illinois 20paul findleyrepublican1960-01-01re - electedpaul findley (r) 56.0% david robinson (d) 44.0%\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT party FROM table_sql WHERE district = 'illinois 12' AND incumbent = 'phil crane') = 'republican' \n             AND (SELECT party FROM table_sql WHERE district = 'illinois 6' AND incumbent = 'henry hyde') = 'democratic' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1243.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: episode number 10 of the season had bcw410 as a production code and an air date of september 11 , 2012\nInput Table: list of white collar episodes\n\n\nno_in_seriesno_in_seasontitledirected_bywritten_byus_viewers_(million)original_air_dateproduction_code471wantedpaul holahanjeff eastin3.212012-07-10bcw401482most wantedpaul holahanmark goffman2.982012-07-17bcw402493diminishing returnsstefan schwartzjim campolongo3.012012-07-24bcw403504parting shotsrobert duncan mcneillalexandra mcnally2.822012-07-31bcw404515honor among thievesarlene sanfordjoe henderson2.932012-08-14bcw405526identity crisisdavid straitonchanning powell3.892012-08-21bcw406537compromising positionspaul holahanmatthew negrete3.362012-08-28bcw407548ancient historyrussell lee finedaniel shattuck3.382012-09-04bcw408559gloves offrenny harlinmark goffman3.82012-09-11bcw4095610vested interestrussell lee finejeff eastin3.412012-09-18bcw4105711family businesspaul holahanjoe henderson2.772013-01-22bcw4115812brass tacksanton cropperjim campolongo & alexandra mcnally2.612013-01-29bcw4125913empire citytim dekaychanning powell & daniel shattuck2.282013-02-05bcw4136014shoot the moonrussell lee finematthew negrete & bob derosa2.422013-02-19bcw4146115the originaljohn kretchmermark goffman2.122013-02-26bcw415\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE no_in_season = 10 \nAND production_code = 'bcw410' \nAND original_air_date = '2012-09-11';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1426.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the gap between first and last was less than 50 points\nInput Table: 1976 world junior figure skating championships\n\n\nranknamenationsp_+_fspointsplaces1mark cockerellunited states1172.4211.02takashi murajapan2165.724.03brian pockarcanada3166.6223.04norbert schrammwest germany4159.840.05andrew bestwickunited kingdom5158.148.06stephan brilwest germany7155.7257.07patrice macrezfrance6151.7671.08pierre laminefrance8150.579.09shinji someyajapan10150.3474.510jozef sabov\u010d\u00edkczechoslovakia9148.8887.011daniel fuererswitzerland13146.1892.512gerald schranzaustria11143.04102.013helmut kristofics - binderaustria15137.32123.014michael pasfieldaustralia12136.6119.015francis demarteaubelgium14131.02140.016adrian vasileromania16127.74143.017miljan begovicyugoslavia17127.3143.018jeremy dowsonsouth africa18114.98166.019marc franquetbelgium19114.38167.0\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MAX(points) FROM table_sql) - (SELECT MIN(points) FROM table_sql) < 50 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1097.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: seasons 2 and 10 both aired in january , almost exactly one year apart\nInput Table: list of all that episodes\n\n\nseasonseriesepisode_titleoriginal_air_datenick_prod138tia & tamera mowry / ll cool j1996-11-16338239montell jordan1996-11-23339441dru hill1996-12-07341542tyra banks / blackstreet1996-12-14342643music special1996-12-17343744a tribe called quest1996-12-213448457021996-12-28345946tony! toni! tone!1997-01-043461047chris farley / mint condition1997-01-1134711481121997-01-183481249sherman hemsley / nas1997-01-253491350john leguizamo / mona lisa1997-02-013501451ray j1997-02-083511552for real1997-09-203521653aaliyah1997-10-043531754az yet1997-09-273541855monica1997-10-113551956mc lyte1997-10-18356\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE season = 2 AND strftime('%m', original_air_date) = '01') > 0 \n             AND (SELECT COUNT(*) FROM table_sql WHERE season = 10 AND strftime('%m', original_air_date) = '01') > 0 \n             AND (SELECT strftime('%Y', original_air_date) FROM table_sql WHERE season = 2) = \n                 (SELECT strftime('%Y', original_air_date, '-1 year') FROM table_sql WHERE season = 10) \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-719.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: carlos cu\u00e9llar had the lowest transfer fee of any player at 7.8 m\nInput Table: 2008 - 09 rangers f.c. season\n\n\nnatnamemoving_totypetransfer_windowtransfer_feesconicholas gallacher9999-01-01end of contract9999-06-01n / aivory coastlacine cherif9999-01-01end of contract9999-06-01n / ascoalistair park9999-01-01end of contract9999-06-01n / aengmichael donald9999-01-01end of contract9999-06-01n / ascocalum reidford9999-01-01end of contract9999-06-01n / ascochris smith9999-01-01end of contract9999-06-01n / abeljeroen van den broeck9999-01-01end of contract9999-06-01n / aslovakiafilip \u0161ebo9999-01-01transfer9999-06-011 mbelthomas buffel9999-01-01transfer9999-06-01n / aespcarlos cu\u00e9llar9999-01-01transfer9999-06-017.8 mscosteven lennon9999-01-01loan9999-06-01n / ascomark weir9999-01-01loan9999-06-01n / ascoandy webster9999-01-01loan9999-06-01n / arsadean furman9999-01-01loan9999-06-01n / ascoalan lowing9999-01-01loan9999-06-01n / ascopaul emslie9999-01-01loan9999-06-01n / ascoscott gallacher9999-01-01loan9999-06-01n / agabondaniel cousin9999-01-01transfer9999-06-013.5 mscoalan gow9999-01-01loan9999-06-01n / aenglee robinson9999-01-01loan9999-01-01n / ascoandrew shinnie9999-01-01loan9999-01-01n / ascosteven kinniburgh9999-01-01loan9999-01-01n / ascorory loy9999-01-01loan9999-01-01n / ascowilliam mclachlan9999-01-01loan9999-01-01n / ascolee robinson9999-01-01loan9999-01-01n / afrajean - claude darcheville9999-01-01transfer9999-01-01freescojordan mcmillan9999-01-01loan9999-01-01n / ascochris burke9999-01-01transfer9999-01-01freecypgeorgios efrem9999-01-01loan9999-01-01n / ascoalan gow9999-01-01loan9999-01-01n / ascocharlie adam9999-01-01loan9999-01-01n / ascoross harvey9999-01-01loan9999-01-01n / ascosteven kinniburgh9999-01-01loan9999-01-01n / a\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MIN(transfer_fee) FROM table_sql WHERE type = 'transfer') = 7.8 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-179.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: herb estes has 708 rebounds\nInput Table: none\n\n\nrankplayeryearsgamesreb_avgtotal_rebounds1jim nowers1972-01-01 - 1976-01-011129.410482kenny sanders1985-01-01 - 1989-01-011079.610263will thomas2004-01-01 - 2008-01-011317.69934george evans1997-01-01 - 2001-01-011168.29535robert dykes1987-01-01 - 1991-01-011227.59256andre gaddy1977-01-01 - 1982-01-01989.39167jai lewis2002-01-01 - 2006-01-011257.28958rob rose1982-01-01 - 1986-01-011137.18059herb estes1973-01-01 - 1976-01-01809.273410jesse young1999-01-01 - 2003-01-011156.2708\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT total_rebounds FROM table_sql WHERE player = 'herb estes') = 708 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1391.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: galloway & upper nithsdal winning party 2003 is liberal democrats while that of paisley south is labour\nInput Table: scottish parliament general election , 2007\n\n\nrankconstituencywinning_party_2003swing_to_gainsnp_'s_place_2003result1galloway & upper nithsdaleconservative0.172ndcon hold2tweeddale , ettrick & lauderdaleliberal democrats1.012ndld hold3cumbernauld & kilsythlabour1.072ndlab hold4kilmarnock & loudounlabour1.922ndsnp gain5dundee westlabour2.132ndsnp gain6western isleslabour2.912ndsnp gain7glasgow govanlabour2.922ndsnp gain8aberdeen centrallabour2.962ndlab hold9linlithgowlabour3.562ndlab hold10west renfrewshirelabour4.412ndlab hold11paisley southlabour4.912ndlab hold\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT winning_party_2003 FROM table_sql WHERE constituency = 'galloway & upper nithsdale') = 'liberal democrats' \n             AND (SELECT winning_party_2003 FROM table_sql WHERE constituency = 'paisley south') = 'labour' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1979.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the cleveland browns have tied a total of twelve games\nInput Table: list of cleveland browns starting quarterbacks\n\n\nquarterbackuniform_no_(s)games_startedwinslossestieswinning_pctsipe , brian1711257550589.0kosar , bernie1910553511595.0ryan , frank137652222697.0graham , otto60 , 147157131810.0couch , tim25922370373.0nelsen , bill165134161676.0phipps , mike155124252490.0plum , milt165133162667.0anderson , derek33416180471.0testaverde , vinny123116150516.0mcdonald , paul16218130381.0mccoy , colt12216150286.0frye , charlie9196130316.0weeden , brandon3195140263.0o'connell , tommy15141031750.0holcomb , kelly1012480333.0quinn , brady1012390250.0ninowski , jim15 , 1111560455.0dilfer , trent811470364.0garcia , jeff510370300.0danielson , gary188530625.0tomczak , mike188440500.0pederson , doug188170125.0pagel , mike107250286.0wallace , seneca67160143.0ratterman , george12 , 165230400.0philcox , todd175230400.0delhomme , jake174220500.0mays , dave104130250.0zeier , eric104130250.0mccown , luke1240400.0parilli , babe183120333.0rypien , mark113210667.0dorsey , ken1130300.0hoyer , brian633001.0strock , don1222001.0christensen , jeff112110500.0detmer , ty1120200.0campbell , jason172110500.0gault , don1111001.0lane , gary1510100.0dawson , len1811001.0wynn , spergon1310100.0luck , terry710100.0cureton , will1610100.0gradkowski , bruce710100.0lewis , thaddeus910100.0\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT SUM(ties) FROM table_sql) = 12 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1377.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: qatar is ranked 8th in the middle east for gdp\nInput Table: list of asian and pacific countries by gdp (ppp)\n\n\nrank_mideastrank_asiarank_worldcountry2011_gdp_(ppp)_billions_of_usd1617iran930.2362923saudi arabia677.66331848united arab emirates261.18941950israel235.44652155qatar181.91262258kuwait150.00272360iraq127.34882666syria107.80392976oman81.005103083yemen63.344113184lebanon61.738123597jordan36.8971337104bahrain30.889\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT rank_mideast FROM table_sql WHERE country = 'qatar') = 8 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1115.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: denni neufeld is listed as a second for winnipeg\nInput Table: 2009 canadian olympic curling trials\n\n\nskipthird_/_vice_skipsecondleadcitykerry burtnykdon walchukrichard daneaultgarth smithwinnipegpat simmonsgerry adamjeff sharpsteve laycockdavidsonjeff stoughtonkevin parkrob fowlersteve gouldwinnipegwayne middaughjon meadjohn eppingscott baileyislingtonbrad gushuemark nicholsryan fryjamie korabst john 'smike mcewenb j neufeldmatt wozniakdenni neufeldwinnipegjoel jordisonscott bitzaryn schmidtdean hickemoose jawbob urseljim cotterkevin folkrick sawatskykelownajean - michel m\u00e9nardmartin cr\u00eate\u00e9ric sylvainjean gagnonl\u00e9visted appelmantom appelmanbradon klassenbrendan melnykedmontongreg mcaulayken maskiewichdeane horningaaron watsonrichmondjason gunnlaugsonjustin richterbraden zawadatyler forrestbeausejour\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE second = 'denni neufeld' \nAND city = 'winnipeg';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-791.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the player on the 1st place has a score of 72 + 66 + 75 = 213\nInput Table: 1998 open championship\n\n\nplaceplayercountryscoreto_par1brian wattsunited states68 + 69 + 73 = 210et2jim furykunited states70 + 70 + 72 = 212+ 2t2mark o'mearaunited states72 + 68 + 72 = 212+ 2t2jesper parneviksweden68 + 72 + 72 = 212+ 25justin rose (a)england72 + 66 + 75 = 213+ 3t6thomas bj\u00e3rndenmark68 + 71 + 76 = 215+ 5t6brad faxonunited states67 + 74 + 74 = 215+ 5t6john hustonunited states65 + 77 + 73 = 215+ 5t6tiger woodsunited states65 + 73 + 77 = 215+ 5t10david duvalunited states70 + 71 + 75 = 216+ 6t10costantino roccaitaly72 + 74 + 70 = 216+ 6t10raymond russellscotland68 + 73 + 75 = 216+ 6t10katsuyoshi tomorijapan75 + 71 + 70 = 216+ 6\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT score FROM table_sql WHERE place = 1) = '72 + 66 + 75 = 213' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-178.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there are zero rebounds with george evans as a player and a rank larger than 8\nInput Table: none\n\n\nrankplayeryearsgamesreb_avgtotal_rebounds1jim nowers1972-01-01 - 1976-01-011129.410482kenny sanders1985-01-01 - 1989-01-011079.610263will thomas2004-01-01 - 2008-01-011317.69934george evans1997-01-01 - 2001-01-011168.29535robert dykes1987-01-01 - 1991-01-011227.59256andre gaddy1977-01-01 - 1982-01-01989.39167jai lewis2002-01-01 - 2006-01-011257.28958rob rose1982-01-01 - 1986-01-011137.18059herb estes1973-01-01 - 1976-01-01809.273410jesse young1999-01-01 - 2003-01-011156.2708\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE player = 'george evans' AND rank > 8 AND total_rebounds = 0) > 0 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1584.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: halloween has production code 2arg09 and was number 47 in the series\nInput Table: modern family (season 2)\n\n\nno_in_seriesno_in_seasontitledirected_bywritten_byoriginal_air_dateproduction_codeus_viewers_(millions)251the old wagonmichael spillerbill wrubel2010-09-222arg0512.67262the kissscott ellisabraham higginbotham2010-09-292arg0411.92273earthquakemichael spillerpaul corrigan & brad walsh2010-10-062arg0111.44284strangers on a treadmillscott ellisdanny zuker2010-10-132arg0211.45295unpluggedmichael spillersteven levitan2010-10-202arg0611.97306halloweenmichael spillerjeffrey richman2010-10-272arg0913.14317chirpmichael spillerdan o 'shannon2010-11-032arg0312.24328manny get your gunmichael spillerteleplay : danny zuker story : christopher lloyd2010-11-172arg1112.09339mother tuckermichael spillerpaul corrigan & brad walsh2010-11-242arg0710.573410dance dance revelationgail mancusoilana wernick2010-12-082arg0811.073511slow down your neighborsgail mancusoilana wernick2011-01-052arg1211.833612our children , ourselvesadam shankmandan o 'shannon & bill wrubel2011-01-122arg1011.123713caught in the actmichael spillersteven levitan & jeffrey richman2011-01-192arg1310.943814bixby 's backchris kochdanny zuker2011-02-092arg1613.163915princess partymichael spillerelaine ko2011-02-162arg1710.574016regrets onlydean parisotabraham higginbotham2011-02-232arg1410.174117two monkeys and a pandabeth mccarthy - millercarol leifer2011-03-022arg1510.114218boys' nightchris kochsteven levitan & jeffrey richman2011-03-232arg2010.94319the musical manmichael spillerpaul corrigan & brad walsh2011-04-132arg199.614420someone to watch over lilymichael spillerbill wrubel2011-04-202arg189.954521mother 's daymichael spillerdan o 'shannon & ilana wernick2011-05-042arg219.94723see you next fallsteven levitandanny zuker2011-05-182arg2410.3\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT no_in_series FROM table_sql WHERE title = 'halloween' AND production_code = '2arg09') = 47 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1704.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: 67 is the pf when ends lost is 40\nInput Table: 2005 tim hortons brier\n\n\nlocaleskipwlpfpaends_wonends_lostblank_endsstolen_endsshot_pctalbertarandy ferbey92905848437986%manitobarandy dutiaume8377694744101379%nova scotiashawn adams8380604741161383%quebecjean - michel m\u00e3nard747769544081580%british columbiadeane horning6572654745181280%ontariowayne middaugh657562424610782%newfoundland and labradorbrad gushue6576694845131079%saskatchewanpat simmons656661434512980%prince edward islandrod macdonald476785415112579%northern ontariomike jakubo38648641489679%new brunswickwade blanchard385683414517878%\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT pf FROM table_sql WHERE ends_lost = 40) = 67 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-622.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: 208.0 is the production code of the episode with series 9\nInput Table: none\n\n\nepisodeseriesepisode_titleoriginal_air_dateproduction_code271return to genesis2008-04-05201282the suspension2008-04-06202293a team reinvented2008-04-12203304the new captain2008-04-13204315the homecoming2008-04-19205326netherball rules!2008-04-20206337doubts within2008-04-26207348rocket 's decent2008-04-27208359the all - stars2008-05-032093610rocket vs sinedd2008-05-042103711the champions stumble2008-05-102113812last stand2008-05-112123913fluxless2008-05-172134014new order2008-07-262144115revelations2008-07-272154216new rules2008-08-022164317open doors2008-08-032174418warren steps in2008-08-092184519the technodroid v3s2008-08-102194620the fallen star2008-08-162204721coach artegor2008-08-172214822rocket , the midfielder2008-08-232224923destiny2008-08-242235024final preparations2008-08-312245125a team unravels2008-08-31225\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN production_code = 208.0 AND series = 9 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE episode = 35;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-291.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: jos\u00e9 couceiro was the head coach in set\u00fabal , and it was manuel machado in guimar\u00e3es , the only time guimar\u00e3es is a city\nInput Table: 2004 - 05 primeira liga\n\n\nclubhead_coachcitystadium2003_-_2004_seasonacad\u00e9mica de coimbrajo\u00e3o carlos pereiracoimbraest\u00e1dio cidade de coimbra13th in the ligabelenensescarlos carvalhallisbonest\u00e1dio do restelo15th in the ligabenficagiovanni trapattonilisbonest\u00e1dio da luz2nd in the ligaboavistajaime pachecoportoest\u00e1dio do bessa - s\u00e9culo xxi8th in the ligabragajesualdo ferreirabragaest\u00e1dio municipal de braga - axa5th in the ligaestoril - praialitosestorilest\u00e1dio ant\u00f3nio coimbra da mota1st in the liga de honragil vicentelu\u00eds camposbarcelosest\u00e1dio cidade de barcelos12th in the ligauni\u00e3o de leiriav\u00edtor pontesleiriaest\u00e1dio dr magalh\u00e3es pessoa10th in the ligapenafielmanuel fernandespenafielest\u00e1dio municipal 25 de abril3rd in the liga de honramar\u00edtimomanuel cajudafunchalest\u00e1dio dos barreiros6th in the liganacionalcasemiro miorfunchalest\u00e1dio da madeira4th in the ligabeira - marmick wadsworthaveiroest\u00e1dio municipal de aveiro11th in the ligamoreirensev\u00edtor oliveiraguimar\u00e3esest\u00e1dio do moreirense9th in the ligaportoluigi delneriportoest\u00e1dio do drag\u00e3o1st in the ligasporting cpjos\u00e9 peseirolisbonest\u00e1dio jos\u00e9 alvalade - s\u00e9culo xxi3rd in the ligario avecarlos britovila do condeest\u00e1dio dos arcos7th in the ligavit\u00f3ria de guimar\u00e3esmanuel machadoguimar\u00e3esest\u00e1dio d afonso henriques14th in the ligavit\u00f3ria de set\u00fabaljos\u00e9 couceiroset\u00fabalest\u00e1dio do bonfim2nd in the liga de honra\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT head_coach FROM table_sql WHERE city = 'set\u00fabal') = 'jos\u00e9 couceiro' \n             AND (SELECT head_coach FROM table_sql WHERE city = 'guimar\u00e3es') = 'manuel machado' \n             AND (SELECT COUNT(*) FROM table_sql WHERE city = 'guimar\u00e3es') = 1 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1298.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: larisa latyna has seven less medals than carl osbum\nInput Table: list of multiple olympic medalists\n\n\nmedal_countdateathletenationsportrecord_medal_event11896-04-06james connollyunited statesathleticstriple jump g11896-04-06alexandre tuff\u00e8refranceathleticstriple jump s11896-04-06ioannis persakisgreeceathleticstriple jump b11896-04-06robert garrettunited statesathleticsdiscus g11896-04-06panagiotis paraskevopoulosgreeceathleticsdiscus s11896-04-06sotirios versisgreeceathleticsdiscus b21896-04-07robert garrettunited statesathleticslong jump s21896-04-07james connollyunited statesathleticslong jump b31896-04-07robert garrettunited statesathleticsshot put g31896-04-09carl schuhmanngermanygymnasticsvault g31896-04-09hermann weing\u00e4rtnergermanygymnasticsvault b41896-04-09hermann weing\u00e4rtnergermanygymnasticspommel horse s51896-04-09hermann weing\u00e4rtnergermanygymnasticsrings s61896-04-09hermann weing\u00e4rtnergermanygymnasticshorizontal bar g61900-07-16robert garrettunited statesathleticsstanding triple jump b61904-09-03ray ewryunited statesathleticsstanding triple jump g71908-07-20ray ewryunited statesathleticsstanding long jump g81908-07-23ray ewryunited statesathleticsstanding high jump g81920-07-29carl osburnunited statesshootingteam 300 m / 600 m military rifle , prone g91920-07-30carl osburnunited statesshooting300 m military rifle , standing g101920-07-31carl osburnunited statesshootingteam free rifle g111924-06-27carl osburnunited statesshooting600 m free rifle s111928-08-03paavo nurmifinlandathletics5000 m s121928-08-04paavo nurmifinlandathletics3000 m steeplechase s121960-09-02edoardo mangiarottiitalyfencingteam foil s131960-09-09edoardo mangiarottiitalyfencingteam \u00e9p\u00e9e g131964-10-21larisa latyninasoviet uniongymnasticsteam g141964-10-21larisa latyninasoviet uniongymnasticsall - around s151964-10-22larisa latyninasoviet uniongymnasticsvault s161964-10-22larisa latyninasoviet uniongymnasticsuneven bars b171964-10-23larisa latyninasoviet uniongymnasticsbalance beam b181964-10-23larisa latyninasoviet uniongymnasticsfloor exercise g182012-07-31michael phelpsunited statesswimming200 m butterfly s192012-07-31michael phelpsunited statesswimming4 x 200 m freestyle g202012-08-02michael phelpsunited statesswimming200 m individual medley g212012-08-03michael phelpsunited statesswimming100 m butterfly g222012-08-04michael phelpsunited statesswimming4 100 m medley relay g\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT medal_count FROM table_sql WHERE athlete = 'larisa latynina') = \n             (SELECT medal_count FROM table_sql WHERE athlete = 'carl osburn') - 7 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1275.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: carmelo anthony was the leading scorer on the nuggets for 10 out of the 13 games played in november\nInput Table: 2009 - 10 denver nuggets season\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord39999-11-01grizzliesw 133 - 123 (ot)carmelo anthony (42)nen\u00ea (9)chauncey billups (12)pepsi center 158233 - 049999-11-03pacersw 111 - 93 (ot)carmelo anthony (25)nen\u00ea (13)anthony carter (5)conseco fieldhouse 106274 - 059999-11-04netsw 122 - 94 (ot)ty lawson (23)kenyon martin (10)chauncey billups (5)izod center 153195 - 079999-11-07hawksl 100 - 125 (ot)carmelo anthony (30)chris andersen (11)chauncey billups (7)philips arena 178015 - 289999-11-10bullsw 90 - 89 (ot)carmelo anthony (20)nen\u00ea (12)chauncey billups (6)united center 214096 - 299999-11-11bucksl 102 - 108 (ot)carmelo anthony (32)carmelo anthony (10)chauncey billups , ty lawson (5)bradley center 129876 - 3109999-11-13lakersw 105 - 79 (ot)carmelo anthony (25)chris andersen (11)chauncey billups (8)pepsi center 191417 - 3119999-11-17raptorsw 130 - 112 (ot)carmelo anthony (32)nen\u00ea (10)chauncey billups (10)pepsi center 164468 - 3129999-11-20clippersl 99 - 106 (ot)carmelo anthony (37)nen\u00ea (12)chauncey billups (7)staples center 181558 - 4139999-11-21bullsw 112 - 93 (ot)carmelo anthony (30)carmelo anthony , kenyon martin (11)carmelo anthony (7)pepsi center 193599 - 4149999-11-24netsw 101 - 87 (ot)carmelo anthony (27)nen\u00ea (9)chauncey billups (7)pepsi center 1630710 - 4159999-11-25timberwolvesw 124 - 111 (ot)carmelo anthony (22)nen\u00ea (8)nen\u00ea , ty lawson (6)target center 1310111 - 4169999-11-27knicksw 128 - 125 (ot)carmelo anthony (50)nen\u00ea , kenyon martin (11)chauncey billups (8)pepsi center 1915512 - 4\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE high_points = (SELECT MAX(high_points) FROM table_sql WHERE team = 'nuggets' AND date LIKE '9999-11%')) = 10 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-948.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: mirko vu\u010dini\u0107 didn't score any goals in a debut year later than 2008\nInput Table: football records in italy\n\n\nrankall_-_time_ranknamedebut_yearcurrent_clubgoalsapps12francesco totti1992-01-01roma230543211antonio di natale2002-01-01udinese180368316alberto gilardino1999-01-01genoa164425453luca toni2000-01-01verona114258577antonio cassano1999-01-01parma99334681giampaolo pazzini2004-01-01milan95275681mirko vu\u010dini\u01072000-01-01juventus95298897diego milito2008-01-01inter86145897sergio pellissier2002-01-01chievo8633310n / aamauri2000-01-01parma76292\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT goals FROM table_sql WHERE name = 'mirko vu\u010dini\u0107' AND debut_year > '2008-01-01') = 0 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-674.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: game number 72 on march 28 was against cleveland with a score of w 94 - 80 (ot)\nInput Table: 2001 - 02 toronto raptors season\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord609999-03-01portlandl 81 - 91 (ot)vince carter (25)antonio davis , hakeem olajuwon (8)chris childs (7)air canada centre 1980029 - 31619999-03-03philadelphial 84 - 96 (ot)antonio davis (26)antonio davis (9)alvin williams (6)air canada centre 1980029 - 32629999-03-05houstonl 109 - 112 (ot)vince carter (43)vince carter , hakeem olajuwon (7)alvin williams (9)compaq center 1422129 - 33639999-03-07dallasl 103 - 122 (ot)vince carter (19)keon clark , antonio davis (15)alvin williams (7)american airlines center 1994529 - 34640000-03-08miamiw 83 - 74 (ot)antonio davis (23)antonio davis (10)chris childs (6)american airlines arena 1650030 - 34659999-03-10orlandol 79 - 92 (ot)vince carter (16)antonio davis (12)chris childs (7)td waterhouse centre 1617130 - 35669999-03-12new jerseyl 84 - 86 (ot)antonio davis (27)antonio davis , jerome williams (13)vince carter (4)continental airlines arena 1610530 - 36670000-03-17sacramentol 113 - 116 (ot)vince carter (22)hakeem olajuwon (13)chris childs (7)air canada centre 1980030 - 37689999-03-19minnesotal 80 - 112 (ot)morris peterson (19)antonio davis (13)alvin williams (7)target center 1701030 - 38699999-03-22clevelandw 94 - 80 (ot)morris peterson (18)keon clark (10)alvin williams (4)gund arena 1784731 - 38709999-03-24washingtonw 92 - 91 (ot)morris peterson (26)antonio davis (9)alvin williams (9)air canada centre 1980032 - 38719999-03-27miamiw 81 - 80 (ot)morris peterson (21)antonio davis , jerome williams (10)chris childs (6)air canada centre 1980033 - 38729999-03-28atlantaw 85 - 83 (ot)antonio davis , morris peterson (15)antonio davis (9)chris childs (7)philips arena 1203634 - 38739999-03-31philadelphiaw 72 - 70 (ot)antonio davis (16)jerome williams (9)chris childs (9)first union center 2065035 - 38\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE game = 72 \nAND date = '9999-03-28' \nAND team = 'cleveland' \nAND score = 'w 94 - 80 (ot)';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1856.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: in 2009 , when the girls doubles is anneke feinya agustin and wenny setiawati , the mixed doubles is wifqi windarto and debby susanto\nInput Table: indonesian national badminton championships\n\n\nyearboys_singlesgirls_singlesboys_doublesgirls_doublesmixed_doubles2001holvy de pauwmaria kristin yuliantihendra setiawan joko riyadililyana natsir natalia poluakanhendra setiawan greysia polii2002andre kurniawan tedjonofransisca ratnasariujang suherlan yoga ukikasahpurwati meiliana jauharimuhammad rijal meiliana jauhari2003alamsyah yunuswiwis meilyannafran kurniawan chandra kowipia zebadiah nitya krishinda maheswarifran kurniawan yulianti2004andre kurniawan tedjonopia zebadiahaditya dwi putra i made agungpia zebadiah nitya krishinda maheswarilingga lie yulianti2005achmad rivaibellaetrix manuputtyrio willianto davin prawidssalily siswanti shendy puspa irawatiabdul rahman richi puspita dili2006nugroho andi saputrosylvinna kurniawandanny bawa chrisnanta afiat yuris wirawanbellaetrix manuputty samantha lintangdanny bawa chrisnanta debby susanto2007nandang ariflindaweni fanetribudi hartono yohanes rendy sugiartoanneke feinya agustin wenny setiawatiwifqi windarto debby susanto2008hermansyahana rovitadidit juang indrianto seiko wahyu kusdiantosuci rizki andini tiara rosalia nuraidahirfan fadhilah weni anggraeni2009riyanto subagjaana rovitajones ralfy jansen dandi prabuditaayu pratiwi anggi widiadidit juang indrianto yayu rahayu2010shesar hiren rhustavitoganis nur rahmadanijones ralfy jansen dandi prabuditaaris budiharti dian fitrianijones ralfy jansen nurbeta kwanrico\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT mixed_doubles FROM table_sql WHERE year = 2009 AND girls_doubles = 'anneke feinya agustin' AND mixed_doubles = 'wifqi windarto debby susanto') = 'wifqi windarto debby susanto' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-984.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: 2010 - 2011 details is the season had kanto gakuin university as the winner , with an attendance of n / a , and a title of 37th\nInput Table: all - japan university rugby championship\n\n\ntitleseasonwinnerscorerunner_-_upvenueattendance9999-01-301993-04-019999-01-0141 - 12hoseinational stadium , tokyo , tokyon / a9999-01-311994-05-019999-01-0122 - 17meijinational stadium , tokyo , tokyon / a9999-01-011995-06-019999-01-0143 - 9wasedanational stadium , tokyo , tokyon / a9999-01-331996-07-019999-01-0132 - 22wasedanational stadium , tokyo , tokyon / a9999-01-011997-08-019999-01-0130 - 17meijinational stadium , tokyo , tokyon / a9999-01-351998-09-019999-01-0147 - 28meijinational stadium , tokyo , tokyon / a9999-01-019999-01-019999-01-0142 - 15kanto gakuin universitynational stadium , tokyo , tokyon / a9999-01-372000-01-019999-01-0142 - 15hoseinational stadium , tokyo , tokyon / a9999-01-012001-02-019999-01-0121 - 16wasedanational stadium , tokyo , tokyon / a9999-01-012002-03-019999-01-0127 - 22kanto gakuin universitynational stadium , tokyo , tokyon / a9999-01-012003-04-019999-01-0133 - 7wasedanational stadium , tokyo , tokyon / a9999-01-412004-05-019999-01-0131 - 19kanto gakuin universitynational stadium , tokyo , tokyo354629999-01-012005-06-019999-01-0141 - 5kanto gakuin universitynational stadium , tokyo , tokyo301639999-01-432006-07-019999-01-0133 - 26wasedanational stadium , tokyo , tokyo319549999-01-012007-08-019999-01-0126 - 6keionational stadium , tokyo , tokyo236949999-01-012008-09-019999-01-0120 - 10teikyonational stadium , tokyo , tokyo223449999-01-012009-10-019999-01-0114 - 13tokainational stadium , tokyo , tokyo175699999-01-012010-11-019999-01-0117 - 14wasedanational stadium , tokyo , tokyo254589999-01-012011-12-019999-01-0115 - 12tenrinational stadium , tokyo , tokyo144079999-01-019999-01-019999-01-0139 - 22tsukubanational stadium , tokyo , tokyo20050\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 1 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE season = '2010-11-01' \nAND winner = 'kanto gakuin university' \nAND attendance = 'n / a' \nAND title = '37th';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1575.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: sergio garcia , padraig harrington and charlie wi tied for third place with - 1 to par\nInput Table: 2008 pga championship\n\n\nplaceplayercountryscoreto_par1ben curtisunited states73 + 67 + 68 = 208- 2t2j b holmesunited states71 + 68 + 70 = 209- 1t2henrik stensonsweden71 + 70 + 68 = 209- 1t4sergio garc\u00edaspain69 + 73 + 69 = 211+ 1t4p\u00e1draig harringtonireland71 + 74 + 66 = 211+ 1t4charlie wisouth korea70 + 70 + 71 = 211+ 1t7andr\u00e9s romeroargentina69 + 78 + 65 = 212+ 2t7jeev milkha singhindia68 + 74 + 70 = 212+ 2t9aaron baddeleyaustralia71 + 71 + 71 = 213+ 3t9steve fleschunited states73 + 70 + 70 = 213+ 3t9david tomsunited states72 + 69 + 72 = 213+ 3t9camilo villegascolombia74 + 72 = 67 = 213+ 3\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 1 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE to_par = '- 1' \nAND place LIKE 't%' \nAND player IN ('sergio garc\u00eda', 'p\u00e1draig harrington', 'charlie wi');\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1258.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the philippines and macau have won the same number of gold and silver medals for wushu , but macau has won 4 more bronze medals\nInput Table: wushu at the asian games\n\n\nranknationgoldsilverbronzetotal1china (chn)4373532iran (iri)435123malaysia (mas)31594hong kong (hkg)294155thailand (tha)236116japan (jpn)165127philippines (phi)158148macau (mac)154109south korea (kor)1461110chinese taipei (tpe)13111511myanmar (mya)112412vietnam (vie)0971613indonesia (ina)022414laos (lao)015615india (ind)012316pakistan (pak)011217singapore (sin)005518mongolia (mgl)003319kazakhstan (kaz)002220yemen (yem)0011totaltotal606187208\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT gold FROM table_sql WHERE nation = 'philippines (phi)') = \n             (SELECT gold FROM table_sql WHERE nation = 'macau (mac)') \n        AND (SELECT silver FROM table_sql WHERE nation = 'philippines (phi)') = \n             (SELECT silver FROM table_sql WHERE nation = 'macau (mac)') \n        AND (SELECT bronze FROM table_sql WHERE nation = 'macau (mac)') - \n             (SELECT bronze FROM table_sql WHERE nation = 'philippines (phi)') = 4 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-75.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the geo id for johnstown is 3810340820\nInput Table: list of townships in north dakota\n\n\ntownshipcountypop_(2010)land_(_sqmi_)water_(sqmi)latitudelongitudegeo_idansi_codejacksonsargent3335.8090.046.066276- 97.94553038081404601036797james hillmountrail3231.824.24348.423125- 102.42993438061405001037048james river valleydickey4028.5970.046.246641- 98.18832938021405401036767jankelogan2835.9950.16346.415512- 99.13170138047406201037193jeffersonpierce4535.0691.12548.232149- 100.18237038069407001759556jim river valleystutsman3834.1341.74647.112388- 98.77847838093407801036484johnsonwells3635.2990.90847.377745- 99.45867738103408201037137johnstowngrand forks7936.1990.048.151362- 97.44903338035409401036624joliettepembina6770.0440.77148.796545- 97.21722738067410201036723\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN geo_id = 3810340820 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE township = 'johnstown';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-308.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: 1 - 0 was the score when the home team was wimbledon\nInput Table: 1990 - 91 fa cup\n\n\ntie_nohome_teamscoreaway_teamdate1liverpool2 - 2brighton & hove albion1991-01-26replaybrighton & hove albion2 - 3liverpool1991-01-302notts county2 - 0oldham athletic1991-01-263crewe alexandra1 - 0rotherham united1991-01-264luton town1 - 1west ham united1991-01-26replaywest ham united5 - 0luton town1991-01-305woking0 - 1everton1991-01-276shrewsbury town1 - 0wimbledon1991-01-267newcastle united2 - 2nottingham forest1991-02-13replaynottingham forest3 - 0newcastle united1991-02-188tottenham hotspur4 - 2oxford united1991-01-269coventry city1 - 1southampton1991-01-26replaysouthampton2 - 0coventry city1991-01-2910portsmouth5 - 1bournemouth1991-01-2611manchester united1 - 0bolton wanderers1991-01-2612norwich city3 - 1swindon town1991-01-2613millwall4 - 4sheffield wednesday1991-01-26replaysheffield wednesday2 - 0millwall1991-01-3014port vale1 - 2manchester city1991-01-2615arsenal0 - 0leeds united1991-01-27replayleeds united1 - 1arsenal1991-01-30replayarsenal0 - 0leeds united1991-02-13replayleeds united1 - 2arsenal1991-02-1616cambridge united2 - 0middlesbrough1991-01-26\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN score = '1 - 0' AND home_team = 'wimbledon' THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1620.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: united states is the country where the player is vijay singh\nInput Table: 2007 fedex cup playoffs\n\n\nUnnamed:_0playercountrypointseventsreset_points1tiger woodsunited states30574131000002vijay singhfiji1912923990003jim furykunited states1669119985004phil mickelsonunited states1603718980005kj choisouth korea1548521975006rory sabbatinisouth africa1354819972507zach johnsonunited states1334119970008charles howell iiiunited states1212621967509brandt snedekerunited states118702596500\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE player = 'vijay singh' \nAND country = 'united states';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1423.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: west germany had two of the top six and won a gold medal\nInput Table: 1976 world junior figure skating championships\n\n\nranknamenationsp_+_fspointsplaces1mark cockerellunited states1172.4211.02takashi murajapan2165.724.03brian pockarcanada3166.6223.04norbert schrammwest germany4159.840.05andrew bestwickunited kingdom5158.148.06stephan brilwest germany7155.7257.07patrice macrezfrance6151.7671.08pierre laminefrance8150.579.09shinji someyajapan10150.3474.510jozef sabov\u010d\u00edkczechoslovakia9148.8887.011daniel fuererswitzerland13146.1892.512gerald schranzaustria11143.04102.013helmut kristofics - binderaustria15137.32123.014michael pasfieldaustralia12136.6119.015francis demarteaubelgium14131.02140.016adrian vasileromania16127.74143.017miljan begovicyugoslavia17127.3143.018jeremy dowsonsouth africa18114.98166.019marc franquetbelgium19114.38167.0\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE nation = 'west germany' AND rank <= 6) >= 2 \n             AND (SELECT COUNT(*) FROM table_sql WHERE nation = 'west germany' AND rank = 1) >= 1 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-470.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: arnold palmer 's place is t3\nInput Table: 1973 u.s. open (golf)\n\n\nplaceplayercountryscoreto_par1gary playersouth africa67 + 70 = 137- 52jim colbertunited states70 + 68 = 138- 4t3jack nicklausunited states71 + 69 = 140- 2t3johnny millerunited states71 + 69 = 140- 2t3bob charlesnew zealand71 + 69 = 140- 2t6gene borekunited states77 + 65 = 142et6julius borosunited states73 + 69 = 142et6tom weiskopfunited states73 + 69 = 142et6arnold palmerunited states71 + 71 = 142et6lee trevinounited states70 + 72 = 142e\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN place = 't3' AND player = 'arnold palmer' THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-792.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the player from united states has a score of 68 + 71 + 76 = 215\nInput Table: 1998 open championship\n\n\nplaceplayercountryscoreto_par1brian wattsunited states68 + 69 + 73 = 210et2jim furykunited states70 + 70 + 72 = 212+ 2t2mark o'mearaunited states72 + 68 + 72 = 212+ 2t2jesper parneviksweden68 + 72 + 72 = 212+ 25justin rose (a)england72 + 66 + 75 = 213+ 3t6thomas bj\u00e3rndenmark68 + 71 + 76 = 215+ 5t6brad faxonunited states67 + 74 + 74 = 215+ 5t6john hustonunited states65 + 77 + 73 = 215+ 5t6tiger woodsunited states65 + 73 + 77 = 215+ 5t10david duvalunited states70 + 71 + 75 = 216+ 6t10costantino roccaitaly72 + 74 + 70 = 216+ 6t10raymond russellscotland68 + 73 + 75 = 216+ 6t10katsuyoshi tomorijapan75 + 71 + 70 = 216+ 6\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT score FROM table_sql WHERE player = 'united states' AND country = 'united states') = '68 + 71 + 76 = 215' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1737.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: 62936 was the highest attendance for the whole week\nInput Table: 1970 new york giants season\n\n\nweekdateopponentresultgame_siteattendance11970-09-19chicago bearsl 24 - 16yankee stadium6293621970-09-27dallas cowboysl 28 - 10cotton bowl5723631970-10-04new orleans saintsl 14 - 10tulane stadium6912641970-10-11philadelphia eaglesw 30 - 23yankee stadium6282051970-10-18boston patriotsw 16 - 0harvard stadium3909161970-10-25st louis cardinalsw 35 - 17yankee stadium6298471970-11-01new york jetsw 22 - 10shea stadium6390381970-11-08dallas cowboysw 23 - 20yankee stadium6293891970-11-15washington redskinsw 35 - 33yankee stadium62915101970-11-23philadelphia eaglesl 23 - 20franklin field59117111970-11-29washington redskinsw 27 - 24robert f kennedy memorial stadium50415121970-12-06buffalo billsw 20 - 6yankee stadium62870131970-12-13st louis cardinalsw 34 - 17busch memorial stadium50845141970-12-20los angeles ramsl 31 - 3yankee stadium62870\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN MAX(attendance) = 62936 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-367.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there was 3 running back positions picked by the 6th round\nInput Table: indianapolis colts draft history\n\n\nroundpickoverallnamepositioncollege155curtis dickeyrunning backtexas a&m12424derrick hatchettcornerbacktexas2432ray donaldsoncentergeorgia22351tim foleyoffensive tacklenotre dame4588ray butlerwide receiverusc66144chris footecenterusc75170wes robertsdefensive endtcu82195ken walteroffensive tackletexas tech96227mark brightrunning backtemple105254larry stewartoffensive tacklemaryland113280ed whitleytight endkansas state126311randy bielskiplacekickertowson1219324marvin simsfullbackclemson\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 3 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE position = 'running back' \nAND round <= 6;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1489.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the last 4 games in season 5 were held in los angeles and london\nInput Table: tsuyoshi fujita\n\n\nseasonevent_typelocationformatdaterank1997 - 98nationalstokyospecial1998-07-0441998 - 99grand prixkyotolimited1999-01-1641998 - 99apac region championshipsingaporespecial1999-03-2731999 - 00grand prixtaipeiextended2000-02-1222000 - 01grand prixkyotoextended2000-11-1212000 - 01grand prixhiroshimalimited2001-01-2762000 - 01pro tourtokyoblock constructed2001-03-1622001 - 02grand prixhong konglimited2001-11-1732001 - 02masterssan diegostandard2002-01-1172001 - 02grand prixfukuokalimited2002-02-1662001 - 02grand prixnagoyateam limited2002-05-1142002 - 03grand prixutsunomiyalimited2002-10-1232002 - 03grand prixhiroshimaextended2003-01-2572002 - 03grand prixbangkokstandard2003-07-1212003 - 04nationalsosakaspecial2004-06-1112003 - 04grand prixkuala lumpurstandard2004-07-2442005grand prixseattleextended2005-03-0572005invitationallos angelesspecial2005-05-1722005pro tourlondonbooster draft2005-07-0822005pro tourlos angelesextended2005-10-2852011pro tournagoyablock constructed and booster draft2011-06-105\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE season = '2011' AND location = 'los angeles') + \n             (SELECT COUNT(*) FROM table_sql WHERE season = '2011' AND location = 'london') = 4 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-511.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: sidney r yates of illinois 10 was elected as incumbent from republican party in 1964\nInput Table: united states house of representatives elections , 1974\n\n\ndistrictincumbentpartyfirst_electedresultcandidatesillinois 3robert p hanrahanrepublican1972-01-01lost re - election democratic gainmarty russo (d) 52.6% robert p hanrahan (r) 47.4%illinois 4ed derwinskirepublican1958-01-01re - electeded derwinski (r) 59.2% ronald a rodger (d) 40.8%illinois 6harold r collierrepublican1956-01-01retired republican holdhenry hyde (r) 53.4% edward v hanrahan (d) 46.6%illinois 9sidney r yatesdemocratic1964-01-01re - electedsidney r yates (d) unopposedillinois 10samuel h youngrepublican1972-01-01lost re - election democratic gainabner j mikva (d) 50.9% samuel h young (r) 49.1%illinois 12phil cranerepublican1969-01-01re - electedphil crane (r) 61.1% betty c spence (d) 38.9%illinois 19tom railsbackrepublican1966-01-01re - electedtom railsback (r) 65.3% jim gende (d) 34.7%illinois 20paul findleyrepublican1960-01-01re - electedpaul findley (r) 54.8% peter f mack (d) 45.2%illinois 23melvin pricedemocratic1944-01-01re - electedmelvin price (d) 80.5% scott randolph (r) 19.5%\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE district = 'illinois 10' \nAND incumbent = 'sidney r yates' \nAND party = 'republican' \nAND first_elected = '1964-01-01' \nAND result = 're - elected';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-938.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: new jersey was the visiting team when they played against vancouver as the home team\nInput Table: none\n\n\ndatevisitorscorehomerecord9999-02-03ny islanders7 - 2new jersey11 - 32 - 119999-02-05new jersey4 - 5washington11 - 33 - 119999-02-06vancouver4 - 4new jersey11 - 33 - 129999-02-09new jersey4 - 5chicago11 - 34 - 1201-02-12new jersey1 - 5st louis11 - 35 - 1201-02-15minnesota3 - 2new jersey11 - 36 - 129999-02-20new jersey0 - 3philadelphia11 - 37 - 1201-02-21buffalo4 - 4new jersey11 - 37 - 139999-02-24detroit1 - 4new jersey12 - 37 - 139999-02-26new jersey4 - 5pittsburgh12 - 38 - 139999-02-27new jersey2 - 6buffalo12 - 39 - 13\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE visitor = 'new jersey' \nAND home = 'vancouver';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1397.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the final score was 66 - 46 when the temple owls beat virginia tech\nInput Table: 2009 - 10 temple owls men 's basketball team\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord19999-11-14delawarew 76 - 56ryan brooks - 23lavoy allen - 15juan fernandez - 5bob carpenter center , newark , de (3080)1 - 029999-11-17georgetown (19)l 46 - 45allen - 12allen - 14luiz guzman - 6verizon center , washington , dc (8712)1 - 139999-11-21sienaw 73 - 69fernandez - 20allen - 7allen - 5liacouras center , philadelphia , pa (6759)2 - 149999-11-24ball statew 66 - 46brooks - 17allen - 9allen / brooks - 7liacouras center , philadelphia , pa (3597)3 - 159999-11-27virginia techw 61 - 50allen - 18allen - 10fernandez - 6palestra , philadelphia , pa (3750)4 - 1\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT score FROM table_sql WHERE team = 'temple owls' AND game = 4) = 'w 66 - 46' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1666.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: three of the people tied for fifth place are from the united states\nInput Table: 1989 u.s. open (golf)\n\n\nplaceplayercountryscoreto_parmoney1curtis strangeunited states71 + 64 + 73 + 70 = 278- 2200000t2chip beckunited states71 + 69 + 71 + 68 = 279- 167823t2mark mccumberunited states70 + 68 + 72 + 69 = 279- 167823t2ian woosnamwales70 + 68 + 73 + 68 = 279- 1678235brian claarunited states71 + 72 + 68 + 69 = 280e34345t6masashi ozakijapan70 + 71 + 68 + 72 = 281+ 128220t6scott simpsonunited states67 + 70 + 69 + 75 = 281+ 1282208peter jacobsenunited states71 + 70 + 71 + 70 = 282+ 224307t9paul azingerunited states71 + 72 + 70 + 70 = 283+ 319968t9hubert greenunited states69 + 72 + 74 + 68 = 283+ 319968t9tom kiteunited states67 + 69 + 69 + 78 = 283+ 319968t9jos\u00e9 mar\u00eda olaz\u00e1balspain69 + 72 + 70 + 72 = 283+ 319968\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 3 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE place = '5' \nAND country = 'united states';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1469.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: natalia strelkova is not the female losing the skating championship\nInput Table: 1979 world figure skating championships\n\n\nranknamenationsp_+_fspointsplaces1linda fratianneunited states1186.92112anett p\u00f6tzscheast germany3184.36183emi watanabejapan4180.52314dagmar lurzwest germany6179.96335denise biellmannswitzerland2177.28496lisa - marie allenunited states5176.68547claudia kristofics - binderaustria7175.44638susanna drianoitaly9173.46709carola wei\u00dfenbergeast germany11170.548810kristiina wegeliusfinland15169.269811carrie rughunited states10169.349712sanda dubrav\u010di\u0107yugoslavia8166.9611513natalia strelkovasoviet union16164.9413414deborah cottrillunited kingdom20164.813615karin riedigerwest germany17164.514216renata baierovaczechoslovakia13164.014417petra ernertwest germany14163.2414918kira ivanovasoviet union12164.0214719janet morrisseycanada18162.0416220reiko kobayashijapan21161.317021jeanne chapmannorway19161.816622anita siegfriedswitzerland26150.3420723astrid jansen in de walnetherlands25149.1821624franca bianconiitaly22149.0421825bodil olssonsweden23147.0222526corine wyrschswitzerland27146.7623327kim myo silnorth korea24145.4823728belinda coulthardaustralia28145.9223829katie symmondsnew zealand29134.5826130shin hae sooksouth korea30120.4427031gloria masspain31112.28279\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT name FROM table_sql WHERE rank = 13) != 'natalia strelkova' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-768.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: 2 is the fewest points that roger dutton / tony wright received\nInput Table: 1972 isle of man tt\n\n\nplaceridercountrymachinespeedtimepoints1siegfried schauzu / wolfgang kalauchwest germanybmw91.85 mph1:13.57.2152heinz luthringshauser / jcusnikwest germanybmw91.70 mph1:14.04.6123gerry boret / nick boretunited kingdomkonig84.43 mph1:20.27.4104wklenk / nscheererwest germanybmw83.62 mph1:21.31.885barry dungworth / rwturringtonunited kingdombmw82.32 mph1:22.30.666roy hanks / jpmannunited kingdombsa80.07 mph1:24.49.657rwoodhouse / dwoodhouseunited kingdombsa79.83 mph1.25.05.4048roger dutton / tony wrightunited kingdombmw79.63 mph1.25.18.039george o'dell / bill boldisonunited kingdombsa79.60 mph1.25.20.2210jbarker / amacfadzeanunited kingdombsa79.52 mph1.25.28.21\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT points FROM table_sql WHERE rider = 'roger dutton / tony wright') = 2 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1527.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: collingwood 's home opponent was st kilda\nInput Table: 1969 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddategeelong16.14 (110)hawthorn14.11 (95)kardinia park315691969-08-23collingwood19.15 (129)south melbourne6.22 (58)victoria park194281969-08-23carlton20.7 (127)richmond24.12 (156)princes park276571969-08-23st kilda21.18 (144)north melbourne8.10 (58)moorabbin oval111091969-08-23melbourne14.13 (97)fitzroy14.15 (99)mcg177901969-08-23footscray14.10 (94)essendon12.10 (82)western oval160431969-08-23\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE home_team = 'collingwood' \nAND away_team = 'st kilda';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1909.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the teams in the first 2 positions held a different amount of points with the 2nd falling behind by 2\nInput Table: 1940 in brazilian football\n\n\npositionteampointsplayedagainstdifference1flamengo1381282fluminense13815103corinthians981544palestra it\u00e1lia881935portuguesa7823- 106botafogo682507vasco da gama6819- 28am\u00e9rica6825- 109s\u00e3o paulo4824- 13\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT points FROM table_sql WHERE position = 1) != (SELECT points FROM table_sql WHERE position = 2) - 2 \n        THEN 'FALSE' \n        ELSE 'TRUE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1639.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: l 72 - 86 results has a seed less than 12 and a year thats larger than 1996\nInput Table: vcu rams men 's basketball\n\n\nyearrecordseedregionresults198018 - 1212eastl 72 - 86198124 - 55eastw 85 - 69 l 56 - 58 ot198324 - 75eastw 76 - 67 l 54 - 56198423 - 76eastw 70 - 69 l 63 - 78198526 - 62westw 81 - 65 l 59 - 63199624 - 912southeastl 51 - 58200423 - 813eastl 78 - 79200728 - 711westw 79 - 77 l 79 - 84 ot200924 - 1011eastl 64 - 65201128 - 1211southwestw 59 - 46 w 74 - 56 w 94 - 76 w 72 - 71 ot w 71 - 61 l 62 - 70201229 - 712midwestw 62 - 59 l 61 - 63201327 - 95southw 88 - 42 l 53 - 78\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT seed FROM table_sql WHERE results = 'l 72 - 86') < 12 \n             AND (SELECT year FROM table_sql WHERE results = 'l 72 - 86') > 1996 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-415.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the male bounder books is no\nInput Table: list of animals of farthing wood characters\n\n\nanimal_namespeciesbookstv_seriesgendertv_seasonsmatefirst_appearancelast_appearancethe great white stagdeeryesyesmale1 , 2 , 3yes (unmentioned)9999-01-019999-01-01the wardenhumanyesyesmale2 , 3n / a9999-01-019999-01-01scarfacefoxyesyes (as a blue fox)male2lady blue (tv) unnamed (books)9999-01-019999-01-01lady bluefoxyes (unnamed)yesfemale2scarface9999-01-019999-01-01measleyweaselnoyesmale2 , 3weasel9999-01-019999-01-01speedyheronyes (unnamed)yesfemale2 , 3whistler9999-01-019999-01-01rangerfoxyesyesmale2 , 3charmer9999-01-019999-01-01bounderfoxyes (unnamed)yesmale2unknown9999-01-019999-01-01hurkelbadgernoyesmale3shadow9999-01-019999-01-01sinuoussnakeyesyesmale (tv) female (books)3adder9999-01-019999-01-01treydeeryesyesmale3n / a9999-01-019999-01-01lairddeernoyesmale3n / a9999-01-019999-01-01ginger catcatyesyes (as cat)male2 , 3n / a9999-01-019999-01-01bullyratyesyesmale3n / a9999-01-019999-01-01spikeratyesyesmale3n / a9999-01-019999-01-01bratratyesyesmale3n / a9999-01-019999-01-01mateless (mirthful)moleyesyesfemale2mole9999-01-019999-01-01paddocktoadyesyesfemale2toad9999-01-019999-01-01the edible frogsfrogyesyesboth2 , 3multiple pairs9999-01-019999-01-01red squirrelsred squirrelno (other squirrels did appear)yesboth2multiple pairs9999-01-019999-01-01stoatstoatno (others did appear)yesfemale2unknown9999-01-019999-01-01blazefoxyesnomalen / aunknown9999-01-019999-01-01russetfoxyesnofemalen / afriendly9999-01-019999-01-01tripfoxyesnomalen / aunknown9999-01-019999-01-01frondbadgeryesnofemalen / an / a9999-01-019999-01-01the beastcatyesnomalen / aanother giant cat9999-01-019999-01-01scraggratnoyesmale3n / a9999-01-019999-01-01the white deer park volesvolesyesyesboth3multiple pairs9999-01-019999-01-01the large town ratratyesyesmale3n / a9999-01-019999-01-01the white deer park squirrelss squirrelno (others do appear)yesboth3n / a9999-01-019999-01-01the white deer park foxesfoxesyesyes (as blue foxes)both2multiple pairs9999-01-019999-01-01the white deerdeeryesyesboth2 , 3multiple pairs9999-01-019999-01-01\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT gender FROM table_sql WHERE animal_name = 'bounder' AND books = 'yes') = 'male' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1616.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: jerome pineau is the winner for october 9th 's event\nInput Table: 2008 french road cycling cup\n\n\ndateeventwinnerteamseries_leader9999-02-24tour du haut vardavide rebellin ( ita )gerolsteinerrinaldo nocentini ( ita )9999-03-23cholet - pays de loirejanek tombak ( est )mitsubishi - jartazirinaldo nocentini ( ita )9999-04-06grand prix de rennesmikhaylo khalilov ( ukr )ceramica flaminia - bossini doccejimmy casper ( fra )'9999-04-15'paris - camembertalejandro valverde ( esp )caisse d'epargnej\u00e9r\u00f4me pineau ( fra )0000-04-17grand prix de denainedvald boasson hagen ( nor )team high roadjimmy casper ( fra )9999-04-19tour du finist\u00e8redavid lelay ( fra )bretagne - armor luxjimmy casper ( fra )9999-04-20tro - bro l\u00e9onfr\u00e9d\u00e9ric guesdon ( fra )fran\u00e7aise des jeuxjimmy casper ( fra )9999-05-04troph\u00e9e des grimpeursdavid lelay ( fra )bretagne - armor luxdavid lelay ( fra )9999-05-31grand prix de plumelec - morbihanthomas voeckler ( fra )bouygues t\u00e9l\u00e9comdavid lelay ( fra )9999-08-03polynormandearnaud g\u00e9rard ( fra )fran\u00e7aise des jeuxj\u00e9r\u00f4me pineau ( fra )9999-08-31chteauroux classicanthony ravard ( fra )agritubelj\u00e9r\u00f4me pineau ( fra )9999-09-21grand prix d'isbergueswilliam bonnet ( fra )cr\u00e9dit agricolej\u00e9r\u00f4me pineau ( fra )9999-10-05tour de vend\u00e9ekoldo fern\u00e1ndez ( esp )euskaltel - euskadij\u00e9r\u00f4me pineau ( fra )9999-10-09paris - bourgesbernhard eisel ( aut )team columbiaj\u00e9r\u00f4me pineau ( fra )\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT winner FROM table_sql WHERE date = '9999-10-09' AND event = 'paris - bourges') = 'j\u00e9r\u00f4me pineau ( fra )' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-925.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there were 2.4 blocks per game in the selection where not field goal percentage was 594 (2nd)\nInput Table: list of career achievements by dwight howard\n\n\nselectionmonthseasonteam_recordpoints_per_gamefield_goal_percentagerebounds_per_gameblocks_per_game9999-01-012006-04-012005-06-017-218.153114.00.79999-01-022006-10-012006-07-0112-417.157613.61.99999-01-032007-10-012007-08-0114-423.861815.02.79999-01-042007-12-012007-08-018-721.759816.12.99999-01-052010-10-012010-11-0113-421.8 (5th)594 (2nd)12.1 (4th in league)2.4\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE selection = '9999-01-05' \nAND field_goal_percentage != 594 \nAND blocks_per_game = 2.4;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1122.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: all the tournaments listed had an average of 2.5 events\nInput Table: brian watts\n\n\ntournamentwinstop_-_5top_-_25eventscuts_mademasters tournament00021us open00121the open championship01274pga championship00064totals0131710\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT AVG(events) FROM table_sql) = 2.5 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1182.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: athlete visa hongisto from finland was in lane number 9\nInput Table: athletics at the 2008 summer olympics - men 's 200 metres\n\n\nlaneathletenationalitytimereact8paul hessionireland20.320.194wallace spearmonunited states20.390.2026jaysuma saidy ndurenorway20.450.1317rondell sorillotrinidad and tobago20.630.1645ramil guliyevazerbaijan20.660.1743visa hongistofinland20.760.1242thuso mpuangsouth africa21.040.1629marvin andersonjamaicadnf0.187\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE athlete = 'visa hongisto' \nAND nationality = 'finland' \nAND lane = 9;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-956.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the chicago black hawks was the visitor team when the record was 2 - 3 on april 17\nInput Table: 1965 - 66 chicago black hawks season\n\n\ndatevisitorscorehomerecord'9999-04-07'detroit red wings1 - 2chicago black hawks1 - 0'9999-04-10'detroit red wings7 - 0chicago black hawks1 - 1'9999-04-12'chicago black hawks2 - 1detroit red wings2 - 19999-04-14chicago black hawks1 - 5detroit red wings2 - 20000-04-17detroit red wings5 - 3chicago black hawks2 - 39999-04-19chicago black hawks2 - 3detroit red wings2 - 4\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE record = '2 - 3' \nAND date = '0000-04-17' \nAND visitor = 'chicago black hawks';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-964.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the title of the episode that aired in january 28 , 2008 is vietnam hosted by don wildman\nInput Table: cities of the underworld\n\n\nproduction_noepisode_nooriginal_airdateepisode_titlehost152012008-01-28underground apocalypsedon wildman162022008-02-04vietnamdon wildman172032008-02-11a - bomb undergrounddon wildman182042008-02-25viking undergrounddon wildman192052008-03-03hitler 's last secretdon wildman202062008-03-10maya undergrounddon wildman212072008-03-17mob undergrounddon wildman222082008-03-24prophecies from belowdon wildman232092008-03-31new york : secret societiesdon wildman242102008-04-14washington , dc : seat of powerdon wildman252112008-04-21stalin 's secret lairdon wildman262122008-04-28katrina undergrounddon wildman272132008-05-05secret soviet basesdon wildman\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN episode_title = 'vietnam' AND original_airdate = '2008-01-28' AND host = 'don wildman' THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1955.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: less than half the 1984 - 1985 season games were played in the boston garden\nInput Table: 1984 - 85 boston celtics season\n\n\ngamedateopponentscorelocationrecord339999-01-02new jersey nets110 - 95brendan byrne arena27 - 6349999-01-04new york knicks105 - 94boston garden28 - 6359999-01-07new york knicks108 - 97madison square garden29 - 6369999-01-09chicago bulls111 - 108boston garden30 - 6379999-01-11washington bullets103 - 101boston garden31 - 6389999-01-12atlanta hawks119 - 111the omni32 - 6399999-01-16los angeles lakers104 - 102boston garden33 - 6409999-01-18indiana pacers86 - 91market square arena33 - 7419999-01-20philadelphia 76ers113 - 97boston garden34 - 7429999-01-23seattle supersonics97 - 107boston garden34 - 8439999-01-25indiana pacers125 - 94boston garden35 - 8449999-01-27portland trail blazers128 - 127boston garden36 - 8459999-01-29detroit pistons131 - 130hartford civic center37 - 8469999-01-30philadelphia 76ers104 - 122the spectrum37 - 9\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE location = 'boston garden') < (SELECT COUNT(*) FROM table_sql) / 2 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-815.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the games on june 18 and 28 , both had a score of 2 - 0\nInput Table: 1998 in paraguayan football\n\n\ndatevenuescorecompreport1998-02-08estadio defensores del chaco asunci\u00f3n , paraguay4 - 0f4501998-03-14qualcomm stadium san diego , united states2 - 2f4511998-03-18estadio ol\u00edmpico universitario mexico city , mexico1 - 1f4521998-03-28yale bowl new haven , united states1 - 1f4531998-04-22stadio ennio tardini parma , italy3 - 1f4541998-05-17olympic stadium tokyo , japan1 - 1kirin cup4551998-05-21kobe universiade memorial stadium kobe , japan1 - 0kirin cup4561998-06-01philips stadion eindhoven , netherlands5 - 1f4571998-06-03steaua stadium bucharest , romania3 - 2f4581998-06-06king baudouin stadium brussels , belgium1 - 0f4591998-06-12stade de la mosson montpellier , france0 - 0world cupreport1998-06-19stade geoffroy - guichard saint - \u00e9tienne , france0 - 0world cupreport1998-06-24stade de toulouse toulouse , france1 - 3world cupreport1998-06-28stade f\u00e9lix bollaert lens , france0 - 0 ( 1 - 0 aet )world cupreport\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT score FROM table_sql WHERE date = '1998-06-18') = '2 - 0' \n             AND (SELECT score FROM table_sql WHERE date = '1998-06-28') = '2 - 0' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-346.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: golden state , memphis , and new orleans all had the same attendance\nInput Table: 2008 - 09 phoenix suns season\n\n\ngamedateteamlocation_attendancerecord759999-04-01houstonus airways center 1842241 - 34769999-04-03sacramentous airways center 1842242 - 3477'9999-04-05'dallasamerican airlines center 2030142 - 35789999-04-08new orleansnew orleans arena 1778143 - 3579'9999-04-10'memphisfedexforum 1590843 - 36809999-04-11minnesotatarget center 1847844 - 36819999-04-13memphisus airways center 1842245 - 3682'9999-04-15'golden stateus airways center46 - 36\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT location_attendance FROM table_sql WHERE team = 'golden state') = \n             (SELECT location_attendance FROM table_sql WHERE team = 'memphis') \n             AND (SELECT location_attendance FROM table_sql WHERE team = 'golden state') = \n             (SELECT location_attendance FROM table_sql WHERE team = 'new orleans') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1578.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the screening that started on may 3rd , 2006 ended on march 29th , 2006\nInput Table: none\n\n\nscreening_startedscreening_completedchapter_unfrozenchapter_openedchapter_closed2005-11-252005-12-229999-01-012008-12-199999-01-012006-06-212006-07-209999-01-012008-06-179999-01-012006-02-062006-03-039999-01-012008-06-179999-01-012006-06-122006-07-149999-01-012008-12-199999-01-012006-03-092006-04-289999-01-012010-06-309999-01-012006-06-062006-07-129999-01-012009-06-309999-01-012006-02-162006-03-239999-01-019999-01-019999-01-012006-06-192006-07-189999-01-012007-06-259999-01-012006-02-082006-03-229999-01-019999-01-019999-01-012006-03-272006-05-019999-01-012007-03-299999-01-012006-06-302006-09-299999-01-012007-12-199999-01-012006-09-112006-10-102013-02-122013-06-259999-01-012006-09-072006-10-139999-01-019999-01-019999-01-012005-10-202005-11-149999-01-012006-06-122006-06-122006-04-032006-06-029999-01-012009-12-219999-01-012006-06-082006-07-119999-01-012007-12-199999-01-012006-05-182006-06-309999-01-012007-07-269999-01-019999-01-019999-01-019999-01-019999-01-019999-01-01\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN screening_started = '2006-05-03' AND screening_completed = '2006-03-29' THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-200.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: melbourne had the second lowest score when playing as the away team\nInput Table: 1972 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddatefootscray14.7 (91)st kilda9.11 (65)western oval186551972-07-15fitzroy16.14 (110)north melbourne9.12 (66)junction oval70071972-07-15essendon13.12 (90)richmond17.9 (111)windy hill222511972-07-15carlton20.8 (128)south melbourne8.15 (63)princes park144651972-07-15hawthorn19.14 (128)geelong15.8 (98)glenferrie oval124251972-07-15collingwood10.13 (73)melbourne8.10 (58)vfl park308831972-07-15\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT away_team_score FROM table_sql WHERE away_team = 'melbourne' ORDER BY away_team_score ASC LIMIT 1 OFFSET 1) = \n             (SELECT MIN(away_team_score) FROM table_sql) \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-54.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: national university of ireland is the only group of origin made up mostly of members from two parties\nInput Table: members of the 5th seanad\n\n\npartyadministrative_panelagricultural_panelcultural_and_educational_panelindustrial_and_commercial_panellabour_panelnational_university_of_irelanduniversity_of_dublinnominated_by_the_taoiseachtotalfianna f\u00e1il4423010721fine gael132201009labour party000150028clann na talmhan020010003independent010101339total7115911331160\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT total FROM table_sql WHERE national_university_of_ireland = 1) = \n             (SELECT SUM(total) FROM table_sql WHERE party IN ('fianna f\u00e1il', 'fine gael')) \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1142.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: punt road oval was the venue where richmond played as the away team\nInput Table: 1946 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddategeelong15.7 (97)melbourne21.14 (140)kardinia park115001946-07-13essendon16.24 (120)footscray14.8 (92)windy hill290001946-07-13collingwood15.23 (113)hawthorn11.14 (80)victoria park110001946-07-13carlton12.13 (85)south melbourne11.18 (84)princes park260001946-07-13st kilda10.14 (74)north melbourne12.11 (83)junction oval70001946-07-13richmond14.14 (98)fitzroy10.12 (72)punt road oval190001946-07-13\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE venue = 'punt road oval' \nAND away_team = 'richmond';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-297.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the score on 21 / 07 / 07 was 14 to 10 and the home team was bradford\nInput Table: 2007 bradford bulls season\n\n\ndatehome_teamscoreaway_teamgoalsattendancecompetition2007-11-02bradford18 - 14huddersfield giantsdeacon 3 / 412130super league xii0007-02-18warrington wolves20 - 36bradforddeacon 6 / 712607super league xii2007-02-24bradford32 - 28wigan warriorsdeacon 6 / 612798super league xii2007-02-03st helens34 - 22bradforddeacon 3 / 411793super league xii2007-11-03bradford56 - 18salford city redsdeacon 8 / 1010640super league xii0007-03-17harlequins rl22 - 36bradforddeacon 6 / 64011super league xii2007-03-25bradford22 - 29catalans dragonsdeacon 3 / 411298super league xii2007-03-30bradford24 - 16castleford tigersdeacon 4 / 46748rugby league challenge cup2007-05-04bradford14 - 18leeds rhinosdeacon 3 / 516706super league xii2007-09-04wakefield trinity wildcats24 - 36bradforddeacon 6 / 79106super league xii2007-04-15bradford52 - 22hull krdeacon 8 / 910881super league xii2007-04-20hull fc22 - 32bradforddeacon 4 / 612767super league xii2007-04-29bradford36 - 24warrington wolvesdeacon 3 / 3 , i harris 3 / 5 ,11200super league xii2007-06-05bradford38 - 42leeds rhinosdeacon 7 / 726667super league xii0007-05-13wakefield trinity wildcats4 - 14bradforddeacon 1 / 33568rugby league challenge cup0007-05-18huddersfield giants36 - 12bradfordi harris 2 / 28667super league xii2007-05-27bradford44 - 18harlequins rldeacon 6 / 810418super league xii2007-02-06catalans dragons20 - 28bradforddeacon 4 / 57555super league xii2007-10-06bradford52 - 20huddersfield giantsdeacon 8 / 107811rugby league challenge cup0007-06-17bradford34 - 8hull fcdeacon 4 / 6 , vainikolo 1 / 111557super league xii2007-06-29leeds rhinos14 - 38bradforddeacon 7 / 722000super league xii2007-06-07wigan warriors25 - 18bradforddeacon 5 / 515107super league xii0007-07-13bradford10 - 4st helensdeacon 3 / 311217super league xii2007-07-21salford city reds14 - 10bradforddeacon 1 / 23438super league xii2007-07-28bradford16 - 35st helensdeacon 1 / 314316rugby league challenge cup2007-05-08bradford38 - 24wakefield trinity wildcatsburgess 5 / 810701super league xii2007-12-08hull kr10 - 28bradfordi harris 4 / 56695super league xii0007-08-19huddersfield giants26 - 22bradfordharris 5 / 56824super league xii2007-09-02bradford16 - 16leeds rhinosdeacon 2 / 418000super league xii2007-09-09bradford40 - 8catalans dragonsiestyn harris (6 / 7)9350super league xii2007-09-14hull fc20 - 10bradfordi harris (1 / 2)14409super league xii2007-09-21bradford30 - 31wigan warriorsi harris (5 / 6)9000super league xii\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT score FROM table_sql WHERE date = '2007-07-21' AND home_team = 'bradford') = '14 - 10' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1453.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: cardiss collins was first elected as democrat in 1969\nInput Table: united states house of representatives elections , 1980\n\n\ndistrictincumbentpartyfirst_electedresultcandidatesillinois 2morgan f murphydemocratic1970-01-01retired democratic holdgus savage (d) 88.2% marsha a harris (r) 11.8%illinois 6henry hyderepublican1974-01-01re - electedhenry hyde (r) 67.0% mario reymond reda (d) 33.0%illinois 7cardiss collinsdemocratic1973-01-01re - electedcardiss collins (d) 85.1% ruth r hooper (r) 14.9%illinois 12phil cranerepublican1969-01-01re - electedphil crane (r) 74.1% david mccartney (d) 25.9%illinois 13robert mccloryrepublican1962-01-01re - electedrobert mcclory (r) 71.7% michael reese (d) 28.3%illinois 15tom corcoranrepublican1976-01-01re - electedtom corcoran (r) 76.7% john p quillin (d) 23.3%illinois 19tom railsbackrepublican1966-01-01re - electedtom railsback (r) 73.4% thomas j hand (d) 26.6%illinois 20paul findleyrepublican1960-01-01re - electedpaul findley (r) 56.0% david robinson (d) 44.0%\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE first_elected = '1969-01-01' \nAND incumbent = 'cardiss collins' \nAND party = 'democratic';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-239.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: globular cluster has more apparent magnitude than irregular galaxy\nInput Table: list of ngc objects (5001 - 6000)\n\n\nngc_numberobject_typeconstellationright_ascension_(_j2000_)declination_(_j2000_)apparent_magnitude5408irregular galaxycentaurus14h03 m21.0s degree22\u203244\u203314.05457spiral galaxyursa major14h03 m12.5s degree20\u203253\u20338.75466globular clusterbo\u00f6tes14h05 m27.4s degree32\u203204\u203310.55474spiral galaxyursa major14h05 m01.5s degree39\u203245\u203311.95477irregular galaxyursa major14h05 m33.1s degree27\u203240\u203314.5\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT apparent_magnitude FROM table_sql WHERE object_type = 'globular cluster') > \n             (SELECT apparent_magnitude FROM table_sql WHERE object_type = 'irregular galaxy') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1473.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: natalia strelkova came in last place with 112.28 points\nInput Table: 1979 world figure skating championships\n\n\nranknamenationsp_+_fspointsplaces1linda fratianneunited states1186.92112anett p\u00f6tzscheast germany3184.36183emi watanabejapan4180.52314dagmar lurzwest germany6179.96335denise biellmannswitzerland2177.28496lisa - marie allenunited states5176.68547claudia kristofics - binderaustria7175.44638susanna drianoitaly9173.46709carola wei\u00dfenbergeast germany11170.548810kristiina wegeliusfinland15169.269811carrie rughunited states10169.349712sanda dubrav\u010di\u0107yugoslavia8166.9611513natalia strelkovasoviet union16164.9413414deborah cottrillunited kingdom20164.813615karin riedigerwest germany17164.514216renata baierovaczechoslovakia13164.014417petra ernertwest germany14163.2414918kira ivanovasoviet union12164.0214719janet morrisseycanada18162.0416220reiko kobayashijapan21161.317021jeanne chapmannorway19161.816622anita siegfriedswitzerland26150.3420723astrid jansen in de walnetherlands25149.1821624franca bianconiitaly22149.0421825bodil olssonsweden23147.0222526corine wyrschswitzerland27146.7623327kim myo silnorth korea24145.4823728belinda coulthardaustralia28145.9223829katie symmondsnew zealand29134.5826130shin hae sooksouth korea30120.4427031gloria masspain31112.28279\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT rank FROM table_sql WHERE name = 'natalia strelkova') = 31 \n             AND (SELECT points FROM table_sql WHERE name = 'natalia strelkova') = 112.28 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1934.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: besides mickael delage , there were only one other winner in the mountain classifcation\nInput Table: 2010 vuelta a espa\u00f1a\n\n\nstagewinnergeneral_classificationpoints_classificationmountains_classificationcombination_classificationteam_classification1team htc - columbiamark cavendishmark cavendish 1not awardedmark cavendishteam htc - columbia2yauheni hutarovichmark cavendishyauheni hutarovichmicka\u00ebl delagejavier ram\u00edrezteam htc - columbia3philippe gilbertphilippe gilbertphilippe gilbertseraf\u00edn mart\u00ednezseraf\u00edn mart\u00ednezteam htc - columbia4igor ant\u00f3nphilippe gilbertigor ant\u00f3nseraf\u00edn mart\u00ednezvincenzo nibalicaisse d'epargne5tyler farrarphilippe gilbertigor ant\u00f3nseraf\u00edn mart\u00ednezvincenzo nibalicaisse d'epargne6thor hushovdphilippe gilbertphilippe gilbertseraf\u00edn mart\u00ednezphilippe gilbertcaisse d'epargne7alessandro petacchiphilippe gilbertmark cavendishseraf\u00edn mart\u00ednezphilippe gilbertcaisse d'epargne8david moncouti\u00e9igor ant\u00f3nmark cavendishseraf\u00edn mart\u00ednezvincenzo nibalicaisse d'epargne9david l\u00f3pezigor ant\u00f3nmark cavendishdavid moncouti\u00e9vincenzo nibalicaisse d'epargne10imanol ervitijoaquim rodr\u00edguezmark cavendishdavid moncouti\u00e9david moncouti\u00e9caisse d'epargne11igor ant\u00f3nigor ant\u00f3nigor ant\u00f3ndavid moncouti\u00e9igor ant\u00f3ncaisse d'epargne12mark cavendishigor ant\u00f3nmark cavendishdavid moncouti\u00e9igor ant\u00f3ncaisse d'epargne13mark cavendishigor ant\u00f3nmark cavendishdavid moncouti\u00e9igor ant\u00f3ncaisse d'epargne14joaquim rodr\u00edguezvincenzo nibalimark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezcaisse d'epargne15carlos barredovincenzo nibalimark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezteam katusha16mikel nievejoaquim rodr\u00edguezmark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezteam katusha17peter velitsvincenzo nibalimark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezteam katusha18mark cavendishvincenzo nibalimark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezteam katusha19philippe gilbertvincenzo nibalimark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezteam katusha20ezequiel mosquera 2vincenzo nibalimark cavendishdavid moncouti\u00e9vincenzo nibaliteam katusha21tyler farrarvincenzo nibalimark cavendishdavid moncouti\u00e9vincenzo nibaliteam katusha\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 1 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE mountains_classification != 'not awarded' \nAND winner != 'micka\u00ebl delage';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-152.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: in four different baseball games the final score was 9 - 2\nInput Table: 2006 texas rangers season\n\n\ndateopponentscorelossattendancerecord9999-09-01indians7 - 2padilla (13 - 9)2377669 - 679999-09-02indians6 - 5volquez (1 - 4)4022269 - 689999-09-03indians5 - 2byrd1966770 - 689999-09-04athletics8 - 1zito2394971 - 689999-09-05athletics5 - 4saarloos2722572 - 689999-09-06athletics9 - 6rupe (0 - 1)1783872 - 699999-09-08mariners7 - 2millwood (14 - 10)2864672 - 709999-09-09mariners3 - 2rheinecker (4 - 6)3345472 - 719999-09-10mariners4 - 2huber3432173 - 719999-09-12tigers3 - 2mahay (1 - 3)2419673 - 729999-09-13tigers11 - 3verlander2467274 - 729999-09-14angels2 - 1volquez (1 - 5)2148874 - 739999-09-15angels2 - 1francisco (0 - 1)3078874 - 749999-09-16angels12 - 6lackey4019675 - 749999-09-17angels8 - 1santana2430376 - 749999-09-18mariners8 - 1hern\u00e1ndez1821477 - 749999-09-19mariners9 - 7wilson (2 - 3)1855177 - 759999-09-20mariners6 - 3tejeda (4 - 4)2600677 - 769999-09-22indians12 - 4byrd2628478 - 769999-09-23indians6 - 3padilla (14 - 10)3835178 - 779999-09-24indians11 - 6millwood (16 - 11)3661778 - 789999-09-25angels8 - 3volquez (1 - 6)3978178 - 799999-09-26angels5 - 2escobar3733979 - 799999-09-27angels6 - 5wilson (2 - 4)3803279 - 809999-09-29mariners6 - 5fruto3076680 - 809999-09-30mariners3 - 1millwood (16 - 12)2331080 - 819999-10-01mariners3 - 2tejeda (5 - 5)2836180 - 82\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 4 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE score = '9 - 2';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1718.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: before round of 9 involved the name glenn capriola\nInput Table: indianapolis colts draft history\n\n\nroundpickoverallnamepositioncollege12626randy burkewide receiverkentucky22553mike ozdowskidefensive endvirginia624163calvin o'neallinebackermichigan726193blanchard carteroffensive tackleunlv825220ken helmsoffensive tacklegeorgia924247glenn capriolarunning backboston college1026277ron bakerguardoklahoma state1125304brian rufflinebackerthe citadel1224331bill deutschrunning backnorth dakota\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE round < 9 \nAND name = 'glenn capriola';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1405.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: ileyton hewitt has won the masters series two times , in 2004 and 2005\nInput Table: lleyton hewitt\n\n\noutcomeyearchampionshipsurfaceopponentscorerunner - up2000-01-01stuttgarthard (i)wayne ferreira6 - 7 (6 - 8) , 6 - 3 , 7 - 6 (7 - 5) , 6 - 7 (2 - 7) , 2 - 6winner2002-01-01indian wellshardtim henman6 - 1 , 6 - 2runner - up2002-01-01cincinnatihardcarlos moy\u00e15 - 7 , 6 - 7 (5 - 7)runner - up2002-01-01pariscarpet (i)marat safin6 - 7 (4 - 7) , 0 - 6 , 4 - 6winner2003-01-01indian wells (2)hardgustavo kuerten6 - 1 , 6 - 1runner - up2004-01-01cincinnati (2)hardandre agassi3 - 6 , 6 - 3 , 2 - 6runner - up2005-01-01indian wellshardroger federer2 - 6 , 4 - 6 , 4 - 6\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 2 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE outcome = 'winner' \nAND championship LIKE '%masters series%' \nAND year IN ('2004-01-01', '2005-01-01');\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1154.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: gaming alerts asked for the least amount of money\nInput Table: dragons' den (uk)\n\n\nepisodefirst_airedentrepreneur_(s)company_or_product_namemoney_requestedinvesting_dragon_(s)episode 12007-10-15celia norowzian & ian forshewbeach break live50000peter jonesepisode 12007-10-15laban roomesgoldgenie (formerly midas touch)60000james caanepisode 22007-10-22sarah luyoudoodoll35000deborah meadenepisode 22007-10-22emmie matthews & ed stevensgaming alerts200000theo paphitisepisode 32007-10-29mark champkinsconcentrate design100000peter jonesepisode 42007-11-05max mcmurdoreestore50000deborah meaden & theo paphitisepisode 42007-11-05jamie jenkinsoncush'n 'shade100000deborah meaden & peter jonesepisode 52007-11-19shane lake and tony charleshungryhousecouk100000james caan & duncan bannatyneepisode 62007-11-26ian helmoresteri spray145000deborah meaden & theo paphitisepisode 62007-11-26mark and eleanor daviscaribbean ready meals100000james caan & duncan bannatyneepisode 72007-12-03sammy frenchfit fur life100000james caanepisode 72007-12-03jerry mantalvanos & paul merkerjpm eco logistics100000deborah meaden & theo paphitisepisode 82007-12-11peter mouleelectroexpo , chocbox150000duncan bannatyne & james caanepisode 92007-12-18amanda jones & james brownred button design50000all five dragons\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN money_requested = (SELECT MIN(money_requested) FROM table_sql) \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE company_or_product_name = 'gaming alerts';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1422.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: mark cockerell finished with a worse score than partice macrez\nInput Table: 1976 world junior figure skating championships\n\n\nranknamenationsp_+_fspointsplaces1mark cockerellunited states1172.4211.02takashi murajapan2165.724.03brian pockarcanada3166.6223.04norbert schrammwest germany4159.840.05andrew bestwickunited kingdom5158.148.06stephan brilwest germany7155.7257.07patrice macrezfrance6151.7671.08pierre laminefrance8150.579.09shinji someyajapan10150.3474.510jozef sabov\u010d\u00edkczechoslovakia9148.8887.011daniel fuererswitzerland13146.1892.512gerald schranzaustria11143.04102.013helmut kristofics - binderaustria15137.32123.014michael pasfieldaustralia12136.6119.015francis demarteaubelgium14131.02140.016adrian vasileromania16127.74143.017miljan begovicyugoslavia17127.3143.018jeremy dowsonsouth africa18114.98166.019marc franquetbelgium19114.38167.0\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT points FROM table_sql WHERE name = 'mark cockerell') < \n             (SELECT points FROM table_sql WHERE name = 'patrice macrez') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-694.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: paul brown stadium had 65677 in attendance on december 19 , 2004\nInput Table: 2004 cleveland browns season\n\n\nweekdateopponentresultstadiumrecordattendance12004-09-12baltimore ravensw 20 - 3cleveland browns stadium1 - 073068.022004-09-19dallas cowboysl 12 - 19texas stadium1 - 163119.032004-09-26new york giantsl 10 - 27giants stadium1 - 278521.042004-10-03washington redskinsw 17 - 13cleveland browns stadium2 - 273348.052004-10-10pittsburgh steelersl 23 - 34heinz field2 - 363609.062004-10-17cincinnati bengalsw 34 - 17cleveland browns stadium3 - 373263.072004-10-24philadelphia eaglesl 31 - 34cleveland browns stadium3 - 473394.089999-01-01----nan92004-11-07baltimore ravensl 13 - 27m&t bank stadium3 - 569781.0102004-11-14pittsburgh steelersl 10 - 24cleveland browns stadium3 - 673703.0112004-11-21new york jetsl 7 - 10cleveland browns stadium3 - 772547.0122004-11-28cincinnati bengalsl 48 - 58paul brown stadium3 - 865677.0132004-12-05new england patriotsl 15 - 42cleveland browns stadium3 - 973028.0142004-12-12buffalo billsl 7 - 37ralph wilson stadium3 - 1072330.0152004-12-19san diego chargersl 0 - 21cleveland browns stadium3 - 1172489.0162004-12-26miami dolphinsl 7 - 10pro player stadium3 - 1273169.0172005-01-02houston texansw 22 - 14reliant stadium4 - 1270724.0\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN attendance = 65677.0 AND date = '2004-12-19' AND stadium = 'paul brown stadium' THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1255.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: pakistan and yemen have won three bronze medals for wushu at the asian games\nInput Table: wushu at the asian games\n\n\nranknationgoldsilverbronzetotal1china (chn)4373532iran (iri)435123malaysia (mas)31594hong kong (hkg)294155thailand (tha)236116japan (jpn)165127philippines (phi)158148macau (mac)154109south korea (kor)1461110chinese taipei (tpe)13111511myanmar (mya)112412vietnam (vie)0971613indonesia (ina)022414laos (lao)015615india (ind)012316pakistan (pak)011217singapore (sin)005518mongolia (mgl)003319kazakhstan (kaz)002220yemen (yem)0011totaltotal606187208\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT bronze FROM table_sql WHERE nation = 'pakistan') + \n             (SELECT bronze FROM table_sql WHERE nation = 'yemen') = 3 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-354.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: xi or xian is the name when the state is jin and the title is duke\nInput Table: list of state leaders in 820s bc\n\n\nstatetypenametitleroyal_housefromcaisovereignyimarquisji837 bccaosovereignyoucount-835 bccaosovereigndaicount-826 bcchensovereignliduke-831 bcchusovereignxiong yan the youngerviscountmi837 bcchusovereignxiong shuangviscountmi827 bcchusovereignxiong xunviscountmi821 bcjinsovereignximarquisji840 bcjinsovereignxianmarquisji822 bclusovereignshendukeji854 bclusovereignwudukeji825 bcqisovereignwudukejiang850 bcqisovereignlidukejiang824 bcqinsovereignqin zhongrulerying845 bcqinsovereignzhuangdukeying822 bcsongsovereignhuiduke-830 bcweysovereignlimarquis-855 bcyansovereignhuimarquis-864 bcyansovereignlimarquis-826 bc\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE state = 'jin' AND (name = 'xi' OR name = 'xian') AND title = 'duke') > 0 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1293.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: larisa latyna has seven more medals than carl osburn\nInput Table: list of multiple olympic medalists\n\n\nmedal_countdateathletenationsportrecord_medal_event11896-04-06james connollyunited statesathleticstriple jump g11896-04-06alexandre tuff\u00e8refranceathleticstriple jump s11896-04-06ioannis persakisgreeceathleticstriple jump b11896-04-06robert garrettunited statesathleticsdiscus g11896-04-06panagiotis paraskevopoulosgreeceathleticsdiscus s11896-04-06sotirios versisgreeceathleticsdiscus b21896-04-07robert garrettunited statesathleticslong jump s21896-04-07james connollyunited statesathleticslong jump b31896-04-07robert garrettunited statesathleticsshot put g31896-04-09carl schuhmanngermanygymnasticsvault g31896-04-09hermann weing\u00e4rtnergermanygymnasticsvault b41896-04-09hermann weing\u00e4rtnergermanygymnasticspommel horse s51896-04-09hermann weing\u00e4rtnergermanygymnasticsrings s61896-04-09hermann weing\u00e4rtnergermanygymnasticshorizontal bar g61900-07-16robert garrettunited statesathleticsstanding triple jump b61904-09-03ray ewryunited statesathleticsstanding triple jump g71908-07-20ray ewryunited statesathleticsstanding long jump g81908-07-23ray ewryunited statesathleticsstanding high jump g81920-07-29carl osburnunited statesshootingteam 300 m / 600 m military rifle , prone g91920-07-30carl osburnunited statesshooting300 m military rifle , standing g101920-07-31carl osburnunited statesshootingteam free rifle g111924-06-27carl osburnunited statesshooting600 m free rifle s111928-08-03paavo nurmifinlandathletics5000 m s121928-08-04paavo nurmifinlandathletics3000 m steeplechase s121960-09-02edoardo mangiarottiitalyfencingteam foil s131960-09-09edoardo mangiarottiitalyfencingteam \u00e9p\u00e9e g131964-10-21larisa latyninasoviet uniongymnasticsteam g141964-10-21larisa latyninasoviet uniongymnasticsall - around s151964-10-22larisa latyninasoviet uniongymnasticsvault s161964-10-22larisa latyninasoviet uniongymnasticsuneven bars b171964-10-23larisa latyninasoviet uniongymnasticsbalance beam b181964-10-23larisa latyninasoviet uniongymnasticsfloor exercise g182012-07-31michael phelpsunited statesswimming200 m butterfly s192012-07-31michael phelpsunited statesswimming4 x 200 m freestyle g202012-08-02michael phelpsunited statesswimming200 m individual medley g212012-08-03michael phelpsunited statesswimming100 m butterfly g222012-08-04michael phelpsunited statesswimming4 100 m medley relay g\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT medal_count FROM table_sql WHERE athlete = 'larisa latynina') - \n             (SELECT medal_count FROM table_sql WHERE athlete = 'carl osburn') = 7 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-961.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the conference for the college that left in 1974 , and again in 1989 , is the aac (naia)\nInput Table: north state conference\n\n\ninstitutionlocationfoundedtypeenrollmentnicknamejoinedleftcurrent_conferenceanderson universityanderson , south carolina1911-01-01private2907trojans1998-01-012010-01-01sacappalachian state universityboone , north carolina1899-01-01public17589mountaineers1930-01-011967-01-01socon ( sun belt in 2014) (ncaa division i)catawba collegesalisbury , north carolina1851-01-01private1300indians1930-01-011989-01-01saccoker collegehartsville , south carolina1908-01-01private1200cobras1991-01-012013-01-01saceast carolina universitygreenville , north carolina1907-01-01public27386pirates1947-01-011962-01-01c - usa ( the american in 2014) (ncaa division i)elon universityelon , north carolina1889-01-01private6720phoenix1930-01-011989-01-01socon ( caa in 2014) (ncaa division i)guilford collegegreensboro , north carolina1837-01-01private2706quakers1930-01-011988-01-01odac (ncaa division iii)high point universityhigh point , north carolina1924-01-01private4519panthers1930-01-011997-01-01big south (ncaa division i)lenoirrhyne universityhickory , north carolina1891-01-01private1983bears1930-01-01, 1985-01-011974-01-01, 1989-01-01saclongwood universityfarmville , virginia1839-01-01public4800lancers1995-01-012003-01-01big south (ncaa division i)mars hill collegemars hill , north carolina1856-01-01private1370lions1973-01-011975-01-01sacnewberry collegenewberry , south carolina1856-01-01private949wolves1961-01-011972-01-01sacuniversity of north carolina at pembrokepembroke , north carolina1887-01-01public6433braves1976-01-011992-01-01peach belt (pbc)presbyterian collegeclinton , south carolina1880-01-01private1300blue hose1965-01-011972-01-01big south (ncaa division i)queens university of charlottecharlotte , north carolina1857-01-01private2386royals1995-01-012013-01-01sacst andrews universitylaurinburg , north carolina1958-01-01private600knights1988-01-012012-01-01aac (naia)western carolina universitycullowhee , north carolina1889-01-01public9608catamounts1933-01-011976-01-01socon (ncaa division i)\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT current_conference FROM table_sql WHERE left = '1974-01-01' OR left = '1989-01-01') = 'aac (naia)' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-2014.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: kardinia park was one of three venues where the home team score was higher than the away team score\nInput Table: 1954 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddategeelong13.12 (90)hawthorn7.6 (48)kardinia park168701954-08-14collingwood12.16 (88)south melbourne13.12 (90)victoria park185561954-08-14carlton10.16 (76)essendon11.14 (80)princes park297441954-08-14richmond10.18 (78)melbourne15.4 (94)punt road oval240001954-08-14north melbourne9.14 (68)footscray9.14 (68)arden street oval220001954-08-14st kilda13.14 (92)fitzroy9.15 (69)junction oval115001954-08-14\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 3 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE home_team_score > away_team_score \nAND venue = 'kardinia park';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1134.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: chris topping and dave sutton have the highest league apps\nInput Table: 1979 - 80 huddersfield town f.c. season\n\n\nnamepositionleague_appsleague_goalsfa_cup_appsfa_cup_goalsleague_cup_appsleague_cup_goalstotal_appstotal_goalsjim branagandf00000 (1)00 (1)0malcolm browndf4622041523david cowlingmf39 (1)10104044 (1)10peter fletcherfw30 (8)17203135 (8)18keith hanveydf3320040392peter hartmf4641140515ian holmesmf6 (4)3004110 (4)4steve kindonfw22 (1)14000022 (1)14mick laverickmf4542040514bernard purdiedf18 (4)0200020 (4)0andy rankingk2400000240ian robinsfw452520425127fred robinsondf3012040361tommy smithfw00001010brian stantonmf4192000439alan starlinggk2202040280dave suttondf4662041527chris toppingdf1302000150\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT league_apps FROM table_sql WHERE name = 'chris topping') = \n             (SELECT MAX(league_apps) FROM table_sql) \n             AND (SELECT league_apps FROM table_sql WHERE name = 'dave sutton') = \n             (SELECT MAX(league_apps) FROM table_sql) \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1337.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the second most rebounds by a bobcats player in one game was 20\nInput Table: 2009 - 10 charlotte bobcats season\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord4701-02-9999portlandl 79 - 98 (ot)raymond felton (23)gerald wallace (10)stephen jackson (4)rose garden 2010624 - 23489999-02-03la lakersl 97 - 99 (ot)stephen jackson (30)nazr mohammed (17)boris diaw (5)staples center 1899724 - 24499999-02-06new orleansl 99 - 104 (ot)stephen jackson (26)boris diaw (8)raymond felton (7)time warner cable arena 1916424 - 25509999-02-09washingtonw 94 - 92 (ot)stephen jackson (22)nazr mohammed (10)raymond felton (5)time warner cable arena 1237625 - 255101-02-10minnesotaw 93 - 92 (ot)stephen jackson (33)nazr mohammed (20)dj augustin (7)target center 1335226 - 255201-02-16new jerseyl 94 - 103 (ot)gerald wallace (21)gerald wallace , boris diaw (10)stephen jackson (5)time warner cable arena 1371226 - 26539999-02-19clevelandw 110 - 93 (ot)stephen jackson (29)tyrus thomas (12)boris diaw (9)time warner cable arena 1956827 - 26549999-02-20milwaukeel 88 - 93 (ot)stephen jackson (35)tyrus thomas (11)stephen jackson (5)bradley center 1717427 - 27559999-02-22la clippersl 94 - 98 (ot)gerald wallace (32)gerald wallace (12)boris diaw , raymond felton (9)staples center 1589227 - 28569999-02-24utahl 93 - 102 (ot)gerald wallace (27)gerald wallace (8)raymond felton (5)energysolutions arena 1991127 - 29\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MAX(high_rebounds) FROM table_sql) = 20 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-245.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: sweden placed higher than austria in the total medal count for the 1988 olympics\nInput Table: 1988 winter olympics\n\n\nranknationgoldsilverbronzetotal1soviet union (urs)1199292east germany (gdr)9106253switzerland (sui)555154finland (fin)41275sweden (swe)40266austria (aut)352107netherlands (ned)32278west germany (frg)24289united states (usa)213610italy (ita)212513canada (can)0235\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT rank FROM table_sql WHERE nation = 'sweden') < \n             (SELECT rank FROM table_sql WHERE nation = 'austria') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-736.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the giants have played more games than the cardinal for the month of september\nInput Table: 2008 arizona diamondbacks season\n\n\ndateopponentscorelossattendancerecord9999-09-01cardinals8 - 6mcclellan (2 - 7)3507570 - 679999-09-02cardinals8 - 2petit (3 - 4)2756870 - 689999-09-03cardinals4 - 3perez (2 - 2)2435071 - 689999-09-05dodgers7 - 0haren (14 - 8)5227071 - 699999-09-06dodgers7 - 2webb (19 - 7)4754371 - 709999-09-07dodgers5 - 3rauch (4 - 6)5413771 - 719999-09-08giants6 - 2petit (3 - 5)3025271 - 729999-09-09giants5 - 4rauch (4 - 7)3051871 - 739999-09-10giants4 - 3lyon (2 - 5)3099271 - 749999-09-12reds3 - 2harang (4 - 16)2904672 - 749999-09-13reds3 - 2 (10)pe\u00f1a (1 - 2)4507572 - 759999-09-14reds2 - 1 (10)rauch (4 - 8)2729772 - 769999-09-15giants3 - 1hennessey (1 - 2)2596973 - 769999-09-16giants2 - 0cain (8 - 13)3319574 - 769999-09-17giants7 - 6s\u00e1nchez (9 - 11)2261675 - 769999-09-18giants3 - 2lincecum (17 - 4)3432376 - 769999-09-19rockies3 - 2scherzer (0 - 3)4313776 - 779999-09-20rockies5 - 3fuentes (1 - 5)3828377 - 779999-09-21rockies13 - 4reynolds (2 - 8)3291578 - 779999-09-22cardinals4 - 2wellemeyer (12 - 9)4034979 - 779999-09-23cardinals7 - 4johnson (10 - 10)4001379 - 789999-09-24cardinals4 - 2scherzer (0 - 4)4002979 - 799999-09-25cardinals12 - 3rosales (1 - 1)4050279 - 809999-09-26rockies6 - 4grilli (3 - 3)3495080 - 809999-09-27rockies6 - 4corpas (3 - 4)3323481 - 809999-09-28rockies2 - 1vizca\u00edno (1 - 2)3590882 - 80\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE opponent = 'giants' AND date LIKE '9999-09%') > \n             (SELECT COUNT(*) FROM table_sql WHERE opponent = 'cardinals' AND date LIKE '9999-09%') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-40.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: steve stricker of of scotland had lower score than of phil mickelson of united states\nInput Table: 2006 u.s. open (golf)\n\n\nplaceplayercountryscoreto_par1steve strickerunited states70 + 69 = 139- 12colin montgomeriescotland69 + 71 = 140et3kenneth ferrieengland71 + 70 = 141+ 1t3geoff ogilvyaustralia71 + 70 = 141+ 1t5jim furykunited states70 + 72 = 142+ 2t5p\u00e1draig harringtonireland70 + 72 = 142+ 2t7jason dufnerunited states72 + 71 = 143+ 3t7graeme mcdowellnorthern ireland71 + 72 = 143+ 3t7phil mickelsonunited states70 + 73 = 143+ 3t7arron oberholserunited states75 + 68 = 143+ 3\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT score FROM table_sql WHERE player = 'steve stricker' AND country = 'scotland') < \n             (SELECT score FROM table_sql WHERE player = 'phil mickelson' AND country = 'united states') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-348.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the game at the fedexforum took place after the game at the target center\nInput Table: 2008 - 09 phoenix suns season\n\n\ngamedateteamlocation_attendancerecord759999-04-01houstonus airways center 1842241 - 34769999-04-03sacramentous airways center 1842242 - 3477'9999-04-05'dallasamerican airlines center 2030142 - 35789999-04-08new orleansnew orleans arena 1778143 - 3579'9999-04-10'memphisfedexforum 1590843 - 36809999-04-11minnesotatarget center 1847844 - 36819999-04-13memphisus airways center 1842245 - 3682'9999-04-15'golden stateus airways center46 - 36\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT date FROM table_sql WHERE game = 5) > \n             (SELECT date FROM table_sql WHERE game = 6) \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-441.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there is a four way tie for the most laps at 75 with a two way tie for the least amount at 7\nInput Table: 1971 south african grand prix\n\n\ndriverconstructorlapstime_/_retiredgridmario andrettiferrari791:47:35.54jackie stewarttyrrell - ford79+ 20.91clay regazzoniferrari79+ 31.43reine wiselllotus - ford79+ 1:09.414chris amonmatra78+ 1 lap2denny hulmemclaren - ford78+ 1 lap7brian redmansurtees - ford78+ 1 lap17jacky ickxferrari78+ 1 lap8graham hillbrabham - ford77+ 2 laps19ronnie petersonmarch - ford77+ 2 laps13henri pescarolomarch - ford77+ 2 laps18rolf stommelensurtees - ford77+ 2 laps15andrea de adamichmarch - alfa romeo75+ 4 laps22emerson fittipaldilotus - ford58engine5john surteessurtees - ford56gearbox6fran\u00e7ois ceverttyrrell - ford45accident9howden ganleybrm42physical24pedro rodr\u00edguezbrm33overheating10dave charltonbrabham - ford31engine16jo siffertbrm31overheating12john lovemarch - ford30differential21jackie pretoriusbrabham - ford22engine20peter gethinmclaren - ford7fuel leak11jo bonniermclaren - ford5suspension23alex soler - roigmarch - ford5engine25\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE laps = 75) = 4 \n             AND (SELECT COUNT(*) FROM table_sql WHERE laps = 7) = 2 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-743.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the result of the 1999 favorite movie was nominated\nInput Table: nickelodeon movies\n\n\nyearcategoryfilmwinner_/_nominee_(s)result1997favorite movie actressharriet the spyrosie o'donnellnominated1999favorite moviethe rugrats movien / awon2001favorite voice from an animated movierugrats in paris : the moviesusan sarandonwon2004favorite voice from an animated movierugrats go wildbruce willisnominated2005favorite movie actorlemony snicket 's a series of unfortunate eventsjim carreynominated2007favorite movie actornacho librejack blacknominated2007favorite movie actresscharlotte 's webdakota fanningwon2012favorite voice from an animated movierangojohnny deppnominated\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN result = 'nominated' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE year = 1999 \nAND category = 'favorite movie';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1771.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: ilir meta was the first person since aleksand\u00ebr meksi , to be elected as a member of the democratic party of albania political party\nInput Table: list of prime ministers of albania\n\n\nnameborn_-_diedterm_startterm_endpolitical_partyprime ministers 1991 onwards1991-01-011991-01-011991-01-01prime ministers 1991 onwardsfatos nano (1st time)9999-01-011991-02-221991-06-05party of labour of albaniaylli bufi9999-01-011991-06-051991-12-10socialist party of albaniavilson ahmeti9999-01-011991-12-101992-04-13non - partyaleksand\u00ebr meksi9999-01-011992-04-131997-03-11democratic party of albaniabashkim fino9999-01-011997-03-111997-07-24socialist party of albaniafatos nano (2nd time)9999-01-011997-07-241998-10-02socialist party of albaniapandeli majko (1st time)9999-01-011998-10-021999-10-29socialist party of albaniailir meta9999-01-011999-10-292002-02-22socialist party of albaniapandeli majko (2nd time)9999-01-012002-02-222002-07-31socialist party of albaniafatos nano (3rd time)9999-01-012002-07-312005-09-11socialist party of albaniasali berisha1944-01-012005-09-112013-09-15democratic party of albaniaedi rama9999-01-012013-09-159999-01-01socialist party of albania\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT political_party FROM table_sql WHERE name = 'ilir meta') = \n             (SELECT political_party FROM table_sql WHERE name = 'aleksand\u00ebr meksi') \n             AND (SELECT term_start FROM table_sql WHERE name = 'ilir meta') > \n             (SELECT term_start FROM table_sql WHERE name = 'aleksand\u00ebr meksi') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-430.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: all about christmas eve is the title of the episode number 12\nInput Table: will & grace (season 5)\n\n\nseriesseasontitledirected_bywritten_byoriginal_air_dateus_viewers_(millions)931and the horse he rode in onjames burrowsadam barr2002-09-2621.5942bacon and eggsjames burrowsalex herschlag2002-10-0320.6953the kid stays out of the picturejames burrowsjhoni marchinko2002-10-1020.2964humongous growthjames burrowskari lizer2002-10-1719.5975it 's the gay pumpkin , charlie brownjames burrowsgary janetti2002-10-3117.2986boardroom and a parked placejames burrowsgail lerner2002-11-0721.1997the needle and the omelet 's donejames burrowstracy poust & jon kinnally2002-11-1419.11008 - 9marry me a little , marry me a little morejames burrowsjeff greenstein & bill wrubel2002-11-2124.310110the honeymoon 's overjames burrowssally bradford2002-12-0519.310211all about christmas evejames burrowsadam barr2002-12-1216.210312field of queensjames burrowskatie palmer2003-01-0916.210413fagmalion part i : gay it forwardjames burrowstracy poust & jon kinnally2003-01-1616.010514fagmalion part ii : attack of the clonesjames burrowsgary janetti2003-01-3015.810615homojojames burrowsbill wrubel2003-02-0616.510716women and children firstjames burrowslaura kightlinger2003-02-1318.710817fagmalion part iii : bye , bye , beardyjames burrowsalex herschlag2003-02-2016.410918fagmalion part iv : the guy who loved mejames burrowsgail lerner2003-03-1315.011019sex , losers , and videotapejames burrowssteve gabriel2003-04-0315.011120leo unwrappedjames burrowssonja warfield2003-04-1714.711221dolls and dollsjames burrowskari lizer2003-04-2417.7\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN title = 'all about christmas eve' AND series = 102 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE season = 5;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-495.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: plymouth county has two locations , rockland and stroughton\nInput Table: massachusetts route 139\n\n\ncountylocationstreet_namesmilepostroads_intersectednotesnorfolkstoughtonpleasant street turnpike street lindelof avenue3.0route 24route 24 exit 20norfolkweymouthanne street(no major junctions)(no major junctions)(no major junctions)plymouthrocklandnorth avenue plain street market street12.2route 123western terminus of route 123 / 139 concurrencyplymouthrocklandnorth avenue plain street market street12.8route 123eastern terminus of route 123 / 139 concurrencyplymouthhanoverhanover street rockland street columbia road17.9route 53northern terminus of route 53 / 139 concurrency\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(DISTINCT location) = 2 AND county = 'plymouth' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE county = 'plymouth' \nAND (location = 'rockland' OR location = 'stoughton');\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1692.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: richie hearn held the qualifying time at 24.521 before september 2003\nInput Table: chicagoland speedway\n\n\nrecorddatedrivertimespeed_/_avg_speednascar sprint cup series9999-01-01nascar sprint cup seriesnascar sprint cup seriesnascar sprint cup seriesqualifying2013-09-14joey logano28.509-race2010-07-10david reutimann2:45:34-nascar nationwide series9999-01-01nascar nationwide seriesnascar nationwide seriesnascar nationwide seriesqualifying2005-07-08ryan newman28.964-race2009-07-10joey logano2:02:10-nascar camping world truck series9999-01-01nascar camping world truck seriesnascar camping world truck seriesnascar camping world truck seriesqualifying2012-07-21justin lofton31.007-race2010-08-27kyle busch1:44:31-izod indycar series9999-01-01izod indycar seriesizod indycar seriesizod indycar seriesqualifying2003-09-06richie hearn24.521-race2006-09-10dan wheldon1:33:37-\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT time FROM table_sql WHERE record = 'qualifying' AND driver = 'richie hearn') = 24.521 \n             AND (SELECT date FROM table_sql WHERE record = 'qualifying' AND driver = 'richie hearn') < '2003-09-01' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-535.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: glenferrie oval venue recorded 5000 more crowd participants than that of the arden street oval venue\nInput Table: 1961 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddatenorth melbourne9.14 (68)st kilda11.16 (82)arden street oval130001961-06-03hawthorn10.13 (73)richmond8.12 (60)glenferrie oval150001961-06-03collingwood18.11 (119)essendon8.10 (58)victoria park282901961-06-03geelong13.13 (91)footscray4.14 (38)kardinia park186831961-06-03south melbourne7.8 (50)fitzroy17.15 (117)lake oval145001961-06-03melbourne15.14 (104)carlton11.13 (79)mcg496781961-06-03\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT crowd FROM table_sql WHERE venue = 'glenferrie oval') - \n             (SELECT crowd FROM table_sql WHERE venue = 'arden street oval') > 5000 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1903.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: gary beach is one of four winners of a tony award\nInput Table: la cage aux folles (musical)\n\n\nyearawardcategorynomineeresult2005tony awardbest revival of a musicalbest revival of a musicalwon2005tony awardbest performance by a leading actor in a musicalgary beachnominated2005tony awardbest choreographyjerry mitchellwon2005tony awardbest costume designwilliam ivey longnominated2005drama desk awardoutstanding revival of a musicaloutstanding revival of a musicalwon2005drama desk awardoutstanding choreographyjerry mitchellwon2005drama desk awardoutstanding costume designwilliam ivey longnominated\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 1 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE award = 'tony award' \nAND result = 'won' \nAND nominee = 'gary beach';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1802.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: daniel uberti left fas on 29 december 2008\nInput Table: primera divisi\u00f3n de f\u00fatbol profesional apertura 2008\n\n\nteamoutgoing_managermanner_of_departuredate_of_vacancyreplaced_bydate_of_appointmentposition_in_tablenejapamauricio cienfuegosmutual consent2008-08-14daniel uberti2008-09-0510thfirpogerardo reinososacked2008-08-25oscar benitez2008-09-027thbalboagustavo de simonesacked2008-08-30roberto gamarra2008-09-0510thalianzapablo centronesacked2008-09-14carlos jurado2008-09-165thfirpooscar ben\u00edtezsacked2008-12-09agust\u00edn castillo2008-12-23post - season (6th)\u00e1guilaagust\u00edn castillosacked2008-12-15pablo centrone2008-12-24post - season (semifinals)fasnelson anchetasacked2008-12-27roberto gamarra2009-01-01post - season (semifinals)nejapadaniel ubertisacked2008-12-29nelson ancheta2008-12-29post - season (10th)balboaroberto gamarramutual consent2009-01-01carlos de toro2009-01-16post - season (7th)\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE outgoing_manager = 'daniel uberti' \nAND date_of_vacancy = '2008-12-29' \nAND team = 'fas';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1795.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: john h tolan is the incumbent with result being new seat republican gain\nInput Table: united states house of representatives elections , 1942\n\n\ndistrictincumbentpartyfirst_electedresultcandidatescalifornia 2harry lane englebrightrepublican1926-01-01re - electedharry lane englebright (r) unopposedcalifornia 4thomas rolphrepublican1940-01-01re - electedthomas rolph (r) 98.3% archie brown ( w / i ) 1.7%california 7john h tolandemocratic1934-01-01re - electedjohn h tolan (d) unopposedcalifornia 9bertrand w gearhartrepublican1934-01-01re - electedbertrand w gearhart (r) unopposedcalifornia 10alfred j elliottdemocratic1937-01-01re - electedalfred j elliott (d) unopposedcalifornia 17cecil r kingdemocratic1942-08-25re - electedcecil r king (d) unopposedcalifornia 22none (district created)none (district created)9999-01-01new seat republican gainjohn j phillips (r) 57.6% n e west (d) 42.4%\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE incumbent = 'john h tolan' \nAND result = 'new seat republican gain';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-201.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the collingwood vs melbourne game has the third largest crowd size\nInput Table: 1972 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddatefootscray14.7 (91)st kilda9.11 (65)western oval186551972-07-15fitzroy16.14 (110)north melbourne9.12 (66)junction oval70071972-07-15essendon13.12 (90)richmond17.9 (111)windy hill222511972-07-15carlton20.8 (128)south melbourne8.15 (63)princes park144651972-07-15hawthorn19.14 (128)geelong15.8 (98)glenferrie oval124251972-07-15collingwood10.13 (73)melbourne8.10 (58)vfl park308831972-07-15\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT crowd FROM table_sql WHERE home_team = 'collingwood' AND away_team = 'melbourne') = \n             (SELECT MAX(crowd) FROM table_sql WHERE (home_team != 'collingwood' OR away_team != 'melbourne')) \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1222.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: four players scored three goals total , and all four are in league 5\nInput Table: 2008 - 09 r.s.c. anderlecht season\n\n\nplayerleaguetitle_playoffsuper_cuptotalmbark boussoufa110011tom de sutter9009guillaume gillet8009marcin wasilewski8008jonathan legear5107nicol\u00e1s frutos6006thomas chatelle4004roland juh\u00e1sz4004stanislav vl\u010dek4004lucas biglia2003dmitri bulykin3003jan pol\u00e1k2003mat\u00edas su\u00e1rez1013jelle van damme3003oleksandr iakovenko2002hern\u00e1n losada1002v\u00edctor bern\u00e1rdez1001bart goor1001nemanja rni\u01070001\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 4 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE total = 3 \nAND league = 5;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1030.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: 2010 - 11 - 17 is the release date with a category of utilities , a developer of dino games , and a title of chord finder\nInput Table: list of zune applications\n\n\ntitledevelopercategoryrelease_dateversionalarm clockmicrosoftutilities2010-12-161.1calculatormicrosoftutilities2009-09-011.0calendarmatchboxutilities2011-07-291.0.0.3chord findermicrosoftutilities2010-11-171.0drum machine hddino gamesutilities2010-10-201.0emailmicrosoftutilities2011-04-011.1.0.1facebookmatchboxsocial networking2010-12-161.4fan predictionihwy , incentertainment2011-06-231.0fingerpaintbabarogaentertainment2011-07-291.1levelmicrosoftutilities2011-06-231.0metronomedino gamesutilities2010-09-091.0msn moneymicrosoftutilities2010-07-291.0notesmicrosoftutilities2011-06-231.0pianomicrosoftentertainment2009-11-011.0shuffle by albummicrosoftutilities2011-02-181.1stopwatchmicrosoftutilities2010-08-051.1twittermatchboxsocial networking2010-12-161.6weathermicrosoftutilities2009-09-011.0windows live messengermicrosoftsocial networking2010-11-171.4zune readermicrosoftutilities2011-02-181.2\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE release_date = '2010-11-17' \nAND category = 'utilities' \nAND developer = 'dino games' \nAND title = 'chord finder';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1461.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: eight games had an attendance of over 70000 during the 1993 new york jets season\nInput Table: 1993 new york jets season\n\n\nweekdateopponentresultgame_siteattendance11993-09-05denver broncosl 26 - 20the meadowlands6813021993-09-12miami dolphinsw 24 - 14joe robbie stadium7031441993-09-26new england patriotsw 45 - 7the meadowlands6483651993-10-03philadelphia eaglesl 35 - 30the meadowlands7259361993-10-10los angeles raidersl 24 - 20los angeles memorial coliseum4162781993-10-24buffalo billsl 19 - 10the meadowlands7154191993-10-31new york giantsw 10 - 6giants stadium71659101993-11-07miami dolphinsw 27 - 10the meadowlands71306111993-11-14indianapolis coltsw 31 - 17rca dome47351121993-11-21cincinnati bengalsw 17 - 12the meadowlands64264131993-11-28new england patriotsw 6 - 0foxboro stadium42810141993-12-05indianapolis coltsl 9 - 6the meadowlands45799151993-12-11washington redskinsw 3 - 0robert f kennedy memorial stadium47970161993-12-18dallas cowboysl 28 - 7the meadowlands73233171993-12-26buffalo billsl 16 - 14rich stadium70817181994-01-02houston oilersl 24 - 0houston astrodome61040\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) >= 8 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE attendance > 70000;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1813.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the gold medalist for equestrian at the asian games has been different in every year they have occurred except 1994 and 1998\nInput Table: equestrian at the asian games\n\n\nyearlocationgoldsilverbronze1982new delhinadia al - moutawaajamila al - moutawaabariaa salem al - sabbah1986seoultakashi tomurashuichi tokiryuzo okuno1994hiroshimakonoshin kuwahararyuzo okunonatya chantrasmi1998bangkokjin kannosohn bong - gakquzier ambak fathil2002busanmikaela mar\u00e3\u00ada jaworskilee jin - kyungtadayoshi hayashi2006dohaali yousuf al - rumaihijasmine chen - shao manjoo jung - hyun2010guangzhouramzy al duhamilatifa al maktomkhaled al - eid\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(DISTINCT gold) FROM table_sql) = (SELECT COUNT(*) FROM table_sql) - 2 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1526.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: 14.13 (97) was the home team score of the match played at western oval\nInput Table: 1969 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddategeelong16.14 (110)hawthorn14.11 (95)kardinia park315691969-08-23collingwood19.15 (129)south melbourne6.22 (58)victoria park194281969-08-23carlton20.7 (127)richmond24.12 (156)princes park276571969-08-23st kilda21.18 (144)north melbourne8.10 (58)moorabbin oval111091969-08-23melbourne14.13 (97)fitzroy14.15 (99)mcg177901969-08-23footscray14.10 (94)essendon12.10 (82)western oval160431969-08-23\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE venue = 'western oval' \nAND home_team_score = '14.13 (97)';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1502.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: constructed was completed during the same time frame of 1993 at the flowood site and the newsome brothers\nInput Table: list of superfund sites in mississippi\n\n\ncerclis_idnamecountyproposedlistedconstruction_completedpartially_deleteddeletedmsd004006995american creosote works , incwinston2001-06-142001-09-139999-01-01--msd008154486chemfax , incharrison1993-06-239999-01-019999-01-01--msd046497012davis timber companylamar2000-05-112000-07-279999-01-01--msd980710941flowood siterankin1983-09-081984-09-211993-09-17-02 / 16 / 1996msd980840045newsom brothers / old reichhold chemicals , incmarion1984-10-151986-06-101997-08-08-09 / 27 / 2000msd065490930picayune wood treatingpearl river2004-03-082004-07-229999-01-01--msd056029648potter cocopiah1993-05-109999-01-019999-01-01--msd086556388sonford productsrankin2006-09-272007-03-079999-01-01--msd980601736walcotte chemical co warehouseswashington9999-01-019999-01-011982-12-30-12 / 30 / 1982\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT construction_completed FROM table_sql WHERE name = 'flowood site') = \n             (SELECT construction_completed FROM table_sql WHERE name = 'newsom brothers / old reichhold chemicals , inc') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1257.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: neither singapore , mongolia , nor myanmar have won a gold medal for wushu at the asian games\nInput Table: wushu at the asian games\n\n\nranknationgoldsilverbronzetotal1china (chn)4373532iran (iri)435123malaysia (mas)31594hong kong (hkg)294155thailand (tha)236116japan (jpn)165127philippines (phi)158148macau (mac)154109south korea (kor)1461110chinese taipei (tpe)13111511myanmar (mya)112412vietnam (vie)0971613indonesia (ina)022414laos (lao)015615india (ind)012316pakistan (pak)011217singapore (sin)005518mongolia (mgl)003319kazakhstan (kaz)002220yemen (yem)0011totaltotal606187208\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT gold FROM table_sql WHERE nation = 'singapore (sin)') = 0 \n             AND (SELECT gold FROM table_sql WHERE nation = 'mongolia (mgl)') = 0 \n             AND (SELECT gold FROM table_sql WHERE nation = 'myanmar (mya)') = 0 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-684.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: united states' davis love iii scored 73 + 71 + 68 = 212\nInput Table: 2002 u.s. open (golf)\n\n\nplaceplayercountryscoreto_par1tiger woodsunited states67 + 68 + 70 = 205- 52sergio garc\u00edaspain68 + 74 + 67 = 209- 1t3jeff maggertunited states69 + 73 + 68 = 210et3phil mickelsonunited states70 + 73 + 67 = 210et5robert allenbyaustralia74 + 70 + 67 = 211+ 1t5p\u00e1draig harringtonireland70 + 68 + 73 = 211+ 1t5billy mayfairunited states69 + 74 + 68 = 211+ 1t8nick faldoengland70 + 76 + 66 = 212+ 2t8justin leonardunited states73 + 71 + 68 = 212+ 2t10tom byrumunited states72 + 72 + 70 = 214+ 4t10davis love iiiunited states71 + 71 + 72 = 214+ 4t10scott mccarronunited states72 + 72 + 70 = 214+ 4\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT score FROM table_sql WHERE player = 'davis love iii') = 73 + 71 + 68 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-460.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the most points scored by the dolphins in a game was 34 points\nInput Table: 1983 miami dolphins season\n\n\nweekdateopponentresultattendance11983-09-04buffalo billsw 12 - 07871521983-09-11new england patriotsw 34 - 245934331983-09-19los angeles raidersl 27 - 145779641983-09-25kansas city chiefsw 14 - 65078551983-10-02new orleans saintsl 17 - 76648961983-10-09buffalo billsl 38 - 355994871983-10-16new york jetsw 32 - 145861581983-10-23baltimore coltsw 21 - 73234391983-10-30los angeles ramsw 30 - 1472175101983-11-06san francisco 49ersw 20 - 1757832111983-11-13new england patriotsl 17 - 660771121983-11-20baltimore coltsw 37 - 054482131983-11-28cincinnati bengalsw 38 - 1474506141983-12-04houston oilersw 24 - 1739434151983-12-10atlanta falconsw 31 - 2456725161983-12-16new york jetsw 34 - 1459975\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN MAX(CAST(SUBSTR(result, INSTR(result, ' ') + 1, INSTR(result, ' - ') - INSTR(result, ' ') - 1) AS INTEGER)) = 34 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1103.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: gary and allison brooks was the episode with the least amount of viewers\nInput Table: gary unmarried\n\n\nepisodeair_datetimeslot18_-_49viewerspilot2008-09-24wednesday 8:30 pm2.3 / 66.84gary gets boundaries2008-10-01wednesday 8:30 pm2.2 / 66.97gary marries off his ex2008-10-08wednesday 8:30 pm2.2 / 67.43gary gets his stuff back2008-10-15wednesday 8:30 pm2.4 / 77.71gary breaks up his ex - wife and girlfriend2008-10-22wednesday 8:30 pm2.5 / 77.85gary meets the gang2008-11-05wednesday 8:30 pm2.1 / 66.44gary and allison 's restaurant2008-11-12wednesday 8:30 pm2.1 / 56.71gary and allison brooks2008-11-19wednesday 8:30 pm2.7 / 78.14gary gives thanks2008-11-26wednesday 8:30 pm2.2 / 77.72gary goes first2008-12-10wednesday 8:30 pm2.4 / 78.03gary toughens up tom2008-12-17wednesday 8:30 pm2.3 / 77.55gary dates louise 's teacher2009-01-14wednesday 8:30 pm2.1 / 57.07gary moves back in2009-01-21wednesday 8:30 pm2.2 / 57.07gary and dennis' sister2009-02-11wednesday 8:30 pm2.1 / 56.86gary 's ex - brother - in - law2009-02-18wednesday 8:30 pm2.1 / 57.26gary uses his veto2009-03-11wednesday 8:30 pm2.3 / 77.71gary hooks up allison2009-03-18wednesday 8:30 pm2.3 / 77.57gary and the trophy2009-04-08wednesday 8:30 pm2.2 / 77.3gary and his half brother2009-05-06wednesday 8:30 pm2.0 / 66.66gary fixes allison 's garbage disposal2009-05-20wednesday 8:30 pm1.7 / 55.55\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN viewers = (SELECT MIN(viewers) FROM table_sql) \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE episode = 'gary and allison brooks';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-365.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: wes roberts and ed whitley were both picked in the 3rd round\nInput Table: indianapolis colts draft history\n\n\nroundpickoverallnamepositioncollege155curtis dickeyrunning backtexas a&m12424derrick hatchettcornerbacktexas2432ray donaldsoncentergeorgia22351tim foleyoffensive tacklenotre dame4588ray butlerwide receiverusc66144chris footecenterusc75170wes robertsdefensive endtcu82195ken walteroffensive tackletexas tech96227mark brightrunning backtemple105254larry stewartoffensive tacklemaryland113280ed whitleytight endkansas state126311randy bielskiplacekickertowson1219324marvin simsfullbackclemson\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT round FROM table_sql WHERE name = 'wes roberts') = 3 \n             AND (SELECT round FROM table_sql WHERE name = 'ed whitley') = 3 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1714.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: 1872 - 1884 was the year for hercules\nInput Table: locomotives of the southern railway\n\n\nclasswheel_arrangementmanufactureryear_madequantity_madequantity_preservedyear_(s)_withdrawnjoseph hamilton beattie (1850 - 1871)joseph hamilton beattie (1850 - 1871)joseph hamilton beattie (1850 - 1871)joseph hamilton beattie (1850 - 1871)joseph hamilton beattie (1850 - 1871)joseph hamilton beattie (1850 - 1871)joseph hamilton beattie (1850 - 1871)hercules2 - 4 - 0nine elms works1851 - 18541501875 - 1884tartar2 - 2 - 2wtsharp brothers1852601871 - 1874sussex2 - 2 - 2wtnine elms works1852801871 - 1876canute2 - 2 - 2nine elms works1855 - 18591201875 - 1885saxon2 - 4 - 0nine elms works1855 - 18571201877 - 1885chaplin2 - 2 - 2wtnine elms works1856301876 - 1877minerva2 - 4 - 0wtnine elms works1856301874 - 1883nelson2 - 4 - 0wtnine elms works1858301882 - 1885nile2 - 4 - 0wtnine elms works1859301882tweed2 - 4 - 0nine elms works1858 - 1859601877 - 1879undine2 - 4 - 0nine elms works1859 - 601201884 - 1886clyde2 - 4 - 0nine elms works1859 - 18681301883 - 1899gem2 - 4 - 0nine elms works1862 - 1863601884 - 1885eagle2 - 4 - 0nine elms works1862301885 - 1886falcon2 - 4 - 0nine elms works1863 - 18671701882 - 18981772 - 4 - 0wtbeyer , peacock & co (82) nine elms works (3)1863 - 18758521886 - 1899 , 1962lion0 - 6 - 0nine elms works1863 - 18733801886 - 1900volcano2 - 4 - 0nine elms works1866 - 18731801886 - 18972210 - 6 - 0beyer , peacock & co1866 - 18732401891 - 19242312 - 4 - 0beyer , peacock & co1866601892 - 1899vesuvius2 - 4 - 0nine elms works1869 - 18753201893 - 1899\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE year_made >= 1872 \nAND year_made <= 1884 \nAND class = 'hercules';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1706.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: alberta is the locale when l is 9\nInput Table: 2005 tim hortons brier\n\n\nlocaleskipwlpfpaends_wonends_lostblank_endsstolen_endsshot_pctalbertarandy ferbey92905848437986%manitobarandy dutiaume8377694744101379%nova scotiashawn adams8380604741161383%quebecjean - michel m\u00e3nard747769544081580%british columbiadeane horning6572654745181280%ontariowayne middaugh657562424610782%newfoundland and labradorbrad gushue6576694845131079%saskatchewanpat simmons656661434512980%prince edward islandrod macdonald476785415112579%northern ontariomike jakubo38648641489679%new brunswickwade blanchard385683414517878%\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE locale = 'alberta' \nAND l = 9;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1329.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: parren mitchell was re - elected in maryland district 7 , defeating elton r wampler\nInput Table: united states house of representatives elections , 1974\n\n\ndistrictincumbentpartyfirst_electedresultcandidatesmaryland 1robert baumanrepublican1973-01-01re - electedrobert bauman (r) 53.0% thomas j hatem (d) 47.0%maryland 2clarence longdemocratic1962-01-01re - electedclarence long (d) 77.1% john m seney (r) 22.9%maryland 4marjorie holtrepublican1972-01-01re - electedmarjorie holt (r) 58.1% fred l wineland (d) 41.9%maryland 6goodloe byrondemocratic1970-01-01re - electedgoodloe byron (d) 73.7% elton r wampler (r) 26.3%maryland 7parren mitchelldemocratic1970-01-01re - electedparren mitchell (d) unopposed\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT result FROM table_sql WHERE district = 'maryland 7' AND incumbent = 'parren mitchell') = 're - elected' \n             AND (SELECT candidates FROM table_sql WHERE district = 'maryland 7' AND incumbent = 'parren mitchell') LIKE '%elton r wampler%' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-702.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: pan wei - lun is the loss of who has a save of huang chun - chung and played against chinatrust whales\nInput Table: 2007 uni - president lions season\n\n\ndateopponentscorelosssave9999-03-17la new bears4 - 5pan wei - lunhuang chun - chung9999-03-18la new bears4 - 1horacio estradatseng yi - cheng9999-03-22chinatrust whales7 - 9kao lung - weini fu - deh9999-03-23chinatrust whales4 - 5pan wei - lunmiguel saladin9999-03-24la new bears1 - 5jeriome robertson||30089999-03-25la new bears1 - 6rob cordemanshuang chun - chung9999-03-27brother elephantspostponed rescheduled for june 19postponed rescheduled for june 19postponed rescheduled for june 199999-03-28brother elephants0 - 4tsao chun - yangchuang wei - chuan9999-03-31macoto cobras11 - 5diegomar markwell||2275\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT loss FROM table_sql WHERE opponent = 'chinatrust whales' AND save = 'huang chun - chung') = 'pan wei - lun' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1576.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: camilo villegas from columbia and david toms from the united states tied for eighth place with + 4 to par\nInput Table: 2008 pga championship\n\n\nplaceplayercountryscoreto_par1ben curtisunited states73 + 67 + 68 = 208- 2t2j b holmesunited states71 + 68 + 70 = 209- 1t2henrik stensonsweden71 + 70 + 68 = 209- 1t4sergio garc\u00edaspain69 + 73 + 69 = 211+ 1t4p\u00e1draig harringtonireland71 + 74 + 66 = 211+ 1t4charlie wisouth korea70 + 70 + 71 = 211+ 1t7andr\u00e9s romeroargentina69 + 78 + 65 = 212+ 2t7jeev milkha singhindia68 + 74 + 70 = 212+ 2t9aaron baddeleyaustralia71 + 71 + 71 = 213+ 3t9steve fleschunited states73 + 70 + 70 = 213+ 3t9david tomsunited states72 + 69 + 72 = 213+ 3t9camilo villegascolombia74 + 72 = 67 = 213+ 3\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT to_par FROM table_sql WHERE player = 'camilo villegas' AND country = 'colombia') = '+ 4' \n             AND (SELECT to_par FROM table_sql WHERE player = 'david toms' AND country = 'united states') = '+ 4' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-534.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: lake oval venue recorded a higher crowd participation than that of the glenferrie oval venue\nInput Table: 1961 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddatenorth melbourne9.14 (68)st kilda11.16 (82)arden street oval130001961-06-03hawthorn10.13 (73)richmond8.12 (60)glenferrie oval150001961-06-03collingwood18.11 (119)essendon8.10 (58)victoria park282901961-06-03geelong13.13 (91)footscray4.14 (38)kardinia park186831961-06-03south melbourne7.8 (50)fitzroy17.15 (117)lake oval145001961-06-03melbourne15.14 (104)carlton11.13 (79)mcg496781961-06-03\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT crowd FROM table_sql WHERE venue = 'lake oval') > \n             (SELECT crowd FROM table_sql WHERE venue = 'glenferrie oval') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1015.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the away team scored 17.5 before a crowd of 12239 on sunday , 30 january\nInput Table: 2000 ansett australia cup\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scoregroundcrowddateadelaide17.5 (107)melbourne19.11 (125)football park122399999-01-30geelong10.14 (74)st kilda11.12 (78)waverley park73949999-01-30st kilda9.12 (66)melbourne13.14 (92)waverley park105339999-02-05adelaide19.10 (124)geelong15.12 (102)football park113269999-02-06adelaide14.11 (95)st kilda15.12 (102)football park130869999-02-13geelong17.12 (114)melbourne11.16 (82)waverley park495201-14-9999\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE away_team_score = '17.5 (107)' \nAND crowd = 12239 \nAND date = '9999-01-30';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-812.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the world cup had three games throughout july 1998 , all of which were in japan\nInput Table: 1998 in paraguayan football\n\n\ndatevenuescorecompreport1998-02-08estadio defensores del chaco asunci\u00f3n , paraguay4 - 0f4501998-03-14qualcomm stadium san diego , united states2 - 2f4511998-03-18estadio ol\u00edmpico universitario mexico city , mexico1 - 1f4521998-03-28yale bowl new haven , united states1 - 1f4531998-04-22stadio ennio tardini parma , italy3 - 1f4541998-05-17olympic stadium tokyo , japan1 - 1kirin cup4551998-05-21kobe universiade memorial stadium kobe , japan1 - 0kirin cup4561998-06-01philips stadion eindhoven , netherlands5 - 1f4571998-06-03steaua stadium bucharest , romania3 - 2f4581998-06-06king baudouin stadium brussels , belgium1 - 0f4591998-06-12stade de la mosson montpellier , france0 - 0world cupreport1998-06-19stade geoffroy - guichard saint - \u00e9tienne , france0 - 0world cupreport1998-06-24stade de toulouse toulouse , france1 - 3world cupreport1998-06-28stade f\u00e9lix bollaert lens , france0 - 0 ( 1 - 0 aet )world cupreport\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 3 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE comp = 'world cup' \nAND date LIKE '1998-07%';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1093.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the episode that aired on december 17th had a higher production number than than the ray j episode and the episode titled '702'\nInput Table: list of all that episodes\n\n\nseasonseriesepisode_titleoriginal_air_datenick_prod138tia & tamera mowry / ll cool j1996-11-16338239montell jordan1996-11-23339441dru hill1996-12-07341542tyra banks / blackstreet1996-12-14342643music special1996-12-17343744a tribe called quest1996-12-213448457021996-12-28345946tony! toni! tone!1997-01-043461047chris farley / mint condition1997-01-1134711481121997-01-183481249sherman hemsley / nas1997-01-253491350john leguizamo / mona lisa1997-02-013501451ray j1997-02-083511552for real1997-09-203521653aaliyah1997-10-043531754az yet1997-09-273541855monica1997-10-113551956mc lyte1997-10-18356\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT nick_prod FROM table_sql WHERE original_air_date = '1996-12-17') > \n             (SELECT nick_prod FROM table_sql WHERE episode_title = 'ray j') AND \n             (SELECT nick_prod FROM table_sql WHERE episode_title = '702') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-364.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: 5 players were picked in the 2nd rounds of the draft\nInput Table: indianapolis colts draft history\n\n\nroundpickoverallnamepositioncollege155curtis dickeyrunning backtexas a&m12424derrick hatchettcornerbacktexas2432ray donaldsoncentergeorgia22351tim foleyoffensive tacklenotre dame4588ray butlerwide receiverusc66144chris footecenterusc75170wes robertsdefensive endtcu82195ken walteroffensive tackletexas tech96227mark brightrunning backtemple105254larry stewartoffensive tacklemaryland113280ed whitleytight endkansas state126311randy bielskiplacekickertowson1219324marvin simsfullbackclemson\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 5 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE round = 2;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-794.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: justin rose is from the united states\nInput Table: 1998 open championship\n\n\nplaceplayercountryscoreto_par1brian wattsunited states68 + 69 + 73 = 210et2jim furykunited states70 + 70 + 72 = 212+ 2t2mark o'mearaunited states72 + 68 + 72 = 212+ 2t2jesper parneviksweden68 + 72 + 72 = 212+ 25justin rose (a)england72 + 66 + 75 = 213+ 3t6thomas bj\u00e3rndenmark68 + 71 + 76 = 215+ 5t6brad faxonunited states67 + 74 + 74 = 215+ 5t6john hustonunited states65 + 77 + 73 = 215+ 5t6tiger woodsunited states65 + 73 + 77 = 215+ 5t10david duvalunited states70 + 71 + 75 = 216+ 6t10costantino roccaitaly72 + 74 + 70 = 216+ 6t10raymond russellscotland68 + 73 + 75 = 216+ 6t10katsuyoshi tomorijapan75 + 71 + 70 = 216+ 6\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT country FROM table_sql WHERE player = 'justin rose (a)') = 'united states' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1389.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: dundee west has higher swing to gain points than western isles\nInput Table: scottish parliament general election , 2007\n\n\nrankconstituencywinning_party_2003swing_to_gainsnp_'s_place_2003result1galloway & upper nithsdaleconservative0.172ndcon hold2tweeddale , ettrick & lauderdaleliberal democrats1.012ndld hold3cumbernauld & kilsythlabour1.072ndlab hold4kilmarnock & loudounlabour1.922ndsnp gain5dundee westlabour2.132ndsnp gain6western isleslabour2.912ndsnp gain7glasgow govanlabour2.922ndsnp gain8aberdeen centrallabour2.962ndlab hold9linlithgowlabour3.562ndlab hold10west renfrewshirelabour4.412ndlab hold11paisley southlabour4.912ndlab hold\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT swing_to_gain FROM table_sql WHERE constituency = 'dundee west') > \n             (SELECT swing_to_gain FROM table_sql WHERE constituency = 'western isles') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-870.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: when the drive was harry schell the entrant was scuderia ambrosiana and when the driver was philippe etancelin the entrant was sa alfa romeo\nInput Table: 1950 swiss grand prix\n\n\ndriverentrantconstructorchassisenginetyrenello paganiscuderia achille varzimaseratimaserati 4clt - 48maserati l4spjohnny claesecurie belgetalbot - lagotalbot - lago t26ctalbot l6dyves giraud - cabantousautomobiles talbot - darracq satalbot - lagotalbot - lago t26c - datalbot l6deug\u00e8ne martinautomobiles talbot - darracq satalbot - lagotalbot - lago t26c - datalbot l6dlouis rosierautomobiles talbot - darracq satalbot - lagotalbot - lago t26c - datalbot l6dluigi fagiolisa alfa romeoalfa romeoalfa romeo 158alfa romeo l8spjuan manuel fangiosa alfa romeoalfa romeoalfa romeo 158alfa romeo l8spnino farinasa alfa romeoalfa romeoalfa romeo 158alfa romeo l8spalberto ascariscuderia ferrariferrariferrari 125ferrari v12spraymond sommerscuderia ferrariferrariferrari 125ferrari v12spluigi villoresiscuderia ferrariferrariferrari 125ferrari v12sppeter whiteheadscuderia ferrariferrariferrari 125ferrari v12splouis chironofficine alfieri maseratimaseratimaserati 4clt - 48maserati l4spfranco rolofficine alfieri maseratimaseratimaserati 4clt - 48maserati l4spprince biraenrico plat\u00e9maseratimaserati 4clt - 48maserati l4sptoulo de graffenriedenrico plat\u00e9maseratimaserati 4clt - 48maserati l4spfelice bonettoscuderia milanomaseratimaserati milano 4clt - 50maserati l4spreg parnellscuderia ambrosianamaseratimaserati 4clt - 48maserati l4sdrudi fischerecurie espadonsva - fiatsva 1500fiat l4sptoni brancaprivatemaseratimaserati 4clmaserati l4spphilippe \u00e9tancelinprivatetalbot - lagotalbot - lago t26ctalbot l6dharry schellecurie bleuetalbot - lagotalbot - lago t26ctalbot l6d\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT entrant FROM table_sql WHERE driver = 'harry schell') = 'scuderia ambrosiana' \n             AND (SELECT entrant FROM table_sql WHERE driver = 'philippe \u00e9tancelin') = 'sa alfa romeo' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-871.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: ecurie espadon was the entrant when talbot - lago was the constructor and albot - lago t26c was the chassis\nInput Table: 1950 swiss grand prix\n\n\ndriverentrantconstructorchassisenginetyrenello paganiscuderia achille varzimaseratimaserati 4clt - 48maserati l4spjohnny claesecurie belgetalbot - lagotalbot - lago t26ctalbot l6dyves giraud - cabantousautomobiles talbot - darracq satalbot - lagotalbot - lago t26c - datalbot l6deug\u00e8ne martinautomobiles talbot - darracq satalbot - lagotalbot - lago t26c - datalbot l6dlouis rosierautomobiles talbot - darracq satalbot - lagotalbot - lago t26c - datalbot l6dluigi fagiolisa alfa romeoalfa romeoalfa romeo 158alfa romeo l8spjuan manuel fangiosa alfa romeoalfa romeoalfa romeo 158alfa romeo l8spnino farinasa alfa romeoalfa romeoalfa romeo 158alfa romeo l8spalberto ascariscuderia ferrariferrariferrari 125ferrari v12spraymond sommerscuderia ferrariferrariferrari 125ferrari v12spluigi villoresiscuderia ferrariferrariferrari 125ferrari v12sppeter whiteheadscuderia ferrariferrariferrari 125ferrari v12splouis chironofficine alfieri maseratimaseratimaserati 4clt - 48maserati l4spfranco rolofficine alfieri maseratimaseratimaserati 4clt - 48maserati l4spprince biraenrico plat\u00e9maseratimaserati 4clt - 48maserati l4sptoulo de graffenriedenrico plat\u00e9maseratimaserati 4clt - 48maserati l4spfelice bonettoscuderia milanomaseratimaserati milano 4clt - 50maserati l4spreg parnellscuderia ambrosianamaseratimaserati 4clt - 48maserati l4sdrudi fischerecurie espadonsva - fiatsva 1500fiat l4sptoni brancaprivatemaseratimaserati 4clmaserati l4spphilippe \u00e9tancelinprivatetalbot - lagotalbot - lago t26ctalbot l6dharry schellecurie bleuetalbot - lagotalbot - lago t26ctalbot l6d\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE entrant = 'ecurie espadon' \nAND constructor = 'talbot - lago' \nAND chassis = 'talbot - lago t26c';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1728.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: brandon backe is the losing pitcher when the winning pitcher is roy oswalt\nInput Table: 2005 texas rangers season\n\n\ndatewinning_teamscorewinning_pitcherlosing_pitcherattendancelocation9999-05-20texas7 - 3kenny rogersbrandon backe38109arlington9999-05-21texas18 - 3chris youngezequiel astacio35781arlington9999-05-22texas2 - 0chan ho parkroy oswalt40583arlington9999-06-24houston5 - 2roy oswaltricardo rodr\u00edguez36199houston9999-06-25texas6 - 5chris youngbrandon backe41868houston\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT losing_pitcher FROM table_sql WHERE winning_pitcher = 'roy oswalt') = 'brandon backe' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-811.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the kirin cup had games on both june 1 and 3 , 1998\nInput Table: 1998 in paraguayan football\n\n\ndatevenuescorecompreport1998-02-08estadio defensores del chaco asunci\u00f3n , paraguay4 - 0f4501998-03-14qualcomm stadium san diego , united states2 - 2f4511998-03-18estadio ol\u00edmpico universitario mexico city , mexico1 - 1f4521998-03-28yale bowl new haven , united states1 - 1f4531998-04-22stadio ennio tardini parma , italy3 - 1f4541998-05-17olympic stadium tokyo , japan1 - 1kirin cup4551998-05-21kobe universiade memorial stadium kobe , japan1 - 0kirin cup4561998-06-01philips stadion eindhoven , netherlands5 - 1f4571998-06-03steaua stadium bucharest , romania3 - 2f4581998-06-06king baudouin stadium brussels , belgium1 - 0f4591998-06-12stade de la mosson montpellier , france0 - 0world cupreport1998-06-19stade geoffroy - guichard saint - \u00e9tienne , france0 - 0world cupreport1998-06-24stade de toulouse toulouse , france1 - 3world cupreport1998-06-28stade f\u00e9lix bollaert lens , france0 - 0 ( 1 - 0 aet )world cupreport\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 2 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE comp = 'kirin cup' \nAND date IN ('1998-06-01', '1998-06-03');\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1653.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: moorabbin oval has less crowd than kardinia park\nInput Table: 1975 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddategeelong14.20 (104)melbourne14.14 (98)kardinia park133281975-06-07st kilda15.9 (99)north melbourne17.19 (121)moorabbin oval178111975-06-07richmond19.14 (128)essendon12.9 (81)mcg494691975-06-07hawthorn19.24 (138)collingwood13.11 (89)princes park238301975-06-07fitzroy15.7 (97)carlton16.10 (106)junction oval162491975-06-07footscray13.11 (89)south melbourne12.15 (87)vfl park140561975-06-07\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT crowd FROM table_sql WHERE venue = 'moorabbin oval') < \n             (SELECT crowd FROM table_sql WHERE venue = 'kardinia park') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1335.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the second lowest attendance figure for a game was 12376\nInput Table: 2009 - 10 charlotte bobcats season\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord4701-02-9999portlandl 79 - 98 (ot)raymond felton (23)gerald wallace (10)stephen jackson (4)rose garden 2010624 - 23489999-02-03la lakersl 97 - 99 (ot)stephen jackson (30)nazr mohammed (17)boris diaw (5)staples center 1899724 - 24499999-02-06new orleansl 99 - 104 (ot)stephen jackson (26)boris diaw (8)raymond felton (7)time warner cable arena 1916424 - 25509999-02-09washingtonw 94 - 92 (ot)stephen jackson (22)nazr mohammed (10)raymond felton (5)time warner cable arena 1237625 - 255101-02-10minnesotaw 93 - 92 (ot)stephen jackson (33)nazr mohammed (20)dj augustin (7)target center 1335226 - 255201-02-16new jerseyl 94 - 103 (ot)gerald wallace (21)gerald wallace , boris diaw (10)stephen jackson (5)time warner cable arena 1371226 - 26539999-02-19clevelandw 110 - 93 (ot)stephen jackson (29)tyrus thomas (12)boris diaw (9)time warner cable arena 1956827 - 26549999-02-20milwaukeel 88 - 93 (ot)stephen jackson (35)tyrus thomas (11)stephen jackson (5)bradley center 1717427 - 27559999-02-22la clippersl 94 - 98 (ot)gerald wallace (32)gerald wallace (12)boris diaw , raymond felton (9)staples center 1589227 - 28569999-02-24utahl 93 - 102 (ot)gerald wallace (27)gerald wallace (8)raymond felton (5)energysolutions arena 1991127 - 29\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MIN(location_attendance) FROM table_sql) = 12376 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-249.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: italy received three more gold medals than canada did but tied with the united states and west germany\nInput Table: 1988 winter olympics\n\n\nranknationgoldsilverbronzetotal1soviet union (urs)1199292east germany (gdr)9106253switzerland (sui)555154finland (fin)41275sweden (swe)40266austria (aut)352107netherlands (ned)32278west germany (frg)24289united states (usa)213610italy (ita)212513canada (can)0235\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT gold FROM table_sql WHERE nation = 'italy') - \n             (SELECT gold FROM table_sql WHERE nation = 'canada') = 3 \n             AND \n             (SELECT gold FROM table_sql WHERE nation = 'italy') = \n             (SELECT gold FROM table_sql WHERE nation = 'united states') \n             AND \n             (SELECT gold FROM table_sql WHERE nation = 'italy') = \n             (SELECT gold FROM table_sql WHERE nation = 'west germany') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1301.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: none of the athletes received medals in gymnastics\nInput Table: list of multiple olympic medalists\n\n\nmedal_countdateathletenationsportrecord_medal_event11896-04-06james connollyunited statesathleticstriple jump g11896-04-06alexandre tuff\u00e8refranceathleticstriple jump s11896-04-06ioannis persakisgreeceathleticstriple jump b11896-04-06robert garrettunited statesathleticsdiscus g11896-04-06panagiotis paraskevopoulosgreeceathleticsdiscus s11896-04-06sotirios versisgreeceathleticsdiscus b21896-04-07robert garrettunited statesathleticslong jump s21896-04-07james connollyunited statesathleticslong jump b31896-04-07robert garrettunited statesathleticsshot put g31896-04-09carl schuhmanngermanygymnasticsvault g31896-04-09hermann weing\u00e4rtnergermanygymnasticsvault b41896-04-09hermann weing\u00e4rtnergermanygymnasticspommel horse s51896-04-09hermann weing\u00e4rtnergermanygymnasticsrings s61896-04-09hermann weing\u00e4rtnergermanygymnasticshorizontal bar g61900-07-16robert garrettunited statesathleticsstanding triple jump b61904-09-03ray ewryunited statesathleticsstanding triple jump g71908-07-20ray ewryunited statesathleticsstanding long jump g81908-07-23ray ewryunited statesathleticsstanding high jump g81920-07-29carl osburnunited statesshootingteam 300 m / 600 m military rifle , prone g91920-07-30carl osburnunited statesshooting300 m military rifle , standing g101920-07-31carl osburnunited statesshootingteam free rifle g111924-06-27carl osburnunited statesshooting600 m free rifle s111928-08-03paavo nurmifinlandathletics5000 m s121928-08-04paavo nurmifinlandathletics3000 m steeplechase s121960-09-02edoardo mangiarottiitalyfencingteam foil s131960-09-09edoardo mangiarottiitalyfencingteam \u00e9p\u00e9e g131964-10-21larisa latyninasoviet uniongymnasticsteam g141964-10-21larisa latyninasoviet uniongymnasticsall - around s151964-10-22larisa latyninasoviet uniongymnasticsvault s161964-10-22larisa latyninasoviet uniongymnasticsuneven bars b171964-10-23larisa latyninasoviet uniongymnasticsbalance beam b181964-10-23larisa latyninasoviet uniongymnasticsfloor exercise g182012-07-31michael phelpsunited statesswimming200 m butterfly s192012-07-31michael phelpsunited statesswimming4 x 200 m freestyle g202012-08-02michael phelpsunited statesswimming200 m individual medley g212012-08-03michael phelpsunited statesswimming100 m butterfly g222012-08-04michael phelpsunited statesswimming4 100 m medley relay g\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE sport = 'gymnastics';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1443.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the final score on september 17 at soldier field was 10 - 27\nInput Table: nbc sunday night football results (2006 - present)\n\n\ndatevisiting_teamfinal_scorehost_teamstadium9999-09-07miami dolphins17 - 28pittsburgh steelersheinz field9999-09-10indianapolis colts26 - 21new york giantsgiants stadium9999-09-17washington redskins10 - 27dallas cowboystexas stadium9999-09-24denver broncos17 - 7new england patriotsgillette stadium9999-10-01seattle seahawks6 - 37chicago bearssoldier field9999-10-08pittsburgh steelers13 - 23san diego chargersqualcomm stadium9999-10-15oakland raiders3 - 13denver broncosinvesco field at mile high9999-10-29dallas cowboys35 - 14carolina panthersbank of america stadium9999-11-05indianapolis colts27 - 20new england patriotsgillette stadium9999-11-12chicago bears38 - 20new york giantsgiants stadium9999-11-19san diego chargers35 - 27denver broncosinvesco field at mile high9999-11-26philadelphia eagles21 - 45indianapolis coltsrca dome9999-12-03seattle seahawks23 - 20denver broncosinvesco field at mile high9999-12-10new orleans saints42 - 17dallas cowboystexas stadium9999-12-17kansas city chiefs9 - 20san diego chargersqualcomm stadium9999-12-25philadelphia eagles23 - 7dallas cowboystexas stadium9999-12-31green bay packers26 - 7chicago bearssoldier field0001-01-06kansas city chiefs8 - 23indianapolis coltsrca dome0001-01-06dallas cowboys20 - 21seattle seahawksqwest field\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT final_score FROM table_sql WHERE date = '9999-09-17' AND stadium = 'soldier field') = '10 - 27' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1779.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the total life expectancy in 1950 - 1955 is greater than 70.1 and the cdr is less than 32.5\nInput Table: none\n\n\nperiodlive_births_per_yeardeaths_per_yearnatural_change_per_yearcbrcdrnctfrimrlife_expectancy_totallife_expectancy_maleslife_expectancy_females1950-01-01 - 1955-01-012 572 000900 0001 672 00044.115.528.66.1513550.949.252.61955-01-01 - 1960-01-012 918 000947 0001 971 00043.214.029.16.1512253.351.555.21960-01-01 - 1965-01-013 303 000986 0002 317 00042.212.629.66.1510955.753.857.69999-01-01 - 1970-01-013 330 000998 0002 332 00037.011.125.95.3810057.655.759.61970-01-01 - 1975-01-013 441 0001 014 0002 427 00033.79.923.84.729159.557.361.81975-01-01 - 1980-01-013 741 0001 043 0002 698 00032.59.023.54.317961.559.263.91980-01-01 - 1985-01-013 974 0001 064 0002 910 00030.88.222.63.86363.460.466.81985-01-01 - 1990-01-013 757 0001 055 0002 702 00026.37.418.93.15265.361.969.11990-01-01 - 1995-01-013 519 0001 058 0002 461 00022.66.815.82.64367.363.671.21995-01-01 - 2000-01-013 624 0001 086 0002 538 00021.56.515.12.453469.365.573.32000-01-01 - 2005-01-013 572 0001 147 0002 425 00019.86.413.42.252770.967.274.8\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT life_expectancy_total FROM table_sql WHERE period = '1950-01-01 - 1955-01-01') > 70.1 \n             AND (SELECT cdr FROM table_sql WHERE period = '1950-01-01 - 1955-01-01') < 32.5 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1323.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: maryland district 6 candidate elton r wampler succeeded incumbant candidate goodloe byron\nInput Table: united states house of representatives elections , 1974\n\n\ndistrictincumbentpartyfirst_electedresultcandidatesmaryland 1robert baumanrepublican1973-01-01re - electedrobert bauman (r) 53.0% thomas j hatem (d) 47.0%maryland 2clarence longdemocratic1962-01-01re - electedclarence long (d) 77.1% john m seney (r) 22.9%maryland 4marjorie holtrepublican1972-01-01re - electedmarjorie holt (r) 58.1% fred l wineland (d) 41.9%maryland 6goodloe byrondemocratic1970-01-01re - electedgoodloe byron (d) 73.7% elton r wampler (r) 26.3%maryland 7parren mitchelldemocratic1970-01-01re - electedparren mitchell (d) unopposed\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT result FROM table_sql WHERE district = 'maryland 6' AND candidates LIKE '%elton r wampler%') = 're - elected' \n             AND (SELECT result FROM table_sql WHERE district = 'maryland 6' AND candidates LIKE '%goodloe byron%') = 're - elected' \n        THEN 'FALSE' \n        ELSE 'TRUE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1641.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: in 1996 they were the 2 seed of the southeast region\nInput Table: vcu rams men 's basketball\n\n\nyearrecordseedregionresults198018 - 1212eastl 72 - 86198124 - 55eastw 85 - 69 l 56 - 58 ot198324 - 75eastw 76 - 67 l 54 - 56198423 - 76eastw 70 - 69 l 63 - 78198526 - 62westw 81 - 65 l 59 - 63199624 - 912southeastl 51 - 58200423 - 813eastl 78 - 79200728 - 711westw 79 - 77 l 79 - 84 ot200924 - 1011eastl 64 - 65201128 - 1211southwestw 59 - 46 w 74 - 56 w 94 - 76 w 72 - 71 ot w 71 - 61 l 62 - 70201229 - 712midwestw 62 - 59 l 61 - 63201327 - 95southw 88 - 42 l 53 - 78\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT seed FROM table_sql WHERE year = 1996 AND region = 'southeast') = 2 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1606.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: during the 2007 - 08 minnesota wild season , minnesota lost by more than 2 on february 27 and february 29\nInput Table: 2007 - 08 minnesota wild season\n\n\ndatevisitorscorehomedecisionattendancerecord01-02-9999minnesota4 - 1columbusbackstrom1852930 - 19 - 39999-02-05detroit3 - 2minnesotabackstrom1856830 - 19 - 401-02-07dallas1 - 0minnesotabackstrom1856830 - 20 - 49999-02-09ny islanders3 - 4minnesotabackstrom1856831 - 20 - 401-02-10minnesota2 - 1st louisharding1647732 - 20 - 401-02-12minnesota2 - 4edmontonharding1683932 - 21 - 401-02-14minnesota5 - 4vancouverbackstrom1863033 - 21 - 49999-02-17nashville4 - 5minnesotabackstrom1856834 - 21 - 49999-02-19vancouver3 - 2minnesotabackstrom1856834 - 21 - 59999-02-20minnesota0 - 3chicagoharding1781234 - 22 - 59999-02-24calgary2 - 1minnesotabackstrom1856834 - 23 - 59999-02-26minnesota1 - 4washingtonbackstrom1739134 - 24 - 59999-02-27minnesota3 - 2tampa baybackstrom1721135 - 24 - 59999-02-29minnesota3 - 2floridabackstrom1692736 - 24 - 5\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT ABS(SUBSTR(score, 1, 1) - SUBSTR(score, 5, 1)) FROM table_sql WHERE date = '9999-02-27' AND visitor = 'minnesota') > 2 \n             AND (SELECT ABS(SUBSTR(score, 1, 1) - SUBSTR(score, 5, 1)) FROM table_sql WHERE date = '9999-02-29' AND visitor = 'minnesota') > 2 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1223.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: thomas chatelle scored four more goals than matias suarez , the next highest ranked player in the belgian first dvision a league who played in the belgian cup\nInput Table: 2008 - 09 r.s.c. anderlecht season\n\n\nplayerleaguetitle_playoffsuper_cuptotalmbark boussoufa110011tom de sutter9009guillaume gillet8009marcin wasilewski8008jonathan legear5107nicol\u00e1s frutos6006thomas chatelle4004roland juh\u00e1sz4004stanislav vl\u010dek4004lucas biglia2003dmitri bulykin3003jan pol\u00e1k2003mat\u00edas su\u00e1rez1013jelle van damme3003oleksandr iakovenko2002hern\u00e1n losada1002v\u00edctor bern\u00e1rdez1001bart goor1001nemanja rni\u01070001\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT total FROM table_sql WHERE player = 'thomas chatelle') > \n             (SELECT total FROM table_sql WHERE player = 'mat\u00edas su\u00e1rez') + 4 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1852.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: when the girls singles is lindaweni fanetri , the mixed doubles is wifqi windarto debby susanto after the year 2007\nInput Table: indonesian national badminton championships\n\n\nyearboys_singlesgirls_singlesboys_doublesgirls_doublesmixed_doubles2001holvy de pauwmaria kristin yuliantihendra setiawan joko riyadililyana natsir natalia poluakanhendra setiawan greysia polii2002andre kurniawan tedjonofransisca ratnasariujang suherlan yoga ukikasahpurwati meiliana jauharimuhammad rijal meiliana jauhari2003alamsyah yunuswiwis meilyannafran kurniawan chandra kowipia zebadiah nitya krishinda maheswarifran kurniawan yulianti2004andre kurniawan tedjonopia zebadiahaditya dwi putra i made agungpia zebadiah nitya krishinda maheswarilingga lie yulianti2005achmad rivaibellaetrix manuputtyrio willianto davin prawidssalily siswanti shendy puspa irawatiabdul rahman richi puspita dili2006nugroho andi saputrosylvinna kurniawandanny bawa chrisnanta afiat yuris wirawanbellaetrix manuputty samantha lintangdanny bawa chrisnanta debby susanto2007nandang ariflindaweni fanetribudi hartono yohanes rendy sugiartoanneke feinya agustin wenny setiawatiwifqi windarto debby susanto2008hermansyahana rovitadidit juang indrianto seiko wahyu kusdiantosuci rizki andini tiara rosalia nuraidahirfan fadhilah weni anggraeni2009riyanto subagjaana rovitajones ralfy jansen dandi prabuditaayu pratiwi anggi widiadidit juang indrianto yayu rahayu2010shesar hiren rhustavitoganis nur rahmadanijones ralfy jansen dandi prabuditaaris budiharti dian fitrianijones ralfy jansen nurbeta kwanrico\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT mixed_doubles FROM table_sql WHERE year > 2007 AND girls_singles = 'lindaweni fanetri') = 'wifqi windarto debby susanto' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-319.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: adrian dantley was on the team the entire time that brad davis was also on the team , as well as surpassing davis by four additional years\nInput Table: utah jazz all - time roster\n\n\nplayernationalitypositionyears_for_jazzschool_/_club_teamadrian dantleyunited statesguard - forward1979-01-01notre damebrad davisunited statesguard1979-01-01marylanddarryl dawkinsunited statescenter1987-01-01maynard evans hspaul dawkinsunited statesguard1979-01-01northern illinoisgreg deaneunited statesguard1979-01-01utahjames donaldsonunited statescenter1993-01-01, 1994-01-01, 1995-01-01washington statejohn drewunited statesguard - forward1982-01-01gardner - webbjohn durenunited statesguard1980-01-01georgetown\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE player = 'adrian dantley' AND years_for_jazz <= '1979-01-01') - \n             (SELECT COUNT(*) FROM table_sql WHERE player = 'brad davis' AND years_for_jazz <= '1979-01-01') = 4 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-472.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the player from new zealand is in last place\nInput Table: 1973 u.s. open (golf)\n\n\nplaceplayercountryscoreto_par1gary playersouth africa67 + 70 = 137- 52jim colbertunited states70 + 68 = 138- 4t3jack nicklausunited states71 + 69 = 140- 2t3johnny millerunited states71 + 69 = 140- 2t3bob charlesnew zealand71 + 69 = 140- 2t6gene borekunited states77 + 65 = 142et6julius borosunited states73 + 69 = 142et6tom weiskopfunited states73 + 69 = 142et6arnold palmerunited states71 + 71 = 142et6lee trevinounited states70 + 72 = 142e\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN place = (SELECT MAX(place) FROM table_sql) AND country = 'new zealand' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1017.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: st kilda was the away team on monday , 14 february\nInput Table: 2000 ansett australia cup\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scoregroundcrowddateadelaide17.5 (107)melbourne19.11 (125)football park122399999-01-30geelong10.14 (74)st kilda11.12 (78)waverley park73949999-01-30st kilda9.12 (66)melbourne13.14 (92)waverley park105339999-02-05adelaide19.10 (124)geelong15.12 (102)football park113269999-02-06adelaide14.11 (95)st kilda15.12 (102)football park130869999-02-13geelong17.12 (114)melbourne11.16 (82)waverley park495201-14-9999\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE away_team = 'st kilda' \nAND strftime('%w', date) = '1' \nAND strftime('%d-%m-%Y', date) = '14-02-9999';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-852.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: fc basel 1893 is one of the two football clubs in asia , and participated in the 2008 an 2010 seasons\nInput Table: list of superleague formula football clubs\n\n\nnofootball_clubcontinentassociated_football_clubseasonsracing_drivers3ac milaneuropeac milan2008 2009 2010robert doornbos giorgio pantano yelmer buurman4ac sparta pragueeuropeac sparta prague2011filip salaquarda5team luxembourgeuropenone2011fr\u00e9d\u00e9ric vervisch6team new zealandoceanianone2011earl bamber7team japanasianone2011duncan tappy8 1 (in 2011)rsc anderlechteuropersc anderlecht2008 2009 2010 2011craig dolby yelmer buurman davide rigon neel jani8team netherlandseuropenone2011robert doornbos10fc basel 1893europefc basel2008 2009 2010max wissel max wissel max wissel12 24 (in 2010)beijing guoanasiabeijing guoan fc2008 2010davide rigon john martin14team brazils americanone2011ant\u00f4nio pizzonia17rangers fceuroperangers fc2008 2009ryan dalziel , james walker john martin24fc midtjyllandeuropefc midtjylland2009kasper andersen24team australiaoceanianone2011john martin31team englandeuropenone2011craig dolby\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE football_club = 'fc basel 1893' AND continent = 'asia' AND seasons LIKE '%2008%' AND seasons LIKE '%2010%') > 0 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1452.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: paul findley , district illinois 20 , was first elected after henry hyde , district illinois 6\nInput Table: united states house of representatives elections , 1980\n\n\ndistrictincumbentpartyfirst_electedresultcandidatesillinois 2morgan f murphydemocratic1970-01-01retired democratic holdgus savage (d) 88.2% marsha a harris (r) 11.8%illinois 6henry hyderepublican1974-01-01re - electedhenry hyde (r) 67.0% mario reymond reda (d) 33.0%illinois 7cardiss collinsdemocratic1973-01-01re - electedcardiss collins (d) 85.1% ruth r hooper (r) 14.9%illinois 12phil cranerepublican1969-01-01re - electedphil crane (r) 74.1% david mccartney (d) 25.9%illinois 13robert mccloryrepublican1962-01-01re - electedrobert mcclory (r) 71.7% michael reese (d) 28.3%illinois 15tom corcoranrepublican1976-01-01re - electedtom corcoran (r) 76.7% john p quillin (d) 23.3%illinois 19tom railsbackrepublican1966-01-01re - electedtom railsback (r) 73.4% thomas j hand (d) 26.6%illinois 20paul findleyrepublican1960-01-01re - electedpaul findley (r) 56.0% david robinson (d) 44.0%\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT first_elected FROM table_sql WHERE district = 'illinois 20' AND incumbent = 'paul findley') > \n             (SELECT first_elected FROM table_sql WHERE district = 'illinois 6' AND incumbent = 'henry hyde') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1032.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: twitter has the version of 1.0.0.3\nInput Table: list of zune applications\n\n\ntitledevelopercategoryrelease_dateversionalarm clockmicrosoftutilities2010-12-161.1calculatormicrosoftutilities2009-09-011.0calendarmatchboxutilities2011-07-291.0.0.3chord findermicrosoftutilities2010-11-171.0drum machine hddino gamesutilities2010-10-201.0emailmicrosoftutilities2011-04-011.1.0.1facebookmatchboxsocial networking2010-12-161.4fan predictionihwy , incentertainment2011-06-231.0fingerpaintbabarogaentertainment2011-07-291.1levelmicrosoftutilities2011-06-231.0metronomedino gamesutilities2010-09-091.0msn moneymicrosoftutilities2010-07-291.0notesmicrosoftutilities2011-06-231.0pianomicrosoftentertainment2009-11-011.0shuffle by albummicrosoftutilities2011-02-181.1stopwatchmicrosoftutilities2010-08-051.1twittermatchboxsocial networking2010-12-161.6weathermicrosoftutilities2009-09-011.0windows live messengermicrosoftsocial networking2010-11-171.4zune readermicrosoftutilities2011-02-181.2\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT version FROM table_sql WHERE title = 'twitter') = '1.0.0.3' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1312.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: fred couples has a score of 70 + 71 + 70 = 211\nInput Table: 1988 u.s. open (golf)\n\n\nplaceplayercountryscoreto_par1curtis strangeunited states70 + 67 + 69 = 206- 7t2nick faldoengland72 + 67 + 68 = 207- 6t2bob gilderunited states68 + 69 + 70 = 207- 6t2scott simpsonunited states69 + 66 + 72 = 207- 6t5larry mizeunited states69 + 67 + 72 = 208- 5t5d a weibringunited states71 + 69 + 68 = 208- 57mark o'mearaunited states71 + 72 + 66 = 209- 48fred couplesunited states72 + 67 + 71 = 210- 39lanny wadkinsunited states70 + 71 + 70 = 211- 210ken greenunited states72 + 70 + 70 = 212- 1\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT score FROM table_sql WHERE player = 'fred couples') = '70 + 71 + 70 = 211' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1902.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: jerry mitchell was nominated for a drama desk award three times\nInput Table: la cage aux folles (musical)\n\n\nyearawardcategorynomineeresult2005tony awardbest revival of a musicalbest revival of a musicalwon2005tony awardbest performance by a leading actor in a musicalgary beachnominated2005tony awardbest choreographyjerry mitchellwon2005tony awardbest costume designwilliam ivey longnominated2005drama desk awardoutstanding revival of a musicaloutstanding revival of a musicalwon2005drama desk awardoutstanding choreographyjerry mitchellwon2005drama desk awardoutstanding costume designwilliam ivey longnominated\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 3 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE nominee = 'jerry mitchell' \nAND award = 'drama desk award';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1019.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: 6.800 is the a score when the b score is more than 9.225 , and the total is less than 15.975\nInput Table: gymnastics at the 2008 summer olympics - men 's rings\n\n\npositiongymnasta_scoreb_scoretotal1chen yibing ( chn )7.39.22516.5252yordan yovchev ( bul )7.38.97516.2753oleksandr vorobiov ( ukr )7.29.0516.254yang wei ( chn )7.38.92516.2255matteo morandi ( ita )7.18.92516.0256andrea coppolino ( ita )6.89.17515.9757danny pinheiro rodrigues ( fra )7.28.615.88robert stanescu ( rou )7.08.7515.75\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT a_score FROM table_sql WHERE b_score > 9.225 AND total < 15.975) = 6.800 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1236.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the packers scored the highest amount of points (6) in a game versus the lions\nInput Table: 1976 detroit lions season\n\n\nweekdateopponentresultattendance11976-09-12chicago bearsl 10 - 35412521976-09-19atlanta falconsw 24 - 105084031976-09-26minnesota vikingsl 10 - 97729241976-10-03green bay packersl 24 - 145504151976-10-10new england patriotsw 30 - 106017461976-10-17washington redskinsl 20 - 74590871976-10-24seattle seahawksw 41 - 146128081976-10-31green bay packersw 27 - 67499291976-11-07minnesota vikingsl 31 - 2346735101976-11-14new orleans saintsl 17 - 1642048111976-11-21chicago bearsw 14 - 1078042121976-11-25buffalo billsw 27 - 1466875131976-12-05new york giantsl 24 - 1066069141976-12-11los angeles ramsl 20 - 1773470\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MAX(CAST(SUBSTR(result, INSTR(result, '-') + 1) AS INTEGER)) FROM table_sql WHERE opponent = 'green bay packers') = 6 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-309.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: 2 - 3 was the score when the home team was liverpool after 30 / 01 / 1991\nInput Table: 1990 - 91 fa cup\n\n\ntie_nohome_teamscoreaway_teamdate1liverpool2 - 2brighton & hove albion1991-01-26replaybrighton & hove albion2 - 3liverpool1991-01-302notts county2 - 0oldham athletic1991-01-263crewe alexandra1 - 0rotherham united1991-01-264luton town1 - 1west ham united1991-01-26replaywest ham united5 - 0luton town1991-01-305woking0 - 1everton1991-01-276shrewsbury town1 - 0wimbledon1991-01-267newcastle united2 - 2nottingham forest1991-02-13replaynottingham forest3 - 0newcastle united1991-02-188tottenham hotspur4 - 2oxford united1991-01-269coventry city1 - 1southampton1991-01-26replaysouthampton2 - 0coventry city1991-01-2910portsmouth5 - 1bournemouth1991-01-2611manchester united1 - 0bolton wanderers1991-01-2612norwich city3 - 1swindon town1991-01-2613millwall4 - 4sheffield wednesday1991-01-26replaysheffield wednesday2 - 0millwall1991-01-3014port vale1 - 2manchester city1991-01-2615arsenal0 - 0leeds united1991-01-27replayleeds united1 - 1arsenal1991-01-30replayarsenal0 - 0leeds united1991-02-13replayleeds united1 - 2arsenal1991-02-1616cambridge united2 - 0middlesbrough1991-01-26\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN score = '2 - 3' AND home_team = 'liverpool' AND date > '1991-01-30' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-612.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: jordan farmar led the team in points for 5 straight games\nInput Table: 2010 - 11 new jersey nets season\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord759999-04-01philadelphial 90 - 115 (ot)brandan wright (15)brandan wright (11)deron williams (7)wells fargo center 1669523 - 52769999-04-03miamil 94 - 108 (ot)deron williams (18)travis outlaw (9)deron williams (9)prudential center 1871123 - 5377'9999-04-05'minnesotaw 107 - 105 (ot)brook lopez (30)brook lopez (12)deron williams (21)prudential center 1346124 - 53789999-04-06detroitl 109 - 116 (ot)brook lopez (39)brook lopez (7)jordan farmar (11)the palace of auburn hills 1455424 - 54799999-04-08new yorkl 93 - 116 (ot)brook lopez (27)jordan farmar (8)jordan farmar (9)prudential center 1802324 - 5580'9999-04-10'torontol 92 - 99 (ot)brook lopez (35)brook lopez (11)jordan farmar (7)air canada centre 1775524 - 56819999-04-11charlottel 103 - 105 (ot)brook lopez (31)dan gadzuric (8)jordan farmar (9)prudential center 1385324 - 57\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE high_points = (SELECT MAX(high_points) FROM table_sql) AND game >= 76 AND game <= 80) = 5 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-412.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the most laps when the grid is 5 is 34.0\nInput Table: 1987 hungarian grand prix\n\n\ndriverconstructorlapstime_/_retiredgridnelson piquetwilliams - honda761:59:26.7933ayrton sennalotus - honda76+ 37.7276alain prostmclaren - tag76+ 1:27.4564thierry boutsenbenetton - ford75+ 1 lap7riccardo patresebrabham - bmw75+ 1 lap10derek warwickarrows - megatron74+ 2 laps9jonathan palmertyrrell - ford74+ 2 laps16eddie cheeverarrows - megatron74+ 2 laps11philippe streifftyrrell - ford74+ 2 laps14ivan capellimarch - ford74+ 2 laps18alessandro nanniniminardi - motori moderni73+ 3 laps20piercarlo ghinzaniligier - megatron73+ 3 laps25pascal fabreags - ford71+ 5 laps26nigel mansellwilliams - honda70wheel1alex caffiosella - alfa romeo64fuel system21ren\u00e9 arnouxligier - megatron57electrical19philippe alliotlola - ford48accident15martin brundlezakspeed45turbo22michele alboretoferrari43engine5andrea de cesarisbrabham - bmw43gearbox13stefan johanssonmclaren - tag14gearbox8teo fabibenetton - ford14gearbox12adri\u00e1n camposminardi - motori moderni14spun off24gerhard bergerferrari13differential2christian dannerzakspeed3engine23satoru nakajimalotus - honda1drive - shaft17\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT laps FROM table_sql WHERE grid = 5) = 34.0 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-6.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the wildcats never scored more than 7 points in any game they won\nInput Table: 1947 kentucky wildcats football team\n\n\ngamedateopponentresultwildcats_pointsopponentsrecord19999-09-20ole missloss7140 - 129999-09-27cincinnatiwin2001 - 139999-10-04xavierwin2072 - 149999-10-119 georgiawin2603 - 1 , 2059999-10-1810 vanderbiltwin1404 - 1 , 1469999-10-25michigan statewin765 - 1 , 1379999-11-0118 alabamaloss0135 - 289999-11-08west virginiawin1566 - 299999-11-15evansvillewin3607 - 2109999-11-22tennesseeloss6137 - 3\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MAX(wildcats_points) FROM table_sql WHERE result = 'win') <= 7 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1087.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the players on the patrick racing team with fewer than 2 point and grids larger than 4 are ryan hunter - reay and oriol servi\u00e0\nInput Table: 2003 tecate telmex monterrey grand prix\n\n\ndriverteamlapstime_/_retiredgridpointspaul tracyteam player 's852:03:04.677222michel jourdain , jrteam rahal85+ 2.0 secs516alex taglianirocketsports racing3+ 12.0 secs314adrian fern\u00e1ndezfern\u00e1ndez racing85+ 14.2 secs612bruno junqueiranewman / haas racing85+ 14.9 secs710roberto morenoherdez competition85+ 30.9 secs148darren manningwalker racing85+ 35.2 secs136patrick carpentierteam player 's84+ 1 lap155alex yoongdale coyne racing84+ 1 lap174patrick lemari\u00e9pk racing84+ 1 lap123jo\u00ebl camathiasdale coyne racing84+ 1 lap192ryan hunter - reayamerican spirit team johansson83+ 2 laps91mario dom\u00ednguezherdez competition83+ 2 laps80jimmy vasseramerican spirit team johansson83+ 2 laps160rodolfo lav\u00ednwalker racing81+ 4 laps180mario haberfeldmi - jack conquest racing67contact110s\u00e9bastien bourdaisnewman / haas racing40contact11oriol servi\u00e0patrick racing38contact40tiago monteirofittipaldi - dingman racing2mechanical100\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE team = 'patrick racing' AND points < 2 AND grid > 4) >= 2 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1117.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: beausejour has a lead of aaron watson\nInput Table: 2009 canadian olympic curling trials\n\n\nskipthird_/_vice_skipsecondleadcitykerry burtnykdon walchukrichard daneaultgarth smithwinnipegpat simmonsgerry adamjeff sharpsteve laycockdavidsonjeff stoughtonkevin parkrob fowlersteve gouldwinnipegwayne middaughjon meadjohn eppingscott baileyislingtonbrad gushuemark nicholsryan fryjamie korabst john 'smike mcewenb j neufeldmatt wozniakdenni neufeldwinnipegjoel jordisonscott bitzaryn schmidtdean hickemoose jawbob urseljim cotterkevin folkrick sawatskykelownajean - michel m\u00e9nardmartin cr\u00eate\u00e9ric sylvainjean gagnonl\u00e9visted appelmantom appelmanbradon klassenbrendan melnykedmontongreg mcaulayken maskiewichdeane horningaaron watsonrichmondjason gunnlaugsonjustin richterbraden zawadatyler forrestbeausejour\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT lead FROM table_sql WHERE city = 'beausejour') = 'aaron watson' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1147.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: 223 was the only episode number with q147 format\nInput Table: none\n\n\nepisodeseasonformattitleoriginal_airdate2171h75lost smurf1988-09-102182h76archives of evil1988-09-102193q143bigmouth 's roommate / bungling babysitters1988-09-172204q144clockwork 's powerplay / clumsy in command1988-09-172215h77don smurfo 's uninvited guests1988-09-242226q145denisa 's greedy doll / denisa 's slumber party1988-09-242237q146grandpa 's nemesis / grandpa 's walking stick1988-10-012248h78a house for nanny1988-10-012259q147it 's a smurfy life / land of lost and found1988-10-0822610h79long live brainy1988-10-0822711h80a maze of mirrors1988-10-1522812q148memory melons / nanny 's way1988-10-1522913q149pappy 's puppy / shutterbug smurfs1988-10-2223014q150smoogle sings the blues / a smurf for denisa1988-10-2223115h81smurf the presses1988-10-2923216h82stealing grandpa 's thunder1988-10-29\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 1 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE episode = 223 \nAND format = 'q147';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-259.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: galina voskoboeva played a total of 3 games on a hard tennis court , and 1 on clay\nInput Table: galina voskoboeva\n\n\noutcomedatetournamentsurfaceopponentscorerunner - up2003-01-28tiptonhard (i)matea mezak6 - 4 , 4 - 6 , 4 - 6winner2003-06-29mont - de - marsanhard (i)oleksandra kravets6 - 4 , 6 - 2runner - up2003-10-03latinaclayroberta vinci3 - 6 , 4 - 6runner - up2005-11-08pittsburghhardlilia osterloh6 - 7 , 4 - 6winner2006-06-06cuneo , italyclayalice canepa6 - 1 , 6 - 2\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE surface = 'hard') = 3 \n             AND (SELECT COUNT(*) FROM table_sql WHERE surface = 'clay') = 1 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1286.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: por type is retirement\nInput Table: 2008 - 09 apoel f.c. season\n\n\nnatnamemoving_totypetransfer_windowtransfer_feesourcegremachlasretiredretirementsummer-contragrcypmakridesmetalurh donetskend of contractsummerfreekerkidanetser\u010dorovi\u0107ael limassolloan returnsummer--cyploukaael limassolend of contractsummerfreekerkidanetgrekapsislevadiakosend of contractsummerfree-cypdaskalakisaek larnacaend of contractsummerfreeapoelnetbraz\u00e9 carlostrofensecontract terminationsummerfreeapoelfccomcycypvourkoudoxa katokopialoansummerfree-cyppanayiotoudigenis morphouloansummerfree-mkdnikolovskiaep paphosmutual consentwinterfree-cyppapathanasiouermis aradippouloanwinterfree-porpaulo costaanorthosis famagustamutual consent loan returnwinterfreeapoelfccomcy\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN type = 'retirement' AND nat = 'por' THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1276.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the nuggets lost all six games played at the pepsi center during this span\nInput Table: 2009 - 10 denver nuggets season\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord39999-11-01grizzliesw 133 - 123 (ot)carmelo anthony (42)nen\u00ea (9)chauncey billups (12)pepsi center 158233 - 049999-11-03pacersw 111 - 93 (ot)carmelo anthony (25)nen\u00ea (13)anthony carter (5)conseco fieldhouse 106274 - 059999-11-04netsw 122 - 94 (ot)ty lawson (23)kenyon martin (10)chauncey billups (5)izod center 153195 - 079999-11-07hawksl 100 - 125 (ot)carmelo anthony (30)chris andersen (11)chauncey billups (7)philips arena 178015 - 289999-11-10bullsw 90 - 89 (ot)carmelo anthony (20)nen\u00ea (12)chauncey billups (6)united center 214096 - 299999-11-11bucksl 102 - 108 (ot)carmelo anthony (32)carmelo anthony (10)chauncey billups , ty lawson (5)bradley center 129876 - 3109999-11-13lakersw 105 - 79 (ot)carmelo anthony (25)chris andersen (11)chauncey billups (8)pepsi center 191417 - 3119999-11-17raptorsw 130 - 112 (ot)carmelo anthony (32)nen\u00ea (10)chauncey billups (10)pepsi center 164468 - 3129999-11-20clippersl 99 - 106 (ot)carmelo anthony (37)nen\u00ea (12)chauncey billups (7)staples center 181558 - 4139999-11-21bullsw 112 - 93 (ot)carmelo anthony (30)carmelo anthony , kenyon martin (11)carmelo anthony (7)pepsi center 193599 - 4149999-11-24netsw 101 - 87 (ot)carmelo anthony (27)nen\u00ea (9)chauncey billups (7)pepsi center 1630710 - 4159999-11-25timberwolvesw 124 - 111 (ot)carmelo anthony (22)nen\u00ea (8)nen\u00ea , ty lawson (6)target center 1310111 - 4169999-11-27knicksw 128 - 125 (ot)carmelo anthony (50)nen\u00ea , kenyon martin (11)chauncey billups (8)pepsi center 1915512 - 4\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE location_attendance LIKE 'pepsi center%' \nAND record NOT LIKE '%w%';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-296.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the score on 15 / 04 / 07 in super league xii was 52 to 22 with an attendance of 9000\nInput Table: 2007 bradford bulls season\n\n\ndatehome_teamscoreaway_teamgoalsattendancecompetition2007-11-02bradford18 - 14huddersfield giantsdeacon 3 / 412130super league xii0007-02-18warrington wolves20 - 36bradforddeacon 6 / 712607super league xii2007-02-24bradford32 - 28wigan warriorsdeacon 6 / 612798super league xii2007-02-03st helens34 - 22bradforddeacon 3 / 411793super league xii2007-11-03bradford56 - 18salford city redsdeacon 8 / 1010640super league xii0007-03-17harlequins rl22 - 36bradforddeacon 6 / 64011super league xii2007-03-25bradford22 - 29catalans dragonsdeacon 3 / 411298super league xii2007-03-30bradford24 - 16castleford tigersdeacon 4 / 46748rugby league challenge cup2007-05-04bradford14 - 18leeds rhinosdeacon 3 / 516706super league xii2007-09-04wakefield trinity wildcats24 - 36bradforddeacon 6 / 79106super league xii2007-04-15bradford52 - 22hull krdeacon 8 / 910881super league xii2007-04-20hull fc22 - 32bradforddeacon 4 / 612767super league xii2007-04-29bradford36 - 24warrington wolvesdeacon 3 / 3 , i harris 3 / 5 ,11200super league xii2007-06-05bradford38 - 42leeds rhinosdeacon 7 / 726667super league xii0007-05-13wakefield trinity wildcats4 - 14bradforddeacon 1 / 33568rugby league challenge cup0007-05-18huddersfield giants36 - 12bradfordi harris 2 / 28667super league xii2007-05-27bradford44 - 18harlequins rldeacon 6 / 810418super league xii2007-02-06catalans dragons20 - 28bradforddeacon 4 / 57555super league xii2007-10-06bradford52 - 20huddersfield giantsdeacon 8 / 107811rugby league challenge cup0007-06-17bradford34 - 8hull fcdeacon 4 / 6 , vainikolo 1 / 111557super league xii2007-06-29leeds rhinos14 - 38bradforddeacon 7 / 722000super league xii2007-06-07wigan warriors25 - 18bradforddeacon 5 / 515107super league xii0007-07-13bradford10 - 4st helensdeacon 3 / 311217super league xii2007-07-21salford city reds14 - 10bradforddeacon 1 / 23438super league xii2007-07-28bradford16 - 35st helensdeacon 1 / 314316rugby league challenge cup2007-05-08bradford38 - 24wakefield trinity wildcatsburgess 5 / 810701super league xii2007-12-08hull kr10 - 28bradfordi harris 4 / 56695super league xii0007-08-19huddersfield giants26 - 22bradfordharris 5 / 56824super league xii2007-09-02bradford16 - 16leeds rhinosdeacon 2 / 418000super league xii2007-09-09bradford40 - 8catalans dragonsiestyn harris (6 / 7)9350super league xii2007-09-14hull fc20 - 10bradfordi harris (1 / 2)14409super league xii2007-09-21bradford30 - 31wigan warriorsi harris (5 / 6)9000super league xii\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT score FROM table_sql WHERE date = '2007-04-15' AND competition = 'super league xii') = '52 - 22' \n             AND (SELECT attendance FROM table_sql WHERE date = '2007-04-15' AND competition = 'super league xii') = 9000 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1061.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the result of the game with a 4 - 1 score was 2 - 1 and the venue was london , england\nInput Table: kwak tae - hwi\n\n\ndatevenuescoreresultcompetition2008-02-02seoul , south korea1 - 04 - 02010 world cup qualification2008-02-17chongqing , china3 - 23 - 22008 east asian cup2008-10-15seoul , south korea4 - 14 - 12010 world cup qualification2010-03-03london , england2 - 02 - 0friendly2012-06-08doha , qatar2 - 14 - 12014 world cup qualification\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT result FROM table_sql WHERE score = '4 - 1' AND venue = 'london , england') = '2 - 1' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-546.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the duration of 02x03 - 03x05 is listed for max martini\nInput Table: list of csi : miami characters\n\n\ncharacterpositionactorfirst_episodefinal_episodedurationfinal_episode_countdr tom lomanmedical examinerchristian clemenson9999-01-019999-01-0108x03 - 10x1952maxine valeradna technicianboti bliss9999-01-019999-01-0102x01 - 08x1176dan cooperav technicianbrendan fehr9999-01-019999-01-0104x01 - 06x1635tyler jensonav technicianbrian pothYYYY-MM-DD9999-10-0701x19 - 03x2429aaron peterstrace technicianarmando kennedy9999-01-019999-01-0103x07 - 04x2516cynthia wellsqd technicianbrooke bloom9999-01-012023-09-2002x16 - 05x1814jake berkeleydetectivejohnny whitworth9999-01-012022-01-0105x02 - 08x2112john hagendetectiveholt mccallany9999-01-019999-10-0701x17 - 03x2411adelle sevilladetectivewanda de jesus9999-01-019999-01-0101x03 - 01x1710rebecca nevinsasachristina chang9999-01-019999-01-0103x06 - 08x2310joseph kaylefingerprints technicianleslie odom , jr9999-01-019999-01-0102x05 - 03x20 , 04x22 - 04x249aaron jessopofficerjoel west9999-01-019999-01-0102x20 - 04x258sam belmontestrace technicianchristian de la fuente9999-01-012022-01-0102x03 - 03x057peter elliottsecret service agentmichael b silver9999-01-019999-01-0102x17 - 05x037monica westasabellamy young9999-01-019999-01-0104x10 - 04x256glen colefbi agentmark rolston9999-01-019999-01-0104x25 - 06x123bob keatondea agentmax martini9999-01-019999-01-0102x08 , 03x20 - 03x223mac taylornypd csigary sinise9999-01-019999-01-0102x23 , 04x072stella bonaseranypd csimelina kanakaredes9999-01-019999-01-0102x231aiden burnnypd csivanessa ferlito9999-01-019999-01-0102x231danny messernypd csicarmine giovinazzo9999-01-019999-01-0102x231sheldon hawkesnypd medical examinerhill harper9999-01-019999-01-0102x231\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE character = 'sam belmontes' \nAND duration = '02x03 - 03x05' \nAND actor = 'max martini';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1471.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there was an 64.64 point difference between the highest score (186.92) and the lowest score (122.28)\nInput Table: 1979 world figure skating championships\n\n\nranknamenationsp_+_fspointsplaces1linda fratianneunited states1186.92112anett p\u00f6tzscheast germany3184.36183emi watanabejapan4180.52314dagmar lurzwest germany6179.96335denise biellmannswitzerland2177.28496lisa - marie allenunited states5176.68547claudia kristofics - binderaustria7175.44638susanna drianoitaly9173.46709carola wei\u00dfenbergeast germany11170.548810kristiina wegeliusfinland15169.269811carrie rughunited states10169.349712sanda dubrav\u010di\u0107yugoslavia8166.9611513natalia strelkovasoviet union16164.9413414deborah cottrillunited kingdom20164.813615karin riedigerwest germany17164.514216renata baierovaczechoslovakia13164.014417petra ernertwest germany14163.2414918kira ivanovasoviet union12164.0214719janet morrisseycanada18162.0416220reiko kobayashijapan21161.317021jeanne chapmannorway19161.816622anita siegfriedswitzerland26150.3420723astrid jansen in de walnetherlands25149.1821624franca bianconiitaly22149.0421825bodil olssonsweden23147.0222526corine wyrschswitzerland27146.7623327kim myo silnorth korea24145.4823728belinda coulthardaustralia28145.9223829katie symmondsnew zealand29134.5826130shin hae sooksouth korea30120.4427031gloria masspain31112.28279\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MAX(points) - MIN(points) FROM table_sql) = 64.64 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1650.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: north melbourne had the second highest score out all the way team\nInput Table: 1975 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddategeelong14.20 (104)melbourne14.14 (98)kardinia park133281975-06-07st kilda15.9 (99)north melbourne17.19 (121)moorabbin oval178111975-06-07richmond19.14 (128)essendon12.9 (81)mcg494691975-06-07hawthorn19.24 (138)collingwood13.11 (89)princes park238301975-06-07fitzroy15.7 (97)carlton16.10 (106)junction oval162491975-06-07footscray13.11 (89)south melbourne12.15 (87)vfl park140561975-06-07\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MAX(away_team_score) FROM table_sql WHERE away_team != 'north melbourne') < \n             (SELECT away_team_score FROM table_sql WHERE away_team = 'north melbourne' ORDER BY away_team_score DESC LIMIT 1 OFFSET 1) \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-902.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: all of the england players took as many wickets as bill johnston\nInput Table: 1948 ashes series\n\n\nplayerteammatcheswicketsaveragebest_bowlingray lindwallaustralia52719.626 / 20bill johnstonaustralia52723.335 / 36alec bedserengland51838.224 / 81keith milleraustralia51323.154 / 125ernie toshackaustralia41133.095 / 40norman yardleyengland5922.662 / 32jim lakerengland3952.444 / 138\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT wickets FROM table_sql WHERE team = 'england' AND player != 'bill johnston') = \n             (SELECT wickets FROM table_sql WHERE player = 'bill johnston') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1991.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the shortest time between two consecutive matches in march was two days\nInput Table: 2000 - 01 sheffield wednesday f.c. season\n\n\ndateopponentvenueresultattendance2000-08-13wolverhampton wanderersa1 - 1190862000-08-19huddersfield townh2 - 3227042000-08-26grimsby towna1 - 077552000-08-28blackburn roversh1 - 1156462000-09-09wimbledonh0 - 5158562000-09-13nottingham foresth0 - 1157002000-09-16tranmere roversa0 - 293522000-09-23preston north endh1 - 3173792000-09-30gillinghama0 - 290992000-10-08west bromwich albionh1 - 2153382000-10-14portsmoutha1 - 2133762000-10-17burnleya0 - 1163722000-10-22birmingham cityh1 - 0146952000-10-25queens park rangersa2 - 1103532000-10-28fulhamh3 - 3175592000-11-04crystal palacea1 - 4153332000-11-07watforda3 - 1111662000-11-01norwich cityh3 - 2169562000-11-18barnsleya0 - 1199892000-11-25crewe alexandraa0 - 171032000-12-02queens park rangersh5 - 2217822000-12-09stockport countyh2 - 4163372000-12-16sheffield uniteda1 - 1251562000-12-23wolverhampton wanderersh0 - 1177872000-12-26bolton wanderersa0 - 2213162000-12-30huddersfield towna0 - 0189312001-01-01grimsby townh1 - 0170042001-01-13blackburn roversa0 - 2193082001-01-20bolton wanderersh0 - 3176382001-02-03watfordh2 - 3161342001-02-10wimbledona1 - 467412001-02-13tranmere roversh1 - 0154442001-02-21nottingham foresta1 - 0232662001-02-24preston north enda0 - 2143792001-03-03gillinghamh2 - 1187022001-03-07portsmouthh0 - 0205032001-03-10west bromwich albiona2 - 1186622001-03-17burnleyh2 - 0201842001-03-24birmingham citya2 - 1197332001-04-01sheffield unitedh1 - 2384332001-04-07stockport countya1 - 296662001-04-14crystal palaceh4 - 1198772001-04-16fulhama1 - 1175002001-04-21barnsleyh2 - 1234982001-04-28norwich citya0 - 1212412001-05-06crewe alexandrah0 - 028007\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT strftime('%j', date) - LAG(strftime('%j', date)) OVER (ORDER BY date) AS days_diff \n              FROM table_sql \n              WHERE strftime('%m', date) = '03') <= 2 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-36.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: p\u00e1draig harrington is the only player from northern ireland\nInput Table: 2006 u.s. open (golf)\n\n\nplaceplayercountryscoreto_par1steve strickerunited states70 + 69 = 139- 12colin montgomeriescotland69 + 71 = 140et3kenneth ferrieengland71 + 70 = 141+ 1t3geoff ogilvyaustralia71 + 70 = 141+ 1t5jim furykunited states70 + 72 = 142+ 2t5p\u00e1draig harringtonireland70 + 72 = 142+ 2t7jason dufnerunited states72 + 71 = 143+ 3t7graeme mcdowellnorthern ireland71 + 72 = 143+ 3t7phil mickelsonunited states70 + 73 = 143+ 3t7arron oberholserunited states75 + 68 = 143+ 3\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE country = 'northern ireland' AND player = 'p\u00e1draig harrington') = 1 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1398.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: only 2 games were played on november 27th\nInput Table: 2009 - 10 temple owls men 's basketball team\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord19999-11-14delawarew 76 - 56ryan brooks - 23lavoy allen - 15juan fernandez - 5bob carpenter center , newark , de (3080)1 - 029999-11-17georgetown (19)l 46 - 45allen - 12allen - 14luiz guzman - 6verizon center , washington , dc (8712)1 - 139999-11-21sienaw 73 - 69fernandez - 20allen - 7allen - 5liacouras center , philadelphia , pa (6759)2 - 149999-11-24ball statew 66 - 46brooks - 17allen - 9allen / brooks - 7liacouras center , philadelphia , pa (3597)3 - 159999-11-27virginia techw 61 - 50allen - 18allen - 10fernandez - 6palestra , philadelphia , pa (3750)4 - 1\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 2 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE date = '9999-11-27';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1241.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: paul holahan only directed episodes for seasons 1 through season 6\nInput Table: list of white collar episodes\n\n\nno_in_seriesno_in_seasontitledirected_bywritten_byus_viewers_(million)original_air_dateproduction_code471wantedpaul holahanjeff eastin3.212012-07-10bcw401482most wantedpaul holahanmark goffman2.982012-07-17bcw402493diminishing returnsstefan schwartzjim campolongo3.012012-07-24bcw403504parting shotsrobert duncan mcneillalexandra mcnally2.822012-07-31bcw404515honor among thievesarlene sanfordjoe henderson2.932012-08-14bcw405526identity crisisdavid straitonchanning powell3.892012-08-21bcw406537compromising positionspaul holahanmatthew negrete3.362012-08-28bcw407548ancient historyrussell lee finedaniel shattuck3.382012-09-04bcw408559gloves offrenny harlinmark goffman3.82012-09-11bcw4095610vested interestrussell lee finejeff eastin3.412012-09-18bcw4105711family businesspaul holahanjoe henderson2.772013-01-22bcw4115812brass tacksanton cropperjim campolongo & alexandra mcnally2.612013-01-29bcw4125913empire citytim dekaychanning powell & daniel shattuck2.282013-02-05bcw4136014shoot the moonrussell lee finematthew negrete & bob derosa2.422013-02-19bcw4146115the originaljohn kretchmermark goffman2.122013-02-26bcw415\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE directed_by = 'paul holahan' \nAND no_in_season <= 6;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1501.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: potter co in copiah was the first project proposed , but the last to be listed\nInput Table: list of superfund sites in mississippi\n\n\ncerclis_idnamecountyproposedlistedconstruction_completedpartially_deleteddeletedmsd004006995american creosote works , incwinston2001-06-142001-09-139999-01-01--msd008154486chemfax , incharrison1993-06-239999-01-019999-01-01--msd046497012davis timber companylamar2000-05-112000-07-279999-01-01--msd980710941flowood siterankin1983-09-081984-09-211993-09-17-02 / 16 / 1996msd980840045newsom brothers / old reichhold chemicals , incmarion1984-10-151986-06-101997-08-08-09 / 27 / 2000msd065490930picayune wood treatingpearl river2004-03-082004-07-229999-01-01--msd056029648potter cocopiah1993-05-109999-01-019999-01-01--msd086556388sonford productsrankin2006-09-272007-03-079999-01-01--msd980601736walcotte chemical co warehouseswashington9999-01-019999-01-011982-12-30-12 / 30 / 1982\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT proposed FROM table_sql WHERE name = 'potter co' AND county = 'copiah') = \n             (SELECT MIN(proposed) FROM table_sql) \n        AND (SELECT listed FROM table_sql WHERE name = 'potter co' AND county = 'copiah') = \n             (SELECT MAX(listed) FROM table_sql) \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1442.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the dallas cowboys and the seattle seahawks played at the qwest field on december 31 , and the cowboys led in a final score of 20 - 9\nInput Table: nbc sunday night football results (2006 - present)\n\n\ndatevisiting_teamfinal_scorehost_teamstadium9999-09-07miami dolphins17 - 28pittsburgh steelersheinz field9999-09-10indianapolis colts26 - 21new york giantsgiants stadium9999-09-17washington redskins10 - 27dallas cowboystexas stadium9999-09-24denver broncos17 - 7new england patriotsgillette stadium9999-10-01seattle seahawks6 - 37chicago bearssoldier field9999-10-08pittsburgh steelers13 - 23san diego chargersqualcomm stadium9999-10-15oakland raiders3 - 13denver broncosinvesco field at mile high9999-10-29dallas cowboys35 - 14carolina panthersbank of america stadium9999-11-05indianapolis colts27 - 20new england patriotsgillette stadium9999-11-12chicago bears38 - 20new york giantsgiants stadium9999-11-19san diego chargers35 - 27denver broncosinvesco field at mile high9999-11-26philadelphia eagles21 - 45indianapolis coltsrca dome9999-12-03seattle seahawks23 - 20denver broncosinvesco field at mile high9999-12-10new orleans saints42 - 17dallas cowboystexas stadium9999-12-17kansas city chiefs9 - 20san diego chargersqualcomm stadium9999-12-25philadelphia eagles23 - 7dallas cowboystexas stadium9999-12-31green bay packers26 - 7chicago bearssoldier field0001-01-06kansas city chiefs8 - 23indianapolis coltsrca dome0001-01-06dallas cowboys20 - 21seattle seahawksqwest field\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT final_score FROM table_sql WHERE date = '9999-12-31' AND host_team = 'dallas cowboys' AND visiting_team = 'seattle seahawks' AND stadium = 'qwest field') = '20 - 9' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-209.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: on june 16th , jeff gordon was the driver in a ford for hendrick motorsports\nInput Table: pocono 400\n\n\nyeardatedriverteammanufacturerlaps-race_timeaverage_speed_(mph)report1982-01-019999-06-06bobby allisondigard motorsportsbuick200500 (804.672)4:24:08113.579report1983-01-019999-06-12bobby allisondigard motorsportsbuick200500 (804.672)3:53:13128.636report1984-01-019999-06-10cale yarboroughranier - lundychevrolet200500 (804.672)3:37:08138.164report1985-01-019999-06-09bill elliottmelling racingford200500 (804.672)3:35:48138.974report1986-01-019999-06-08tim richmondhendrick motorsportschevrolet200500 (804.672)4:24:50113.279report1987-01-019999-06-14tim richmondhendrick motorsportschevrolet200500 (804.672)4:05:57122.166report1988-01-019999-06-19geoffrey bodinehendrick motorsportschevrolet200500 (804.672)3:58:21126.147report1989-01-019999-06-18terry labontejunior johnson & associatesford200500 (804.672)3:48:27131.32report1990-01-019999-06-17harry gantleo jackson racingoldsmobile200500 (804.672)4:08:25120.6report1991-01-019999-06-16darrell waltripdarwal , incchevrolet200500 (804.672)4:04:34122.666report1992-01-019999-06-14alan kulwickiak racingford200500 (804.672)3:28:18144.023report1993-01-019999-06-13kyle pettysabco racingpontiac200500 (804.672)3:37:23138.005report1994-01-019999-06-12rusty wallacepenske racingford200500 (804.672)3:52:55128.801report1995-01-019999-06-11terry labontehendrick motorsportschevrolet200500 (804.672)3:37:50137.72report1996-01-019999-06-16jeff gordonhendrick motorsportschevrolet200500 (804.672)3:35:40139.104report1997-01-019999-06-08jeff gordonhendrick motorsportschevrolet200500 (804.672)3:34:33139.828report1998-01-019999-06-21jeremy mayfieldpenske racingford200500 (804.672)4:14:39117.809report1999-01-019999-06-20bobby labontejoe gibbs racingpontiac200500 (804.672)4:12:19118.898report2000-01-019999-06-19jeremy mayfieldpenske racingford200500 (804.672)3:34:41139.741report2001-01-019999-06-17ricky ruddrobert yates racingford200500 (804.672)3:43:14134.389report2002-01-019999-06-09dale jarrettrobert yates racingford200500 (804.672)3:29:10143.426report2003-01-019999-06-08tony stewartjoe gibbs racingchevrolet200500 (804.672)3:42:24134.892report2004-01-019999-06-13jimmie johnsonhendrick motorsportschevrolet200500 (804.672)4:27:33112.129report2005-01-019999-06-12carl edwardsroush racingford201502.5 (808.695)3:53:24129.177report2006-01-019999-06-11denny hamlinjoe gibbs racingchevrolet200500 (804.672)3:47:52131.656report2007-01-019999-06-10jeff gordonhendrick motorsportschevrolet106265 (426.476)1:57:15135.608report2008-01-019999-06-08kasey kahnegillett evernham motorsportsdodge200500 (804.672)3:59:36125.209report2009-01-019999-06-07tony stewartstewart - haas racingchevrolet200500 (804.672)3:36:35138.515report2010-01-019999-06-06denny hamlinjoe gibbs racingtoyota204510 (820.765)3:44:30136.303report2011-01-019999-06-12jeff gordonhendrick motorsportschevrolet200500 (804.672)3:26:21145.384report2012-01-019999-06-10joey loganojoe gibbs racingtoyota160400 (643.737)3:03:12131.004report\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE date = '9999-06-16' \nAND driver = 'jeff gordon' \nAND team = 'hendrick motorsports' \nAND manufacturer = 'ford';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1359.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: miguel zapata is the goalkeeper with 24 goals and an average of 0.61\nInput Table: 2008 - 09 segunda divisi\u00f3n b\n\n\ngoalkeepergoalsmatchesaverageteammiguel zapata17280.61atl\u00e9tico ciudadrub\u00e9n mart\u00ednez24320.75cartagenaorlando quintana29340.85lorca deportiva\u00e1lvaro campos24280.86real murcia bmat\u00edas garavano26300.87m\u00e9rida\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT goals FROM table_sql WHERE goalkeeper = 'miguel zapata') = 24 \n             AND (SELECT average FROM table_sql WHERE goalkeeper = 'miguel zapata') = 0.61 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1136.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there are two players with the highest number of total goals ian robins and chris toppings\nInput Table: 1979 - 80 huddersfield town f.c. season\n\n\nnamepositionleague_appsleague_goalsfa_cup_appsfa_cup_goalsleague_cup_appsleague_cup_goalstotal_appstotal_goalsjim branagandf00000 (1)00 (1)0malcolm browndf4622041523david cowlingmf39 (1)10104044 (1)10peter fletcherfw30 (8)17203135 (8)18keith hanveydf3320040392peter hartmf4641140515ian holmesmf6 (4)3004110 (4)4steve kindonfw22 (1)14000022 (1)14mick laverickmf4542040514bernard purdiedf18 (4)0200020 (4)0andy rankingk2400000240ian robinsfw452520425127fred robinsondf3012040361tommy smithfw00001010brian stantonmf4192000439alan starlinggk2202040280dave suttondf4662041527chris toppingdf1302000150\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MAX(total_goals) FROM table_sql) = (SELECT total_goals FROM table_sql WHERE name = 'ian robins') \n             OR (SELECT MAX(total_goals) FROM table_sql) = (SELECT total_goals FROM table_sql WHERE name = 'chris topping') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-255.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: galina voskoboeva played 20% of her games on a clay top tennis court\nInput Table: galina voskoboeva\n\n\noutcomedatetournamentsurfaceopponentscorerunner - up2003-01-28tiptonhard (i)matea mezak6 - 4 , 4 - 6 , 4 - 6winner2003-06-29mont - de - marsanhard (i)oleksandra kravets6 - 4 , 6 - 2runner - up2003-10-03latinaclayroberta vinci3 - 6 , 4 - 6runner - up2005-11-08pittsburghhardlilia osterloh6 - 7 , 4 - 6winner2006-06-06cuneo , italyclayalice canepa6 - 1 , 6 - 2\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE surface = 'clay') / (SELECT COUNT(*) FROM table_sql) >= 0.2 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-105.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: united states has a 69 + 73 + 72 + 75 = 289 score\nInput Table: 1975 u.s. open (golf)\n\n\nplaceplayercountryscoreto_parmoneyt1lou grahamunited states74 + 72 + 68 + 73 = 287+ 3playofft1john mahaffeyunited states73 + 71 + 72 + 71 = 287+ 3playofft3frank beardunited states74 + 69 + 67 + 78 = 288+ 410875t3ben crenshawunited states70 + 68 + 76 + 74 = 288+ 410875t3hale irwinunited states74 + 71 + 73 + 70 = 288+ 410875t3bob murphyunited states74 + 73 + 72 + 69 = 288+ 410875t7jack nicklausunited states72 + 70 + 75 + 72 = 289+ 57500t7peter oosterhuisengland69 + 73 + 72 + 75 = 289+ 57500t9pat fitzsimonsunited states67 + 73 + 73 + 77 = 290+ 65000t9arnold palmerunited states69 + 75 + 73 + 73 = 290+ 65000t9tom watsonunited states67 + 68 + 78 + 77 = 290+ 65000\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT score FROM table_sql WHERE country = 'united states' AND player = 'lou graham') = 289 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-224.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: on march 15 , 2007 and in region 2 the highest number of episodes is 3\nInput Table: none\n\n\nvolumediscsepisodesregion_1region_2region_41142006-01-312007-02-192007-03-152142006-03-282007-06-042007-07-053142006-05-302007-09-032008-03-134142006-07-182008-02-182008-06-195142006-09-192008-05-262009-03-05\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT episodes FROM table_sql WHERE region_2 = '2007-03-15') = 3 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-739.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the highest attendance of the season was on september 5\nInput Table: 2008 arizona diamondbacks season\n\n\ndateopponentscorelossattendancerecord9999-09-01cardinals8 - 6mcclellan (2 - 7)3507570 - 679999-09-02cardinals8 - 2petit (3 - 4)2756870 - 689999-09-03cardinals4 - 3perez (2 - 2)2435071 - 689999-09-05dodgers7 - 0haren (14 - 8)5227071 - 699999-09-06dodgers7 - 2webb (19 - 7)4754371 - 709999-09-07dodgers5 - 3rauch (4 - 6)5413771 - 719999-09-08giants6 - 2petit (3 - 5)3025271 - 729999-09-09giants5 - 4rauch (4 - 7)3051871 - 739999-09-10giants4 - 3lyon (2 - 5)3099271 - 749999-09-12reds3 - 2harang (4 - 16)2904672 - 749999-09-13reds3 - 2 (10)pe\u00f1a (1 - 2)4507572 - 759999-09-14reds2 - 1 (10)rauch (4 - 8)2729772 - 769999-09-15giants3 - 1hennessey (1 - 2)2596973 - 769999-09-16giants2 - 0cain (8 - 13)3319574 - 769999-09-17giants7 - 6s\u00e1nchez (9 - 11)2261675 - 769999-09-18giants3 - 2lincecum (17 - 4)3432376 - 769999-09-19rockies3 - 2scherzer (0 - 3)4313776 - 779999-09-20rockies5 - 3fuentes (1 - 5)3828377 - 779999-09-21rockies13 - 4reynolds (2 - 8)3291578 - 779999-09-22cardinals4 - 2wellemeyer (12 - 9)4034979 - 779999-09-23cardinals7 - 4johnson (10 - 10)4001379 - 789999-09-24cardinals4 - 2scherzer (0 - 4)4002979 - 799999-09-25cardinals12 - 3rosales (1 - 1)4050279 - 809999-09-26rockies6 - 4grilli (3 - 3)3495080 - 809999-09-27rockies6 - 4corpas (3 - 4)3323481 - 809999-09-28rockies2 - 1vizca\u00edno (1 - 2)3590882 - 80\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN MAX(attendance) = 52270 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE date = '9999-09-05';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-459.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the dolphins' final 10 games were victories\nInput Table: 1983 miami dolphins season\n\n\nweekdateopponentresultattendance11983-09-04buffalo billsw 12 - 07871521983-09-11new england patriotsw 34 - 245934331983-09-19los angeles raidersl 27 - 145779641983-09-25kansas city chiefsw 14 - 65078551983-10-02new orleans saintsl 17 - 76648961983-10-09buffalo billsl 38 - 355994871983-10-16new york jetsw 32 - 145861581983-10-23baltimore coltsw 21 - 73234391983-10-30los angeles ramsw 30 - 1472175101983-11-06san francisco 49ersw 20 - 1757832111983-11-13new england patriotsl 17 - 660771121983-11-20baltimore coltsw 37 - 054482131983-11-28cincinnati bengalsw 38 - 1474506141983-12-04houston oilersw 24 - 1739434151983-12-10atlanta falconsw 31 - 2456725161983-12-16new york jetsw 34 - 1459975\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE result = 'w' AND week > 6) = 10 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1913.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: none teams tied on points , but most were separated by more than 1 goal difference\nInput Table: 1940 in brazilian football\n\n\npositionteampointsplayedagainstdifference1flamengo1381282fluminense13815103corinthians981544palestra it\u00e1lia881935portuguesa7823- 106botafogo682507vasco da gama6819- 28am\u00e9rica6825- 109s\u00e3o paulo4824- 13\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE points = (SELECT MAX(points) FROM table_sql) \nAND difference > 1;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1116.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: steve gould is lead in richmond\nInput Table: 2009 canadian olympic curling trials\n\n\nskipthird_/_vice_skipsecondleadcitykerry burtnykdon walchukrichard daneaultgarth smithwinnipegpat simmonsgerry adamjeff sharpsteve laycockdavidsonjeff stoughtonkevin parkrob fowlersteve gouldwinnipegwayne middaughjon meadjohn eppingscott baileyislingtonbrad gushuemark nicholsryan fryjamie korabst john 'smike mcewenb j neufeldmatt wozniakdenni neufeldwinnipegjoel jordisonscott bitzaryn schmidtdean hickemoose jawbob urseljim cotterkevin folkrick sawatskykelownajean - michel m\u00e9nardmartin cr\u00eate\u00e9ric sylvainjean gagnonl\u00e9visted appelmantom appelmanbradon klassenbrendan melnykedmontongreg mcaulayken maskiewichdeane horningaaron watsonrichmondjason gunnlaugsonjustin richterbraden zawadatyler forrestbeausejour\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE lead = 'steve gould' \nAND city = 'richmond';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1971.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the name of the visitor in vancouver on february 24 , is winnipeg\nInput Table: 1992 - 93 vancouver canucks season\n\n\ndatevisitorscorehomedecisionattendancerecord01-02-9999minnesota5 - 4vancouvermclean1483029 - 15 - 89999-02-03tampa bay2 - 4vancouverwhitmore1417130 - 15 - 89999-02-09vancouver5 - 1quebecmclean1436031 - 15 - 801-02-11vancouver2 - 5torontomclean1572031 - 16 - 801-02-12vancouver3 - 1buffalowhitmore1632532 - 16 - 801-02-15vancouver0 - 3los angelesmclean1600532 - 17 - 89999-02-18philadelphia3 - 2vancouverwhitmore1615032 - 18 - 89999-02-20winnipeg2 - 4vancouvermclean1615033 - 18 - 89999-02-22toronto8 - 1vancouvermclean1615033 - 19 - 89999-02-24ny rangers4 - 5vancouverwhitmore1615034 - 19 - 89999-02-26vancouver7 - 4winnipegmclean1539835 - 19 - 8\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN visitor = 'winnipeg' AND date = '9999-02-24' AND home = 'vancouver' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-479.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: princes park had footscray as its home team\nInput Table: 1927 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddatefootscray10.6 (66)melbourne10.13 (73)western oval110001927-09-10carlton15.16 (106)st kilda7.9 (51)princes park240001927-09-10richmond16.23 (119)hawthorn6.17 (53)punt road oval110001927-09-10south melbourne14.11 (95)geelong15.15 (105)lake oval150001927-09-10fitzroy5.13 (43)essendon14.10 (94)brunswick street oval110001927-09-10north melbourne7.14 (56)collingwood11.16 (82)arden street oval110001927-09-10\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE venue = 'princes park' \nAND home_team = 'footscray';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-994.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: january was the month that aired the most episodes with five\nInput Table: list of republic of doyle episodes\n\n\nUnnamed:_0titledirected_bywritten_byviewersoriginal_airdateprod_code1fathers and sonsmike clattenburgallan hawco , perry chafe and malcolm macrury9690002010-01-061012the return of the grievous angelsteve dimarcoallan hawco and avrum jacobson7150002010-01-131023duchess of georgemike clattenburgallan hawco , perry chafe and malcolm macrury6850002010-01-201035hit and rumsteve dimarcomatt maclennan5940002010-02-031056the one who got awaylarry mcleanjesse mckeown10120002010-02-101067the woman who knew too littlerobert liebermanjeremy boxen10530002010-03-031078the tell - tale safejerry ciccorittijohn callaghan and steve cochrane9860002010-03-101089he sleeps with the chipsphil earnshawperry chafe9080002010-03-1710910the pen is mightier than the doylerobert liebermansteve cochrane and avrum jacobson8970002010-03-2411011a horse dividedsteve scainijesse mckeown9020002010-03-31111\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE strftime('%m', original_airdate) = '01') = 5 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1383.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: highest total score for ukraine is 2 while the highest total score of estonia is 8\nInput Table: 2006 - 07 isu junior grand prix\n\n\nranknationgoldsilverbronzetotal1united states24128442russia556163canada127104japan14385estonia12145italy03146south korea00337france01127ukraine01128spain01018china01018czech republic0011\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT total FROM table_sql WHERE nation = 'ukraine') = 2 \n             AND (SELECT total FROM table_sql WHERE nation = 'estonia') = 8 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-169.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the ebraer emb 120 basilia from switzerland is a transport / utility type aircraft\nInput Table: uruguayan air force\n\n\naircraftorigintypeversionsin_servicecessna a - 37 dragonflyunited statesattack / fightera - 37b12 (16 delivered)fma ia 58 pucar\u00e3\u00a1argentinaattacka - 585 (6 delivered)lockheed c - 130 herculesunited statestransport / utilityc - 130b2embraer emb 110 bandeirantebraziltransport / utilityc - 953beechcraft twin bonanzaunited statestransport / utilityd501casa c - 212 aviocarspaintransportc - 212 - 2002embraer emb 120 brasiliabraziltransportemb 1201cessna 206 stationairunited statesutility / liaisonu206h10beechcraft b58 baronunited statestrainer / liaisonb - 582british aerospace 125united kingdomvip transport700a 600a2aermacchi sf260italytrainert - 260 eu12pilatus pc - 7 turbo trainerswitzerlandtrainer- 925 (6 delivered)cessna t - 41 mescalerounited statestrainert - 41d7aerospatiale as 365 dauphinfranceliaison / transportas 3651bell 212 twin hueyunited statestransport / utilitybell 2124bell uh - 1 iroquoisunited statestransport / utilityuh - 1h13\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE aircraft = 'embraer emb 120 brasilia' AND origin = 'switzerland' AND type = 'transport / utility') > 0 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-620.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the title of the episode with series number 14 is new rules\nInput Table: none\n\n\nepisodeseriesepisode_titleoriginal_air_dateproduction_code271return to genesis2008-04-05201282the suspension2008-04-06202293a team reinvented2008-04-12203304the new captain2008-04-13204315the homecoming2008-04-19205326netherball rules!2008-04-20206337doubts within2008-04-26207348rocket 's decent2008-04-27208359the all - stars2008-05-032093610rocket vs sinedd2008-05-042103711the champions stumble2008-05-102113812last stand2008-05-112123913fluxless2008-05-172134014new order2008-07-262144115revelations2008-07-272154216new rules2008-08-022164317open doors2008-08-032174418warren steps in2008-08-092184519the technodroid v3s2008-08-102194620the fallen star2008-08-162204721coach artegor2008-08-172214822rocket , the midfielder2008-08-232224923destiny2008-08-242235024final preparations2008-08-312245125a team unravels2008-08-31225\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN episode_title = 'new rules' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE episode = 40;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-141.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the nation of croatia received less than 2 silver medals with a total medal of only 1\nInput Table: 2003 world taekwondo championships\n\n\nranknationgoldsilverbronzetotal1south korea802102iran22153chinese taipei20134united states12365spain11356china11137greece10238croatia02139france020210germany012311canada011211denmark011113cuba010113great britain010113mexico010116azerbaijan004417thailand002218australia001118austria001118belarus001118kazakhstan001118morocco001118philippines001118turkey001118venezuela0011totaltotal16163264\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT silver FROM table_sql WHERE nation = 'croatia' AND rank != 'total') < 2 \n             AND (SELECT total FROM table_sql WHERE nation = 'croatia' AND rank != 'total') = 1 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1797.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the actor of the character ariadne oliver is hugh fraser\nInput Table: list of agatha christie 's poirot episodes\n\n\nactorcharactertitle_/_rankseriesyearsdavid suchethercule poirotvarious1 - 131989 - 2013hugh fraserarthur hastingscaptain obe1 - 8 , 131989 - 2002 , 2013philip jacksonjames jappchief inspector1 - 8 , 131989 - 2001 , 2013pauline moranfelicity lemonsecretary1 - 3 , 5 - 8 , 131989 - 1991 , 1993 - 2001 , 2013zo\u00eb wanamakerariadne olivercrime novelist10 - 132006 - 2013david yellandgeorgebutler10 - 132006 - 2013\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT actor FROM table_sql WHERE character = 'ariadne oliver') = 'hugh fraser' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1346.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the game between footscray and fitzroy was played at windy hill\nInput Table: 1962 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddatemelbourne11.18 (84)st kilda11.6 (72)mcg489521962-06-23essendon15.17 (107)geelong10.7 (67)windy hill350001962-06-23collingwood10.14 (74)fitzroy9.11 (65)victoria park264881962-06-23carlton12.9 (81)footscray9.10 (64)princes park324001962-06-23south melbourne10.13 (73)richmond11.13 (79)lake oval170001962-06-23north melbourne10.8 (68)hawthorn10.7 (67)arden street oval84701962-06-23\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE home_team = 'footscray' \nAND away_team = 'fitzroy' \nAND venue = 'windy hill';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1325.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: parren mitchell was re - elected for the district maryland 8\nInput Table: united states house of representatives elections , 1974\n\n\ndistrictincumbentpartyfirst_electedresultcandidatesmaryland 1robert baumanrepublican1973-01-01re - electedrobert bauman (r) 53.0% thomas j hatem (d) 47.0%maryland 2clarence longdemocratic1962-01-01re - electedclarence long (d) 77.1% john m seney (r) 22.9%maryland 4marjorie holtrepublican1972-01-01re - electedmarjorie holt (r) 58.1% fred l wineland (d) 41.9%maryland 6goodloe byrondemocratic1970-01-01re - electedgoodloe byron (d) 73.7% elton r wampler (r) 26.3%maryland 7parren mitchelldemocratic1970-01-01re - electedparren mitchell (d) unopposed\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE district = 'maryland 8' \nAND incumbent = 'parren mitchell' \nAND result = 're - elected';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-398.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: botswana defence force xi has the lowest agg in the season\nInput Table: 1992 african cup of champions clubs\n\n\nteam_1aggteam_21st_leg2nd_legbotswana defence force xi1 - 2mbabane highlanders1 - 10 - 1arsenal (maseru)4 - 0eleven arrows fc3 - 01 - 0cd el\u00e1 nguema2 - 6primeiro de agosto2 - 30 - 3 1lprc oilers2 - 3mighty blackpool1 - 01 - 3asc police2 - 2 (4 - 5)as real bamako1 - 11 - 1port autonome0 - 0 (1 - 3)sporting clube da praia0 - 00 - 0saint - george sa2 - 4al ittihad2 - 10 - 3saint - louis fc2 - 7young africans1 - 31 - 4sahel sc4 - 2postel sport2 - 12 - 1tourbillon fc1 - 1forces arm\u00e9es ca0 - 01 - 1\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MIN(agg) FROM table_sql) = (SELECT agg FROM table_sql WHERE team_1 = 'botswana defence force xi') \n             OR (SELECT MIN(agg) FROM table_sql) = (SELECT agg FROM table_sql WHERE team_2 = 'botswana defence force xi') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-668.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: aldershot town was the opponent on 10 march 2009 , when bradford city scored their highest point total\nInput Table: 2008 - 09 bradford city a.f.c. season\n\n\ngamedateopponentvenueresultattendance12008-08-09notts countyhome2 - 11403822008-08-16macclesfield townaway2 - 0255632008-08-23rochdalehome2 - 01315442008-08-30aldershot townaway2 - 3380552008-09-06port valeaway2 - 0727362008-09-13exeter cityhome4 - 11268372008-09-20bournemouthhome1 - 31282482008-09-27shrewsbury townaway0 - 2651792008-10-04luton townhome1 - 113083102008-10-11accrington stanleyaway3 - 23012112008-10-18gillinghamhome2 - 212432122008-10-21darlingtonaway1 - 23034132008-10-24grimsby townaway3 - 14470142008-10-28buryhome1 - 012830152008-11-01barnethome3 - 312510162008-11-15wycombe wanderersaway0 - 15002172008-11-22rotherham unitedaway2 - 04586182008-11-25chesterfieldhome3 - 212145192008-12-06dagenham & redbridgehome1 - 112145202008-12-13brentfordaway1 - 24339212008-12-20chester cityhome0 - 012092222008-12-26lincoln cityaway0 - 06156232008-12-28morecambehome4 - 013105242009-01-03shrewsbury townhome0 - 012877252009-01-17accrington stanleyhome1 - 112172262009-01-24luton townaway3 - 36053272009-01-27buryaway0 - 14112282009-01-31grimsby townhome2 - 012816292009-02-07gillinghamaway2 - 04866302009-02-14wycombe wanderershome1 - 012689312009-02-17darlingtonhome0 - 012782322009-02-21barnetaway1 - 42445332009-02-28notts countyaway1 - 35138342009-03-01macclesfield townhome1 - 011908352009-03-07aldershot townhome5 - 012465362009-03-10rochdaleaway0 - 35157372009-03-14exeter cityaway0 - 15253382009-03-17bournemouthaway1 - 44847392009-03-21port valehome0 - 112436402009-03-28chester cityaway0 - 02735412009-04-04brentfordhome1 - 112832422009-04-10morecambeaway1 - 24546432009-04-13lincoln cityhome1 - 112932\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT result FROM table_sql WHERE date = '2009-03-10' AND opponent = 'aldershot town') = '0 - 3' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1811.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: equestrian at the asian games has been located in a different city every year that it occurred except 1994 and 1998\nInput Table: equestrian at the asian games\n\n\nyearlocationgoldsilverbronze1982new delhinadia al - moutawaajamila al - moutawaabariaa salem al - sabbah1986seoultakashi tomurashuichi tokiryuzo okuno1994hiroshimakonoshin kuwahararyuzo okunonatya chantrasmi1998bangkokjin kannosohn bong - gakquzier ambak fathil2002busanmikaela mar\u00e3\u00ada jaworskilee jin - kyungtadayoshi hayashi2006dohaali yousuf al - rumaihijasmine chen - shao manjoo jung - hyun2010guangzhouramzy al duhamilatifa al maktomkhaled al - eid\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(DISTINCT location) = COUNT(*) - 2 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE year != 1994 AND year != 1998;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-502.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: freddy gonzalez was the winner if the points classification award was given to oscar solis and the sprints classification award was given to epm - une\nInput Table: 2010 vuelta a colombia\n\n\nstagewinnergeneral_classificationpoints_classificationmountains_classificationsprints_classificationteam_classification1ind ant - idea - fla - lot de medell\u00ednsergio luis henaono awardno awardno awardind ant - idea - fla - lot de medell\u00edn2jaime casta\u00f1eda\u00f3scar sevillajaime casta\u00f1edajaime vergaracamilo g\u00f3mezind ant - idea - fla - lot de medell\u00edn3jairo p\u00e9rezjairo p\u00e9rezjaime casta\u00f1edajaime vergarajulian lopezind ant - idea - fla - lot de medell\u00edn4sergio luis henao\u00f3scar sevilla\u00f3scar sevillajaime vergarajulian lopezind ant - idea - fla - lot de medell\u00edn5fabio duarte\u00f3scar sevilla\u00f3scar sevillajaime vergarajulian lopezind ant - idea - fla - lot de medell\u00edn6luis felipe laverde\u00f3scar sevilla\u00f3scar sevillajaime vergarajaime suazaind ant - idea - fla - lot de medell\u00edn7freddy gonzalez\u00f3scar sevilla\u00f3scar sevillajaime vergaracamilo g\u00f3mezcol es pasion caf\u00e9 de colombia 4728diego calder\u00f3n\u00f3scar sevilla\u00f3scar sevillaoscar solisjuan alejandro garciaind ant - idea - fla - lot de medell\u00edn9jos\u00e9 rujanosergio luis henaosergio luis henaooscar solisjuan alejandro garciaind ant - idea - fla - lot de medell\u00edn10sergio luis henaosergio luis henaosergio luis henaooscar solisjuan alejandro garciaepm - une11jaime vergarasergio luis henaosergio luis henaooscar solisjuan alejandro garciaepm - une12fabio duartesergio luis henaosergio luis henaooscar solisjuan alejandro garciacol es pasion caf\u00e9 de colombia 47213javier gonzalezsergio luis henaosergio luis henaojos\u00e9 rujanojuan alejandro garciaepm - une\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT winner FROM table_sql WHERE points_classification = 'oscar solis' AND sprints_classification = 'epm - une') = 'freddy gonzalez' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1193.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: alfredo binda won seven races of the 1933 giro d'italia , but he was the race leader for 15 races\nInput Table: 1933 giro d'italia\n\n\ndatecoursedistancewinnerrace_leader9999-05-06milan to turin-learco guerra ( ita )learco guerra ( ita )9999-05-07turin to genoa-alfredo binda ( ita )alfredo binda ( ita )9999-05-08genoa to pisa-learco guerra ( ita )alfredo binda ( ita )9999-05-09rest dayrest dayrest dayrest day9999-05-10pisa to florence-giuseppe olmo ( ita )alfredo binda ( ita )9999-05-11florence to grosseto-learco guerra ( ita )jef demuysere ( bel )9999-05-12grosseto to rome-mario cipriani ( ita )jef demuysere ( bel )9999-05-13rest dayrest dayrest dayrest day9999-05-14rome to naples-gerard loncke ( bel )jef demuysere ( bel )9999-05-15naples to foggia-alfredo binda ( ita )alfredo binda ( ita )9999-05-16rest dayrest dayrest dayrest day9999-05-17foggia to chieti-alfredo binda ( ita )alfredo binda ( ita )9999-05-18chieti to ascoli piceno-alfredo binda ( ita )alfredo binda ( ita )9999-05-19rest dayrest dayrest dayrest day9999-05-20ascoli piceno to riccione-fernand cornez ( fra )alfredo binda ( ita )9999-05-21riccione to bologna-giuseppe olmo ( ita )alfredo binda ( ita )9999-05-22bologna to ferrara-alfredo binda ( ita )alfredo binda ( ita )9999-05-23rest dayrest dayrest dayrest day9999-05-24ferrara to udine-ettore meini ( ita )alfredo binda ( ita )9999-05-25udine to bassano del grappa-ettore meini ( ita )alfredo binda ( ita )9999-05-26bassano del grappa to bolzano-gerard loncke ( bel )alfredo binda ( ita )9999-05-27rest dayrest dayrest dayrest day9999-05-28bolzano to milan-alfredo binda ( ita )alfredo binda ( ita )2023-09-20-km (mi)-km (mi)\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE winner = 'alfredo binda ( ita )') = 7 \n             AND (SELECT COUNT(*) FROM table_sql WHERE race_leader = 'alfredo binda ( ita )') = 15 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-975.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: coopers town is famous for the blanchard bridge\nInput Table: list of bridges on the national register of historic places in north dakota\n\n\nnamelistedlocationcountytypebeaver creek bridge1997-02-27finleysteelepratt through trusscaledonia bridge1997-02-27caledoniatraillpratt through trusscedar creek bridge1997-02-27haynesadamspratt through trusscolton 's crossing bridge1997-02-27lisbonransompratt through trusscrystal bridge1997-05-30crystalpembinaconcrete t - beam bridgeeastwood park bridge1975-04-21minotwardcantilever typeelliott bridge1997-02-27townermchenrypratt through trussfairview lift bridge1997-03-14cartwrightmckenzierailroad lift bridgegrace city bridge1997-02-27grace cityfosterpratt through trussgreat northern railway underpass1997-02-27stanleymountrailconcrete deck girder bridgeknife river bridge near stanton2001-04-25stantonmercerpratt through trusslisbon bridge1997-02-27lisbonransomsteel cantilever bean bridgemidland continental overpass1997-02-27jamestownstutsmansteel cantilever beam bridgemidway bridge1997-02-27johnstowngrand forkswarren bedstead bridgenesheim bridge1997-02-27mcvillenelsonpratt through trussnew rockford bridge1997-03-13new rockford closed to trafficeddywarren through truss bridgenorthwood bridge1997-02-27northwoodgrand forkspratt pony trussnorway bridge1997-02-27mayvilletraillpratt pony trussost valle bridge1997-02-27thompsongrand forkspratt through trussromness bridge1997-02-27cooperstowngriggspratt through trusssorlie memorial bridge1999-07-19grand forksgrand forksparker through truss bridgeviking bridge1997-02-27portlandtraillpratt through trusswest antelope bridge1997-02-27florabensonpratt pony truss bridgewest park bridge1997-02-27valley citybarnesconcrete false arch bridgewestgaard bridge1997-02-27voltairemchenrypratt pony through trussblanchard bridge1997-02-27blanchardtraillpratt through trussgoose river bridge1997-02-27hillsborotraillpratt through trussliberty memorial bridge1997-03-11 removed 2009-03-25bismarckburleighwarren - turner through trussporter elliott bridge1997-02-27hillsborotraillwarren through trussportland park bridge2004-09-23portlandtraillsteel through girderrainbow arch bridge2004-09-23valley citybarnesmarsh rainbow arch\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE name = 'blanchard bridge' \nAND location = 'cooperstown';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1769.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: ilir meta , bashkim fino , ylli bufi and pandeli majko (1st time) were all members of the democratic party of albania\nInput Table: list of prime ministers of albania\n\n\nnameborn_-_diedterm_startterm_endpolitical_partyprime ministers 1991 onwards1991-01-011991-01-011991-01-01prime ministers 1991 onwardsfatos nano (1st time)9999-01-011991-02-221991-06-05party of labour of albaniaylli bufi9999-01-011991-06-051991-12-10socialist party of albaniavilson ahmeti9999-01-011991-12-101992-04-13non - partyaleksand\u00ebr meksi9999-01-011992-04-131997-03-11democratic party of albaniabashkim fino9999-01-011997-03-111997-07-24socialist party of albaniafatos nano (2nd time)9999-01-011997-07-241998-10-02socialist party of albaniapandeli majko (1st time)9999-01-011998-10-021999-10-29socialist party of albaniailir meta9999-01-011999-10-292002-02-22socialist party of albaniapandeli majko (2nd time)9999-01-012002-02-222002-07-31socialist party of albaniafatos nano (3rd time)9999-01-012002-07-312005-09-11socialist party of albaniasali berisha1944-01-012005-09-112013-09-15democratic party of albaniaedi rama9999-01-012013-09-159999-01-01socialist party of albania\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE political_party = 'democratic party of albania' AND \n              name IN ('ilir meta', 'bashkim fino', 'ylli bufi', 'pandeli majko (1st time)')) = 4 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1801.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: roberto gamarra is the outgoing manager of nejapa\nInput Table: primera divisi\u00f3n de f\u00fatbol profesional apertura 2008\n\n\nteamoutgoing_managermanner_of_departuredate_of_vacancyreplaced_bydate_of_appointmentposition_in_tablenejapamauricio cienfuegosmutual consent2008-08-14daniel uberti2008-09-0510thfirpogerardo reinososacked2008-08-25oscar benitez2008-09-027thbalboagustavo de simonesacked2008-08-30roberto gamarra2008-09-0510thalianzapablo centronesacked2008-09-14carlos jurado2008-09-165thfirpooscar ben\u00edtezsacked2008-12-09agust\u00edn castillo2008-12-23post - season (6th)\u00e1guilaagust\u00edn castillosacked2008-12-15pablo centrone2008-12-24post - season (semifinals)fasnelson anchetasacked2008-12-27roberto gamarra2009-01-01post - season (semifinals)nejapadaniel ubertisacked2008-12-29nelson ancheta2008-12-29post - season (10th)balboaroberto gamarramutual consent2009-01-01carlos de toro2009-01-16post - season (7th)\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE team = 'nejapa' \nAND outgoing_manager = 'roberto gamarra';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1757.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: august 31st 1947 was the date of the last game of the season\nInput Table: 1947 san francisco 49ers season\n\n\nweekdateopponentresultscorerecord11947-08-31brooklyn dodgersw23 - 71 - 021947-09-07los angeles donsw17 - 142 - 031947-09-14baltimore coltsw14 - 73 - 041947-09-21new york yankeesl21 - 163 - 151947-09-28buffalo billsw41 - 244 - 161947-10-05baltimore coltst28 - 284 - 1 - 171947-10-12chicago rocketsw42 - 285 - 1 - 181947-10-26cleveland brownsl14 - 75 - 2 - 191947-11-02los angeles donsw26 - 166 - 2 - 1101947-11-09new york yankeesl24 - 166 - 3 - 1111947-11-16cleveland brownsl37 - 146 - 4 - 1121947-11-21chicago rocketsw41 - 167 - 4 - 1131947-11-27brooklyn dodgersw21 - 78 - 4 - 1141947-12-07buffalo billst21 - 218 - 4 - 2\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MAX(date) FROM table_sql) = '1947-08-31' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-872.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: when the engine was maserati l4s and the driver was nino farina\nInput Table: 1950 swiss grand prix\n\n\ndriverentrantconstructorchassisenginetyrenello paganiscuderia achille varzimaseratimaserati 4clt - 48maserati l4spjohnny claesecurie belgetalbot - lagotalbot - lago t26ctalbot l6dyves giraud - cabantousautomobiles talbot - darracq satalbot - lagotalbot - lago t26c - datalbot l6deug\u00e8ne martinautomobiles talbot - darracq satalbot - lagotalbot - lago t26c - datalbot l6dlouis rosierautomobiles talbot - darracq satalbot - lagotalbot - lago t26c - datalbot l6dluigi fagiolisa alfa romeoalfa romeoalfa romeo 158alfa romeo l8spjuan manuel fangiosa alfa romeoalfa romeoalfa romeo 158alfa romeo l8spnino farinasa alfa romeoalfa romeoalfa romeo 158alfa romeo l8spalberto ascariscuderia ferrariferrariferrari 125ferrari v12spraymond sommerscuderia ferrariferrariferrari 125ferrari v12spluigi villoresiscuderia ferrariferrariferrari 125ferrari v12sppeter whiteheadscuderia ferrariferrariferrari 125ferrari v12splouis chironofficine alfieri maseratimaseratimaserati 4clt - 48maserati l4spfranco rolofficine alfieri maseratimaseratimaserati 4clt - 48maserati l4spprince biraenrico plat\u00e9maseratimaserati 4clt - 48maserati l4sptoulo de graffenriedenrico plat\u00e9maseratimaserati 4clt - 48maserati l4spfelice bonettoscuderia milanomaseratimaserati milano 4clt - 50maserati l4spreg parnellscuderia ambrosianamaseratimaserati 4clt - 48maserati l4sdrudi fischerecurie espadonsva - fiatsva 1500fiat l4sptoni brancaprivatemaseratimaserati 4clmaserati l4spphilippe \u00e9tancelinprivatetalbot - lagotalbot - lago t26ctalbot l6dharry schellecurie bleuetalbot - lagotalbot - lago t26ctalbot l6d\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE engine = 'maserati l4s' \nAND driver = 'nino farina';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-772.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: week 8 had the lowest attendance during the first 10 weeks , at 61603\nInput Table: 2000 cincinnati bengals season\n\n\nweekdateopponentresultattendance22000-09-10cleveland brownsl 24 - 76400632000-09-17jacksonville jaguarsl 13 - 04565342000-09-24baltimore ravensl 37 - 06848152000-10-01miami dolphinsl 31 - 166153562000-10-08tennessee titansl 23 - 146340672000-10-15pittsburgh steelersl 15 - 05432882000-10-22denver broncosw 31 - 216160392000-10-29cleveland brownsw 12 - 373118102000-11-05baltimore ravensl 27 - 754759112000-11-12dallas cowboysl 23 - 662170122000-11-19new england patriotsl 16 - 1360292132000-11-26pittsburgh steelersl 48 - 2863925142000-12-03arizona cardinalsw 24 - 1350289152000-12-10tennessee titansl 35 - 368498162000-12-17jacksonville jaguarsw 17 - 1450469172000-12-24philadelphia eaglesl 16 - 764902\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT attendance FROM table_sql WHERE week <= 10 ORDER BY attendance ASC LIMIT 1) = 61603 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1669.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there are a total of five countries represented by the players\nInput Table: 1989 u.s. open (golf)\n\n\nplaceplayercountryscoreto_parmoney1curtis strangeunited states71 + 64 + 73 + 70 = 278- 2200000t2chip beckunited states71 + 69 + 71 + 68 = 279- 167823t2mark mccumberunited states70 + 68 + 72 + 69 = 279- 167823t2ian woosnamwales70 + 68 + 73 + 68 = 279- 1678235brian claarunited states71 + 72 + 68 + 69 = 280e34345t6masashi ozakijapan70 + 71 + 68 + 72 = 281+ 128220t6scott simpsonunited states67 + 70 + 69 + 75 = 281+ 1282208peter jacobsenunited states71 + 70 + 71 + 70 = 282+ 224307t9paul azingerunited states71 + 72 + 70 + 70 = 283+ 319968t9hubert greenunited states69 + 72 + 74 + 68 = 283+ 319968t9tom kiteunited states67 + 69 + 69 + 78 = 283+ 319968t9jos\u00e9 mar\u00eda olaz\u00e1balspain69 + 72 + 70 + 72 = 283+ 319968\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(DISTINCT country) = 5 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-777.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: marc roskin directed season 1\nInput Table: list of leverage episodes\n\n\nseriesseasontitledirected_bywritten_byoriginal_air_dateus_viewers_(in_millions)451the long way down jobdean devlinjoe hortua & john rogers2011-06-263.42462the 10 li'l grifters jobarvin browngeoffrey thorne2011-07-032.46473the 15 minutes jobmarc roskinjosh schaer2011-07-103.24484the van gogh jobjohn rogerschris downey2011-07-174.06495the hot potato jobjohn harrisonjenn kao2011-07-243.25506the carnival jobfrank ozm scott veach & paul guyot2011-07-313.38517the grave danger jobjohn harrisonrebecca kirsch2011-08-143.36528the boiler room jobarvin brownpaul guyot2011-08-143.295410the queen 's gambit jobjonathan frakesm scott veach & rebecca kirsch2011-08-283.225511the experimental jobmarc roskinm scott veach2011-11-272.15612the office jobjonathan frakesjeremy bernstein & josh schaer2011-12-041.835713the girls' night out jobmarc roskinchris downey & jenn kao2011-12-111.835814the boys' night out jobjohn rogersjohn rogers2011-12-182.115915the lonely hearts jobjonathan frakeskerry glover2011-12-251.996016the gold jobmarc roskinjoe hortua2012-01-012.266117the radio jobdean devlinchris downey & paul guyot2012-01-082.32\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE season = 1 \nAND directed_by = 'marc roskin';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1246.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: during the years of 1950 through 1965 , the goals scored were less than 160\nInput Table: list of top association football goal scorers by country\n\n\nranknameyearsmatchesgoals1dudu georgescu1970-01-01 - 1986-01-013702522ionel danciulescu1993-01-01 - present4272103rodion camataru1974-01-01 - 1989-01-013771984marin radu1974-01-01 - 1989-01-013841905ion oblemenco1964-01-01 - 1976-01-012721705florea dumitrache1966-01-01 - 1983-01-013571707mircea sandu1970-01-01 - 1987-01-014071678victor piturca1975-01-01 - 1989-01-013011669mihai adam9999-01-01 - 1976-01-0135316010titus ozon1947-01-01 - 1964-01-01270157\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT SUM(goals) FROM table_sql WHERE years >= '1950-01-01' AND years <= '1965-01-01') < 160 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1615.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: series leader david lelay (fra) was also the winner for the tour du haut var\nInput Table: 2008 french road cycling cup\n\n\ndateeventwinnerteamseries_leader9999-02-24tour du haut vardavide rebellin ( ita )gerolsteinerrinaldo nocentini ( ita )9999-03-23cholet - pays de loirejanek tombak ( est )mitsubishi - jartazirinaldo nocentini ( ita )9999-04-06grand prix de rennesmikhaylo khalilov ( ukr )ceramica flaminia - bossini doccejimmy casper ( fra )'9999-04-15'paris - camembertalejandro valverde ( esp )caisse d'epargnej\u00e9r\u00f4me pineau ( fra )0000-04-17grand prix de denainedvald boasson hagen ( nor )team high roadjimmy casper ( fra )9999-04-19tour du finist\u00e8redavid lelay ( fra )bretagne - armor luxjimmy casper ( fra )9999-04-20tro - bro l\u00e9onfr\u00e9d\u00e9ric guesdon ( fra )fran\u00e7aise des jeuxjimmy casper ( fra )9999-05-04troph\u00e9e des grimpeursdavid lelay ( fra )bretagne - armor luxdavid lelay ( fra )9999-05-31grand prix de plumelec - morbihanthomas voeckler ( fra )bouygues t\u00e9l\u00e9comdavid lelay ( fra )9999-08-03polynormandearnaud g\u00e9rard ( fra )fran\u00e7aise des jeuxj\u00e9r\u00f4me pineau ( fra )9999-08-31chteauroux classicanthony ravard ( fra )agritubelj\u00e9r\u00f4me pineau ( fra )9999-09-21grand prix d'isbergueswilliam bonnet ( fra )cr\u00e9dit agricolej\u00e9r\u00f4me pineau ( fra )9999-10-05tour de vend\u00e9ekoldo fern\u00e1ndez ( esp )euskaltel - euskadij\u00e9r\u00f4me pineau ( fra )9999-10-09paris - bourgesbernhard eisel ( aut )team columbiaj\u00e9r\u00f4me pineau ( fra )\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT winner FROM table_sql WHERE event = 'tour du haut var' AND series_leader = 'david lelay ( fra )') = 'david lelay ( fra )' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-667.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: five of the games listed ended with 0 - 0 result and 3 with a result of 5 - 0\nInput Table: 2008 - 09 bradford city a.f.c. season\n\n\ngamedateopponentvenueresultattendance12008-08-09notts countyhome2 - 11403822008-08-16macclesfield townaway2 - 0255632008-08-23rochdalehome2 - 01315442008-08-30aldershot townaway2 - 3380552008-09-06port valeaway2 - 0727362008-09-13exeter cityhome4 - 11268372008-09-20bournemouthhome1 - 31282482008-09-27shrewsbury townaway0 - 2651792008-10-04luton townhome1 - 113083102008-10-11accrington stanleyaway3 - 23012112008-10-18gillinghamhome2 - 212432122008-10-21darlingtonaway1 - 23034132008-10-24grimsby townaway3 - 14470142008-10-28buryhome1 - 012830152008-11-01barnethome3 - 312510162008-11-15wycombe wanderersaway0 - 15002172008-11-22rotherham unitedaway2 - 04586182008-11-25chesterfieldhome3 - 212145192008-12-06dagenham & redbridgehome1 - 112145202008-12-13brentfordaway1 - 24339212008-12-20chester cityhome0 - 012092222008-12-26lincoln cityaway0 - 06156232008-12-28morecambehome4 - 013105242009-01-03shrewsbury townhome0 - 012877252009-01-17accrington stanleyhome1 - 112172262009-01-24luton townaway3 - 36053272009-01-27buryaway0 - 14112282009-01-31grimsby townhome2 - 012816292009-02-07gillinghamaway2 - 04866302009-02-14wycombe wanderershome1 - 012689312009-02-17darlingtonhome0 - 012782322009-02-21barnetaway1 - 42445332009-02-28notts countyaway1 - 35138342009-03-01macclesfield townhome1 - 011908352009-03-07aldershot townhome5 - 012465362009-03-10rochdaleaway0 - 35157372009-03-14exeter cityaway0 - 15253382009-03-17bournemouthaway1 - 44847392009-03-21port valehome0 - 112436402009-03-28chester cityaway0 - 02735412009-04-04brentfordhome1 - 112832422009-04-10morecambeaway1 - 24546432009-04-13lincoln cityhome1 - 112932\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE result = '0 - 0') = 5 \n             AND (SELECT COUNT(*) FROM table_sql WHERE result = '5 - 0') = 3 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1508.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: arienai kisu was broadcasted 14 days after the title with the earliest broadcast date\nInput Table: tsuki no koibito\n\n\nUnnamed:_0episode_titleromanized_titletranslation_of_titlebroadcast_dateratingsep 1\u304a\u307e\u3048\u304c\u6b32\u3057\u3044omae ga hosiii want you2010-05-1022.4%ep 2\u3042\u308a\u3048\u306a\u3044\u30ad\u30b9arienai kisuthe unthinkable kiss2010-05-1719.2%ep 3\u5fa9\u8b90\u306e\u30d7\u30ed\u30dd\u30fc\u30bafukusy\u016b no purop\u014dzuthe proposal out of revenge2010-05-2415.6%ep 4\u3053\u3093\u306a\u306b\u597d\u304d\u3060\u3063\u305f\u3093\u3060\u2026konna ni suki dattanda\u2026that 's how much i liked you2010-05-3115.5%ep 5\u597d\u304d\u3068\u8a00\u3048\u305f\u3089\u3044\u3044\u306e\u306bsuki to ietara iinoniif only i could say , i like you2010-06-0717.4%ep 6\u6700\u7d42\u7ae0\u5e8f\u5e55\u30fb\u5225\u308csaish\u016bsh\u014djomakuwakarea prologue of final chapter , farewell2010-06-1413.4%\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT broadcast_date FROM table_sql WHERE episode_title = '\u3042\u308a\u3048\u306a\u3044\u30ad\u30b9') - \n             (SELECT MIN(broadcast_date) FROM table_sql) = 14 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-211.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the team for ricky rudd is joe gibbs racing\nInput Table: pocono 400\n\n\nyeardatedriverteammanufacturerlaps-race_timeaverage_speed_(mph)report1982-01-019999-06-06bobby allisondigard motorsportsbuick200500 (804.672)4:24:08113.579report1983-01-019999-06-12bobby allisondigard motorsportsbuick200500 (804.672)3:53:13128.636report1984-01-019999-06-10cale yarboroughranier - lundychevrolet200500 (804.672)3:37:08138.164report1985-01-019999-06-09bill elliottmelling racingford200500 (804.672)3:35:48138.974report1986-01-019999-06-08tim richmondhendrick motorsportschevrolet200500 (804.672)4:24:50113.279report1987-01-019999-06-14tim richmondhendrick motorsportschevrolet200500 (804.672)4:05:57122.166report1988-01-019999-06-19geoffrey bodinehendrick motorsportschevrolet200500 (804.672)3:58:21126.147report1989-01-019999-06-18terry labontejunior johnson & associatesford200500 (804.672)3:48:27131.32report1990-01-019999-06-17harry gantleo jackson racingoldsmobile200500 (804.672)4:08:25120.6report1991-01-019999-06-16darrell waltripdarwal , incchevrolet200500 (804.672)4:04:34122.666report1992-01-019999-06-14alan kulwickiak racingford200500 (804.672)3:28:18144.023report1993-01-019999-06-13kyle pettysabco racingpontiac200500 (804.672)3:37:23138.005report1994-01-019999-06-12rusty wallacepenske racingford200500 (804.672)3:52:55128.801report1995-01-019999-06-11terry labontehendrick motorsportschevrolet200500 (804.672)3:37:50137.72report1996-01-019999-06-16jeff gordonhendrick motorsportschevrolet200500 (804.672)3:35:40139.104report1997-01-019999-06-08jeff gordonhendrick motorsportschevrolet200500 (804.672)3:34:33139.828report1998-01-019999-06-21jeremy mayfieldpenske racingford200500 (804.672)4:14:39117.809report1999-01-019999-06-20bobby labontejoe gibbs racingpontiac200500 (804.672)4:12:19118.898report2000-01-019999-06-19jeremy mayfieldpenske racingford200500 (804.672)3:34:41139.741report2001-01-019999-06-17ricky ruddrobert yates racingford200500 (804.672)3:43:14134.389report2002-01-019999-06-09dale jarrettrobert yates racingford200500 (804.672)3:29:10143.426report2003-01-019999-06-08tony stewartjoe gibbs racingchevrolet200500 (804.672)3:42:24134.892report2004-01-019999-06-13jimmie johnsonhendrick motorsportschevrolet200500 (804.672)4:27:33112.129report2005-01-019999-06-12carl edwardsroush racingford201502.5 (808.695)3:53:24129.177report2006-01-019999-06-11denny hamlinjoe gibbs racingchevrolet200500 (804.672)3:47:52131.656report2007-01-019999-06-10jeff gordonhendrick motorsportschevrolet106265 (426.476)1:57:15135.608report2008-01-019999-06-08kasey kahnegillett evernham motorsportsdodge200500 (804.672)3:59:36125.209report2009-01-019999-06-07tony stewartstewart - haas racingchevrolet200500 (804.672)3:36:35138.515report2010-01-019999-06-06denny hamlinjoe gibbs racingtoyota204510 (820.765)3:44:30136.303report2011-01-019999-06-12jeff gordonhendrick motorsportschevrolet200500 (804.672)3:26:21145.384report2012-01-019999-06-10joey loganojoe gibbs racingtoyota160400 (643.737)3:03:12131.004report\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE driver = 'ricky rudd' \nAND team = 'joe gibbs racing';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-74.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the township of jackson is in the mountrail county\nInput Table: list of townships in north dakota\n\n\ntownshipcountypop_(2010)land_(_sqmi_)water_(sqmi)latitudelongitudegeo_idansi_codejacksonsargent3335.8090.046.066276- 97.94553038081404601036797james hillmountrail3231.824.24348.423125- 102.42993438061405001037048james river valleydickey4028.5970.046.246641- 98.18832938021405401036767jankelogan2835.9950.16346.415512- 99.13170138047406201037193jeffersonpierce4535.0691.12548.232149- 100.18237038069407001759556jim river valleystutsman3834.1341.74647.112388- 98.77847838093407801036484johnsonwells3635.2990.90847.377745- 99.45867738103408201037137johnstowngrand forks7936.1990.048.151362- 97.44903338035409401036624joliettepembina6770.0440.77148.796545- 97.21722738067410201036723\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE township = 'jackson' \nAND county = 'mountrail';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1029.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: 2010 - 11 - 17 is the release date of version 1.0 with a category of utilities , a developer of dino games , and a title of msn money\nInput Table: list of zune applications\n\n\ntitledevelopercategoryrelease_dateversionalarm clockmicrosoftutilities2010-12-161.1calculatormicrosoftutilities2009-09-011.0calendarmatchboxutilities2011-07-291.0.0.3chord findermicrosoftutilities2010-11-171.0drum machine hddino gamesutilities2010-10-201.0emailmicrosoftutilities2011-04-011.1.0.1facebookmatchboxsocial networking2010-12-161.4fan predictionihwy , incentertainment2011-06-231.0fingerpaintbabarogaentertainment2011-07-291.1levelmicrosoftutilities2011-06-231.0metronomedino gamesutilities2010-09-091.0msn moneymicrosoftutilities2010-07-291.0notesmicrosoftutilities2011-06-231.0pianomicrosoftentertainment2009-11-011.0shuffle by albummicrosoftutilities2011-02-181.1stopwatchmicrosoftutilities2010-08-051.1twittermatchboxsocial networking2010-12-161.6weathermicrosoftutilities2009-09-011.0windows live messengermicrosoftsocial networking2010-11-171.4zune readermicrosoftutilities2011-02-181.2\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE release_date = '2010-11-17' \nAND version = '1.0' \nAND category = 'utilities' \nAND developer = 'dino games' \nAND title = 'msn money';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-910.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: all athletes have the same wind except eric walder and bob beamon\nInput Table: long jump\n\n\nmarkwindathletenationalityvenuedate8.95 m (29ft4\u00bcin)0.3mike powellunited statestokyo1991-08-308.90 m (29ft2\u00bcin) a2.0bob beamonunited statesmexico city1968-10-188.87 m (29ft1in)0.2carl lewisunited statestokyo1991-08-308.86 m (29ft0\u00bein) a1.9robert emmiyansoviet uniontsakhkadzor1987-05-228.74 m (28ft8in)1.4larry myricksunited statesindianapolis1988-07-188.74 m (28ft8in) a2.0erick walderunited statesel paso1994-04-028.74 m (28ft8in)1.2dwight phillipsunited stateseugene2009-06-078.73 m (28ft7\u00bdin)1.2irving saladinopanamahengelo2008-05-248.71 m (28ft6\u00bein)1.9iv\u00e1n pedrosocubasalamanca1995-07-188.66 m (28ft4\u00bein)1.6lo\u00fais ts\u00e1toumasgreecekalam\u00e1ta2007-06-02\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(DISTINCT wind) = 1 \n            AND wind NOT IN (\n                SELECT wind \n                FROM table_sql \n                WHERE athlete = 'eric walder' OR athlete = 'bob beamon'\n            ) \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-243.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the fire control for the sporter target is a1\nInput Table: none\n\n\ncolt_model_nonamestockfire_controlrear_sightforward_assistcase_deflectorbarrel_lengthbarrel_profilebarrel_twisthand_guardsbayonet_lugmuzzle_devicer6000ar - 15 sporter (sp1)a1s - 1a1nono20 ina11:12triangularyestype 2 duckbill or a1r6001ar - 15 sporter carbine (sp1 carbine)2nd generations - 1a1nono16 ina11:12short ribbedyesa1r6002ar - 15 sporter (sp1 , bundled with 3x scope)a1s - 1a1nono20 ina11:12triangularyesa1r6420ar - 15a2 sporter ii carbine3rd generations - 1a1yesno & yes16 ina11:7short ribbedyesa2r6430sporter lightweight (9 mm)a2s - 1a1noremovable16 ina11:10short ribbedyesa1r6450ar - 15 9 mm carbine3rd generations - 1a1nono & removable16 ina11:10short ribbedyesa1r6500ar - 15a2 sporter iia2s - 1a1yesno & yes20 ina21:7ribbedyesa2r6520ar - 15a2 government carbine3rd generations - 1a2yesyes16 ina11:7short ribbedyesa2r6530sporter lightweight 2233rd generations - 1a2yesyes16 ina11:7short ribbednoa2r6550ar - 15a2 governmenta2s - 1a2yesyes20 ina21:7ribbedyesa2r6550ccar - 15a2 government (w / factory camouflage finish)a2s - 1a2yesyes20 ina21:7ribbedyesa2r6551sporter targeta2s - 1a2yesyes20 ina21:7ribbednoa2r6600ar - 15a2 hbara2s - 1a2yesyes20 inhbar1:7ribbedyesa2r6601sporter match hbara2s - 1a2yesyes20 inhbar1:7ribbednoa2r6700sporter competition hbara2s - 1flattopyesyes20 inhbar1:9ribbednoa2r6721ar - 15a3 tactical carbine4th generations - 1a2yesyes16 inhbar1:9short ribbedyesa2r6724sporter competition hbara2s - 1flattopyesyes24 inhbar1:9ribbednoa2r6731ar - 15a3 competition hbara2s - 1a2yesyes16 inhbar1:9short ribbednoa2r6750sporter competition hbar (bundled w / bipod)a2s - 1a2yesyes20 insuper - heavy1:7ribbednoa2r6821sporter carbine (7.62x39 mm)3rd generations - 1a2yesyes16 inhbar1:12short ribbednoa1\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN fire_control = 'a1' AND name = 'sporter target' THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-251.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: eight different countries received the same number of bronze medals\nInput Table: 1988 winter olympics\n\n\nranknationgoldsilverbronzetotal1soviet union (urs)1199292east germany (gdr)9106253switzerland (sui)555154finland (fin)41275sweden (swe)40266austria (aut)352107netherlands (ned)32278west germany (frg)24289united states (usa)213610italy (ita)212513canada (can)0235\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(DISTINCT nation) = 8 AND COUNT(bronze) = 1 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE bronze = (SELECT bronze FROM table_sql GROUP BY bronze HAVING COUNT(*) > 1)\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-180.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: 6.2 is the total of rebound averages with more than 124 games and a rank of 10\nInput Table: none\n\n\nrankplayeryearsgamesreb_avgtotal_rebounds1jim nowers1972-01-01 - 1976-01-011129.410482kenny sanders1985-01-01 - 1989-01-011079.610263will thomas2004-01-01 - 2008-01-011317.69934george evans1997-01-01 - 2001-01-011168.29535robert dykes1987-01-01 - 1991-01-011227.59256andre gaddy1977-01-01 - 1982-01-01989.39167jai lewis2002-01-01 - 2006-01-011257.28958rob rose1982-01-01 - 1986-01-011137.18059herb estes1973-01-01 - 1976-01-01809.273410jesse young1999-01-01 - 2003-01-011156.2708\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT SUM(reb_avg) FROM table_sql WHERE games > 124 AND rank = 10) = 6.2 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1987.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the matches on march 7 , 2001 and february 21 , 2001 both had attendances over 25000\nInput Table: 2000 - 01 sheffield wednesday f.c. season\n\n\ndateopponentvenueresultattendance2000-08-13wolverhampton wanderersa1 - 1190862000-08-19huddersfield townh2 - 3227042000-08-26grimsby towna1 - 077552000-08-28blackburn roversh1 - 1156462000-09-09wimbledonh0 - 5158562000-09-13nottingham foresth0 - 1157002000-09-16tranmere roversa0 - 293522000-09-23preston north endh1 - 3173792000-09-30gillinghama0 - 290992000-10-08west bromwich albionh1 - 2153382000-10-14portsmoutha1 - 2133762000-10-17burnleya0 - 1163722000-10-22birmingham cityh1 - 0146952000-10-25queens park rangersa2 - 1103532000-10-28fulhamh3 - 3175592000-11-04crystal palacea1 - 4153332000-11-07watforda3 - 1111662000-11-01norwich cityh3 - 2169562000-11-18barnsleya0 - 1199892000-11-25crewe alexandraa0 - 171032000-12-02queens park rangersh5 - 2217822000-12-09stockport countyh2 - 4163372000-12-16sheffield uniteda1 - 1251562000-12-23wolverhampton wanderersh0 - 1177872000-12-26bolton wanderersa0 - 2213162000-12-30huddersfield towna0 - 0189312001-01-01grimsby townh1 - 0170042001-01-13blackburn roversa0 - 2193082001-01-20bolton wanderersh0 - 3176382001-02-03watfordh2 - 3161342001-02-10wimbledona1 - 467412001-02-13tranmere roversh1 - 0154442001-02-21nottingham foresta1 - 0232662001-02-24preston north enda0 - 2143792001-03-03gillinghamh2 - 1187022001-03-07portsmouthh0 - 0205032001-03-10west bromwich albiona2 - 1186622001-03-17burnleyh2 - 0201842001-03-24birmingham citya2 - 1197332001-04-01sheffield unitedh1 - 2384332001-04-07stockport countya1 - 296662001-04-14crystal palaceh4 - 1198772001-04-16fulhama1 - 1175002001-04-21barnsleyh2 - 1234982001-04-28norwich citya0 - 1212412001-05-06crewe alexandrah0 - 028007\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT attendance FROM table_sql WHERE date = '2001-03-07') > 25000 \n             AND (SELECT attendance FROM table_sql WHERE date = '2001-02-21') > 25000 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-920.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the blue jays fell to 76 - 86 following their loss to the red sox on september 28\nInput Table: 1997 toronto blue jays season\n\n\ndateopponentscorelossattendancerecord9999-09-01mets3 - 0hentgen (14 - 9)1919665 - 719999-09-02mets8 - 5clemens (20 - 5)1763565 - 729999-09-03mets4 - 2quantrill (6 - 6)1451365 - 739999-09-04rangers6 - 2carpenter (1 - 7)2617865 - 749999-09-05rangers5 - 1pavlik (2 - 4)2712166 - 749999-09-06rangers2 - 1burkett (7 - 12)3123267 - 749999-09-07rangers4 - 0oliver (11 - 11)3021268 - 749999-09-08angels12 - 10james (4 - 5)2577569 - 749999-09-09angels2 - 0hill (7 - 12)2567470 - 749999-09-10athletics3 - 2plesac (1 - 4)476470 - 759999-09-11athletics8 - 7escobar (2 - 1)613570 - 769999-09-12mariners7 - 3clemens (21 - 6)3704470 - 779999-09-13mariners6 - 3ayala (10 - 5)5163171 - 779999-09-14mariners3 - 2risley (0 - 1)4547771 - 789999-09-15mariners7 - 3williams (8 - 14)4168471 - 799999-09-17red sox4 - 3quantrill (6 - 7)2364871 - 809999-09-18red sox3 - 2escobar (3 - 2)2799071 - 819999-09-19yankees3 - 0gooden (8 - 5)3119572 - 819999-09-20yankees4 - 3 (11)janzen (1 - 1)3833272 - 829999-09-21yankees5 - 4 (10)almanzar (0 - 1)4003872 - 839999-09-22yankees8 - 1hentgen (15 - 10)2338072 - 849999-09-23orioles3 - 2clemens (21 - 7)2927672 - 859999-09-24orioles9 - 3daal (1 - 1)2744372 - 869999-09-25orioles4 - 3mussina (15 - 8)2832473 - 869999-09-26red sox3 - 0henry (7 - 3)3415574 - 869999-09-27red sox12 - 5corsi (5 - 3)3740175 - 869999-09-28red sox3 - 2gordon (6 - 10)4025176 - 86\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN record = '76 - 86' AND opponent = 'red sox' AND date = '9999-09-28' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1832.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the date of vacancy is after 28 december 2011 with the incoming head coach , carlos azenha\nInput Table: 2010 - 11 primeira liga\n\n\nteamoutgoing_head_coachmanner_of_departuredate_of_vacancyposition_in_tableincoming_head_coachdate_of_appointmentuni\u00e3o de leirialito vidigalsacked2010-07-07off - seasonpedro caixinha2010-07-10mar\u00edtimomitchell van der gaagsacked2010-09-1415thpedro martins2010-09-14naval 1 de maiovictor zvunkasacked2010-09-2714throg\u00e9rio gon\u00e7alves2010-10-06acad\u00e9micajorge costaresigned2010-12-219thjos\u00e9 guilherme2010-12-27naval 1 de maiorog\u00e9rio gon\u00e7alvessacked2010-12-1916thcarlos mozer2010-12-30portimonenselitossacked2011-12-2816thcarlos azenha2010-12-29acad\u00e9micajos\u00e9 guilhermeresigned2011-02-2013thulisses morais2011-02-22sportingpaulo s\u00e9rgioresigned2011-02-263rdjos\u00e9 couceiro2011-02-26beira - marleonardo jardimresigned2011-02-2810thrui bento2011-03-01vit\u00f3ria de set\u00fabalmanuel fernandessacked2011-03-0114thbruno ribeiro2011-03-01\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT date_of_vacancy FROM table_sql WHERE date_of_vacancy > '2011-12-28' AND incoming_head_coach = 'carlos azenha') IS NOT NULL \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-473.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the player in second place is from south africa\nInput Table: 1973 u.s. open (golf)\n\n\nplaceplayercountryscoreto_par1gary playersouth africa67 + 70 = 137- 52jim colbertunited states70 + 68 = 138- 4t3jack nicklausunited states71 + 69 = 140- 2t3johnny millerunited states71 + 69 = 140- 2t3bob charlesnew zealand71 + 69 = 140- 2t6gene borekunited states77 + 65 = 142et6julius borosunited states73 + 69 = 142et6tom weiskopfunited states73 + 69 = 142et6arnold palmerunited states71 + 71 = 142et6lee trevinounited states70 + 72 = 142e\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT player FROM table_sql WHERE place = 2) = 'gary player' \n             AND (SELECT country FROM table_sql WHERE place = 2) = 'south africa' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1209.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: plymouth argyle played the away team derby county after 14 march 1984\nInput Table: 1983 - 84 fa cup\n\n\ntie_nohome_teamscoreaway_teamdate1notts county1 - 2everton1984-03-102sheffield wednesday0 - 0southampton1984-03-11replaysouthampton5 - 1sheffield wednesday1984-03-203plymouth argyle0 - 0derby county1984-03-10replayderby county0 - 1plymouth argyle1984-03-144birmingham city1 - 3watford1984-03-10\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE home_team = 'plymouth argyle' \nAND away_team = 'derby county' \nAND date > '1984-03-14';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1534.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: neither the 2010 nor the 2011 kids' choice awards nominated cole sprouse for the favorite tv actor category\nInput Table: the suite life on deck\n\n\nyearawardcategoryrecipientresult2010green globe film awardsoutstanding actors asians in hollywoodbrenda songnominated20102010 kids' choice awardsfavorite tv showthe suite life on decknominated20102010 kids' choice awardsfavorite tv actorcole sprousenominated20102010 kids' choice awardsfavorite tv actordylan sprousewon2010hollywood teen tv awardsteen pick show : comedythe suite life on decknominated2010hollywood teen tv awardsteen pick actress : comedydebby ryannominated2010hollywood teen tv awardsteen pick actor : comedydylan sprousenominated20112011 kids' choice awardsfavorite tv showthe suite life on decknominated20112011 kids' choice awardsfavorite tv actorcole sprousenominated20112011 kids' choice awardsfavorite tv actordylan sprousewon20112011 kids' choice awardsfavorite tv sidekickbrenda songnominated2011casting society of americabest casting children 's seriesdana gergely brandi bricewon\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE award = \"2010 kids' choice awards\" AND category = \"favorite tv actor\" AND recipient = \"cole sprouse\") = 0 \n             AND (SELECT COUNT(*) FROM table_sql WHERE award = \"2011 kids' choice awards\" AND category = \"favorite tv actor\" AND recipient = \"cole sprouse\") = 0 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-46.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the time value for the rider brian finch , team suzuki and a rank greater than 3 is 2:14.59.0\nInput Table: 1970 isle of man tt\n\n\nrankriderteamspeedtime1frank whitewaysuzuki89.94 mph2:05.52.02gordon pantalltriumph88.90 mph2:07.20.03ray knighttriumph88.89 mph2:07.20.44rbaylietriumph87.58 mph2:09.15.05graham pennytriumph86.70 mph2:10.34.46jwadesuzuki85.31 mph2:12.42.07brian finchvelocette83.86 mph2:14.59.0\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT time FROM table_sql WHERE rider = 'brian finch' AND team = 'suzuki' AND rank > 3) = '2:14.59.0' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-73.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the geo id for dickey county is 3804740620\nInput Table: list of townships in north dakota\n\n\ntownshipcountypop_(2010)land_(_sqmi_)water_(sqmi)latitudelongitudegeo_idansi_codejacksonsargent3335.8090.046.066276- 97.94553038081404601036797james hillmountrail3231.824.24348.423125- 102.42993438061405001037048james river valleydickey4028.5970.046.246641- 98.18832938021405401036767jankelogan2835.9950.16346.415512- 99.13170138047406201037193jeffersonpierce4535.0691.12548.232149- 100.18237038069407001759556jim river valleystutsman3834.1341.74647.112388- 98.77847838093407801036484johnsonwells3635.2990.90847.377745- 99.45867738103408201037137johnstowngrand forks7936.1990.048.151362- 97.44903338035409401036624joliettepembina6770.0440.77148.796545- 97.21722738067410201036723\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE county = 'dickey' \nAND geo_id = 3804740620;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-355.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: yi is the name when the royal house is ji and the state is cai and the year was 826\nInput Table: list of state leaders in 820s bc\n\n\nstatetypenametitleroyal_housefromcaisovereignyimarquisji837 bccaosovereignyoucount-835 bccaosovereigndaicount-826 bcchensovereignliduke-831 bcchusovereignxiong yan the youngerviscountmi837 bcchusovereignxiong shuangviscountmi827 bcchusovereignxiong xunviscountmi821 bcjinsovereignximarquisji840 bcjinsovereignxianmarquisji822 bclusovereignshendukeji854 bclusovereignwudukeji825 bcqisovereignwudukejiang850 bcqisovereignlidukejiang824 bcqinsovereignqin zhongrulerying845 bcqinsovereignzhuangdukeying822 bcsongsovereignhuiduke-830 bcweysovereignlimarquis-855 bcyansovereignhuimarquis-864 bcyansovereignlimarquis-826 bc\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE name = 'yi' \nAND royal_house = 'ji' \nAND state = 'cai' \nAND \"from\" = 826;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-458.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the dolphins' defense recorded three shutouts during the 1983 season\nInput Table: 1983 miami dolphins season\n\n\nweekdateopponentresultattendance11983-09-04buffalo billsw 12 - 07871521983-09-11new england patriotsw 34 - 245934331983-09-19los angeles raidersl 27 - 145779641983-09-25kansas city chiefsw 14 - 65078551983-10-02new orleans saintsl 17 - 76648961983-10-09buffalo billsl 38 - 355994871983-10-16new york jetsw 32 - 145861581983-10-23baltimore coltsw 21 - 73234391983-10-30los angeles ramsw 30 - 1472175101983-11-06san francisco 49ersw 20 - 1757832111983-11-13new england patriotsl 17 - 660771121983-11-20baltimore coltsw 37 - 054482131983-11-28cincinnati bengalsw 38 - 1474506141983-12-04houston oilersw 24 - 1739434151983-12-10atlanta falconsw 31 - 2456725161983-12-16new york jetsw 34 - 1459975\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 3 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE result LIKE 'w%' \nAND result NOT LIKE '%-%';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1156.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the detroit pistons lost six games during this period of their 2010 - 2011 season\nInput Table: 2010 - 11 detroit pistons season\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord629999-03-01milwaukeel 90 - 92 (ot)rodney stuckey (25)greg monroe , charlie villanueva (9)rodney stuckey (5)bradley center 1136422 - 40639999-03-02minnesotal 105 - 116 (ot)austin daye (22)greg monroe (11)rodney stuckey (10)the palace of auburn hills 1312222 - 41649999-03-06washingtonw 113 - 102 (ot)tayshaun prince (20)greg monroe , rodney stuckey (7)rodney stuckey (9)the palace of auburn hills 1750623 - 41659999-03-09san antoniol 104 - 111 (ot)richard hamilton (20)greg monroe (10)tracy mcgrady (9)at&t center 1858123 - 42669999-03-11oklahoma cityl 94 - 104 (ot)richard hamilton (20)greg monroe (10)greg monroe , rodney stuckey (6)oklahoma city arena 1820323 - 43679999-03-12denverl 101 - 131 (ot)chris wilcox (21)austin daye , ben gordon , greg monroe (6)will bynum (10)pepsi center 1915523 - 44689999-03-16torontow 107 - 93 (ot)richard hamilton (24)greg monroe (10)rodney stuckey (14)the palace of auburn hills 1516624 - 44699999-03-18new yorkw 99 - 95 (ot)tayshaun prince (16)chris wilcox (12)will bynum (5)the palace of auburn hills 2207625 - 44709999-03-20atlantal 96 - 104 (ot)rodney stuckey (22)greg monroe (10)rodney stuckey (8)philips arena 1758025 - 45719999-03-23miamil 94 - 100 (ot)richard hamilton (27)greg monroe (12)rodney stuckey (6)the palace of auburn hills 2207625 - 46729999-03-25clevelandl 91 - 97 (ot)richard hamilton , tayshaun prince (15)chris wilcox , greg monroe (8)rodney stuckey (4)quicken loans arena 1990725 - 47739999-03-26indianaw 100 - 88 (ot)richard hamilton (23)greg monroe (13)richard hamilton , rodney stuckey (6)the palace of auburn hills 1921626 - 47\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 6 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE record LIKE '% - %' \nAND record NOT LIKE '% - % - %';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-549.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: on week 12 the attendance was 64217\nInput Table: 2001 cincinnati bengals season\n\n\nweekdateopponentresultattendance12001-09-09new england patriotsw 23 - 175152122001-09-23baltimore ravensw 21 - 105112132001-09-30san diego chargersl 28 - 145604842001-10-07pittsburgh steelersl 16 - 76233552001-10-14cleveland brownsw 24 - 146421762001-10-21chicago bearsl 24 - 06340872001-10-28detroit lionsw 31 - 276934392001-11-11jacksonville jaguarsl 30 - 1357161102001-11-18tennessee titansl 20 - 763865112001-11-25cleveland brownsl 18 - 072918122001-12-02tampa bay buccaneersl 16 - 1352135132001-12-09jacksonville jaguarsl 14 - 1044920142001-12-16new york jetsl 15 - 1477745152001-12-23baltimore ravensl 16 - 068987162001-12-30pittsburgh steelersw 26 - 2363751172002-01-06tennessee titansw 23 - 2168798\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN attendance = 64217 AND week = 12 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1910.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the second team had less points than the first and are separated by a two goal difference\nInput Table: 1940 in brazilian football\n\n\npositionteampointsplayedagainstdifference1flamengo1381282fluminense13815103corinthians981544palestra it\u00e1lia881935portuguesa7823- 106botafogo682507vasco da gama6819- 28am\u00e9rica6825- 109s\u00e3o paulo4824- 13\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT points FROM table_sql WHERE position = 2) < \n             (SELECT points FROM table_sql WHERE position = 1) \n        AND (SELECT difference FROM table_sql WHERE position = 2) = 2 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1670.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the most amount of money won by someone from wales is 46823\nInput Table: 1989 u.s. open (golf)\n\n\nplaceplayercountryscoreto_parmoney1curtis strangeunited states71 + 64 + 73 + 70 = 278- 2200000t2chip beckunited states71 + 69 + 71 + 68 = 279- 167823t2mark mccumberunited states70 + 68 + 72 + 69 = 279- 167823t2ian woosnamwales70 + 68 + 73 + 68 = 279- 1678235brian claarunited states71 + 72 + 68 + 69 = 280e34345t6masashi ozakijapan70 + 71 + 68 + 72 = 281+ 128220t6scott simpsonunited states67 + 70 + 69 + 75 = 281+ 1282208peter jacobsenunited states71 + 70 + 71 + 70 = 282+ 224307t9paul azingerunited states71 + 72 + 70 + 70 = 283+ 319968t9hubert greenunited states69 + 72 + 74 + 68 = 283+ 319968t9tom kiteunited states67 + 69 + 69 + 78 = 283+ 319968t9jos\u00e9 mar\u00eda olaz\u00e1balspain69 + 72 + 70 + 72 = 283+ 319968\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MAX(money) FROM table_sql WHERE country = 'wales') = 46823 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1968.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: dallas was the opponent in the game in which austin daye (16) did the lowest points\nInput Table: 2010 - 11 detroit pistons season\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord19999-10-05miamil 89 - 105 (ot)ben gordon (17)ben gordon , charlie villanueva (5)rodney stuckey (5)american airlines arena 196000 - 129999-10-08milwaukeew 115 - 110 (ot)austin daye (21)austin daye (7)will bynum (9)the palace of auburn hills 128211 - 139999-10-11atlantaw 94 - 85 (ot)rodney stuckey (16)greg monroe (7)richard hamilton (7)the palace of auburn hills 105912 - 149999-10-13dallasl 96 - 101 (ot)austin daye (16)ben wallace , jason maxiell (8)rodney stuckey (6)van andel arena 102072 - 259999-10-15minnesotal 88 - 99 (ot)austin daye (18)austin daye (11)will bynum (5)carrier dome 117472 - 369999-10-16charlottel 94 - 97 (ot)rodney stuckey (25)greg monroe (8)rodney stuckey , will bynum (5)colonial life arena 68472 - 479999-10-19washingtonw 98 - 92 (ot)rodney stuckey (34)ben wallace (11)rodney stuckey (7)huntington center 64243 - 4\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MIN(high_points) FROM table_sql WHERE team = 'dallas') = 16 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1600.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: in 1975 , jean - fran\u00e7ois bouvery france came in 4th when anders martinson usa came in second\nInput Table: cleveland international piano competition\n\n\nyearfirstsecondthirdfourth2013stanislav khristenko russiaarseny tarasevich - nikolaev russiafran\u00e7ois dumont francejiayan sun china2011alexander schimpf germanyalexei chernov russiaeric zuber usakyu yeon kim south korea2009martina filjak croatiadmitri levkovich canadawilliam youn south koreaevgeny brakhman russia2007alexander ghindin russiayaron kohlberg israelalexandre moutouzkine russiaran dank israel2005chu - fang huang chinasergey kuznetsov russiastanislav khristenko russiaspencer myer usa2003kotaro fukuma japansoyeon lee south koreakonstantin soukhovetski russiaandrius zlabys lithuania2001roberto plano italyminsoo sohn south korea\u00f6zg\u00fcr aydin turkeygilles vonsattel switzerland1999antonio pompa - baldi italyvassily primakov russiashoko inoue japansean botkin usa1997per tengstrand swedengulnora alimova uzbekistanning an chinadror biran israel1995margarita shevchenko russiamarina lomazov / ukraine / usadmitri teterin russiagiampaolo stuani italy1993amir katz israelnot awardedseizo azuma and japan yuko nakamichi japankatsunori ishii japan1991ilya itin russiaanders martinson usamarkus pawlik germanyjean - fran\u00e7ois bouvery france1989sergei babayan armenia ( ussr )nicholas angelich usamegumi kaneko japanpascal godart france1987thierry huillet franceasaf zohar israeljonathan bass usabeatrice hsin - chen long / taiwan / china1985daejin kim south koreabenedetto lupo italyh\u00e9l\u00e8ne jeanney franceneil rutman usa1983youngshin an south koreamayumi kameda japanst\u00e9phane lemelin canadaroy kogan usa1981philippe bianconi francedan riddle usar\u00e9my loumbrozo franceroy kogan usa1979edward newman usajean - yves thibaudet franceangela hewitt canadafrederick blum usa1977nathalie bera - tagrine francebarry salwen usadouglas montgomery usalaura silverman usa1975john owings usajulian martin usajohn - patrick millow franceroe van boskirk usa\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT fourth FROM table_sql WHERE year = 1975) = 'jean - fran\u00e7ois bouvery france' \n             AND (SELECT second FROM table_sql WHERE year = 1975) = 'anders martinson usa' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1181.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the time for wallace spearmon of the united states is more than the time for rondell sorillo of trinidad and tobago\nInput Table: athletics at the 2008 summer olympics - men 's 200 metres\n\n\nlaneathletenationalitytimereact8paul hessionireland20.320.194wallace spearmonunited states20.390.2026jaysuma saidy ndurenorway20.450.1317rondell sorillotrinidad and tobago20.630.1645ramil guliyevazerbaijan20.660.1743visa hongistofinland20.760.1242thuso mpuangsouth africa21.040.1629marvin andersonjamaicadnf0.187\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT time FROM table_sql WHERE athlete = 'wallace spearmon' AND nationality = 'united states') > \n             (SELECT time FROM table_sql WHERE athlete = 'rondell sorillo' AND nationality = 'trinidad and tobago') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1782.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: in there period where there were 900000 deaths per year , there were also 2500000 natural changes per year\nInput Table: none\n\n\nperiodlive_births_per_yeardeaths_per_yearnatural_change_per_yearcbrcdrnctfrimrlife_expectancy_totallife_expectancy_maleslife_expectancy_females1950-01-01 - 1955-01-012 572 000900 0001 672 00044.115.528.66.1513550.949.252.61955-01-01 - 1960-01-012 918 000947 0001 971 00043.214.029.16.1512253.351.555.21960-01-01 - 1965-01-013 303 000986 0002 317 00042.212.629.66.1510955.753.857.69999-01-01 - 1970-01-013 330 000998 0002 332 00037.011.125.95.3810057.655.759.61970-01-01 - 1975-01-013 441 0001 014 0002 427 00033.79.923.84.729159.557.361.81975-01-01 - 1980-01-013 741 0001 043 0002 698 00032.59.023.54.317961.559.263.91980-01-01 - 1985-01-013 974 0001 064 0002 910 00030.88.222.63.86363.460.466.81985-01-01 - 1990-01-013 757 0001 055 0002 702 00026.37.418.93.15265.361.969.11990-01-01 - 1995-01-013 519 0001 058 0002 461 00022.66.815.82.64367.363.671.21995-01-01 - 2000-01-013 624 0001 086 0002 538 00021.56.515.12.453469.365.573.32000-01-01 - 2005-01-013 572 0001 147 0002 425 00019.86.413.42.252770.967.274.8\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT natural_change_per_year FROM table_sql WHERE deaths_per_year = 900000) = 2500000 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-89.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there have been 19 games since 13 august 2005 which had an attendance exactly equal to that of arsenal in 9 april 2006\nInput Table: 2005 - 06 manchester united f.c. season\n\n\ndateopponentsh_/_aresult_f_-_aattendanceleague_position2005-08-13evertona2 - 0386104th2005-08-20aston villah1 - 0679344th2005-08-28newcastle uniteda2 - 0523274th2005-09-10manchester cityh1 - 1678394th2005-09-18liverpoola0 - 0449173rd2005-09-24blackburn roversh1 - 2677656th2005-10-01fulhama3 - 2218624th2005-10-15sunderlanda3 - 1390853rd2005-10-22tottenham hotspurh1 - 1678565th2005-10-29middlesbrougha1 - 4305797th2005-11-06chelseah1 - 0678644th2005-11-19charlton athletica3 - 1267303rd2005-11-27west ham uniteda2 - 1347552nd2005-12-03portsmouthh3 - 0676842nd2005-12-11evertonh1 - 1678313rd2005-12-14wigan athletich4 - 0677932nd2005-12-17aston villaa2 - 0371282nd2005-12-26west bromwich albionh3 - 0679722nd2005-12-28birmingham citya2 - 2284592nd2005-12-31bolton wanderersh4 - 1678582nd2006-01-03arsenala0 - 0383132nd2006-01-14manchester citya1 - 3471922nd2006-01-22liverpoolh1 - 0678742nd2006-02-01blackburn roversa3 - 4254842nd2006-02-04fulhamh4 - 2678442nd2006-02-11portsmoutha3 - 1202062nd2006-03-06wigan athletica2 - 1235242nd2006-03-12newcastle unitedh2 - 0678582nd2006-03-18west bromwich albiona2 - 1276232nd2006-03-26birmingham cityh3 - 0690702nd2006-03-29west ham unitedh1 - 0695222nd2006-04-01bolton wanderersa2 - 1277182nd2006-04-09arsenalh2 - 0709082nd2006-04-14sunderlandh0 - 0725192nd2006-04-17tottenham hotspura2 - 1361412nd2006-04-29chelseaa0 - 3422192nd2006-05-01middlesbroughh0 - 0695312nd2006-05-07charlton athletich4 - 0730062nd\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 19 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE attendance = (SELECT attendance FROM table_sql WHERE date = '2006-04-09' AND opponents = 'arsenal')\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1608.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: during the 2007 - 08 minnesota wild season , the match on february 12 and february 20 both had the same score\nInput Table: 2007 - 08 minnesota wild season\n\n\ndatevisitorscorehomedecisionattendancerecord01-02-9999minnesota4 - 1columbusbackstrom1852930 - 19 - 39999-02-05detroit3 - 2minnesotabackstrom1856830 - 19 - 401-02-07dallas1 - 0minnesotabackstrom1856830 - 20 - 49999-02-09ny islanders3 - 4minnesotabackstrom1856831 - 20 - 401-02-10minnesota2 - 1st louisharding1647732 - 20 - 401-02-12minnesota2 - 4edmontonharding1683932 - 21 - 401-02-14minnesota5 - 4vancouverbackstrom1863033 - 21 - 49999-02-17nashville4 - 5minnesotabackstrom1856834 - 21 - 49999-02-19vancouver3 - 2minnesotabackstrom1856834 - 21 - 59999-02-20minnesota0 - 3chicagoharding1781234 - 22 - 59999-02-24calgary2 - 1minnesotabackstrom1856834 - 23 - 59999-02-26minnesota1 - 4washingtonbackstrom1739134 - 24 - 59999-02-27minnesota3 - 2tampa baybackstrom1721135 - 24 - 59999-02-29minnesota3 - 2floridabackstrom1692736 - 24 - 5\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT score FROM table_sql WHERE date = '01-02-12') = \n             (SELECT score FROM table_sql WHERE date = '9999-02-20') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-853.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: ac sparta prague and team netherlands are both located on the asian continent\nInput Table: list of superleague formula football clubs\n\n\nnofootball_clubcontinentassociated_football_clubseasonsracing_drivers3ac milaneuropeac milan2008 2009 2010robert doornbos giorgio pantano yelmer buurman4ac sparta pragueeuropeac sparta prague2011filip salaquarda5team luxembourgeuropenone2011fr\u00e9d\u00e9ric vervisch6team new zealandoceanianone2011earl bamber7team japanasianone2011duncan tappy8 1 (in 2011)rsc anderlechteuropersc anderlecht2008 2009 2010 2011craig dolby yelmer buurman davide rigon neel jani8team netherlandseuropenone2011robert doornbos10fc basel 1893europefc basel2008 2009 2010max wissel max wissel max wissel12 24 (in 2010)beijing guoanasiabeijing guoan fc2008 2010davide rigon john martin14team brazils americanone2011ant\u00f4nio pizzonia17rangers fceuroperangers fc2008 2009ryan dalziel , james walker john martin24fc midtjyllandeuropefc midtjylland2009kasper andersen24team australiaoceanianone2011john martin31team englandeuropenone2011craig dolby\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT continent FROM table_sql WHERE football_club = 'ac sparta prague') = \n             (SELECT continent FROM table_sql WHERE football_club = 'team netherlands') \n             AND (SELECT continent FROM table_sql WHERE football_club = 'ac sparta prague') = 'asia' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-326.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there were two republican imcubents that were first elected in 1974\nInput Table: united states house of representatives elections , 1994\n\n\ndistrictincumbentpartyfirst_electedstatusopponentpennsylvania4ron klinkdemocratic1992-01-01re - electedron klink (d) 64.2% ed peglow (r) 35.8%pennsylvania5william f clinger , jrrepublican1978-01-01re - electedwilliam f clinger , jr (r) unopposedpennsylvania7curt weldonrepublican1986-01-01re - electedcurt weldon (r) 69.7% sara r nichols (d) 30.3%pennsylvania9bud shusterrepublican1972-01-01re - electedbud shuster (r) unopposedpennsylvania12john murthademocratic1974-01-01re - electedjohn murtha (d) 68.9% bill choby (r) 31.1%pennsylvania17george gekasrepublican1982-01-01re - electedgeorge gekas (r) unopposedpennsylvania18rick santorumrepublican1990-01-01retired to run for us senate democratic gainmichael f doyle (d) 54.8% john mccarty (r) 45.2%pennsylvania19william f goodlingrepublican1974-01-01re - electedwilliam f goodling (r) unopposed\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 2 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE first_elected = '1974-01-01' \nAND party = 'republican';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1511.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: fukusy\u016b no purop\u014dzu had 3.2% higher ratings than the title with the most recent broadcast date\nInput Table: tsuki no koibito\n\n\nUnnamed:_0episode_titleromanized_titletranslation_of_titlebroadcast_dateratingsep 1\u304a\u307e\u3048\u304c\u6b32\u3057\u3044omae ga hosiii want you2010-05-1022.4%ep 2\u3042\u308a\u3048\u306a\u3044\u30ad\u30b9arienai kisuthe unthinkable kiss2010-05-1719.2%ep 3\u5fa9\u8b90\u306e\u30d7\u30ed\u30dd\u30fc\u30bafukusy\u016b no purop\u014dzuthe proposal out of revenge2010-05-2415.6%ep 4\u3053\u3093\u306a\u306b\u597d\u304d\u3060\u3063\u305f\u3093\u3060\u2026konna ni suki dattanda\u2026that 's how much i liked you2010-05-3115.5%ep 5\u597d\u304d\u3068\u8a00\u3048\u305f\u3089\u3044\u3044\u306e\u306bsuki to ietara iinoniif only i could say , i like you2010-06-0717.4%ep 6\u6700\u7d42\u7ae0\u5e8f\u5e55\u30fb\u5225\u308csaish\u016bsh\u014djomakuwakarea prologue of final chapter , farewell2010-06-1413.4%\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT ratings FROM table_sql WHERE broadcast_date = (SELECT MAX(broadcast_date) FROM table_sql)) - \n             (SELECT ratings FROM table_sql WHERE romanized_title = 'fukusy\u016b no purop\u014dzu') > 3.2 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-965.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: episode number 213 aired on january 28 , 2008\nInput Table: cities of the underworld\n\n\nproduction_noepisode_nooriginal_airdateepisode_titlehost152012008-01-28underground apocalypsedon wildman162022008-02-04vietnamdon wildman172032008-02-11a - bomb undergrounddon wildman182042008-02-25viking undergrounddon wildman192052008-03-03hitler 's last secretdon wildman202062008-03-10maya undergrounddon wildman212072008-03-17mob undergrounddon wildman222082008-03-24prophecies from belowdon wildman232092008-03-31new york : secret societiesdon wildman242102008-04-14washington , dc : seat of powerdon wildman252112008-04-21stalin 's secret lairdon wildman262122008-04-28katrina undergrounddon wildman272132008-05-05secret soviet basesdon wildman\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE episode_no = 213 \nAND original_airdate = '2008-01-28';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1609.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: during the 2007 - 08 minnesota wild season , minnesota played at home more times than they played away\nInput Table: 2007 - 08 minnesota wild season\n\n\ndatevisitorscorehomedecisionattendancerecord01-02-9999minnesota4 - 1columbusbackstrom1852930 - 19 - 39999-02-05detroit3 - 2minnesotabackstrom1856830 - 19 - 401-02-07dallas1 - 0minnesotabackstrom1856830 - 20 - 49999-02-09ny islanders3 - 4minnesotabackstrom1856831 - 20 - 401-02-10minnesota2 - 1st louisharding1647732 - 20 - 401-02-12minnesota2 - 4edmontonharding1683932 - 21 - 401-02-14minnesota5 - 4vancouverbackstrom1863033 - 21 - 49999-02-17nashville4 - 5minnesotabackstrom1856834 - 21 - 49999-02-19vancouver3 - 2minnesotabackstrom1856834 - 21 - 59999-02-20minnesota0 - 3chicagoharding1781234 - 22 - 59999-02-24calgary2 - 1minnesotabackstrom1856834 - 23 - 59999-02-26minnesota1 - 4washingtonbackstrom1739134 - 24 - 59999-02-27minnesota3 - 2tampa baybackstrom1721135 - 24 - 59999-02-29minnesota3 - 2floridabackstrom1692736 - 24 - 5\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE home = 'minnesota') > \n             (SELECT COUNT(*) FROM table_sql WHERE visitor = 'minnesota') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-793.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: brain watts has a score of 68 + 69 + 73 = 210 from england\nInput Table: 1998 open championship\n\n\nplaceplayercountryscoreto_par1brian wattsunited states68 + 69 + 73 = 210et2jim furykunited states70 + 70 + 72 = 212+ 2t2mark o'mearaunited states72 + 68 + 72 = 212+ 2t2jesper parneviksweden68 + 72 + 72 = 212+ 25justin rose (a)england72 + 66 + 75 = 213+ 3t6thomas bj\u00e3rndenmark68 + 71 + 76 = 215+ 5t6brad faxonunited states67 + 74 + 74 = 215+ 5t6john hustonunited states65 + 77 + 73 = 215+ 5t6tiger woodsunited states65 + 73 + 77 = 215+ 5t10david duvalunited states70 + 71 + 75 = 216+ 6t10costantino roccaitaly72 + 74 + 70 = 216+ 6t10raymond russellscotland68 + 73 + 75 = 216+ 6t10katsuyoshi tomorijapan75 + 71 + 70 = 216+ 6\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT score FROM table_sql WHERE player = 'brian watts' AND country = 'england') = '68 + 69 + 73 = 210' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1358.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: alvaro campos is goalkeeper for the team that had no matches with an average higher than 0.61\nInput Table: 2008 - 09 segunda divisi\u00f3n b\n\n\ngoalkeepergoalsmatchesaverageteammiguel zapata17280.61atl\u00e9tico ciudadrub\u00e9n mart\u00ednez24320.75cartagenaorlando quintana29340.85lorca deportiva\u00e1lvaro campos24280.86real murcia bmat\u00edas garavano26300.87m\u00e9rida\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE team = 'real murcia b' AND average > 0.61) = 0 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1727.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: 1 game was on may 20 in houston\nInput Table: 2005 texas rangers season\n\n\ndatewinning_teamscorewinning_pitcherlosing_pitcherattendancelocation9999-05-20texas7 - 3kenny rogersbrandon backe38109arlington9999-05-21texas18 - 3chris youngezequiel astacio35781arlington9999-05-22texas2 - 0chan ho parkroy oswalt40583arlington9999-06-24houston5 - 2roy oswaltricardo rodr\u00edguez36199houston9999-06-25texas6 - 5chris youngbrandon backe41868houston\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE date = '9999-05-20' \nAND location = 'houston';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-375.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the black knights lost to stanford 21 - 10\nInput Table: 1975 army cadets football team\n\n\ngamedateopponentresultblack_knights_pointsopponentsrecord19999-09-13holy crosswin4471 - 029999-09-20lehighwin54322 - 039999-09-27villanovaloss0102 - 149999-10-04stanfordloss14672 - 259999-10-11dukeloss10212 - 369999-10-18pittsburghloss20522 - 479999-10-25penn stateloss0312 - 589999-11-01air forceloss3332 - 699999-11-08boston collegeloss0312 - 7109999-11-15vanderbiltloss14232 - 8\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT record FROM table_sql WHERE opponent = 'stanford') = '2 - 3' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-669.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: three of the total games featured had an attendance in the 3000s and 1 in the 12000s\nInput Table: 2008 - 09 bradford city a.f.c. season\n\n\ngamedateopponentvenueresultattendance12008-08-09notts countyhome2 - 11403822008-08-16macclesfield townaway2 - 0255632008-08-23rochdalehome2 - 01315442008-08-30aldershot townaway2 - 3380552008-09-06port valeaway2 - 0727362008-09-13exeter cityhome4 - 11268372008-09-20bournemouthhome1 - 31282482008-09-27shrewsbury townaway0 - 2651792008-10-04luton townhome1 - 113083102008-10-11accrington stanleyaway3 - 23012112008-10-18gillinghamhome2 - 212432122008-10-21darlingtonaway1 - 23034132008-10-24grimsby townaway3 - 14470142008-10-28buryhome1 - 012830152008-11-01barnethome3 - 312510162008-11-15wycombe wanderersaway0 - 15002172008-11-22rotherham unitedaway2 - 04586182008-11-25chesterfieldhome3 - 212145192008-12-06dagenham & redbridgehome1 - 112145202008-12-13brentfordaway1 - 24339212008-12-20chester cityhome0 - 012092222008-12-26lincoln cityaway0 - 06156232008-12-28morecambehome4 - 013105242009-01-03shrewsbury townhome0 - 012877252009-01-17accrington stanleyhome1 - 112172262009-01-24luton townaway3 - 36053272009-01-27buryaway0 - 14112282009-01-31grimsby townhome2 - 012816292009-02-07gillinghamaway2 - 04866302009-02-14wycombe wanderershome1 - 012689312009-02-17darlingtonhome0 - 012782322009-02-21barnetaway1 - 42445332009-02-28notts countyaway1 - 35138342009-03-01macclesfield townhome1 - 011908352009-03-07aldershot townhome5 - 012465362009-03-10rochdaleaway0 - 35157372009-03-14exeter cityaway0 - 15253382009-03-17bournemouthaway1 - 44847392009-03-21port valehome0 - 112436402009-03-28chester cityaway0 - 02735412009-04-04brentfordhome1 - 112832422009-04-10morecambeaway1 - 24546432009-04-13lincoln cityhome1 - 112932\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 4 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE attendance LIKE '3%' \nOR attendance LIKE '12%';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1441.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the denver broncos and the chicago bears played at the rca dome , ending in the broncos' favor with a score of 23 - 8\nInput Table: nbc sunday night football results (2006 - present)\n\n\ndatevisiting_teamfinal_scorehost_teamstadium9999-09-07miami dolphins17 - 28pittsburgh steelersheinz field9999-09-10indianapolis colts26 - 21new york giantsgiants stadium9999-09-17washington redskins10 - 27dallas cowboystexas stadium9999-09-24denver broncos17 - 7new england patriotsgillette stadium9999-10-01seattle seahawks6 - 37chicago bearssoldier field9999-10-08pittsburgh steelers13 - 23san diego chargersqualcomm stadium9999-10-15oakland raiders3 - 13denver broncosinvesco field at mile high9999-10-29dallas cowboys35 - 14carolina panthersbank of america stadium9999-11-05indianapolis colts27 - 20new england patriotsgillette stadium9999-11-12chicago bears38 - 20new york giantsgiants stadium9999-11-19san diego chargers35 - 27denver broncosinvesco field at mile high9999-11-26philadelphia eagles21 - 45indianapolis coltsrca dome9999-12-03seattle seahawks23 - 20denver broncosinvesco field at mile high9999-12-10new orleans saints42 - 17dallas cowboystexas stadium9999-12-17kansas city chiefs9 - 20san diego chargersqualcomm stadium9999-12-25philadelphia eagles23 - 7dallas cowboystexas stadium9999-12-31green bay packers26 - 7chicago bearssoldier field0001-01-06kansas city chiefs8 - 23indianapolis coltsrca dome0001-01-06dallas cowboys20 - 21seattle seahawksqwest field\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT stadium FROM table_sql WHERE visiting_team = 'denver broncos' AND host_team = 'chicago bears') = 'rca dome' \n             AND (SELECT final_score FROM table_sql WHERE visiting_team = 'denver broncos' AND host_team = 'chicago bears') = '23 - 8' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1360.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: atl\u00e9tico ciudad played 28 matches with an average of less than 0.61\nInput Table: 2008 - 09 segunda divisi\u00f3n b\n\n\ngoalkeepergoalsmatchesaverageteammiguel zapata17280.61atl\u00e9tico ciudadrub\u00e9n mart\u00ednez24320.75cartagenaorlando quintana29340.85lorca deportiva\u00e1lvaro campos24280.86real murcia bmat\u00edas garavano26300.87m\u00e9rida\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT average FROM table_sql WHERE team = 'atl\u00e9tico ciudad' AND matches = 28) < 0.61 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-469.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the player gene borek in t6 is from new zealand\nInput Table: 1973 u.s. open (golf)\n\n\nplaceplayercountryscoreto_par1gary playersouth africa67 + 70 = 137- 52jim colbertunited states70 + 68 = 138- 4t3jack nicklausunited states71 + 69 = 140- 2t3johnny millerunited states71 + 69 = 140- 2t3bob charlesnew zealand71 + 69 = 140- 2t6gene borekunited states77 + 65 = 142et6julius borosunited states73 + 69 = 142et6tom weiskopfunited states73 + 69 = 142et6arnold palmerunited states71 + 71 = 142et6lee trevinounited states70 + 72 = 142e\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT country FROM table_sql WHERE place = 't6' AND player = 'gene borek') = 'new zealand' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1079.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the highest attendances were 20066 , occurring on 6 dates\nInput Table: 2003 - 04 detroit red wings season\n\n\ndatevisitorscorehomedecisionattendancerecord0002-01-01detroit4 - 1carolinajoseph1705324 - 12 - 4 - 10001-01-03anaheim1 - 3detroitlegace2006625 - 12 - 4 - 10000-01-05nashville0 - 6detroitjoseph2006626 - 12 - 4 - 10001-01-07boston3 - 0detroitjoseph2006626 - 13 - 4 - 10000-01-10detroit1 - 2bostonjoseph1756526 - 13 - 4 - 29999-01-14chicago2 - 4detroitlegace2006627 - 13 - 4 - 20000-01-16phoenix3 - 3detroitjoseph2006627 - 13 - 5 - 29999-01-19detroit1 - 2san josejoseph1736127 - 14 - 5 - 29999-01-21detroit2 - 2anaheimlegace1717427 - 14 - 6 - 29999-01-22detroit5 - 4los angelesjoseph1811828 - 14 - 6 - 29999-01-24detroit2 - 5phoenixjoseph1901928 - 15 - 6 - 29999-01-26detroit2 - 2dallaslegace1853228 - 15 - 7 - 29999-01-29new jersey2 - 5detroitjoseph2006629 - 15 - 7 - 29999-01-31carolina4 - 4detroitlegace2006630 - 15 - 8 - 2\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 6 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE attendance = 20066;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-347.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the highest attendance was at the target center\nInput Table: 2008 - 09 phoenix suns season\n\n\ngamedateteamlocation_attendancerecord759999-04-01houstonus airways center 1842241 - 34769999-04-03sacramentous airways center 1842242 - 3477'9999-04-05'dallasamerican airlines center 2030142 - 35789999-04-08new orleansnew orleans arena 1778143 - 3579'9999-04-10'memphisfedexforum 1590843 - 36809999-04-11minnesotatarget center 1847844 - 36819999-04-13memphisus airways center 1842245 - 3682'9999-04-15'golden stateus airways center46 - 36\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN MAX(location_attendance) = 'target center' THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1989.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there were four differnt games where no goals were scored by either side\nInput Table: 2000 - 01 sheffield wednesday f.c. season\n\n\ndateopponentvenueresultattendance2000-08-13wolverhampton wanderersa1 - 1190862000-08-19huddersfield townh2 - 3227042000-08-26grimsby towna1 - 077552000-08-28blackburn roversh1 - 1156462000-09-09wimbledonh0 - 5158562000-09-13nottingham foresth0 - 1157002000-09-16tranmere roversa0 - 293522000-09-23preston north endh1 - 3173792000-09-30gillinghama0 - 290992000-10-08west bromwich albionh1 - 2153382000-10-14portsmoutha1 - 2133762000-10-17burnleya0 - 1163722000-10-22birmingham cityh1 - 0146952000-10-25queens park rangersa2 - 1103532000-10-28fulhamh3 - 3175592000-11-04crystal palacea1 - 4153332000-11-07watforda3 - 1111662000-11-01norwich cityh3 - 2169562000-11-18barnsleya0 - 1199892000-11-25crewe alexandraa0 - 171032000-12-02queens park rangersh5 - 2217822000-12-09stockport countyh2 - 4163372000-12-16sheffield uniteda1 - 1251562000-12-23wolverhampton wanderersh0 - 1177872000-12-26bolton wanderersa0 - 2213162000-12-30huddersfield towna0 - 0189312001-01-01grimsby townh1 - 0170042001-01-13blackburn roversa0 - 2193082001-01-20bolton wanderersh0 - 3176382001-02-03watfordh2 - 3161342001-02-10wimbledona1 - 467412001-02-13tranmere roversh1 - 0154442001-02-21nottingham foresta1 - 0232662001-02-24preston north enda0 - 2143792001-03-03gillinghamh2 - 1187022001-03-07portsmouthh0 - 0205032001-03-10west bromwich albiona2 - 1186622001-03-17burnleyh2 - 0201842001-03-24birmingham citya2 - 1197332001-04-01sheffield unitedh1 - 2384332001-04-07stockport countya1 - 296662001-04-14crystal palaceh4 - 1198772001-04-16fulhama1 - 1175002001-04-21barnsleyh2 - 1234982001-04-28norwich citya0 - 1212412001-05-06crewe alexandrah0 - 028007\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 4 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE result = '0 - 0';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1833.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: as the team is uni\u00e3o de leiria , the date of appointment is before10 july 2010\nInput Table: 2010 - 11 primeira liga\n\n\nteamoutgoing_head_coachmanner_of_departuredate_of_vacancyposition_in_tableincoming_head_coachdate_of_appointmentuni\u00e3o de leirialito vidigalsacked2010-07-07off - seasonpedro caixinha2010-07-10mar\u00edtimomitchell van der gaagsacked2010-09-1415thpedro martins2010-09-14naval 1 de maiovictor zvunkasacked2010-09-2714throg\u00e9rio gon\u00e7alves2010-10-06acad\u00e9micajorge costaresigned2010-12-219thjos\u00e9 guilherme2010-12-27naval 1 de maiorog\u00e9rio gon\u00e7alvessacked2010-12-1916thcarlos mozer2010-12-30portimonenselitossacked2011-12-2816thcarlos azenha2010-12-29acad\u00e9micajos\u00e9 guilhermeresigned2011-02-2013thulisses morais2011-02-22sportingpaulo s\u00e9rgioresigned2011-02-263rdjos\u00e9 couceiro2011-02-26beira - marleonardo jardimresigned2011-02-2810thrui bento2011-03-01vit\u00f3ria de set\u00fabalmanuel fernandessacked2011-03-0114thbruno ribeiro2011-03-01\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT date_of_appointment FROM table_sql WHERE team = 'uni\u00e3o de leiria') < '2010-07-10' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-638.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the call sign for the radio owned by bell media is ckfr\nInput Table: media in kelowna\n\n\nfrequencycall_signbrandingformatowner1150 amckfram 1150news / talkastral media00 88.9 fmcbtk - fmcbc radio onepublic news / talkcanadian broadcasting corporation00 89.7 fmcbu - fm - 3cbc radio 2public musiccanadian broadcasting corporation00 90.5 fmcbuf - fm - 2premi\u00e8re cha\u00eenepublic news / talkcanadian broadcasting corporation00 96.3 fmckko - fmk96.3classic rocksun country cablevision00 99.9 fmchsu - fm99.9 sun fmcontemporary hits radiobell media0 101.5 fmcilk - fm101.5 ez rockadult contemporarybell media0 103.1 fmckqq - fmq103hot adult contemporaryjim pattison group0 103.9 fmcjui - fm103.9 the juiceadult hitsvista broadcast group0 104.7 fmcklz - fmpower 104active rockjim pattison group\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE owner = 'bell media' \nAND call_sign = 'ckfr';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1874.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: patty sheehan , judy rankin and kathy whitworth were all captains that won the solheim cup one time\nInput Table: solheim cup\n\n\nyearvenuewinning_teamscoreusa_captaineurope_captain2013-01-01colorado golf club , colorado , usaeurope18 - 10meg mallonliselotte neumann2011-01-01killeen castle golf resort , irelandeurope15 - 13rosie jonesalison nicholas2009-01-01rich harvest farms , illinois , usaunited states16 - 12beth danielalison nicholas2007-01-01halmstad gk , swedenunited states16 - 12betsy kinghelen alfredsson2005-01-01crooked stick golf club , indiana , usaunited states15\u00bd - 12\u00bdnancy lopezcatrin nilsmark2003-01-01barseb\u00e4ck golf & country club , swedeneurope17\u00bd - 10\u00bdpatty sheehancatrin nilsmark2002-01-01interlachen country club , minnesota , usaunited states15\u00bd - 12\u00bdpatty sheehandale reid2000-01-01loch lomond golf club , scotlandeurope14\u00bd - 11\u00bdpat bradleydale reid1998-01-01muirfield village , ohio , usaunited states16 - 12judy rankinpia nilsson1996-01-01st pierre golf & country club , walesunited states17 - 11judy rankinmickey walker1994-01-01the greenbrier , west virginia , usaunited states13 - 7joanne carnermickey walker1992-01-01dalmahoy country club , scotlandeurope11\u00bd - 6\u00bdkathy whitworthmickey walker1990-01-01lake nona golf & country club , florida , usaunited states11\u00bd - 4\u00bdkathy whitworthmickey walker\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(DISTINCT usa_captain) FROM table_sql WHERE winning_team = 'united states') = 3 \n             AND (SELECT COUNT(DISTINCT europe_captain) FROM table_sql WHERE winning_team = 'europe') = 3 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-223.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there is more than one disc\nInput Table: none\n\n\nvolumediscsepisodesregion_1region_2region_41142006-01-312007-02-192007-03-152142006-03-282007-06-042007-07-053142006-05-302007-09-032008-03-134142006-07-182008-02-182008-06-195142006-09-192008-05-262009-03-05\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(DISTINCT discs) > 1 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-926.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there were 24.8 points per game in the selection where rebounds per game were 17\nInput Table: list of career achievements by dwight howard\n\n\nselectionmonthseasonteam_recordpoints_per_gamefield_goal_percentagerebounds_per_gameblocks_per_game9999-01-012006-04-012005-06-017-218.153114.00.79999-01-022006-10-012006-07-0112-417.157613.61.99999-01-032007-10-012007-08-0114-423.861815.02.79999-01-042007-12-012007-08-018-721.759816.12.99999-01-052010-10-012010-11-0113-421.8 (5th)594 (2nd)12.1 (4th in league)2.4\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE points_per_game = 24.8 \nAND rebounds_per_game = 17;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1855.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: in 2010 , when mixed doubles is danny bawa chrisnanta and debby susanto , the boys singles is nugroho andi saputro\nInput Table: indonesian national badminton championships\n\n\nyearboys_singlesgirls_singlesboys_doublesgirls_doublesmixed_doubles2001holvy de pauwmaria kristin yuliantihendra setiawan joko riyadililyana natsir natalia poluakanhendra setiawan greysia polii2002andre kurniawan tedjonofransisca ratnasariujang suherlan yoga ukikasahpurwati meiliana jauharimuhammad rijal meiliana jauhari2003alamsyah yunuswiwis meilyannafran kurniawan chandra kowipia zebadiah nitya krishinda maheswarifran kurniawan yulianti2004andre kurniawan tedjonopia zebadiahaditya dwi putra i made agungpia zebadiah nitya krishinda maheswarilingga lie yulianti2005achmad rivaibellaetrix manuputtyrio willianto davin prawidssalily siswanti shendy puspa irawatiabdul rahman richi puspita dili2006nugroho andi saputrosylvinna kurniawandanny bawa chrisnanta afiat yuris wirawanbellaetrix manuputty samantha lintangdanny bawa chrisnanta debby susanto2007nandang ariflindaweni fanetribudi hartono yohanes rendy sugiartoanneke feinya agustin wenny setiawatiwifqi windarto debby susanto2008hermansyahana rovitadidit juang indrianto seiko wahyu kusdiantosuci rizki andini tiara rosalia nuraidahirfan fadhilah weni anggraeni2009riyanto subagjaana rovitajones ralfy jansen dandi prabuditaayu pratiwi anggi widiadidit juang indrianto yayu rahayu2010shesar hiren rhustavitoganis nur rahmadanijones ralfy jansen dandi prabuditaaris budiharti dian fitrianijones ralfy jansen nurbeta kwanrico\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN boys_singles = 'nugroho andi saputro' \n             AND mixed_doubles = 'danny bawa chrisnanta debby susanto' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE year = 2010;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-703.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: macoto cobras is the opponent when horacio estrada is the loss\nInput Table: 2007 uni - president lions season\n\n\ndateopponentscorelosssave9999-03-17la new bears4 - 5pan wei - lunhuang chun - chung9999-03-18la new bears4 - 1horacio estradatseng yi - cheng9999-03-22chinatrust whales7 - 9kao lung - weini fu - deh9999-03-23chinatrust whales4 - 5pan wei - lunmiguel saladin9999-03-24la new bears1 - 5jeriome robertson||30089999-03-25la new bears1 - 6rob cordemanshuang chun - chung9999-03-27brother elephantspostponed rescheduled for june 19postponed rescheduled for june 19postponed rescheduled for june 199999-03-28brother elephants0 - 4tsao chun - yangchuang wei - chuan9999-03-31macoto cobras11 - 5diegomar markwell||2275\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN opponent = 'macoto cobras' AND loss = 'horacio estrada' THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1957.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the chicago bulls were the only teamn to play the boston celtics in boston garden and win\nInput Table: 1984 - 85 boston celtics season\n\n\ngamedateopponentscorelocationrecord339999-01-02new jersey nets110 - 95brendan byrne arena27 - 6349999-01-04new york knicks105 - 94boston garden28 - 6359999-01-07new york knicks108 - 97madison square garden29 - 6369999-01-09chicago bulls111 - 108boston garden30 - 6379999-01-11washington bullets103 - 101boston garden31 - 6389999-01-12atlanta hawks119 - 111the omni32 - 6399999-01-16los angeles lakers104 - 102boston garden33 - 6409999-01-18indiana pacers86 - 91market square arena33 - 7419999-01-20philadelphia 76ers113 - 97boston garden34 - 7429999-01-23seattle supersonics97 - 107boston garden34 - 8439999-01-25indiana pacers125 - 94boston garden35 - 8449999-01-27portland trail blazers128 - 127boston garden36 - 8459999-01-29detroit pistons131 - 130hartford civic center37 - 8469999-01-30philadelphia 76ers104 - 122the spectrum37 - 9\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 1 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE opponent = 'chicago bulls' \nAND location = 'boston garden' \nAND score LIKE '% - %' \nAND score NOT LIKE '1%' \nAND score NOT LIKE '%1' \nAND record NOT LIKE '1%' \nAND record NOT LIKE '%1';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1899.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: willam ivey long won the 2005 drama desk award for outstanding choreography\nInput Table: la cage aux folles (musical)\n\n\nyearawardcategorynomineeresult2005tony awardbest revival of a musicalbest revival of a musicalwon2005tony awardbest performance by a leading actor in a musicalgary beachnominated2005tony awardbest choreographyjerry mitchellwon2005tony awardbest costume designwilliam ivey longnominated2005drama desk awardoutstanding revival of a musicaloutstanding revival of a musicalwon2005drama desk awardoutstanding choreographyjerry mitchellwon2005drama desk awardoutstanding costume designwilliam ivey longnominated\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE year = 2005 \nAND award = 'drama desk award' \nAND category = 'outstanding choreography' \nAND nominee = 'william ivey long' \nAND result = 'won';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-935.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: when detroit was the home team , chicago was the visitor team against them\nInput Table: none\n\n\ndatevisitorscorehomerecord9999-02-03ny islanders7 - 2new jersey11 - 32 - 119999-02-05new jersey4 - 5washington11 - 33 - 119999-02-06vancouver4 - 4new jersey11 - 33 - 129999-02-09new jersey4 - 5chicago11 - 34 - 1201-02-12new jersey1 - 5st louis11 - 35 - 1201-02-15minnesota3 - 2new jersey11 - 36 - 129999-02-20new jersey0 - 3philadelphia11 - 37 - 1201-02-21buffalo4 - 4new jersey11 - 37 - 139999-02-24detroit1 - 4new jersey12 - 37 - 139999-02-26new jersey4 - 5pittsburgh12 - 38 - 139999-02-27new jersey2 - 6buffalo12 - 39 - 13\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE home = 'detroit' \nAND visitor = 'chicago';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1928.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: tyler farrar was the winner of the stage three times\nInput Table: 2010 vuelta a espa\u00f1a\n\n\nstagewinnergeneral_classificationpoints_classificationmountains_classificationcombination_classificationteam_classification1team htc - columbiamark cavendishmark cavendish 1not awardedmark cavendishteam htc - columbia2yauheni hutarovichmark cavendishyauheni hutarovichmicka\u00ebl delagejavier ram\u00edrezteam htc - columbia3philippe gilbertphilippe gilbertphilippe gilbertseraf\u00edn mart\u00ednezseraf\u00edn mart\u00ednezteam htc - columbia4igor ant\u00f3nphilippe gilbertigor ant\u00f3nseraf\u00edn mart\u00ednezvincenzo nibalicaisse d'epargne5tyler farrarphilippe gilbertigor ant\u00f3nseraf\u00edn mart\u00ednezvincenzo nibalicaisse d'epargne6thor hushovdphilippe gilbertphilippe gilbertseraf\u00edn mart\u00ednezphilippe gilbertcaisse d'epargne7alessandro petacchiphilippe gilbertmark cavendishseraf\u00edn mart\u00ednezphilippe gilbertcaisse d'epargne8david moncouti\u00e9igor ant\u00f3nmark cavendishseraf\u00edn mart\u00ednezvincenzo nibalicaisse d'epargne9david l\u00f3pezigor ant\u00f3nmark cavendishdavid moncouti\u00e9vincenzo nibalicaisse d'epargne10imanol ervitijoaquim rodr\u00edguezmark cavendishdavid moncouti\u00e9david moncouti\u00e9caisse d'epargne11igor ant\u00f3nigor ant\u00f3nigor ant\u00f3ndavid moncouti\u00e9igor ant\u00f3ncaisse d'epargne12mark cavendishigor ant\u00f3nmark cavendishdavid moncouti\u00e9igor ant\u00f3ncaisse d'epargne13mark cavendishigor ant\u00f3nmark cavendishdavid moncouti\u00e9igor ant\u00f3ncaisse d'epargne14joaquim rodr\u00edguezvincenzo nibalimark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezcaisse d'epargne15carlos barredovincenzo nibalimark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezteam katusha16mikel nievejoaquim rodr\u00edguezmark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezteam katusha17peter velitsvincenzo nibalimark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezteam katusha18mark cavendishvincenzo nibalimark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezteam katusha19philippe gilbertvincenzo nibalimark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezteam katusha20ezequiel mosquera 2vincenzo nibalimark cavendishdavid moncouti\u00e9vincenzo nibaliteam katusha21tyler farrarvincenzo nibalimark cavendishdavid moncouti\u00e9vincenzo nibaliteam katusha\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 3 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE winner = 'tyler farrar';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-887.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: denis menchov scored the most uci points of any cyclists from russia\nInput Table: 2007 volta a catalunya\n\n\ncyclistcountryteamtimeuci_pointsvladimir karpetsrussiacaisse d'epargne9999-01-0150denis menchovrussiarabobank9999-01-0140michael rogersaustraliat - mobile team9999-01-0135christophe moreaufranceag2r pr\u00e9voyance9999-01-0130\u00f3scar sevillaspainrelax - gam9999-01-01n / afrancisco mancebospainrelax - gam9999-01-01n / ajohn gadretfranceag2r pr\u00e9voyance9999-01-0215marcos - antonio serranospainkarpin - galicia9999-01-01n / alaurens ten damnetherlandsunibetcom9999-01-015janez brajkovi\u010dsloveniadiscovery channel9999-01-022\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MAX(uci_points) FROM table_sql WHERE country = 'russia') = \n             (SELECT uci_points FROM table_sql WHERE cyclist = 'denis menchov') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1814.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: south korea is the only country to have hosted equestrian at the asian games more than one time , in seoul two times\nInput Table: equestrian at the asian games\n\n\nyearlocationgoldsilverbronze1982new delhinadia al - moutawaajamila al - moutawaabariaa salem al - sabbah1986seoultakashi tomurashuichi tokiryuzo okuno1994hiroshimakonoshin kuwahararyuzo okunonatya chantrasmi1998bangkokjin kannosohn bong - gakquzier ambak fathil2002busanmikaela mar\u00e3\u00ada jaworskilee jin - kyungtadayoshi hayashi2006dohaali yousuf al - rumaihijasmine chen - shao manjoo jung - hyun2010guangzhouramzy al duhamilatifa al maktomkhaled al - eid\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 1 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE location = 'seoul' \nAND year != 1986;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1900.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the 2005 nominee for best costume design won the award\nInput Table: la cage aux folles (musical)\n\n\nyearawardcategorynomineeresult2005tony awardbest revival of a musicalbest revival of a musicalwon2005tony awardbest performance by a leading actor in a musicalgary beachnominated2005tony awardbest choreographyjerry mitchellwon2005tony awardbest costume designwilliam ivey longnominated2005drama desk awardoutstanding revival of a musicaloutstanding revival of a musicalwon2005drama desk awardoutstanding choreographyjerry mitchellwon2005drama desk awardoutstanding costume designwilliam ivey longnominated\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE year = 2005 \nAND award = 'tony award' \nAND category = 'best costume design' \nAND nominee = 'william ivey long' \nAND result = 'won';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1726.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the winning pitcher on june 24 was chris young\nInput Table: 2005 texas rangers season\n\n\ndatewinning_teamscorewinning_pitcherlosing_pitcherattendancelocation9999-05-20texas7 - 3kenny rogersbrandon backe38109arlington9999-05-21texas18 - 3chris youngezequiel astacio35781arlington9999-05-22texas2 - 0chan ho parkroy oswalt40583arlington9999-06-24houston5 - 2roy oswaltricardo rodr\u00edguez36199houston9999-06-25texas6 - 5chris youngbrandon backe41868houston\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT winning_pitcher FROM table_sql WHERE date = '9999-06-24') = 'chris young' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-366.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: usc and clemson college had the most players drafted at 3 each\nInput Table: indianapolis colts draft history\n\n\nroundpickoverallnamepositioncollege155curtis dickeyrunning backtexas a&m12424derrick hatchettcornerbacktexas2432ray donaldsoncentergeorgia22351tim foleyoffensive tacklenotre dame4588ray butlerwide receiverusc66144chris footecenterusc75170wes robertsdefensive endtcu82195ken walteroffensive tackletexas tech96227mark brightrunning backtemple105254larry stewartoffensive tacklemaryland113280ed whitleytight endkansas state126311randy bielskiplacekickertowson1219324marvin simsfullbackclemson\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE college = 'usc') = 3 \n             AND (SELECT COUNT(*) FROM table_sql WHERE college = 'clemson') = 3 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1148.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the total medals for the nation with 1 silver and 0 golds is more than 2\nInput Table: volleyball at the summer olympics\n\n\nranknationgoldsilverbronzetotal1soviet union32162united states30143brazil23054russia11245japan11136netherlands11027yugoslavia10128poland10019italy023510czechoslovakia011211bulgaria010111east germany010113argentina001113cuba001113romania0011\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT total FROM table_sql WHERE silver = 1 AND gold = 0) > 2 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1845.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: cannons is the opponent on july 14 at bishop kearney field\nInput Table: 2005 philadelphia barrage season\n\n\ndateopponenthome_/_awayfieldresult9999-05-29cannonshomevillanova stadiuml 12 - 139999-06-04lizardshomevillanova stadiuml 14 - 199999-06-12bayhawksawayjohnny unitas stadiuml 9 - 319999-06-18prideawayalumni stadium (kean university)w 11 - 109999-06-25lizardsawaymitchel athletic complexl 12 - 189999-06-30cannonsawaynickerson fieldw 15 - 149999-07-09rattlersawaybishop kearney fieldw 26 - 159999-07-14rattlershomevillanova stadiuml 10 - 149999-07-23cannonsawaynickerson fieldl 10 - 119999-07-28lizardshomevillanova stadiumw 16 - 149999-08-04bayhawkshomevillanova stadiuml 9 - 199999-08-11pridehomevillanova stadiuml 12 - 16\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE date = '9999-07-14' \nAND opponent = 'cannons' \nAND field = 'bishop kearney field';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1933.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: tyler farrar did not win any stages\nInput Table: 2010 vuelta a espa\u00f1a\n\n\nstagewinnergeneral_classificationpoints_classificationmountains_classificationcombination_classificationteam_classification1team htc - columbiamark cavendishmark cavendish 1not awardedmark cavendishteam htc - columbia2yauheni hutarovichmark cavendishyauheni hutarovichmicka\u00ebl delagejavier ram\u00edrezteam htc - columbia3philippe gilbertphilippe gilbertphilippe gilbertseraf\u00edn mart\u00ednezseraf\u00edn mart\u00ednezteam htc - columbia4igor ant\u00f3nphilippe gilbertigor ant\u00f3nseraf\u00edn mart\u00ednezvincenzo nibalicaisse d'epargne5tyler farrarphilippe gilbertigor ant\u00f3nseraf\u00edn mart\u00ednezvincenzo nibalicaisse d'epargne6thor hushovdphilippe gilbertphilippe gilbertseraf\u00edn mart\u00ednezphilippe gilbertcaisse d'epargne7alessandro petacchiphilippe gilbertmark cavendishseraf\u00edn mart\u00ednezphilippe gilbertcaisse d'epargne8david moncouti\u00e9igor ant\u00f3nmark cavendishseraf\u00edn mart\u00ednezvincenzo nibalicaisse d'epargne9david l\u00f3pezigor ant\u00f3nmark cavendishdavid moncouti\u00e9vincenzo nibalicaisse d'epargne10imanol ervitijoaquim rodr\u00edguezmark cavendishdavid moncouti\u00e9david moncouti\u00e9caisse d'epargne11igor ant\u00f3nigor ant\u00f3nigor ant\u00f3ndavid moncouti\u00e9igor ant\u00f3ncaisse d'epargne12mark cavendishigor ant\u00f3nmark cavendishdavid moncouti\u00e9igor ant\u00f3ncaisse d'epargne13mark cavendishigor ant\u00f3nmark cavendishdavid moncouti\u00e9igor ant\u00f3ncaisse d'epargne14joaquim rodr\u00edguezvincenzo nibalimark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezcaisse d'epargne15carlos barredovincenzo nibalimark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezteam katusha16mikel nievejoaquim rodr\u00edguezmark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezteam katusha17peter velitsvincenzo nibalimark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezteam katusha18mark cavendishvincenzo nibalimark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezteam katusha19philippe gilbertvincenzo nibalimark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezteam katusha20ezequiel mosquera 2vincenzo nibalimark cavendishdavid moncouti\u00e9vincenzo nibaliteam katusha21tyler farrarvincenzo nibalimark cavendishdavid moncouti\u00e9vincenzo nibaliteam katusha\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE winner = 'tyler farrar';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1522.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the home town of cody zeller is wichita , ks\nInput Table: usa today all - usa high school basketball team\n\n\nplayerheightschoolhometowncollegekhem birch6 - 9notre dame prepmontreal , qc , canadapittsburgh / unlvperry ellis6 - 8wichita heights high schoolwichita , kskansasmyles mack5 - 9st anthony high schooljersey city , njrutgersshabazz muhammad6 - 6bishop gorman high schoollas vegas , nvuclacody zeller6 - 11washington high schoolwashington , inindiana\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN hometown = 'wichita , ks' THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE player = 'cody zeller';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1713.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: 15 of the eagle class were made but 0 were preserved\nInput Table: locomotives of the southern railway\n\n\nclasswheel_arrangementmanufactureryear_madequantity_madequantity_preservedyear_(s)_withdrawnjoseph hamilton beattie (1850 - 1871)joseph hamilton beattie (1850 - 1871)joseph hamilton beattie (1850 - 1871)joseph hamilton beattie (1850 - 1871)joseph hamilton beattie (1850 - 1871)joseph hamilton beattie (1850 - 1871)joseph hamilton beattie (1850 - 1871)hercules2 - 4 - 0nine elms works1851 - 18541501875 - 1884tartar2 - 2 - 2wtsharp brothers1852601871 - 1874sussex2 - 2 - 2wtnine elms works1852801871 - 1876canute2 - 2 - 2nine elms works1855 - 18591201875 - 1885saxon2 - 4 - 0nine elms works1855 - 18571201877 - 1885chaplin2 - 2 - 2wtnine elms works1856301876 - 1877minerva2 - 4 - 0wtnine elms works1856301874 - 1883nelson2 - 4 - 0wtnine elms works1858301882 - 1885nile2 - 4 - 0wtnine elms works1859301882tweed2 - 4 - 0nine elms works1858 - 1859601877 - 1879undine2 - 4 - 0nine elms works1859 - 601201884 - 1886clyde2 - 4 - 0nine elms works1859 - 18681301883 - 1899gem2 - 4 - 0nine elms works1862 - 1863601884 - 1885eagle2 - 4 - 0nine elms works1862301885 - 1886falcon2 - 4 - 0nine elms works1863 - 18671701882 - 18981772 - 4 - 0wtbeyer , peacock & co (82) nine elms works (3)1863 - 18758521886 - 1899 , 1962lion0 - 6 - 0nine elms works1863 - 18733801886 - 1900volcano2 - 4 - 0nine elms works1866 - 18731801886 - 18972210 - 6 - 0beyer , peacock & co1866 - 18732401891 - 19242312 - 4 - 0beyer , peacock & co1866601892 - 1899vesuvius2 - 4 - 0nine elms works1869 - 18753201893 - 1899\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT quantity_made FROM table_sql WHERE class = 'eagle') = 15 \n             AND (SELECT quantity_preserved FROM table_sql WHERE class = 'eagle') = 0 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1911.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: less than 3 teams hold a minus goal difference , while more than 5 have scored more goals against them\nInput Table: 1940 in brazilian football\n\n\npositionteampointsplayedagainstdifference1flamengo1381282fluminense13815103corinthians981544palestra it\u00e1lia881935portuguesa7823- 106botafogo682507vasco da gama6819- 28am\u00e9rica6825- 109s\u00e3o paulo4824- 13\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE difference < 0) < 3 \n             AND (SELECT COUNT(*) FROM table_sql WHERE against > played) > 5 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1072.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the largest attendance of 44505 was at the game that took place on september 13 , 1976\nInput Table: 1976 buffalo bills season\n\n\nweekdateopponentresultattendance11976-09-13miami dolphinsl 30 - 217768321976-09-19houston oilersl 13 - 36138431976-09-26tampa bay buccaneersw 14 - 94450541976-10-03kansas city chiefsw 50 - 175190951976-10-10new york jetsl 17 - 145911061976-10-17baltimore coltsl 31 - 137100971976-10-24new england patriotsl 26 - 224514481976-10-31new york jetsl 19 - 144128591976-11-07new england patriotsl 20 - 1061157101976-11-15dallas cowboysl 17 - 1051799111976-11-21san diego chargersl 34 - 1336539121976-11-25detroit lionsl 27 - 1466875131976-12-05miami dolphinsl 45 - 2743475141976-12-12baltimore coltsl 58 - 2050451\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN attendance = 44505 AND date = '1976-09-13' THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1698.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: katee shean and joshua aleen danced a jazz style and were safe\nInput Table: so you think you can dance (u.s. season 4)\n\n\ncouplestylemusicchoreographer_(s)resultscourtney galiano mark kanemuraviennese waltzthe time of my life - david cookjason gilkisonkanemura eliminatedcourtney galiano mark kanemurajazzthe garden- mirahsonya tayehkanemura eliminatedkatee shean joshua allencontemporaryall by myself - celine diontyce dioriosafekatee shean joshua allenpaso doblefilet from le r\u00eavejason gilkisonsafechelsie hightower stephen twitch bossmamboahora me toca a mi- v\u00edctor manuelletony meredith melanie lapatin assistinghightower eliminatedchelsie hightower stephen twitch bosship - hopcontrol - vitamin string quartettabitha and napoleon d'umohightower eliminated\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE couple = 'katee shean joshua allen' \nAND style = 'jazz' \nAND results = 'safe';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-933.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the score of the game with a 12 - 38 - 13 record is 2 - 6\nInput Table: none\n\n\ndatevisitorscorehomerecord9999-02-03ny islanders7 - 2new jersey11 - 32 - 119999-02-05new jersey4 - 5washington11 - 33 - 119999-02-06vancouver4 - 4new jersey11 - 33 - 129999-02-09new jersey4 - 5chicago11 - 34 - 1201-02-12new jersey1 - 5st louis11 - 35 - 1201-02-15minnesota3 - 2new jersey11 - 36 - 129999-02-20new jersey0 - 3philadelphia11 - 37 - 1201-02-21buffalo4 - 4new jersey11 - 37 - 139999-02-24detroit1 - 4new jersey12 - 37 - 139999-02-26new jersey4 - 5pittsburgh12 - 38 - 139999-02-27new jersey2 - 6buffalo12 - 39 - 13\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN score = '2 - 6' THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE record = '12 - 38 - 13';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-722.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: chris burke was one of five players to have a free transfer fee\nInput Table: 2008 - 09 rangers f.c. season\n\n\nnatnamemoving_totypetransfer_windowtransfer_feesconicholas gallacher9999-01-01end of contract9999-06-01n / aivory coastlacine cherif9999-01-01end of contract9999-06-01n / ascoalistair park9999-01-01end of contract9999-06-01n / aengmichael donald9999-01-01end of contract9999-06-01n / ascocalum reidford9999-01-01end of contract9999-06-01n / ascochris smith9999-01-01end of contract9999-06-01n / abeljeroen van den broeck9999-01-01end of contract9999-06-01n / aslovakiafilip \u0161ebo9999-01-01transfer9999-06-011 mbelthomas buffel9999-01-01transfer9999-06-01n / aespcarlos cu\u00e9llar9999-01-01transfer9999-06-017.8 mscosteven lennon9999-01-01loan9999-06-01n / ascomark weir9999-01-01loan9999-06-01n / ascoandy webster9999-01-01loan9999-06-01n / arsadean furman9999-01-01loan9999-06-01n / ascoalan lowing9999-01-01loan9999-06-01n / ascopaul emslie9999-01-01loan9999-06-01n / ascoscott gallacher9999-01-01loan9999-06-01n / agabondaniel cousin9999-01-01transfer9999-06-013.5 mscoalan gow9999-01-01loan9999-06-01n / aenglee robinson9999-01-01loan9999-01-01n / ascoandrew shinnie9999-01-01loan9999-01-01n / ascosteven kinniburgh9999-01-01loan9999-01-01n / ascorory loy9999-01-01loan9999-01-01n / ascowilliam mclachlan9999-01-01loan9999-01-01n / ascolee robinson9999-01-01loan9999-01-01n / afrajean - claude darcheville9999-01-01transfer9999-01-01freescojordan mcmillan9999-01-01loan9999-01-01n / ascochris burke9999-01-01transfer9999-01-01freecypgeorgios efrem9999-01-01loan9999-01-01n / ascoalan gow9999-01-01loan9999-01-01n / ascocharlie adam9999-01-01loan9999-01-01n / ascoross harvey9999-01-01loan9999-01-01n / ascosteven kinniburgh9999-01-01loan9999-01-01n / a\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 1 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE transfer_fee = 'free';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-395.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the game between team 1 saint - louis fc and team 2 eleven arrows fc has the highest combined agg compared to any featured games\nInput Table: 1992 african cup of champions clubs\n\n\nteam_1aggteam_21st_leg2nd_legbotswana defence force xi1 - 2mbabane highlanders1 - 10 - 1arsenal (maseru)4 - 0eleven arrows fc3 - 01 - 0cd el\u00e1 nguema2 - 6primeiro de agosto2 - 30 - 3 1lprc oilers2 - 3mighty blackpool1 - 01 - 3asc police2 - 2 (4 - 5)as real bamako1 - 11 - 1port autonome0 - 0 (1 - 3)sporting clube da praia0 - 00 - 0saint - george sa2 - 4al ittihad2 - 10 - 3saint - louis fc2 - 7young africans1 - 31 - 4sahel sc4 - 2postel sport2 - 12 - 1tourbillon fc1 - 1forces arm\u00e9es ca0 - 01 - 1\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MAX(agg) FROM table_sql) = (SELECT agg FROM table_sql WHERE team_1 = 'saint - louis fc' AND team_2 = 'eleven arrows fc') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-31.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the attendance was less than 20000 over five times between august 4th and 6th\nInput Table: 1997 colorado rockies season\n\n\ndateopponentscorelossattendancerecord9999-08-01pirates7 - 6rinc\u00f3n (4 - 5)2265752 - 589999-08-02pirates6 - 5swift (4 - 5)3238852 - 599999-08-03pirates8 - 4reed (3 - 5)2498952 - 609999-08-04phillies7 - 3castillo (8 - 10)1523052 - 619999-08-05phillies4 - 2bottalico (2 - 4)1642853 - 619999-08-06mets4 - 0mlicki (5 - 8)2663354 - 619999-08-07mets12 - 4swift (4 - 6)2953654 - 629999-08-08pirates5 - 3lieber (6 - 12)4826255 - 629999-08-09pirates8 - 7rinc\u00f3n (4 - 6)4832356 - 629999-08-10pirates8 - 7wilkins (7 - 3)4801857 - 629999-08-12phillies5 - 0thomson (4 - 7)4822857 - 639999-08-13phillies12 - 8wright (6 - 8)4849157 - 649999-08-15mets6 - 2reed (10 - 6)4830858 - 649999-08-16mets7 - 5mcmichael (7 - 10)4831159 - 649999-08-17mets6 - 4mlicki (5 - 10)4844060 - 649999-08-19reds6 - 5wright (6 - 9)3172260 - 659999-08-20reds5 - 3white (1 - 1)2196861 - 659999-08-21astros10 - 4bailey (9 - 9)2296261 - 669999-08-22astros9 - 1thomson (5 - 8)3306161 - 679999-08-23astros6 - 3hudek (0 - 2)3237462 - 679999-08-24astros3 - 1wright (6 - 10)2891862 - 689999-08-25reds7 - 6castillo (10 - 11)4814362 - 699999-08-25reds6 - 4hutton (3 - 2)4808162 - 709999-08-26reds9 - 5mart\u00ednez (1 - 1)4806363 - 709999-08-27reds7 - 5remlinger (6 - 6)4803264 - 709999-08-28mariners9 - 5olivares (6 - 9)4842265 - 709999-08-29mariners6 - 5timlin (3 - 3)4817866 - 709999-08-30athletics4 - 3mohler (1 - 10)4830867 - 709999-08-31athletics10 - 4oquist (2 - 5)4804168 - 70\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) >= 5 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE date >= '9999-08-04' \nAND date <= '9999-08-06' \nAND attendance < 20000;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-764.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: pole vault was the event before august 26 , 2005\nInput Table: memorial van damme\n\n\neventrecordathletenationalitydate100 m10.72 ( - 0.3 m / s)shelly - ann fraser - prycejamaica2013-09-06200 m21.64 ( + 0.8 m / s)merlene otteyjamaica1991-09-13400 m48.83sanya richardsunited states2009-09-04800 m1:55.16pamela jelimokenya2008-09-061000 m2:28.98svetlana masterkovarussia1996-08-231500 m3:55.33s\u00fcreyya ayhanturkey2003-09-05mile4:17.75maryam yusuf jamalbahrain2007-09-142000 m5:30.19gelete burkaethiopia2009-09-043000 m8:24.81 +meseret defarethiopia2007-09-14two miles8:58.58meseret defarethiopia2007-09-145000 m14:25.43vivian cheruiyotkenya2008-09-06100 m hurdles12.42 ( - 0.3 m / s)yordanka donkovabulgaria1986-09-05400 m hurdles53.43nezha bidouanemorocco1998-08-283000 m steeplechase9:15.06milcah chemoskenya2013-09-06high jump2.05 manna chicherovarussia2011-09-16pole vault4.93 myelena isinbayevarussia2005-08-26long jump7.25 m ( + 1.7 m / s)heike drechslergermany1991-09-13triple jump15.14 m ( + 0.3 m / s)tatyana lebedevarussia2003-09-05shot put20.57 mnatalya lisovskayasoviet union1987-09-11discus throw69.84 mtsvetanka christovabulgaria1986-09-05javelin throw72.18 m ( old design ) 67.76 m ( current design )fatima whitbread trine hattestadunited kingdom norway1986-09-054100 m relay42.97united statesunited states1988-08-19\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT event FROM table_sql WHERE date < '2005-08-26' ORDER BY date DESC LIMIT 1) = 'pole vault' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1259.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: hong kong has won 4 more bronze medals than thailand for wushu\nInput Table: wushu at the asian games\n\n\nranknationgoldsilverbronzetotal1china (chn)4373532iran (iri)435123malaysia (mas)31594hong kong (hkg)294155thailand (tha)236116japan (jpn)165127philippines (phi)158148macau (mac)154109south korea (kor)1461110chinese taipei (tpe)13111511myanmar (mya)112412vietnam (vie)0971613indonesia (ina)022414laos (lao)015615india (ind)012316pakistan (pak)011217singapore (sin)005518mongolia (mgl)003319kazakhstan (kaz)002220yemen (yem)0011totaltotal606187208\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT bronze FROM table_sql WHERE nation = 'hong kong (hkg)') - \n             (SELECT bronze FROM table_sql WHERE nation = 'thailand (tha)') = 4 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-461.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the lowest attendance figure for a 1983 dolphins' game was 39434\nInput Table: 1983 miami dolphins season\n\n\nweekdateopponentresultattendance11983-09-04buffalo billsw 12 - 07871521983-09-11new england patriotsw 34 - 245934331983-09-19los angeles raidersl 27 - 145779641983-09-25kansas city chiefsw 14 - 65078551983-10-02new orleans saintsl 17 - 76648961983-10-09buffalo billsl 38 - 355994871983-10-16new york jetsw 32 - 145861581983-10-23baltimore coltsw 21 - 73234391983-10-30los angeles ramsw 30 - 1472175101983-11-06san francisco 49ersw 20 - 1757832111983-11-13new england patriotsl 17 - 660771121983-11-20baltimore coltsw 37 - 054482131983-11-28cincinnati bengalsw 38 - 1474506141983-12-04houston oilersw 24 - 1739434151983-12-10atlanta falconsw 31 - 2456725161983-12-16new york jetsw 34 - 1459975\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN MIN(attendance) = 39434 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1472.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: linda fratianne finished in first place , but anett p\u00f6tzsch did not manage to get in the top 3\nInput Table: 1979 world figure skating championships\n\n\nranknamenationsp_+_fspointsplaces1linda fratianneunited states1186.92112anett p\u00f6tzscheast germany3184.36183emi watanabejapan4180.52314dagmar lurzwest germany6179.96335denise biellmannswitzerland2177.28496lisa - marie allenunited states5176.68547claudia kristofics - binderaustria7175.44638susanna drianoitaly9173.46709carola wei\u00dfenbergeast germany11170.548810kristiina wegeliusfinland15169.269811carrie rughunited states10169.349712sanda dubrav\u010di\u0107yugoslavia8166.9611513natalia strelkovasoviet union16164.9413414deborah cottrillunited kingdom20164.813615karin riedigerwest germany17164.514216renata baierovaczechoslovakia13164.014417petra ernertwest germany14163.2414918kira ivanovasoviet union12164.0214719janet morrisseycanada18162.0416220reiko kobayashijapan21161.317021jeanne chapmannorway19161.816622anita siegfriedswitzerland26150.3420723astrid jansen in de walnetherlands25149.1821624franca bianconiitaly22149.0421825bodil olssonsweden23147.0222526corine wyrschswitzerland27146.7623327kim myo silnorth korea24145.4823728belinda coulthardaustralia28145.9223829katie symmondsnew zealand29134.5826130shin hae sooksouth korea30120.4427031gloria masspain31112.28279\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT rank FROM table_sql WHERE name = 'linda fratianne') = 1 \n             AND (SELECT rank FROM table_sql WHERE name = 'anett p\u00f6tzsch') NOT IN (1, 2, 3) \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1592.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: stuart potts wasn't the man of the match in the league / cup\nInput Table: 2008 - 09 guildford flames season\n\n\ndateopponentvenueresultattendancecompetitionman_of_the_match9999-01-01slough jetshomelost 2 - 31308league / cuplukas smital9999-01-02slough jetsawaylost 5 - 6 (ot)320leaguepaul dixon9999-01-08swindon wildcatsawaywon 6 - 3754league / cuplukas smital9999-01-09swindon wildcatshomewon 4 - 21568league / cupneil liddiard9999-01-15sheffield scimitarsawaywon 7 - 4364league / cuprick plant9999-01-16milton keynes lightninghomelost 2 - 41161league / cupdavid savage9999-01-19romford raidershomewon 6 - 21016league / cupalex mettam9999-01-22wightlink raidersawaylost 5 - 4509league / cupstuart potts9999-01-23telford tigershomewon 4 - 21368leaguealex mettam / mark williams9999-01-29romford raidershomewon 7 - 21238leaguemartin bouz9999-01-30bracknell beesawaywon 4 - 0not reportedleague / cupjoe watkins\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE man_of_the_match = 'stuart potts' AND competition = 'league / cup') = 0 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1233.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the highest attendance figure for a game was 42048\nInput Table: 1976 detroit lions season\n\n\nweekdateopponentresultattendance11976-09-12chicago bearsl 10 - 35412521976-09-19atlanta falconsw 24 - 105084031976-09-26minnesota vikingsl 10 - 97729241976-10-03green bay packersl 24 - 145504151976-10-10new england patriotsw 30 - 106017461976-10-17washington redskinsl 20 - 74590871976-10-24seattle seahawksw 41 - 146128081976-10-31green bay packersw 27 - 67499291976-11-07minnesota vikingsl 31 - 2346735101976-11-14new orleans saintsl 17 - 1642048111976-11-21chicago bearsw 14 - 1078042121976-11-25buffalo billsw 27 - 1466875131976-12-05new york giantsl 24 - 1066069141976-12-11los angeles ramsl 20 - 1773470\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN MAX(attendance) = 42048 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-177.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: no other game have total rebounds smaller than 1048\nInput Table: none\n\n\nrankplayeryearsgamesreb_avgtotal_rebounds1jim nowers1972-01-01 - 1976-01-011129.410482kenny sanders1985-01-01 - 1989-01-011079.610263will thomas2004-01-01 - 2008-01-011317.69934george evans1997-01-01 - 2001-01-011168.29535robert dykes1987-01-01 - 1991-01-011227.59256andre gaddy1977-01-01 - 1982-01-01989.39167jai lewis2002-01-01 - 2006-01-011257.28958rob rose1982-01-01 - 1986-01-011137.18059herb estes1973-01-01 - 1976-01-01809.273410jesse young1999-01-01 - 2003-01-011156.2708\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE total_rebounds < 1048;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1708.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: 46 is the value of ends lost when blank ends is 9\nInput Table: 2005 tim hortons brier\n\n\nlocaleskipwlpfpaends_wonends_lostblank_endsstolen_endsshot_pctalbertarandy ferbey92905848437986%manitobarandy dutiaume8377694744101379%nova scotiashawn adams8380604741161383%quebecjean - michel m\u00e3nard747769544081580%british columbiadeane horning6572654745181280%ontariowayne middaugh657562424610782%newfoundland and labradorbrad gushue6576694845131079%saskatchewanpat simmons656661434512980%prince edward islandrod macdonald476785415112579%northern ontariomike jakubo38648641489679%new brunswickwade blanchard385683414517878%\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN ends_lost = 46 AND blank_ends = 9 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1530.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: arizona is the college who has the last draft pick\nInput Table: 1990 buffalo bills season\n\n\nroundpickplayerpositioncollege116james williamsdefensive backfresno state243carwell gardnerrunning backlouisville370glenn parkerguardarizona4101eddie fullerrunning backlsu6155john niespunterarizona7167brent griffithguardminnesota - duluth7171brent collinslinebackercarson - newman7182fred derigginose tacklesyracuse8209marvcus pattonmiddle linebackerucla9239clarkston hineswide receiverduke10266mike lodishdefensive tackleucla11293al edwardswide receivernorthwestern state , la\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN college = 'arizona' AND pick = (SELECT MAX(pick) FROM table_sql) THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1016.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: melbourne was the home team when the teams met at adelaide\nInput Table: 2000 ansett australia cup\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scoregroundcrowddateadelaide17.5 (107)melbourne19.11 (125)football park122399999-01-30geelong10.14 (74)st kilda11.12 (78)waverley park73949999-01-30st kilda9.12 (66)melbourne13.14 (92)waverley park105339999-02-05adelaide19.10 (124)geelong15.12 (102)football park113269999-02-06adelaide14.11 (95)st kilda15.12 (102)football park130869999-02-13geelong17.12 (114)melbourne11.16 (82)waverley park495201-14-9999\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE home_team = 'melbourne' \nAND ground = 'adelaide';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1967.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: ben gordon (17) did the high rebounds in the game in which rodney stuckey (16) did the high points\nInput Table: 2010 - 11 detroit pistons season\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord19999-10-05miamil 89 - 105 (ot)ben gordon (17)ben gordon , charlie villanueva (5)rodney stuckey (5)american airlines arena 196000 - 129999-10-08milwaukeew 115 - 110 (ot)austin daye (21)austin daye (7)will bynum (9)the palace of auburn hills 128211 - 139999-10-11atlantaw 94 - 85 (ot)rodney stuckey (16)greg monroe (7)richard hamilton (7)the palace of auburn hills 105912 - 149999-10-13dallasl 96 - 101 (ot)austin daye (16)ben wallace , jason maxiell (8)rodney stuckey (6)van andel arena 102072 - 259999-10-15minnesotal 88 - 99 (ot)austin daye (18)austin daye (11)will bynum (5)carrier dome 117472 - 369999-10-16charlottel 94 - 97 (ot)rodney stuckey (25)greg monroe (8)rodney stuckey , will bynum (5)colonial life arena 68472 - 479999-10-19washingtonw 98 - 92 (ot)rodney stuckey (34)ben wallace (11)rodney stuckey (7)huntington center 64243 - 4\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT high_rebounds FROM table_sql WHERE high_points = 16) = 17 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-524.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: \u62c5 / \u64d4 is one of three characters that has a metric value measured in kg\nInput Table: chinese units of measurement\n\n\njyutpingcharacterportugueserelative_valuemetric_valueimperial_valuelei4\u5398liz1 / 160037.79931 mg~0.2133 drfan1\u5206condorim1 / 1600377.9936375 mg~0.2133 drcin4\u9322maz1 / 1603.779936375 g~2.1333drloeng2\u5169tael1 / 1637.79936375 g~1.3333ozgan1\u65a4cate1604.78982 g~1.3333lbdaam3\u62c5 / \u64d4pico10060.478982 kg~133.3333lb\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 1 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE metric_value LIKE '%kg' \nAND (character = '\u62c5' OR character = '\u64d4');\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-673.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: on march 10 , vince carter (43) had high points and alvin williams (9) had high assists\nInput Table: 2001 - 02 toronto raptors season\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord609999-03-01portlandl 81 - 91 (ot)vince carter (25)antonio davis , hakeem olajuwon (8)chris childs (7)air canada centre 1980029 - 31619999-03-03philadelphial 84 - 96 (ot)antonio davis (26)antonio davis (9)alvin williams (6)air canada centre 1980029 - 32629999-03-05houstonl 109 - 112 (ot)vince carter (43)vince carter , hakeem olajuwon (7)alvin williams (9)compaq center 1422129 - 33639999-03-07dallasl 103 - 122 (ot)vince carter (19)keon clark , antonio davis (15)alvin williams (7)american airlines center 1994529 - 34640000-03-08miamiw 83 - 74 (ot)antonio davis (23)antonio davis (10)chris childs (6)american airlines arena 1650030 - 34659999-03-10orlandol 79 - 92 (ot)vince carter (16)antonio davis (12)chris childs (7)td waterhouse centre 1617130 - 35669999-03-12new jerseyl 84 - 86 (ot)antonio davis (27)antonio davis , jerome williams (13)vince carter (4)continental airlines arena 1610530 - 36670000-03-17sacramentol 113 - 116 (ot)vince carter (22)hakeem olajuwon (13)chris childs (7)air canada centre 1980030 - 37689999-03-19minnesotal 80 - 112 (ot)morris peterson (19)antonio davis (13)alvin williams (7)target center 1701030 - 38699999-03-22clevelandw 94 - 80 (ot)morris peterson (18)keon clark (10)alvin williams (4)gund arena 1784731 - 38709999-03-24washingtonw 92 - 91 (ot)morris peterson (26)antonio davis (9)alvin williams (9)air canada centre 1980032 - 38719999-03-27miamiw 81 - 80 (ot)morris peterson (21)antonio davis , jerome williams (10)chris childs (6)air canada centre 1980033 - 38729999-03-28atlantaw 85 - 83 (ot)antonio davis , morris peterson (15)antonio davis (9)chris childs (7)philips arena 1203634 - 38739999-03-31philadelphiaw 72 - 70 (ot)antonio davis (16)jerome williams (9)chris childs (9)first union center 2065035 - 38\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT high_points FROM table_sql WHERE date = '9999-03-10') = 43 \n             AND (SELECT high_assists FROM table_sql WHERE date = '9999-03-10') = 9 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1607.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: during the 2007 - 08 minnesota wild season , the difference in the score on february 10 and february 24 was more than 2\nInput Table: 2007 - 08 minnesota wild season\n\n\ndatevisitorscorehomedecisionattendancerecord01-02-9999minnesota4 - 1columbusbackstrom1852930 - 19 - 39999-02-05detroit3 - 2minnesotabackstrom1856830 - 19 - 401-02-07dallas1 - 0minnesotabackstrom1856830 - 20 - 49999-02-09ny islanders3 - 4minnesotabackstrom1856831 - 20 - 401-02-10minnesota2 - 1st louisharding1647732 - 20 - 401-02-12minnesota2 - 4edmontonharding1683932 - 21 - 401-02-14minnesota5 - 4vancouverbackstrom1863033 - 21 - 49999-02-17nashville4 - 5minnesotabackstrom1856834 - 21 - 49999-02-19vancouver3 - 2minnesotabackstrom1856834 - 21 - 59999-02-20minnesota0 - 3chicagoharding1781234 - 22 - 59999-02-24calgary2 - 1minnesotabackstrom1856834 - 23 - 59999-02-26minnesota1 - 4washingtonbackstrom1739134 - 24 - 59999-02-27minnesota3 - 2tampa baybackstrom1721135 - 24 - 59999-02-29minnesota3 - 2floridabackstrom1692736 - 24 - 5\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT ABS(SUBSTR(score, 1, 1) - SUBSTR(score, 5, 1)) FROM table_sql WHERE date = '01-02-10') > 2 \n             AND (SELECT ABS(SUBSTR(score, 1, 1) - SUBSTR(score, 5, 1)) FROM table_sql WHERE date = '9999-02-24') > 2 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1579.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the screening completed on 30 june 2006 was started five months after the screening that was completed on 4 october 2006\nInput Table: none\n\n\nscreening_startedscreening_completedchapter_unfrozenchapter_openedchapter_closed2005-11-252005-12-229999-01-012008-12-199999-01-012006-06-212006-07-209999-01-012008-06-179999-01-012006-02-062006-03-039999-01-012008-06-179999-01-012006-06-122006-07-149999-01-012008-12-199999-01-012006-03-092006-04-289999-01-012010-06-309999-01-012006-06-062006-07-129999-01-012009-06-309999-01-012006-02-162006-03-239999-01-019999-01-019999-01-012006-06-192006-07-189999-01-012007-06-259999-01-012006-02-082006-03-229999-01-019999-01-019999-01-012006-03-272006-05-019999-01-012007-03-299999-01-012006-06-302006-09-299999-01-012007-12-199999-01-012006-09-112006-10-102013-02-122013-06-259999-01-012006-09-072006-10-139999-01-019999-01-019999-01-012005-10-202005-11-149999-01-012006-06-122006-06-122006-04-032006-06-029999-01-012009-12-219999-01-012006-06-082006-07-119999-01-012007-12-199999-01-012006-05-182006-06-309999-01-012007-07-269999-01-019999-01-019999-01-019999-01-019999-01-019999-01-01\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT screening_started FROM table_sql WHERE screening_completed = '2006-06-30') > \n             (SELECT screening_started FROM table_sql WHERE screening_completed = '2006-10-04') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-515.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: when rank is more than 4 and country is japan for notes shows sc / d\nInput Table: rowing at the 2008 summer olympics - men 's lightweight double sculls\n\n\nrankrowerscountrytimenotes1pedro fraga , nuno mendesportugal6:39.07sa / b2eyder batista , yunior perezcuba6:40.15sa / b3kazushige ura , daisaku takedajapan6:43.03sc / d4zsolt hirling , tam\u00e3\u00a1s vargahungary6:50.48sc / d5devender kumar khandwal , manjeet singhindia7:02.06sc / d6jang kang - eun , kim hong - kyunsouth korea7:12.17sc / d\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE rank > 4 \nAND country = 'japan' \nAND notes = 'sc / d';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1996.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: dan fell 's was released in 2003\nInput Table: royal canadian mint numismatic coins (2000s)\n\n\nyearthemeartistmintageissue_price2000steam buggyjohn mardon4436759.952000the bluenosej franklin wrightincluded in steam buggy59.952000the torontojohn mardonincluded in steam buggy59.952001the russell light fourjohn mardon4182859.952001the marco poloj franklin wrightincluded in the russell59.952001the scotiadon curleyincluded in the russell59.952002the gray - dortjohn mardon3594459.952002the william lawrencebonnie rossincluded in the gray - dort59.952002d - 10 locomotivedan fellincluded in the gray - dort59.952003hmcs bras dordon curley3199759.952003cnr fa - 1 diesel electricjohn mardonincluded in hmcs bras dor59.952003bricklin sv - 1brian hughesincluded in hmcs bras dor59.95\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE artist = 'dan fell' \nAND year = 2003;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-330.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: on november 29 , 1997 when the new orleans saints were in the opponents has the least attendance of the season\nInput Table: 1997 oakland raiders season\n\n\nweekdateopponentresulttv_timeattendance11997-08-31tennessee oilersl 24 - 21nbc 10:00 am3017121997-09-08kansas city chiefsl 28 - 27abc 6:00 pm6152331997-09-14atlanta falconsw 36 - 31nbc 10:00 am4792241997-09-21new york jetsl 23 - 22nbc 10:00 am7258651997-09-28st louis ramsw 35 - 17fox 1:15 pm4250661997-10-05san diego chargersl 25 - 10nbc 1:15 pm4364881997-10-19denver broncosw 28 - 25nbc 1:15 pm5700691997-10-26seattle seahawksl 45 - 34nbc 1:15 pm66264101997-11-02carolina panthersl 38 - 14nbc 10:00 am71064111997-11-09new orleans saintsl 13 - 10fox 1:15 pm40091121997-11-16san diego chargersw 38 - 13nbc 1:15 pm65714131997-11-24denver broncosl 31 - 3abc 6:00 pm75307141997-11-30miami dolphinsl 34 - 16nbc 1:15 pm50569151997-12-07kansas city chiefsl 30 - 0nbc 10:00 am76379161997-12-14seattle seahawksl 22 - 21nbc 1:15 pm40124171997-12-21jacksonville jaguarsl 20 - 9nbc 1:15 pm40032\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT attendance FROM table_sql WHERE date = '1997-11-09' AND opponent = 'new orleans saints') = \n             (SELECT MIN(attendance) FROM table_sql) \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-161.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: of all the countries , england contributed the most players of all the countries\nInput Table: utah jazz all - time roster\n\n\nplayernationalitypositionyears_for_jazzschool_/_club_teamrick adelmanunited statesguard1974-01-01loyola (ca)john amaechienglandcenter / forward2001-03-01penn statelouis amundsonunited statesforward2007-01-01unlvj j andersonunited statesforward1982-01-01bradleyshandon andersonunited statesguard / forward9999-01-01georgiarafael ara\u00e3jobrazilcenter2006-01-01byucarlos arroyopuerto ricoguard2002-05-01florida internationalisaac austinunited statescenter1991-01-01arizona stateanthony aventunited statesforward1998-01-01seton hall\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(DISTINCT nationality) FROM table_sql) = \n             (SELECT COUNT(DISTINCT nationality) FROM table_sql WHERE nationality = 'england') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-21.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: volleyball is the sport with the earliest date\nInput Table: iowa corn cy - hawk series\n\n\ndatesitesportwinning_teamseries2007-09-04cedar rapidsm golfiowa stateiowa state 2 - 02007-09-08des moinesvolleyballiowa stateiowa state 4 - 02007-09-09iowa cityw soccertieiowa state 5 - 12007-09-15amesfootballiowa stateiowa state 8 - 12007-11-10peoriam cross countryiowa stateiowa state 10 - 12007-11-10peoriaw cross countryiowaiowa state 10 - 32007-12-05amesw basketballiowa stateiowa state 12 - 32007-12-07amesw swimmingiowa stateiowa state 14 - 32007-12-08amesm basketballiowa stateiowa state 16 - 32007-12-09ameswrestlingiowaiowa state 16 - 52008-02-22amesw gymnasticsiowa stateiowa state 18 - 52008-03-07iowa cityw gymnasticsiowaiowa state 18 - 72008-04-01amessoftballiowaiowa state 18 - 9\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN sport = 'volleyball' AND date = (SELECT MIN(date) FROM table_sql) THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1031.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: babaroga is the developer with a release date of 2010 - 12 - 16 and the title of facebook\nInput Table: list of zune applications\n\n\ntitledevelopercategoryrelease_dateversionalarm clockmicrosoftutilities2010-12-161.1calculatormicrosoftutilities2009-09-011.0calendarmatchboxutilities2011-07-291.0.0.3chord findermicrosoftutilities2010-11-171.0drum machine hddino gamesutilities2010-10-201.0emailmicrosoftutilities2011-04-011.1.0.1facebookmatchboxsocial networking2010-12-161.4fan predictionihwy , incentertainment2011-06-231.0fingerpaintbabarogaentertainment2011-07-291.1levelmicrosoftutilities2011-06-231.0metronomedino gamesutilities2010-09-091.0msn moneymicrosoftutilities2010-07-291.0notesmicrosoftutilities2011-06-231.0pianomicrosoftentertainment2009-11-011.0shuffle by albummicrosoftutilities2011-02-181.1stopwatchmicrosoftutilities2010-08-051.1twittermatchboxsocial networking2010-12-161.6weathermicrosoftutilities2009-09-011.0windows live messengermicrosoftsocial networking2010-11-171.4zune readermicrosoftutilities2011-02-181.2\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE developer = 'babaroga' \nAND release_date = '2010-12-16' \nAND title = 'facebook';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-475.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: gene borek from new zealand is tied for 3rd place\nInput Table: 1973 u.s. open (golf)\n\n\nplaceplayercountryscoreto_par1gary playersouth africa67 + 70 = 137- 52jim colbertunited states70 + 68 = 138- 4t3jack nicklausunited states71 + 69 = 140- 2t3johnny millerunited states71 + 69 = 140- 2t3bob charlesnew zealand71 + 69 = 140- 2t6gene borekunited states77 + 65 = 142et6julius borosunited states73 + 69 = 142et6tom weiskopfunited states73 + 69 = 142et6arnold palmerunited states71 + 71 = 142et6lee trevinounited states70 + 72 = 142e\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE place = 't3' AND player = 'gene borek' AND country = 'new zealand') > 0 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1409.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: ileyton hewitt faced the same opponent , wayne ferreira , in every masters series final\nInput Table: lleyton hewitt\n\n\noutcomeyearchampionshipsurfaceopponentscorerunner - up2000-01-01stuttgarthard (i)wayne ferreira6 - 7 (6 - 8) , 6 - 3 , 7 - 6 (7 - 5) , 6 - 7 (2 - 7) , 2 - 6winner2002-01-01indian wellshardtim henman6 - 1 , 6 - 2runner - up2002-01-01cincinnatihardcarlos moy\u00e15 - 7 , 6 - 7 (5 - 7)runner - up2002-01-01pariscarpet (i)marat safin6 - 7 (4 - 7) , 0 - 6 , 4 - 6winner2003-01-01indian wells (2)hardgustavo kuerten6 - 1 , 6 - 1runner - up2004-01-01cincinnati (2)hardandre agassi3 - 6 , 6 - 3 , 2 - 6runner - up2005-01-01indian wellshardroger federer2 - 6 , 4 - 6 , 4 - 6\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(DISTINCT opponent) = 1 AND MAX(opponent) = 'wayne ferreira' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE championship LIKE '%masters series final%';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-728.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: 6 - 2 , 7 - 5 was the score for the opponent against katerina maleeva in the final\nInput Table: isabel cueto\n\n\ndatetournamentsurfaceopponent_in_the_finalscore1988-07-04b\u00e5stad , swedenclaysandra cecchini7 - 5 , 6 - 11988-08-01athens , greececlaylaura golarsa6 - 0 , 6 - 11989-07-17estoril , portugalclaysandra cecchini7 - 6 (3) , 6 - 21989-07-31sofia , bulgariaclaykaterina maleeva6 - 2 , 7 - 6 (3)1990-07-09palermo , italyclaybarbara paulus6 - 2 , 6 - 3\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT score FROM table_sql WHERE opponent_in_the_final = 'katerina maleeva') = '6 - 2 , 7 - 5' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-813.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: netherlands and romania had games on june 24 and 28 , respectively , in 1998\nInput Table: 1998 in paraguayan football\n\n\ndatevenuescorecompreport1998-02-08estadio defensores del chaco asunci\u00f3n , paraguay4 - 0f4501998-03-14qualcomm stadium san diego , united states2 - 2f4511998-03-18estadio ol\u00edmpico universitario mexico city , mexico1 - 1f4521998-03-28yale bowl new haven , united states1 - 1f4531998-04-22stadio ennio tardini parma , italy3 - 1f4541998-05-17olympic stadium tokyo , japan1 - 1kirin cup4551998-05-21kobe universiade memorial stadium kobe , japan1 - 0kirin cup4561998-06-01philips stadion eindhoven , netherlands5 - 1f4571998-06-03steaua stadium bucharest , romania3 - 2f4581998-06-06king baudouin stadium brussels , belgium1 - 0f4591998-06-12stade de la mosson montpellier , france0 - 0world cupreport1998-06-19stade geoffroy - guichard saint - \u00e9tienne , france0 - 0world cupreport1998-06-24stade de toulouse toulouse , france1 - 3world cupreport1998-06-28stade f\u00e9lix bollaert lens , france0 - 0 ( 1 - 0 aet )world cupreport\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE (date = '1998-06-24' AND (venue LIKE '%netherlands%' OR venue LIKE '%holland%'))) > 0 \n             AND (SELECT COUNT(*) FROM table_sql WHERE (date = '1998-06-28' AND (venue LIKE '%romania%'))) > 0 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1594.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the wightlink raiders were the opponent at the home game\nInput Table: 2008 - 09 guildford flames season\n\n\ndateopponentvenueresultattendancecompetitionman_of_the_match9999-01-01slough jetshomelost 2 - 31308league / cuplukas smital9999-01-02slough jetsawaylost 5 - 6 (ot)320leaguepaul dixon9999-01-08swindon wildcatsawaywon 6 - 3754league / cuplukas smital9999-01-09swindon wildcatshomewon 4 - 21568league / cupneil liddiard9999-01-15sheffield scimitarsawaywon 7 - 4364league / cuprick plant9999-01-16milton keynes lightninghomelost 2 - 41161league / cupdavid savage9999-01-19romford raidershomewon 6 - 21016league / cupalex mettam9999-01-22wightlink raidersawaylost 5 - 4509league / cupstuart potts9999-01-23telford tigershomewon 4 - 21368leaguealex mettam / mark williams9999-01-29romford raidershomewon 7 - 21238leaguemartin bouz9999-01-30bracknell beesawaywon 4 - 0not reportedleague / cupjoe watkins\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE opponent = 'wightlink raiders' \nAND venue = 'home';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1533.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the suite life on deck won the teen pick show : comedy category of the hollywood teen tv awards\nInput Table: the suite life on deck\n\n\nyearawardcategoryrecipientresult2010green globe film awardsoutstanding actors asians in hollywoodbrenda songnominated20102010 kids' choice awardsfavorite tv showthe suite life on decknominated20102010 kids' choice awardsfavorite tv actorcole sprousenominated20102010 kids' choice awardsfavorite tv actordylan sprousewon2010hollywood teen tv awardsteen pick show : comedythe suite life on decknominated2010hollywood teen tv awardsteen pick actress : comedydebby ryannominated2010hollywood teen tv awardsteen pick actor : comedydylan sprousenominated20112011 kids' choice awardsfavorite tv showthe suite life on decknominated20112011 kids' choice awardsfavorite tv actorcole sprousenominated20112011 kids' choice awardsfavorite tv actordylan sprousewon20112011 kids' choice awardsfavorite tv sidekickbrenda songnominated2011casting society of americabest casting children 's seriesdana gergely brandi bricewon\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE year = 2010 \nAND award = 'hollywood teen tv awards' \nAND category = 'teen pick show : comedy' \nAND recipient = 'the suite life on deck' \nAND result = 'won';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1144.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: on 13 july , 1946 , the home team scored 14.8 (92)\nInput Table: 1946 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddategeelong15.7 (97)melbourne21.14 (140)kardinia park115001946-07-13essendon16.24 (120)footscray14.8 (92)windy hill290001946-07-13collingwood15.23 (113)hawthorn11.14 (80)victoria park110001946-07-13carlton12.13 (85)south melbourne11.18 (84)princes park260001946-07-13st kilda10.14 (74)north melbourne12.11 (83)junction oval70001946-07-13richmond14.14 (98)fitzroy10.12 (72)punt road oval190001946-07-13\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE date = '1946-07-13' \nAND home_team_score = '14.8 (92)';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1291.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: south korea got 2 gold awards in total\nInput Table: 1967 world judo championships\n\n\nranknationgoldsilverbronzetotal1japan534122netherlands11133germany01233south korea01235soviet union00226great britain0011\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT gold FROM table_sql WHERE nation = 'south korea') = 2 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-8.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the wildcats played four games in september , two games in october , and two games in november\nInput Table: 1947 kentucky wildcats football team\n\n\ngamedateopponentresultwildcats_pointsopponentsrecord19999-09-20ole missloss7140 - 129999-09-27cincinnatiwin2001 - 139999-10-04xavierwin2072 - 149999-10-119 georgiawin2603 - 1 , 2059999-10-1810 vanderbiltwin1404 - 1 , 1469999-10-25michigan statewin765 - 1 , 1379999-11-0118 alabamaloss0135 - 289999-11-08west virginiawin1566 - 299999-11-15evansvillewin3607 - 2109999-11-22tennesseeloss6137 - 3\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE date LIKE '9999-09%') = 4 \n             AND (SELECT COUNT(*) FROM table_sql WHERE date LIKE '9999-10%') = 2 \n             AND (SELECT COUNT(*) FROM table_sql WHERE date LIKE '9999-11%') = 2 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1085.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there was a tie for the largest point gap two times during the season\nInput Table: 2003 - 04 detroit red wings season\n\n\ndatevisitorscorehomedecisionattendancerecord0002-01-01detroit4 - 1carolinajoseph1705324 - 12 - 4 - 10001-01-03anaheim1 - 3detroitlegace2006625 - 12 - 4 - 10000-01-05nashville0 - 6detroitjoseph2006626 - 12 - 4 - 10001-01-07boston3 - 0detroitjoseph2006626 - 13 - 4 - 10000-01-10detroit1 - 2bostonjoseph1756526 - 13 - 4 - 29999-01-14chicago2 - 4detroitlegace2006627 - 13 - 4 - 20000-01-16phoenix3 - 3detroitjoseph2006627 - 13 - 5 - 29999-01-19detroit1 - 2san josejoseph1736127 - 14 - 5 - 29999-01-21detroit2 - 2anaheimlegace1717427 - 14 - 6 - 29999-01-22detroit5 - 4los angelesjoseph1811828 - 14 - 6 - 29999-01-24detroit2 - 5phoenixjoseph1901928 - 15 - 6 - 29999-01-26detroit2 - 2dallaslegace1853228 - 15 - 7 - 29999-01-29new jersey2 - 5detroitjoseph2006629 - 15 - 7 - 29999-01-31carolina4 - 4detroitlegace2006630 - 15 - 8 - 2\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 2 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM (\n    SELECT \n        MAX(record) - MIN(record) AS point_gap \n    FROM table_sql\n) AS subquery\nWHERE point_gap = (\n    SELECT \n        MAX(record) - MIN(record) AS point_gap \n    FROM table_sql\n);\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1744.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: pentium dual - core t3200 with release date q2 2008 has frequency 2 ghz and sspec number sla4h (m0)\nInput Table: list of intel pentium dual - core microprocessors\n\n\nmodel_numbersspec_numberfrequencyl2_cachefsbmultvoltagetdpsocketrelease_datepart_number_(s)release_price_(_usd_)pentium dual - core t2310slaec (m0)1.47 ghz1 mb533 mt / s111.075 - 1.175v35 wsocket p2007-10-01lf80537 ge0201 m90pentium dual - core t2330sla4k (m0)1.6 ghz1 mb533 mt / s121.075 - 1.175v35 wsocket p2007-10-01lf80537 ge0251 mnoempentium dual - core t2370sla4j (m0)1.73 ghz1 mb533 mt / s131.075 - 1.175v35 wsocket p2007-10-01lf80537 ge0301 moempentium dual - core t2390sla4h (m0)1.87 ghz1 mb533 mt / s141.075 - 1.175v35 wsocket p2008-04-01lf80537 ge0361 moempentium dual - core t2410sla4 g (m0)2 ghz1 mb533 mt / s151.075 - 1.175v35 wsocket p2008-07-01lf80537 ge0411 moempentium dual - core t3200slavg (m0)2 ghz1 mb667 mt / s121.075 - 1.175v35 wsocket p2008-10-01lf80537 gf0411 moem\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT frequency FROM table_sql WHERE model_number = 'pentium dual - core t3200' AND release_date = '2008-04-01') = '2 ghz' \n             AND (SELECT sspec_number FROM table_sql WHERE model_number = 'pentium dual - core t3200' AND release_date = '2008-04-01') = 'sla4h (m0)' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1002.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: daisuke hanazawa was the opponent at gcm - dog 4 in chiba , japan\nInput Table: katsuya inoue\n\n\nresrecordopponentmethodeventroundtimelocationloss19 - 9 - 4naoyuki kotanisubmission (armbar)9999-01-019999-01-019999-01-019999-01-01loss19 - 8 - 4kota okazawako (punch)9999-01-019999-01-019999-01-019999-01-01win19 - 7 - 4katsuhiko nagatadecision (unanimous)9999-01-019999-01-039999-01-019999-01-01loss18 - 7 - 4maximo blancotko (strikes)9999-01-019999-01-029999-01-019999-01-01draw18 - 6 - 4mizuto hirotadraw9999-01-019999-01-039999-01-019999-01-01win17 - 6 - 3koji oishidecision (unanimous)9999-01-019999-01-039999-01-019999-01-01win18 - 6 - 3daisuke hanazawadecision (unanimous)9999-01-019999-01-039999-01-019999-01-01loss16 - 6 - 3nick diaztko (corner stoppage)9999-01-019999-01-019999-01-019999-01-01draw16 - 5 - 3djamal kurbanovdraw9999-01-019999-01-039999-01-019999-01-01win16 - 5 - 2satoru kitaokadecision (split)9999-01-019999-01-039999-01-019999-01-01draw15 - 5 - 2shigetoshi iwasedraw2007-01-019999-01-039999-01-019999-01-01win15 - 5 - 1fabricio nascimentotko (punches)2007-01-019999-01-029999-01-019999-01-01win14 - 5 - 1koji oishiko (punches)9999-01-019999-01-029999-01-019999-01-01x loss13 - 5 - 1yoshiyuki yoshidako (punch)9999-01-019999-01-019999-01-019999-01-01win13 - 4 - 1takefume hanaitko (punches)9999-01-019999-01-029999-01-019999-01-01x loss12 - 4 - 1daizo ishigedecision (unanimous)9999-01-069999-01-039999-01-019999-01-01win12 - 3 - 1kim haeng kitko (punches)9999-03-019999-01-039999-01-019999-01-01draw11 - 3 - 1satoru kitaokadraw9999-01-019999-01-039999-01-019999-01-01win11 - 3daisuke hanazawadecision (majority)9999-01-049999-01-039999-01-019999-01-01x loss10 - 3akira kikuchitko (punches)9999-01-029999-01-019999-01-019999-01-01win10 - 2kenji araiko (punch)9999-01-019999-01-029999-01-019999-01-01win9 - 2heath simstko (punches)9999-01-019999-01-019999-01-019999-01-01win8 - 2kyle nokedecision (split)9999-01-019999-01-039999-01-019999-01-01win7 - 2satoru kitaokadecision (unanimous)9999-01-019999-01-039999-01-019999-01-01win6 - 2takuya wadadecision (unanimous)9999-01-019999-01-039999-01-019999-01-01win5 - 2hikaru satotko (punches)9999-01-019999-01-019999-01-019999-01-01win4 - 2ichiro kanaidecision (majority)9999-01-019999-01-029999-01-019999-01-01x loss3 - 2eiji ishikawadecision (majority)9999-01-019999-01-029999-01-019999-01-01win3 - 1taro minatodecision (unanimous)9999-01-129999-01-029999-01-019999-01-01win2 - 1ichiro kanaidecision (unanimous)9999-01-079999-01-029999-01-019999-01-01win1 - 1motohiro tachiharadecision (unanimous)9999-01-059999-01-029999-01-019999-01-01x loss0 - 1yoshinori onikitko (strikes)9999-01-049999-01-019999-01-099999-01-01\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN opponent = 'daisuke hanazawa' \n        AND event = 'gcm - dog 4' \n        AND location = 'chiba , japan' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-41.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: p\u00e1draig harrington and graeme mcdowell are both fron northern ireland\nInput Table: 2006 u.s. open (golf)\n\n\nplaceplayercountryscoreto_par1steve strickerunited states70 + 69 = 139- 12colin montgomeriescotland69 + 71 = 140et3kenneth ferrieengland71 + 70 = 141+ 1t3geoff ogilvyaustralia71 + 70 = 141+ 1t5jim furykunited states70 + 72 = 142+ 2t5p\u00e1draig harringtonireland70 + 72 = 142+ 2t7jason dufnerunited states72 + 71 = 143+ 3t7graeme mcdowellnorthern ireland71 + 72 = 143+ 3t7phil mickelsonunited states70 + 73 = 143+ 3t7arron oberholserunited states75 + 68 = 143+ 3\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT country FROM table_sql WHERE player = 'p\u00e1draig harrington') = 'northern ireland' \n             AND (SELECT country FROM table_sql WHERE player = 'graeme mcdowell') = 'northern ireland' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1225.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: jelle van damme scored three times as much as each of the other two players in the uefa champions league tournament\nInput Table: 2008 - 09 r.s.c. anderlecht season\n\n\nplayerleaguetitle_playoffsuper_cuptotalmbark boussoufa110011tom de sutter9009guillaume gillet8009marcin wasilewski8008jonathan legear5107nicol\u00e1s frutos6006thomas chatelle4004roland juh\u00e1sz4004stanislav vl\u010dek4004lucas biglia2003dmitri bulykin3003jan pol\u00e1k2003mat\u00edas su\u00e1rez1013jelle van damme3003oleksandr iakovenko2002hern\u00e1n losada1002v\u00edctor bern\u00e1rdez1001bart goor1001nemanja rni\u01070001\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT total FROM table_sql WHERE player = 'jelle van damme' AND league = 'uefa champions league') > \n             (SELECT total FROM table_sql WHERE player = 'mbark boussoufa' AND league = 'uefa champions league') * 3 \n             AND (SELECT total FROM table_sql WHERE player = 'jelle van damme' AND league = 'uefa champions league') > \n             (SELECT total FROM table_sql WHERE player = 'tom de sutter' AND league = 'uefa champions league') * 3 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1235.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the most points scored by the lions in a single game was 58\nInput Table: 1976 detroit lions season\n\n\nweekdateopponentresultattendance11976-09-12chicago bearsl 10 - 35412521976-09-19atlanta falconsw 24 - 105084031976-09-26minnesota vikingsl 10 - 97729241976-10-03green bay packersl 24 - 145504151976-10-10new england patriotsw 30 - 106017461976-10-17washington redskinsl 20 - 74590871976-10-24seattle seahawksw 41 - 146128081976-10-31green bay packersw 27 - 67499291976-11-07minnesota vikingsl 31 - 2346735101976-11-14new orleans saintsl 17 - 1642048111976-11-21chicago bearsw 14 - 1078042121976-11-25buffalo billsw 27 - 1466875131976-12-05new york giantsl 24 - 1066069141976-12-11los angeles ramsl 20 - 1773470\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN MAX(CAST(SUBSTR(result, INSTR(result, ' ') + 1, INSTR(result, ' - ') - INSTR(result, ' ') - 1) AS INTEGER)) = 58 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-533.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: north melbourne home team recorded an home score of 7.8 (50) while south melbourne recorded an home score of 9.14 (68)\nInput Table: 1961 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddatenorth melbourne9.14 (68)st kilda11.16 (82)arden street oval130001961-06-03hawthorn10.13 (73)richmond8.12 (60)glenferrie oval150001961-06-03collingwood18.11 (119)essendon8.10 (58)victoria park282901961-06-03geelong13.13 (91)footscray4.14 (38)kardinia park186831961-06-03south melbourne7.8 (50)fitzroy17.15 (117)lake oval145001961-06-03melbourne15.14 (104)carlton11.13 (79)mcg496781961-06-03\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT home_team_score FROM table_sql WHERE home_team = 'north melbourne') = '7.8 (50)' \n             AND (SELECT home_team_score FROM table_sql WHERE home_team = 'south melbourne') = '9.14 (68)' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1349.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the game against opponent buffalo sabres had an attendance of 10750\nInput Table: 2008 - 09 tampa bay lightning season\n\n\ngamedateopponentscorelocationattendancerecordpoints379999-01-01washington capitals4 - 7verizon center1822710 - 17 - 1030380001-01-03carolina hurricanes2 - 3st pete times forum1587310 - 18 - 1030390001-01-04atlanta thrashers4 - 1philips arena1075011 - 18 - 1032400001-01-08phoenix coyotes1 - 4jobingcom arena1373611 - 19 - 1032410000-01-09anaheim ducks4 - 3honda center1717412 - 19 - 1034420001-01-12los angeles kings3 - 1staples center1651113 - 19 - 1036430001-01-13san jose sharks1 - 7hp pavilion at san jose1749613 - 20 - 1036440000-01-15philadelphia flyers4 - 1st pete times forum1560414 - 20 - 1038450000-01-17florida panthers3 - 4st pete times forum1721714 - 21 - 1038469999-01-19dallas stars4 - 2st pete times forum1399115 - 21 - 1040479999-01-21buffalo sabres5 - 3st pete times forum1561116 - 21 - 1042489999-01-27montreal canadiens5 - 3st pete times forum1591217 - 21 - 1044499999-01-29carolina hurricanes2 - 3rbc center1640517 - 22 - 1044500000-01-30philadelphia flyers1 - 6st pete times forum1812017 - 23 - 1044\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN attendance = 10750 AND opponent = 'buffalo sabres' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE game = 47;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-497.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: milepost 12.8 is at weymouth\nInput Table: massachusetts route 139\n\n\ncountylocationstreet_namesmilepostroads_intersectednotesnorfolkstoughtonpleasant street turnpike street lindelof avenue3.0route 24route 24 exit 20norfolkweymouthanne street(no major junctions)(no major junctions)(no major junctions)plymouthrocklandnorth avenue plain street market street12.2route 123western terminus of route 123 / 139 concurrencyplymouthrocklandnorth avenue plain street market street12.8route 123eastern terminus of route 123 / 139 concurrencyplymouthhanoverhanover street rockland street columbia road17.9route 53northern terminus of route 53 / 139 concurrency\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE milepost = 12.8 \nAND location = 'weymouth';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-934.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: st louis was the visiting team in the game against new jersey when the record was 11 - 33 - 12\nInput Table: none\n\n\ndatevisitorscorehomerecord9999-02-03ny islanders7 - 2new jersey11 - 32 - 119999-02-05new jersey4 - 5washington11 - 33 - 119999-02-06vancouver4 - 4new jersey11 - 33 - 129999-02-09new jersey4 - 5chicago11 - 34 - 1201-02-12new jersey1 - 5st louis11 - 35 - 1201-02-15minnesota3 - 2new jersey11 - 36 - 129999-02-20new jersey0 - 3philadelphia11 - 37 - 1201-02-21buffalo4 - 4new jersey11 - 37 - 139999-02-24detroit1 - 4new jersey12 - 37 - 139999-02-26new jersey4 - 5pittsburgh12 - 38 - 139999-02-27new jersey2 - 6buffalo12 - 39 - 13\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT visitor FROM table_sql WHERE record = '11 - 33 - 12' AND home = 'new jersey') = 'st louis' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1659.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: game 4.0 , series 1 - 4 was on april 25th\nInput Table: 2008 - 09 san antonio spurs season\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendanceseries19999-04-18dallasl 97 - 105 (ot)tim duncan (27)tim duncan (9)tony parker (8)at&t center 187970 - 129999-04-20dallasw 105 - 84 (ot)tony parker (38)tim duncan (11)tony parker (8)at&t center 187971 - 139999-04-23dallasl 67 - 88 (ot)tony parker (12)kurt thomas (10)tony parker (3)american airlines center 204911 - 249999-04-25dallasl 90 - 99 (ot)tony parker (43)tim duncan (10)tim duncan (7)american airlines center 208291 - 359999-04-28dallasl 93 - 106 (ot)tim duncan (31)tim duncan (12)tony parker (6)at&t center 208291 - 4\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE game = 4.0 \nAND series = '1 - 4' \nAND date = '9999-04-25';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-636.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the call sign for astral media 's radio station is cjui - fm\nInput Table: media in kelowna\n\n\nfrequencycall_signbrandingformatowner1150 amckfram 1150news / talkastral media00 88.9 fmcbtk - fmcbc radio onepublic news / talkcanadian broadcasting corporation00 89.7 fmcbu - fm - 3cbc radio 2public musiccanadian broadcasting corporation00 90.5 fmcbuf - fm - 2premi\u00e8re cha\u00eenepublic news / talkcanadian broadcasting corporation00 96.3 fmckko - fmk96.3classic rocksun country cablevision00 99.9 fmchsu - fm99.9 sun fmcontemporary hits radiobell media0 101.5 fmcilk - fm101.5 ez rockadult contemporarybell media0 103.1 fmckqq - fmq103hot adult contemporaryjim pattison group0 103.9 fmcjui - fm103.9 the juiceadult hitsvista broadcast group0 104.7 fmcklz - fmpower 104active rockjim pattison group\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE owner = 'astral media' \nAND branding = 'cjui - fm';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-2003.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: for centru county , the percentage of total exports is 13.8% and the percentage of total imports is 11.2%\nInput Table: list of romanian counties by foreign trade\n\n\ncountyexports_(us_mil)percent_of_total_exportsimports_(us_mil)percent_of_total_importsbucharest - ilfov 8001.219.2 % 26557.839.8 %sud - muntenia 6300 , 715.1 % 6785.510.2 %vest 6270.215.0 % 6597.69.9 %sud - est 576213.8 % 7501.911.2 %centru 533812.8 % 7.879.411.8 %nord - vest 4726.611.3 % 6999.110.5 %sud - vest oltenia 3226.27.7 % 2007.83.0 %\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN percent_of_total_exports = '13.8 %' AND percent_of_total_imports = '11.2 %' THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE county = 'centru';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1593.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the away match had a 2 - 3 result\nInput Table: 2008 - 09 guildford flames season\n\n\ndateopponentvenueresultattendancecompetitionman_of_the_match9999-01-01slough jetshomelost 2 - 31308league / cuplukas smital9999-01-02slough jetsawaylost 5 - 6 (ot)320leaguepaul dixon9999-01-08swindon wildcatsawaywon 6 - 3754league / cuplukas smital9999-01-09swindon wildcatshomewon 4 - 21568league / cupneil liddiard9999-01-15sheffield scimitarsawaywon 7 - 4364league / cuprick plant9999-01-16milton keynes lightninghomelost 2 - 41161league / cupdavid savage9999-01-19romford raidershomewon 6 - 21016league / cupalex mettam9999-01-22wightlink raidersawaylost 5 - 4509league / cupstuart potts9999-01-23telford tigershomewon 4 - 21368leaguealex mettam / mark williams9999-01-29romford raidershomewon 7 - 21238leaguemartin bouz9999-01-30bracknell beesawaywon 4 - 0not reportedleague / cupjoe watkins\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN result = 'lost 2 - 3' AND venue = 'away' THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-947.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there were 96 goals achieved when chievo was the club which debuted after 1999\nInput Table: football records in italy\n\n\nrankall_-_time_ranknamedebut_yearcurrent_clubgoalsapps12francesco totti1992-01-01roma230543211antonio di natale2002-01-01udinese180368316alberto gilardino1999-01-01genoa164425453luca toni2000-01-01verona114258577antonio cassano1999-01-01parma99334681giampaolo pazzini2004-01-01milan95275681mirko vu\u010dini\u01072000-01-01juventus95298897diego milito2008-01-01inter86145897sergio pellissier2002-01-01chievo8633310n / aamauri2000-01-01parma76292\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT goals FROM table_sql WHERE debut_year > '1999-01-01' AND current_club = 'chievo') = 96 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-550.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the opponent is at cleveland browns on week 14\nInput Table: 2001 cincinnati bengals season\n\n\nweekdateopponentresultattendance12001-09-09new england patriotsw 23 - 175152122001-09-23baltimore ravensw 21 - 105112132001-09-30san diego chargersl 28 - 145604842001-10-07pittsburgh steelersl 16 - 76233552001-10-14cleveland brownsw 24 - 146421762001-10-21chicago bearsl 24 - 06340872001-10-28detroit lionsw 31 - 276934392001-11-11jacksonville jaguarsl 30 - 1357161102001-11-18tennessee titansl 20 - 763865112001-11-25cleveland brownsl 18 - 072918122001-12-02tampa bay buccaneersl 16 - 1352135132001-12-09jacksonville jaguarsl 14 - 1044920142001-12-16new york jetsl 15 - 1477745152001-12-23baltimore ravensl 16 - 068987162001-12-30pittsburgh steelersw 26 - 2363751172002-01-06tennessee titansw 23 - 2168798\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN opponent = 'cleveland browns' AND week = 14 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1828.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: on 21 august 1943 , north melbourne was the away team at glenferrie oval\nInput Table: 1943 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddatehawthorn13.10 (88)south melbourne7.14 (56)glenferrie oval150001943-08-21collingwood16.17 (113)fitzroy9.9 (63)victoria park65001943-08-21carlton15.23 (113)north melbourne7.5 (47)princes park80001943-08-21richmond15.19 (109)melbourne12.13 (85)punt road oval90001943-08-21footscray9.10 (64)essendon6.15 (51)western oval60001943-08-21\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE date = '1943-08-21' \nAND away_team = 'north melbourne' \nAND venue = 'glenferrie oval';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1361.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: miguel zapata had exactly 24 goals under his name\nInput Table: 2008 - 09 segunda divisi\u00f3n b\n\n\ngoalkeepergoalsmatchesaverageteammiguel zapata17280.61atl\u00e9tico ciudadrub\u00e9n mart\u00ednez24320.75cartagenaorlando quintana29340.85lorca deportiva\u00e1lvaro campos24280.86real murcia bmat\u00edas garavano26300.87m\u00e9rida\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT goals FROM table_sql WHERE goalkeeper = 'miguel zapata') = 24 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1872.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the solheim cup was hosted outside the us on seven occasions from 1990 - 2013\nInput Table: solheim cup\n\n\nyearvenuewinning_teamscoreusa_captaineurope_captain2013-01-01colorado golf club , colorado , usaeurope18 - 10meg mallonliselotte neumann2011-01-01killeen castle golf resort , irelandeurope15 - 13rosie jonesalison nicholas2009-01-01rich harvest farms , illinois , usaunited states16 - 12beth danielalison nicholas2007-01-01halmstad gk , swedenunited states16 - 12betsy kinghelen alfredsson2005-01-01crooked stick golf club , indiana , usaunited states15\u00bd - 12\u00bdnancy lopezcatrin nilsmark2003-01-01barseb\u00e4ck golf & country club , swedeneurope17\u00bd - 10\u00bdpatty sheehancatrin nilsmark2002-01-01interlachen country club , minnesota , usaunited states15\u00bd - 12\u00bdpatty sheehandale reid2000-01-01loch lomond golf club , scotlandeurope14\u00bd - 11\u00bdpat bradleydale reid1998-01-01muirfield village , ohio , usaunited states16 - 12judy rankinpia nilsson1996-01-01st pierre golf & country club , walesunited states17 - 11judy rankinmickey walker1994-01-01the greenbrier , west virginia , usaunited states13 - 7joanne carnermickey walker1992-01-01dalmahoy country club , scotlandeurope11\u00bd - 6\u00bdkathy whitworthmickey walker1990-01-01lake nona golf & country club , florida , usaunited states11\u00bd - 4\u00bdkathy whitworthmickey walker\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 7 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE year BETWEEN 1990 AND 2013 \nAND venue NOT LIKE '%usa%';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-900.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the bowler with 13 wickets appeared in less matches than the bowler with 11 wickets\nInput Table: 1948 ashes series\n\n\nplayerteammatcheswicketsaveragebest_bowlingray lindwallaustralia52719.626 / 20bill johnstonaustralia52723.335 / 36alec bedserengland51838.224 / 81keith milleraustralia51323.154 / 125ernie toshackaustralia41133.095 / 40norman yardleyengland5922.662 / 32jim lakerengland3952.444 / 138\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT matches FROM table_sql WHERE wickets = 13) < \n             (SELECT matches FROM table_sql WHERE wickets = 11) \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1784.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there are 3 624 000 live births per year in the period from 1975 to 1980\nInput Table: none\n\n\nperiodlive_births_per_yeardeaths_per_yearnatural_change_per_yearcbrcdrnctfrimrlife_expectancy_totallife_expectancy_maleslife_expectancy_females1950-01-01 - 1955-01-012 572 000900 0001 672 00044.115.528.66.1513550.949.252.61955-01-01 - 1960-01-012 918 000947 0001 971 00043.214.029.16.1512253.351.555.21960-01-01 - 1965-01-013 303 000986 0002 317 00042.212.629.66.1510955.753.857.69999-01-01 - 1970-01-013 330 000998 0002 332 00037.011.125.95.3810057.655.759.61970-01-01 - 1975-01-013 441 0001 014 0002 427 00033.79.923.84.729159.557.361.81975-01-01 - 1980-01-013 741 0001 043 0002 698 00032.59.023.54.317961.559.263.91980-01-01 - 1985-01-013 974 0001 064 0002 910 00030.88.222.63.86363.460.466.81985-01-01 - 1990-01-013 757 0001 055 0002 702 00026.37.418.93.15265.361.969.11990-01-01 - 1995-01-013 519 0001 058 0002 461 00022.66.815.82.64367.363.671.21995-01-01 - 2000-01-013 624 0001 086 0002 538 00021.56.515.12.453469.365.573.32000-01-01 - 2005-01-013 572 0001 147 0002 425 00019.86.413.42.252770.967.274.8\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN live_births_per_year = 3624000 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE period = '1975-01-01 - 1980-01-01';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-318.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: darryl dawkins played for the jazz seven years before paul dawkins\nInput Table: utah jazz all - time roster\n\n\nplayernationalitypositionyears_for_jazzschool_/_club_teamadrian dantleyunited statesguard - forward1979-01-01notre damebrad davisunited statesguard1979-01-01marylanddarryl dawkinsunited statescenter1987-01-01maynard evans hspaul dawkinsunited statesguard1979-01-01northern illinoisgreg deaneunited statesguard1979-01-01utahjames donaldsonunited statescenter1993-01-01, 1994-01-01, 1995-01-01washington statejohn drewunited statesguard - forward1982-01-01gardner - webbjohn durenunited statesguard1980-01-01georgetown\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT strftime('%Y', years_for_jazz) FROM table_sql WHERE player = 'darryl dawkins') - \n             (SELECT strftime('%Y', years_for_jazz) FROM table_sql WHERE player = 'paul dawkins') = 7 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1290.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there are no countries that have 4 bronze medals\nInput Table: 1967 world judo championships\n\n\nranknationgoldsilverbronzetotal1japan534122netherlands11133germany01233south korea01235soviet union00226great britain0011\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE bronze = 4;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1478.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the date for score of w 112 - 91 is after march 19\nInput Table: 1991 - 92 seattle supersonics season\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord589999-03-01cleveland cavaliersw 113 - 107e johnson , r pierce (22)b benjamin , m cage (14)r pierce (6)seattle center coliseum 1364732 - 26599999-03-03denver nuggetsw 111 - 92s kemp (21)s kemp (13)g payton (9)seattle center coliseum 986533 - 26609999-03-05phoenix sunsl 105 - 118r pierce (23)s kemp (19)g payton (12)arizona veterans memorial coliseum 1449633 - 27619999-03-07new jersey netsw 109 - 98r pierce (27)m cage (13)n mcmillan (7)seattle center coliseum 1341934 - 27620000-03-08portland trail blazersl 97 - 109r pierce (28)r pierce (10)g payton (7)memorial coliseum 1288834 - 28639999-03-10detroit pistonsl 92 - 98g payton (19)s kemp (9)n mcmillan (5)seattle center coliseum 1309834 - 29649999-03-11los angeles clippersw 104 - 96r pierce (19)b benjamin , m cage (6)g payton (9)los angeles memorial sports arena 1091235 - 296501-03-15dallas mavericksw 109 - 100r pierce (23)s kemp (15)g payton (8)seattle center coliseum 1216336 - 29660000-03-17golden state warriorsl 107 - 119r pierce (24)s kemp (15)r pierce (5)seattle center coliseum 1316336 - 30679999-03-19houston rocketsw 112 - 91r pierce (22)m cage , s kemp (14)g payton (11)the summit 1512237 - 30689999-03-21san antonio spursl 96 - 101e johnson (23)s kemp (13)d barros , m cage , n mcmillan (4)hemisfair arena 1605737 - 31699999-03-22dallas mavericksw 113 - 105e johnson (31)s kemp (17)n mcmillan (8)reunion arena 1434538 - 31709999-03-24houston rocketsw 128 - 106d mckey (23)m cage , s kemp (11)n mcmillan , g payton (7)seattle center coliseum 1137739 - 31719999-03-27milwaukee bucksw 96 - 95e johnson (21)n mcmillan (7)n mcmillan (6)seattle center coliseum 1145040 - 31729999-03-28new york knicksl 87 - 92s kemp (27)s kemp (12)n mcmillan (6)seattle center coliseum 1481240 - 32\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE score = 'w 112 - 91' \nAND date > '9999-03-19';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-5.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the wildcats kept the opposing team scoreless in ten games\nInput Table: 1947 kentucky wildcats football team\n\n\ngamedateopponentresultwildcats_pointsopponentsrecord19999-09-20ole missloss7140 - 129999-09-27cincinnatiwin2001 - 139999-10-04xavierwin2072 - 149999-10-119 georgiawin2603 - 1 , 2059999-10-1810 vanderbiltwin1404 - 1 , 1469999-10-25michigan statewin765 - 1 , 1379999-11-0118 alabamaloss0135 - 289999-11-08west virginiawin1566 - 299999-11-15evansvillewin3607 - 2109999-11-22tennesseeloss6137 - 3\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE opponents > 0;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-957.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the record was 5 - 3 for the detroit red wings vs chicago black hawks on april 14\nInput Table: 1965 - 66 chicago black hawks season\n\n\ndatevisitorscorehomerecord'9999-04-07'detroit red wings1 - 2chicago black hawks1 - 0'9999-04-10'detroit red wings7 - 0chicago black hawks1 - 1'9999-04-12'chicago black hawks2 - 1detroit red wings2 - 19999-04-14chicago black hawks1 - 5detroit red wings2 - 20000-04-17detroit red wings5 - 3chicago black hawks2 - 39999-04-19chicago black hawks2 - 3detroit red wings2 - 4\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT record FROM table_sql WHERE date = '9999-04-14' AND visitor = 'detroit red wings' AND home = 'chicago black hawks') = '5 - 3' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-150.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the final game score was 8 - 3 in two different games of the 2007 season\nInput Table: 2006 texas rangers season\n\n\ndateopponentscorelossattendancerecord9999-09-01indians7 - 2padilla (13 - 9)2377669 - 679999-09-02indians6 - 5volquez (1 - 4)4022269 - 689999-09-03indians5 - 2byrd1966770 - 689999-09-04athletics8 - 1zito2394971 - 689999-09-05athletics5 - 4saarloos2722572 - 689999-09-06athletics9 - 6rupe (0 - 1)1783872 - 699999-09-08mariners7 - 2millwood (14 - 10)2864672 - 709999-09-09mariners3 - 2rheinecker (4 - 6)3345472 - 719999-09-10mariners4 - 2huber3432173 - 719999-09-12tigers3 - 2mahay (1 - 3)2419673 - 729999-09-13tigers11 - 3verlander2467274 - 729999-09-14angels2 - 1volquez (1 - 5)2148874 - 739999-09-15angels2 - 1francisco (0 - 1)3078874 - 749999-09-16angels12 - 6lackey4019675 - 749999-09-17angels8 - 1santana2430376 - 749999-09-18mariners8 - 1hern\u00e1ndez1821477 - 749999-09-19mariners9 - 7wilson (2 - 3)1855177 - 759999-09-20mariners6 - 3tejeda (4 - 4)2600677 - 769999-09-22indians12 - 4byrd2628478 - 769999-09-23indians6 - 3padilla (14 - 10)3835178 - 779999-09-24indians11 - 6millwood (16 - 11)3661778 - 789999-09-25angels8 - 3volquez (1 - 6)3978178 - 799999-09-26angels5 - 2escobar3733979 - 799999-09-27angels6 - 5wilson (2 - 4)3803279 - 809999-09-29mariners6 - 5fruto3076680 - 809999-09-30mariners3 - 1millwood (16 - 12)2331080 - 819999-10-01mariners3 - 2tejeda (5 - 5)2836180 - 82\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 2 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE score = '8 - 3';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1219.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: of the four players who played in the belgian cup , jonathan legear scored more goals than the other players combined\nInput Table: 2008 - 09 r.s.c. anderlecht season\n\n\nplayerleaguetitle_playoffsuper_cuptotalmbark boussoufa110011tom de sutter9009guillaume gillet8009marcin wasilewski8008jonathan legear5107nicol\u00e1s frutos6006thomas chatelle4004roland juh\u00e1sz4004stanislav vl\u010dek4004lucas biglia2003dmitri bulykin3003jan pol\u00e1k2003mat\u00edas su\u00e1rez1013jelle van damme3003oleksandr iakovenko2002hern\u00e1n losada1002v\u00edctor bern\u00e1rdez1001bart goor1001nemanja rni\u01070001\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT SUM(title_playoff) FROM table_sql WHERE league = 'belgian cup' AND player != 'jonathan legear') <\n             (SELECT title_playoff FROM table_sql WHERE league = 'belgian cup' AND player = 'jonathan legear') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1129.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the two players with the highest league apps are malcolm brown and peter hart\nInput Table: 1979 - 80 huddersfield town f.c. season\n\n\nnamepositionleague_appsleague_goalsfa_cup_appsfa_cup_goalsleague_cup_appsleague_cup_goalstotal_appstotal_goalsjim branagandf00000 (1)00 (1)0malcolm browndf4622041523david cowlingmf39 (1)10104044 (1)10peter fletcherfw30 (8)17203135 (8)18keith hanveydf3320040392peter hartmf4641140515ian holmesmf6 (4)3004110 (4)4steve kindonfw22 (1)14000022 (1)14mick laverickmf4542040514bernard purdiedf18 (4)0200020 (4)0andy rankingk2400000240ian robinsfw452520425127fred robinsondf3012040361tommy smithfw00001010brian stantonmf4192000439alan starlinggk2202040280dave suttondf4662041527chris toppingdf1302000150\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MAX(league_apps) FROM table_sql) = (SELECT league_apps FROM table_sql WHERE name = 'malcolm brown') \n             OR (SELECT MAX(league_apps) FROM table_sql) = (SELECT league_apps FROM table_sql WHERE name = 'peter hart') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-450.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the second highest scoring team for the games that happened on the 18th of june was by carlton\nInput Table: 1938 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddategeelong11.23 (89)hawthorn6.13 (49)corio oval70001938-06-18fitzroy16.12 (108)south melbourne8.8 (56)brunswick street oval120001938-06-18st kilda14.12 (96)melbourne16.16 (112)junction oval140001938-06-18richmond15.14 (104)essendon15.9 (99)punt road oval200001938-06-18footscray13.9 (87)collingwood10.5 (65)western oval180001938-06-18north melbourne11.5 (71)carlton16.25 (121)arden street oval130001938-06-18\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MAX(home_team_score) FROM table_sql WHERE date = '1938-06-18' AND home_team != 'carlton') < \n             (SELECT home_team_score FROM table_sql WHERE date = '1938-06-18' AND away_team = 'carlton') \n             OR \n             (SELECT MAX(away_team_score) FROM table_sql WHERE date = '1938-06-18' AND away_team != 'carlton') < \n             (SELECT away_team_score FROM table_sql WHERE date = '1938-06-18' AND home_team = 'carlton') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1748.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: pentium dual - core t2410 with sspec number sla4j (m0) has socket p and release date q2 2008\nInput Table: list of intel pentium dual - core microprocessors\n\n\nmodel_numbersspec_numberfrequencyl2_cachefsbmultvoltagetdpsocketrelease_datepart_number_(s)release_price_(_usd_)pentium dual - core t2310slaec (m0)1.47 ghz1 mb533 mt / s111.075 - 1.175v35 wsocket p2007-10-01lf80537 ge0201 m90pentium dual - core t2330sla4k (m0)1.6 ghz1 mb533 mt / s121.075 - 1.175v35 wsocket p2007-10-01lf80537 ge0251 mnoempentium dual - core t2370sla4j (m0)1.73 ghz1 mb533 mt / s131.075 - 1.175v35 wsocket p2007-10-01lf80537 ge0301 moempentium dual - core t2390sla4h (m0)1.87 ghz1 mb533 mt / s141.075 - 1.175v35 wsocket p2008-04-01lf80537 ge0361 moempentium dual - core t2410sla4 g (m0)2 ghz1 mb533 mt / s151.075 - 1.175v35 wsocket p2008-07-01lf80537 ge0411 moempentium dual - core t3200slavg (m0)2 ghz1 mb667 mt / s121.075 - 1.175v35 wsocket p2008-10-01lf80537 gf0411 moem\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE model_number = 'pentium dual - core t2410' \nAND sspec_number = 'sla4j (m0)' \nAND socket = 'socket p' \nAND release_date LIKE '2008-Q2%';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1732.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: date for the opponent the chicago bears was december 5 , 1983\nInput Table: 1983 detroit lions season\n\n\nweekdateopponentresultattendance11983-09-04tampa bay buccaneersw 11 - 06215421983-09-11cleveland brownsl 31 - 266009531983-09-18atlanta falconsl 30 - 145462241983-09-25minnesota vikingsl 20 - 175825451983-10-02los angeles ramsl 21 - 104940361983-10-09green bay packersw 38 - 146773871983-10-16chicago bearsw 31 - 176670981983-10-23washington redskinsl 38 - 174318991983-10-30chicago bearsw 38 - 1758764101983-11-07new york giantsw 15 - 968985111983-11-13houston oilersl 27 - 1740660121983-11-20green bay packersw 23 - 20 ot50050131983-11-24pittsburgh steelersw 45 - 377724141983-12-05minnesota vikingsw 13 - 279169151983-12-11cincinnati bengalsl 17 - 945728161983-12-18tampa bay buccaneersw 23 - 2078392\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT date FROM table_sql WHERE opponent = 'chicago bears') = '1983-12-05' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-374.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the black knights' record was 2 - 2 when they scored 54 points against lehigh on september 20th\nInput Table: 1975 army cadets football team\n\n\ngamedateopponentresultblack_knights_pointsopponentsrecord19999-09-13holy crosswin4471 - 029999-09-20lehighwin54322 - 039999-09-27villanovaloss0102 - 149999-10-04stanfordloss14672 - 259999-10-11dukeloss10212 - 369999-10-18pittsburghloss20522 - 479999-10-25penn stateloss0312 - 589999-11-01air forceloss3332 - 699999-11-08boston collegeloss0312 - 7109999-11-15vanderbiltloss14232 - 8\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT record FROM table_sql WHERE game = 2) = '2 - 2' \n             AND (SELECT black_knights_points FROM table_sql WHERE game = 2) = 54 \n             AND (SELECT opponent FROM table_sql WHERE game = 2) = 'lehigh' \n             AND (SELECT date FROM table_sql WHERE game = 2) = '9999-09-20' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-531.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: during the 1961 vfl season , lake oval venue recorded the highest crowd participation\nInput Table: 1961 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddatenorth melbourne9.14 (68)st kilda11.16 (82)arden street oval130001961-06-03hawthorn10.13 (73)richmond8.12 (60)glenferrie oval150001961-06-03collingwood18.11 (119)essendon8.10 (58)victoria park282901961-06-03geelong13.13 (91)footscray4.14 (38)kardinia park186831961-06-03south melbourne7.8 (50)fitzroy17.15 (117)lake oval145001961-06-03melbourne15.14 (104)carlton11.13 (79)mcg496781961-06-03\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MAX(crowd) FROM table_sql) = crowd \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END\nFROM table_sql\nWHERE venue = 'lake oval';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-790.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: brian watts of sweden with to par + 2 has scored 68 + 69 + 73 = 210 and is at place t2\nInput Table: 1998 open championship\n\n\nplaceplayercountryscoreto_par1brian wattsunited states68 + 69 + 73 = 210et2jim furykunited states70 + 70 + 72 = 212+ 2t2mark o'mearaunited states72 + 68 + 72 = 212+ 2t2jesper parneviksweden68 + 72 + 72 = 212+ 25justin rose (a)england72 + 66 + 75 = 213+ 3t6thomas bj\u00e3rndenmark68 + 71 + 76 = 215+ 5t6brad faxonunited states67 + 74 + 74 = 215+ 5t6john hustonunited states65 + 77 + 73 = 215+ 5t6tiger woodsunited states65 + 73 + 77 = 215+ 5t10david duvalunited states70 + 71 + 75 = 216+ 6t10costantino roccaitaly72 + 74 + 70 = 216+ 6t10raymond russellscotland68 + 73 + 75 = 216+ 6t10katsuyoshi tomorijapan75 + 71 + 70 = 216+ 6\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT place FROM table_sql WHERE player = 'brian watts' AND country = 'sweden' AND to_par = '+ 2' AND score = '68 + 69 + 73 = 210') = 't2' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-192.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: no team scored more than 10 against cambridge university\nInput Table: 1978 new zealand rugby union tour of britain and ireland\n\n\nopposing_teamagainstdatevenuestatuscambridge university121978-10-18grange road , cambridgetour matchcardiff71978-10-21cardiff arms park , cardifftour matchwest wales xv71978-10-25st helen 's , swanseatour matchlondon counties121978-10-28twickenham , londontour matchmunster121978-10-31thomond park , limericktour matchireland61978-11-04lansdowne road , dublintest matchulster71978-11-07ravenhill , belfasttour matchwales121978-11-01cardiff arms park , cardifftest matchsouth and south - west counties01978-11-15memorial ground , bristoltour matchmidland counties151978-11-18welford road , leicestertour matchcombined services61978-11-21aldershot military stadium , aldershottour matchengland61978-11-25twickenham , londontest matchmonmouthshire91978-11-29rodney parade , newporttour matchnorth of england61978-12-02birkenhead park , birkenheadtour matchnorth and midland of scotland31978-12-05linksfield stadium , aberdeentour matchscotland91978-12-09murrayfield , edinburghtest matchbridgend61978-12-13brewery field , bridgendtour matchbarbarians161978-12-16cardiff arms park , cardifftour match\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MAX(against) FROM table_sql WHERE opposing_team = 'cambridge university') > 10 \n        THEN 'FALSE' \n        ELSE 'TRUE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-993.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there were three episodes that aired in february , while only two aired in january\nInput Table: list of republic of doyle episodes\n\n\nUnnamed:_0titledirected_bywritten_byviewersoriginal_airdateprod_code1fathers and sonsmike clattenburgallan hawco , perry chafe and malcolm macrury9690002010-01-061012the return of the grievous angelsteve dimarcoallan hawco and avrum jacobson7150002010-01-131023duchess of georgemike clattenburgallan hawco , perry chafe and malcolm macrury6850002010-01-201035hit and rumsteve dimarcomatt maclennan5940002010-02-031056the one who got awaylarry mcleanjesse mckeown10120002010-02-101067the woman who knew too littlerobert liebermanjeremy boxen10530002010-03-031078the tell - tale safejerry ciccorittijohn callaghan and steve cochrane9860002010-03-101089he sleeps with the chipsphil earnshawperry chafe9080002010-03-1710910the pen is mightier than the doylerobert liebermansteve cochrane and avrum jacobson8970002010-03-2411011a horse dividedsteve scainijesse mckeown9020002010-03-31111\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE original_airdate LIKE '2010-02%') = 3 \n             AND (SELECT COUNT(*) FROM table_sql WHERE original_airdate LIKE '2010-01%') = 2 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1729.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: kenny rogers is the losing pitcher when attendance is 38109\nInput Table: 2005 texas rangers season\n\n\ndatewinning_teamscorewinning_pitcherlosing_pitcherattendancelocation9999-05-20texas7 - 3kenny rogersbrandon backe38109arlington9999-05-21texas18 - 3chris youngezequiel astacio35781arlington9999-05-22texas2 - 0chan ho parkroy oswalt40583arlington9999-06-24houston5 - 2roy oswaltricardo rodr\u00edguez36199houston9999-06-25texas6 - 5chris youngbrandon backe41868houston\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE losing_pitcher = 'kenny rogers' \nAND attendance = 38109;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-851.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: japan is the only football club located in oceania\nInput Table: list of superleague formula football clubs\n\n\nnofootball_clubcontinentassociated_football_clubseasonsracing_drivers3ac milaneuropeac milan2008 2009 2010robert doornbos giorgio pantano yelmer buurman4ac sparta pragueeuropeac sparta prague2011filip salaquarda5team luxembourgeuropenone2011fr\u00e9d\u00e9ric vervisch6team new zealandoceanianone2011earl bamber7team japanasianone2011duncan tappy8 1 (in 2011)rsc anderlechteuropersc anderlecht2008 2009 2010 2011craig dolby yelmer buurman davide rigon neel jani8team netherlandseuropenone2011robert doornbos10fc basel 1893europefc basel2008 2009 2010max wissel max wissel max wissel12 24 (in 2010)beijing guoanasiabeijing guoan fc2008 2010davide rigon john martin14team brazils americanone2011ant\u00f4nio pizzonia17rangers fceuroperangers fc2008 2009ryan dalziel , james walker john martin24fc midtjyllandeuropefc midtjylland2009kasper andersen24team australiaoceanianone2011john martin31team englandeuropenone2011craig dolby\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 1 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE continent = 'oceania' \nAND football_club = 'team japan';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-823.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: phil mickelson is the the only player from united states\nInput Table: 1996 pga championship\n\n\nplaceplayercountryscoreto_parmoney1mark brooksunited states68 + 70 + 69 + 70 = 277- 114300002kenny perryunited states66 + 72 + 71 + 68 = 277- 11260000t3steve elkingtonaustralia67 + 74 + 67 + 70 = 278- 10140000t3tommy tollesunited states69 + 71 + 71 + 67 = 278- 10140000t5justin leonardunited states71 + 66 + 72 + 70 = 279- 986667t5jesper parneviksweden73 + 67 + 69 + 70 = 279- 986667t5vijay singhfiji69 + 69 + 69 + 72 = 279- 986667t8lee janzenunited states68 + 71 + 71 + 70 = 280- 857500t8per - ulrik johanssonsweden73 + 72 + 66 + 69 = 280- 857500t8phil mickelsonunited states67 + 67 + 74 + 72 = 280- 857500t8larry mizeunited states71 + 70 + 69 + 70 = 280- 857500t8frank nobilonew zealand69 + 72 + 71 + 68 = 280- 857500t8nick pricezimbabwe68 + 71 + 69 + 72 = 280- 857500\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 1 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE country = 'united states' \nAND player != 'phil mickelson';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1518.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the hometown of the last player of the list is las vegas , nv\nInput Table: usa today all - usa high school basketball team\n\n\nplayerheightschoolhometowncollegekhem birch6 - 9notre dame prepmontreal , qc , canadapittsburgh / unlvperry ellis6 - 8wichita heights high schoolwichita , kskansasmyles mack5 - 9st anthony high schooljersey city , njrutgersshabazz muhammad6 - 6bishop gorman high schoollas vegas , nvuclacody zeller6 - 11washington high schoolwashington , inindiana\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN hometown = 'las vegas , nv' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE player = 'cody zeller';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1279.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: ty lawson led or was tied for the lead in assists for 10 out of 13 games\nInput Table: 2009 - 10 denver nuggets season\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord39999-11-01grizzliesw 133 - 123 (ot)carmelo anthony (42)nen\u00ea (9)chauncey billups (12)pepsi center 158233 - 049999-11-03pacersw 111 - 93 (ot)carmelo anthony (25)nen\u00ea (13)anthony carter (5)conseco fieldhouse 106274 - 059999-11-04netsw 122 - 94 (ot)ty lawson (23)kenyon martin (10)chauncey billups (5)izod center 153195 - 079999-11-07hawksl 100 - 125 (ot)carmelo anthony (30)chris andersen (11)chauncey billups (7)philips arena 178015 - 289999-11-10bullsw 90 - 89 (ot)carmelo anthony (20)nen\u00ea (12)chauncey billups (6)united center 214096 - 299999-11-11bucksl 102 - 108 (ot)carmelo anthony (32)carmelo anthony (10)chauncey billups , ty lawson (5)bradley center 129876 - 3109999-11-13lakersw 105 - 79 (ot)carmelo anthony (25)chris andersen (11)chauncey billups (8)pepsi center 191417 - 3119999-11-17raptorsw 130 - 112 (ot)carmelo anthony (32)nen\u00ea (10)chauncey billups (10)pepsi center 164468 - 3129999-11-20clippersl 99 - 106 (ot)carmelo anthony (37)nen\u00ea (12)chauncey billups (7)staples center 181558 - 4139999-11-21bullsw 112 - 93 (ot)carmelo anthony (30)carmelo anthony , kenyon martin (11)carmelo anthony (7)pepsi center 193599 - 4149999-11-24netsw 101 - 87 (ot)carmelo anthony (27)nen\u00ea (9)chauncey billups (7)pepsi center 1630710 - 4159999-11-25timberwolvesw 124 - 111 (ot)carmelo anthony (22)nen\u00ea (8)nen\u00ea , ty lawson (6)target center 1310111 - 4169999-11-27knicksw 128 - 125 (ot)carmelo anthony (50)nen\u00ea , kenyon martin (11)chauncey billups (8)pepsi center 1915512 - 4\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE high_assists >= (SELECT MAX(high_assists) FROM table_sql WHERE team = 'ty lawson')) = 10 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-670.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: bradford city went against port vale two times according to the chart , on 13 september 2008 and 28 march 2009\nInput Table: 2008 - 09 bradford city a.f.c. season\n\n\ngamedateopponentvenueresultattendance12008-08-09notts countyhome2 - 11403822008-08-16macclesfield townaway2 - 0255632008-08-23rochdalehome2 - 01315442008-08-30aldershot townaway2 - 3380552008-09-06port valeaway2 - 0727362008-09-13exeter cityhome4 - 11268372008-09-20bournemouthhome1 - 31282482008-09-27shrewsbury townaway0 - 2651792008-10-04luton townhome1 - 113083102008-10-11accrington stanleyaway3 - 23012112008-10-18gillinghamhome2 - 212432122008-10-21darlingtonaway1 - 23034132008-10-24grimsby townaway3 - 14470142008-10-28buryhome1 - 012830152008-11-01barnethome3 - 312510162008-11-15wycombe wanderersaway0 - 15002172008-11-22rotherham unitedaway2 - 04586182008-11-25chesterfieldhome3 - 212145192008-12-06dagenham & redbridgehome1 - 112145202008-12-13brentfordaway1 - 24339212008-12-20chester cityhome0 - 012092222008-12-26lincoln cityaway0 - 06156232008-12-28morecambehome4 - 013105242009-01-03shrewsbury townhome0 - 012877252009-01-17accrington stanleyhome1 - 112172262009-01-24luton townaway3 - 36053272009-01-27buryaway0 - 14112282009-01-31grimsby townhome2 - 012816292009-02-07gillinghamaway2 - 04866302009-02-14wycombe wanderershome1 - 012689312009-02-17darlingtonhome0 - 012782322009-02-21barnetaway1 - 42445332009-02-28notts countyaway1 - 35138342009-03-01macclesfield townhome1 - 011908352009-03-07aldershot townhome5 - 012465362009-03-10rochdaleaway0 - 35157372009-03-14exeter cityaway0 - 15253382009-03-17bournemouthaway1 - 44847392009-03-21port valehome0 - 112436402009-03-28chester cityaway0 - 02735412009-04-04brentfordhome1 - 112832422009-04-10morecambeaway1 - 24546432009-04-13lincoln cityhome1 - 112932\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 2 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE opponent = 'port vale' \nAND (date = '2008-09-13' OR date = '2009-03-28');\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-325.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: bud shuster ran opposed in the election\nInput Table: united states house of representatives elections , 1994\n\n\ndistrictincumbentpartyfirst_electedstatusopponentpennsylvania4ron klinkdemocratic1992-01-01re - electedron klink (d) 64.2% ed peglow (r) 35.8%pennsylvania5william f clinger , jrrepublican1978-01-01re - electedwilliam f clinger , jr (r) unopposedpennsylvania7curt weldonrepublican1986-01-01re - electedcurt weldon (r) 69.7% sara r nichols (d) 30.3%pennsylvania9bud shusterrepublican1972-01-01re - electedbud shuster (r) unopposedpennsylvania12john murthademocratic1974-01-01re - electedjohn murtha (d) 68.9% bill choby (r) 31.1%pennsylvania17george gekasrepublican1982-01-01re - electedgeorge gekas (r) unopposedpennsylvania18rick santorumrepublican1990-01-01retired to run for us senate democratic gainmichael f doyle (d) 54.8% john mccarty (r) 45.2%pennsylvania19william f goodlingrepublican1974-01-01re - electedwilliam f goodling (r) unopposed\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE opponent LIKE '%bud shuster%' \nAND status = 're - elected';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-59.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: joe germanese is the player with the number of 24 picks\nInput Table: 2008 mls superdraft\n\n\npickmls_teamplayerpositionaffiliation15san jose earthquakesshea salinasmfurman carolina dynamo16new york red bullseric brunnerdohio state michigan bucks17real salt lakealex nimofgeneration adidas18new england revolutionmichael videiramduke cary railhawks u23 's19fc dallaseric avilamuc santa barbara ventura county fusion20columbus crewgeorge jostenm / fgonzaga michigan bucks21los angeles galaxyely allenf / mwashington22columbus crewricardo pierre - louisflee university cape cod crusaders23kansas city wizardsyomby williamdold dominion hampton roads piranhas24dc unitedandrew jacobsonmcalifornia25kansas city wizardsjonathan leathersdfurman atlanta silverbacks u23 's26chicago firepeter lowrym / fsanta clara san jose frogs27new england revolutionjoe germanesemduke cary railhawks u23 's28toronto fcbrian edwardsgkwake forest\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT player FROM table_sql WHERE pick = 24) = 'joe germanese' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-946.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: 0 goals occurred with diego milito in a debut year before 2008\nInput Table: football records in italy\n\n\nrankall_-_time_ranknamedebut_yearcurrent_clubgoalsapps12francesco totti1992-01-01roma230543211antonio di natale2002-01-01udinese180368316alberto gilardino1999-01-01genoa164425453luca toni2000-01-01verona114258577antonio cassano1999-01-01parma99334681giampaolo pazzini2004-01-01milan95275681mirko vu\u010dini\u01072000-01-01juventus95298897diego milito2008-01-01inter86145897sergio pellissier2002-01-01chievo8633310n / aamauri2000-01-01parma76292\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT goals FROM table_sql WHERE debut_year < '2008-01-01' AND name = 'diego milito') = 0 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1668.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the average score for players from japan is 251\nInput Table: 1989 u.s. open (golf)\n\n\nplaceplayercountryscoreto_parmoney1curtis strangeunited states71 + 64 + 73 + 70 = 278- 2200000t2chip beckunited states71 + 69 + 71 + 68 = 279- 167823t2mark mccumberunited states70 + 68 + 72 + 69 = 279- 167823t2ian woosnamwales70 + 68 + 73 + 68 = 279- 1678235brian claarunited states71 + 72 + 68 + 69 = 280e34345t6masashi ozakijapan70 + 71 + 68 + 72 = 281+ 128220t6scott simpsonunited states67 + 70 + 69 + 75 = 281+ 1282208peter jacobsenunited states71 + 70 + 71 + 70 = 282+ 224307t9paul azingerunited states71 + 72 + 70 + 70 = 283+ 319968t9hubert greenunited states69 + 72 + 74 + 68 = 283+ 319968t9tom kiteunited states67 + 69 + 69 + 78 = 283+ 319968t9jos\u00e9 mar\u00eda olaz\u00e1balspain69 + 72 + 70 + 72 = 283+ 319968\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT AVG(score) FROM table_sql WHERE country = 'japan') = 251 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-911.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: four athletes had a mark of 28 feet\nInput Table: long jump\n\n\nmarkwindathletenationalityvenuedate8.95 m (29ft4\u00bcin)0.3mike powellunited statestokyo1991-08-308.90 m (29ft2\u00bcin) a2.0bob beamonunited statesmexico city1968-10-188.87 m (29ft1in)0.2carl lewisunited statestokyo1991-08-308.86 m (29ft0\u00bein) a1.9robert emmiyansoviet uniontsakhkadzor1987-05-228.74 m (28ft8in)1.4larry myricksunited statesindianapolis1988-07-188.74 m (28ft8in) a2.0erick walderunited statesel paso1994-04-028.74 m (28ft8in)1.2dwight phillipsunited stateseugene2009-06-078.73 m (28ft7\u00bdin)1.2irving saladinopanamahengelo2008-05-248.71 m (28ft6\u00bein)1.9iv\u00e1n pedrosocubasalamanca1995-07-188.66 m (28ft4\u00bein)1.6lo\u00fais ts\u00e1toumasgreecekalam\u00e1ta2007-06-02\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 4 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE mark LIKE '28ft%';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1792.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: democratic is the party with first elected being 1926\nInput Table: united states house of representatives elections , 1942\n\n\ndistrictincumbentpartyfirst_electedresultcandidatescalifornia 2harry lane englebrightrepublican1926-01-01re - electedharry lane englebright (r) unopposedcalifornia 4thomas rolphrepublican1940-01-01re - electedthomas rolph (r) 98.3% archie brown ( w / i ) 1.7%california 7john h tolandemocratic1934-01-01re - electedjohn h tolan (d) unopposedcalifornia 9bertrand w gearhartrepublican1934-01-01re - electedbertrand w gearhart (r) unopposedcalifornia 10alfred j elliottdemocratic1937-01-01re - electedalfred j elliott (d) unopposedcalifornia 17cecil r kingdemocratic1942-08-25re - electedcecil r king (d) unopposedcalifornia 22none (district created)none (district created)9999-01-01new seat republican gainjohn j phillips (r) 57.6% n e west (d) 42.4%\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE party = 'democratic' \nAND first_elected = '1926-01-01';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-496.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: hanover in plymouth county intersects route 123\nInput Table: massachusetts route 139\n\n\ncountylocationstreet_namesmilepostroads_intersectednotesnorfolkstoughtonpleasant street turnpike street lindelof avenue3.0route 24route 24 exit 20norfolkweymouthanne street(no major junctions)(no major junctions)(no major junctions)plymouthrocklandnorth avenue plain street market street12.2route 123western terminus of route 123 / 139 concurrencyplymouthrocklandnorth avenue plain street market street12.8route 123eastern terminus of route 123 / 139 concurrencyplymouthhanoverhanover street rockland street columbia road17.9route 53northern terminus of route 53 / 139 concurrency\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) > 0 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE county = 'plymouth' \nAND location = 'hanover' \nAND roads_intersected LIKE '%route 123%';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1812.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: nadia al - moutawaa was the first person to win the gold medal in equestrian at the asian games and win silver another year\nInput Table: equestrian at the asian games\n\n\nyearlocationgoldsilverbronze1982new delhinadia al - moutawaajamila al - moutawaabariaa salem al - sabbah1986seoultakashi tomurashuichi tokiryuzo okuno1994hiroshimakonoshin kuwahararyuzo okunonatya chantrasmi1998bangkokjin kannosohn bong - gakquzier ambak fathil2002busanmikaela mar\u00e3\u00ada jaworskilee jin - kyungtadayoshi hayashi2006dohaali yousuf al - rumaihijasmine chen - shao manjoo jung - hyun2010guangzhouramzy al duhamilatifa al maktomkhaled al - eid\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE gold = 'nadia al - moutawaa') = 1 \n             AND (SELECT COUNT(*) FROM table_sql WHERE silver = 'nadia al - moutawaa') = 1 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-765.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the date of the discus throw for bulgaria was after september 5 , 1986\nInput Table: memorial van damme\n\n\neventrecordathletenationalitydate100 m10.72 ( - 0.3 m / s)shelly - ann fraser - prycejamaica2013-09-06200 m21.64 ( + 0.8 m / s)merlene otteyjamaica1991-09-13400 m48.83sanya richardsunited states2009-09-04800 m1:55.16pamela jelimokenya2008-09-061000 m2:28.98svetlana masterkovarussia1996-08-231500 m3:55.33s\u00fcreyya ayhanturkey2003-09-05mile4:17.75maryam yusuf jamalbahrain2007-09-142000 m5:30.19gelete burkaethiopia2009-09-043000 m8:24.81 +meseret defarethiopia2007-09-14two miles8:58.58meseret defarethiopia2007-09-145000 m14:25.43vivian cheruiyotkenya2008-09-06100 m hurdles12.42 ( - 0.3 m / s)yordanka donkovabulgaria1986-09-05400 m hurdles53.43nezha bidouanemorocco1998-08-283000 m steeplechase9:15.06milcah chemoskenya2013-09-06high jump2.05 manna chicherovarussia2011-09-16pole vault4.93 myelena isinbayevarussia2005-08-26long jump7.25 m ( + 1.7 m / s)heike drechslergermany1991-09-13triple jump15.14 m ( + 0.3 m / s)tatyana lebedevarussia2003-09-05shot put20.57 mnatalya lisovskayasoviet union1987-09-11discus throw69.84 mtsvetanka christovabulgaria1986-09-05javelin throw72.18 m ( old design ) 67.76 m ( current design )fatima whitbread trine hattestadunited kingdom norway1986-09-054100 m relay42.97united statesunited states1988-08-19\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT date FROM table_sql WHERE event = 'discus throw' AND nationality = 'bulgaria') > '1986-09-05' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1095.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the episode called aaliyah was the first episode to air\nInput Table: list of all that episodes\n\n\nseasonseriesepisode_titleoriginal_air_datenick_prod138tia & tamera mowry / ll cool j1996-11-16338239montell jordan1996-11-23339441dru hill1996-12-07341542tyra banks / blackstreet1996-12-14342643music special1996-12-17343744a tribe called quest1996-12-213448457021996-12-28345946tony! toni! tone!1997-01-043461047chris farley / mint condition1997-01-1134711481121997-01-183481249sherman hemsley / nas1997-01-253491350john leguizamo / mona lisa1997-02-013501451ray j1997-02-083511552for real1997-09-203521653aaliyah1997-10-043531754az yet1997-09-273541855monica1997-10-113551956mc lyte1997-10-18356\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MIN(original_air_date) FROM table_sql) = '1997-10-04' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1042.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there are only three highest ranks listed in the table\nInput Table: list of sumo record holders\n\n\nnametotalfirstlasthighest_rankkotonishiki341990-09-011999-09-01sekiwakekai\u014d321994-05-012000-07-01\u014dzekimus\u014dyama311994-03-012000-09-01\u014dzekihasegawa301965-11-011974-09-01sekiwakekotomitsuki302001-01-012007-07-01\u014dzekiakinoshima271988-11-012000-09-01sekiwaketakamiyama271969-11-011982-09-01sekiwaketakat\u014driki261991-05-012000-05-01sekiwakewakanosato262000-11-012005-09-01sekiwakedaikirin221966-11-011970-09-01\u014dzekitochiazuma ii221997-07-012005-01-01\u014dzekikisenosato222006-07-012011-09-01\u014dzeki\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(DISTINCT highest_rank) = 3 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1284.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: paulo costa is the name that had a moving to trofense in the transfer window of summer\nInput Table: 2008 - 09 apoel f.c. season\n\n\nnatnamemoving_totypetransfer_windowtransfer_feesourcegremachlasretiredretirementsummer-contragrcypmakridesmetalurh donetskend of contractsummerfreekerkidanetser\u010dorovi\u0107ael limassolloan returnsummer--cyploukaael limassolend of contractsummerfreekerkidanetgrekapsislevadiakosend of contractsummerfree-cypdaskalakisaek larnacaend of contractsummerfreeapoelnetbraz\u00e9 carlostrofensecontract terminationsummerfreeapoelfccomcycypvourkoudoxa katokopialoansummerfree-cyppanayiotoudigenis morphouloansummerfree-mkdnikolovskiaep paphosmutual consentwinterfree-cyppapathanasiouermis aradippouloanwinterfree-porpaulo costaanorthosis famagustamutual consent loan returnwinterfreeapoelfccomcy\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT name FROM table_sql WHERE moving_to = 'trofense' AND transfer_window = 'summer') = 'paulo costa' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-327.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: district pennsylvania12 has incumbent ron klink\nInput Table: united states house of representatives elections , 1994\n\n\ndistrictincumbentpartyfirst_electedstatusopponentpennsylvania4ron klinkdemocratic1992-01-01re - electedron klink (d) 64.2% ed peglow (r) 35.8%pennsylvania5william f clinger , jrrepublican1978-01-01re - electedwilliam f clinger , jr (r) unopposedpennsylvania7curt weldonrepublican1986-01-01re - electedcurt weldon (r) 69.7% sara r nichols (d) 30.3%pennsylvania9bud shusterrepublican1972-01-01re - electedbud shuster (r) unopposedpennsylvania12john murthademocratic1974-01-01re - electedjohn murtha (d) 68.9% bill choby (r) 31.1%pennsylvania17george gekasrepublican1982-01-01re - electedgeorge gekas (r) unopposedpennsylvania18rick santorumrepublican1990-01-01retired to run for us senate democratic gainmichael f doyle (d) 54.8% john mccarty (r) 45.2%pennsylvania19william f goodlingrepublican1974-01-01re - electedwilliam f goodling (r) unopposed\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE district = 'pennsylvania12' \nAND incumbent = 'ron klink';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-10.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: every team had several wins\nInput Table: c\u00e9sar ramos\n\n\nseasonseriesteamraceswinspolesf_/_lapspodiumspointsposition2007formula renault 2.0 italybvm minardi team14000110614th2007eurocup formula renault 2.0bvm minardi team60000n / anc2007formula renault 2.0 italy - winter seriesbvm minardi team444441441st2008formula renault 2.0 italybvm minardi team1401242166th2008eurocup formula renault 2.0bvm minardi team140001387th2009formula 3 euro seriesmanor motorsport160000025th2009masters of formula 3manor motorsport10000n / a28th2010italian formula three championshipbvm - target racing1632781611st2011formula renault 3.5 seriess fortec motorsport1702004711th\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = (SELECT COUNT(*) FROM table_sql WHERE wins > 0) THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1790.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: john j phillips (r) 57.6% n e west (d) 42.4% are from the democratic party\nInput Table: united states house of representatives elections , 1942\n\n\ndistrictincumbentpartyfirst_electedresultcandidatescalifornia 2harry lane englebrightrepublican1926-01-01re - electedharry lane englebright (r) unopposedcalifornia 4thomas rolphrepublican1940-01-01re - electedthomas rolph (r) 98.3% archie brown ( w / i ) 1.7%california 7john h tolandemocratic1934-01-01re - electedjohn h tolan (d) unopposedcalifornia 9bertrand w gearhartrepublican1934-01-01re - electedbertrand w gearhart (r) unopposedcalifornia 10alfred j elliottdemocratic1937-01-01re - electedalfred j elliott (d) unopposedcalifornia 17cecil r kingdemocratic1942-08-25re - electedcecil r king (d) unopposedcalifornia 22none (district created)none (district created)9999-01-01new seat republican gainjohn j phillips (r) 57.6% n e west (d) 42.4%\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN party = 'democratic' AND candidates LIKE '%(d)%' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE candidates LIKE '%john j phillips (r) 57.6% n e west (d) 42.4%';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-144.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: all games in the 2006 season were played in the month of september\nInput Table: 2006 texas rangers season\n\n\ndateopponentscorelossattendancerecord9999-09-01indians7 - 2padilla (13 - 9)2377669 - 679999-09-02indians6 - 5volquez (1 - 4)4022269 - 689999-09-03indians5 - 2byrd1966770 - 689999-09-04athletics8 - 1zito2394971 - 689999-09-05athletics5 - 4saarloos2722572 - 689999-09-06athletics9 - 6rupe (0 - 1)1783872 - 699999-09-08mariners7 - 2millwood (14 - 10)2864672 - 709999-09-09mariners3 - 2rheinecker (4 - 6)3345472 - 719999-09-10mariners4 - 2huber3432173 - 719999-09-12tigers3 - 2mahay (1 - 3)2419673 - 729999-09-13tigers11 - 3verlander2467274 - 729999-09-14angels2 - 1volquez (1 - 5)2148874 - 739999-09-15angels2 - 1francisco (0 - 1)3078874 - 749999-09-16angels12 - 6lackey4019675 - 749999-09-17angels8 - 1santana2430376 - 749999-09-18mariners8 - 1hern\u00e1ndez1821477 - 749999-09-19mariners9 - 7wilson (2 - 3)1855177 - 759999-09-20mariners6 - 3tejeda (4 - 4)2600677 - 769999-09-22indians12 - 4byrd2628478 - 769999-09-23indians6 - 3padilla (14 - 10)3835178 - 779999-09-24indians11 - 6millwood (16 - 11)3661778 - 789999-09-25angels8 - 3volquez (1 - 6)3978178 - 799999-09-26angels5 - 2escobar3733979 - 799999-09-27angels6 - 5wilson (2 - 4)3803279 - 809999-09-29mariners6 - 5fruto3076680 - 809999-09-30mariners3 - 1millwood (16 - 12)2331080 - 819999-10-01mariners3 - 2tejeda (5 - 5)2836180 - 82\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = (SELECT COUNT(*) FROM table_sql WHERE date LIKE '9999-09%') THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-448.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: only two teams (hawthorn and south melbourne) scored more than 10\nInput Table: 1938 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddategeelong11.23 (89)hawthorn6.13 (49)corio oval70001938-06-18fitzroy16.12 (108)south melbourne8.8 (56)brunswick street oval120001938-06-18st kilda14.12 (96)melbourne16.16 (112)junction oval140001938-06-18richmond15.14 (104)essendon15.9 (99)punt road oval200001938-06-18footscray13.9 (87)collingwood10.5 (65)western oval180001938-06-18north melbourne11.5 (71)carlton16.25 (121)arden street oval130001938-06-18\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE home_team_score > 10 OR away_team_score > 10) = 2 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-609.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: brook lopez led the team in assists for more games than deron williams did\nInput Table: 2010 - 11 new jersey nets season\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord759999-04-01philadelphial 90 - 115 (ot)brandan wright (15)brandan wright (11)deron williams (7)wells fargo center 1669523 - 52769999-04-03miamil 94 - 108 (ot)deron williams (18)travis outlaw (9)deron williams (9)prudential center 1871123 - 5377'9999-04-05'minnesotaw 107 - 105 (ot)brook lopez (30)brook lopez (12)deron williams (21)prudential center 1346124 - 53789999-04-06detroitl 109 - 116 (ot)brook lopez (39)brook lopez (7)jordan farmar (11)the palace of auburn hills 1455424 - 54799999-04-08new yorkl 93 - 116 (ot)brook lopez (27)jordan farmar (8)jordan farmar (9)prudential center 1802324 - 5580'9999-04-10'torontol 92 - 99 (ot)brook lopez (35)brook lopez (11)jordan farmar (7)air canada centre 1775524 - 56819999-04-11charlottel 103 - 105 (ot)brook lopez (31)dan gadzuric (8)jordan farmar (9)prudential center 1385324 - 57\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE high_assists > high_assists AND team = 'brook lopez') > \n             (SELECT COUNT(*) FROM table_sql WHERE high_assists > high_assists AND team = 'deron williams') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-721.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: ten of the players were transferred at the end of their contract\nInput Table: 2008 - 09 rangers f.c. season\n\n\nnatnamemoving_totypetransfer_windowtransfer_feesconicholas gallacher9999-01-01end of contract9999-06-01n / aivory coastlacine cherif9999-01-01end of contract9999-06-01n / ascoalistair park9999-01-01end of contract9999-06-01n / aengmichael donald9999-01-01end of contract9999-06-01n / ascocalum reidford9999-01-01end of contract9999-06-01n / ascochris smith9999-01-01end of contract9999-06-01n / abeljeroen van den broeck9999-01-01end of contract9999-06-01n / aslovakiafilip \u0161ebo9999-01-01transfer9999-06-011 mbelthomas buffel9999-01-01transfer9999-06-01n / aespcarlos cu\u00e9llar9999-01-01transfer9999-06-017.8 mscosteven lennon9999-01-01loan9999-06-01n / ascomark weir9999-01-01loan9999-06-01n / ascoandy webster9999-01-01loan9999-06-01n / arsadean furman9999-01-01loan9999-06-01n / ascoalan lowing9999-01-01loan9999-06-01n / ascopaul emslie9999-01-01loan9999-06-01n / ascoscott gallacher9999-01-01loan9999-06-01n / agabondaniel cousin9999-01-01transfer9999-06-013.5 mscoalan gow9999-01-01loan9999-06-01n / aenglee robinson9999-01-01loan9999-01-01n / ascoandrew shinnie9999-01-01loan9999-01-01n / ascosteven kinniburgh9999-01-01loan9999-01-01n / ascorory loy9999-01-01loan9999-01-01n / ascowilliam mclachlan9999-01-01loan9999-01-01n / ascolee robinson9999-01-01loan9999-01-01n / afrajean - claude darcheville9999-01-01transfer9999-01-01freescojordan mcmillan9999-01-01loan9999-01-01n / ascochris burke9999-01-01transfer9999-01-01freecypgeorgios efrem9999-01-01loan9999-01-01n / ascoalan gow9999-01-01loan9999-01-01n / ascocharlie adam9999-01-01loan9999-01-01n / ascoross harvey9999-01-01loan9999-01-01n / ascosteven kinniburgh9999-01-01loan9999-01-01n / a\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 10 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE type = 'transfer' \nAND moving_to = '9999-01-01' \nAND transfer_window = '9999-06-01' \nAND transfer_fee = 'n / a';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-485.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the april 26th 2004 tournament took place in surbiton , great britain\nInput Table: alex bogdanovic\n\n\ndatetournamentsurfaceopponent_in_the_finalscore2003-06-02surbiton , great britaingrasswesley moodie4 - 6 , 7 - 6 (2) , 1 - 62004-04-26glasgow , great britain f1carpetga\u00ebl monfils4 - 6 , 3 - 62004-07-05nottingham , great britaingrassjo - wilfried tsonga3 - 6 , 4 - 62006-10-02mons , belgiumhardjanko tipsarevi\u01074 - 6 , 6 - 1 , 2 - 62007-04-16cardiff , great britainhardfr\u00e9d\u00e9ric niemeyer4 - 6 , 5 - 72011-04-04little rock , ar , usa f9hardarnau brugu\u00e9s - davi3 - 6 , 1 - 62012-09-24irvine , ca , usa f26harddaniel nguyen5 - 7 , 2 - 62013-04-08oklahoma city , usa f9hardrik de voest3 - 6 , 2 - 6\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE date = '2004-04-26' \nAND tournament = 'surbiton , great britain';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-894.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: george town is the ntfa div 1 team that has 8 wins and less than 2 draws\nInput Table: none\n\n\nntfa_div_1winsbyeslossesdrawsagainstbridgenorth150301247rocherlea130501661bracknell120511589george town90811431scottsdale801001607deloraine601021639longford501211607hillwood101612071\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT wins FROM table_sql WHERE ntfa_div_1 = 'george town') = 8 \n             AND (SELECT draws FROM table_sql WHERE ntfa_div_1 = 'george town') < 2 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-379.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the home media center had no os x and windows\nInput Table: comparison of upnp av media servers\n\n\nnamelicenseos_xunix_-_likewindowsweb_interface360 media servergplnoyesyesyesavia media playerpropnonononobrisamitpartialpartialnoyescoherencemitpartialpartialpartialyesdivxpropyesnoyesnoelgato eyeconnectpropyesnononofoobar2000propnonoyesnofuppesgplyesyesyesyesgeexbox usharegplnoyesnoyesgmediaservergplnoyesnonohome media centergplv2nonoyesyesisedora media serverpropyesnoyesyesjriver media centerpropnonoyesyeskooraroo mediapropyesyesyesyeslximediagplyesyesyesnomajestic media serverpropyesnononomediatombgplpartialyesnoyesminidlnagpl / bsdpartialyesyespartialmezzmopropnonoyesnomyihomepropyesyesyesnomythtv with upnpgplyesyesnoyesnullriver medialinkpropyesnononoplayonpropnonoyesyesplexpropyesyesyesyesps3 media servergplyesyesyesyespymedsmitpartialpartialnonorygellgplv2noyesnonorivetpropyesnononoserviiopropyesyesyesyessimplecenter premiumpropnonoyesyesskiftapropyesyesyesnosongbirdgplv2yesnoyesnotvblepropnonoyesnotversitypropnonoyesyestvmobilipropyesyesyesyestvsharepropnonoyesnotwonkyserverpropyesyesyesyesuniversal media servergplyesyesyesyeswindows media connectpropnonoyesnowild media serverpropyesyesyesyesxbmc media centergplyesyesyesyesxupnpdgplv2noyesnoyesyazsoft playbackpropyesnonononamelicenseos xunix - likewindowsweb interface\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE name = 'home media center' AND os_x = 'no' AND windows = 'no') = 1 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1876.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the highest score for a winning team was 18 , while the lowest score for a winning team was 13\nInput Table: solheim cup\n\n\nyearvenuewinning_teamscoreusa_captaineurope_captain2013-01-01colorado golf club , colorado , usaeurope18 - 10meg mallonliselotte neumann2011-01-01killeen castle golf resort , irelandeurope15 - 13rosie jonesalison nicholas2009-01-01rich harvest farms , illinois , usaunited states16 - 12beth danielalison nicholas2007-01-01halmstad gk , swedenunited states16 - 12betsy kinghelen alfredsson2005-01-01crooked stick golf club , indiana , usaunited states15\u00bd - 12\u00bdnancy lopezcatrin nilsmark2003-01-01barseb\u00e4ck golf & country club , swedeneurope17\u00bd - 10\u00bdpatty sheehancatrin nilsmark2002-01-01interlachen country club , minnesota , usaunited states15\u00bd - 12\u00bdpatty sheehandale reid2000-01-01loch lomond golf club , scotlandeurope14\u00bd - 11\u00bdpat bradleydale reid1998-01-01muirfield village , ohio , usaunited states16 - 12judy rankinpia nilsson1996-01-01st pierre golf & country club , walesunited states17 - 11judy rankinmickey walker1994-01-01the greenbrier , west virginia , usaunited states13 - 7joanne carnermickey walker1992-01-01dalmahoy country club , scotlandeurope11\u00bd - 6\u00bdkathy whitworthmickey walker1990-01-01lake nona golf & country club , florida , usaunited states11\u00bd - 4\u00bdkathy whitworthmickey walker\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MAX(CAST(SUBSTR(score, 1, INSTR(score, '-')-1) AS INTEGER)) FROM table_sql WHERE winning_team = 'europe') = 18 \n             AND (SELECT MIN(CAST(SUBSTR(score, 1, INSTR(score, '-')-1) AS INTEGER)) FROM table_sql WHERE winning_team = 'united states') = 13 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1595.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the league / cup competion , played against the swindon wildcats , was lost 4 - 2 with neil liddiard named as man of the match\nInput Table: 2008 - 09 guildford flames season\n\n\ndateopponentvenueresultattendancecompetitionman_of_the_match9999-01-01slough jetshomelost 2 - 31308league / cuplukas smital9999-01-02slough jetsawaylost 5 - 6 (ot)320leaguepaul dixon9999-01-08swindon wildcatsawaywon 6 - 3754league / cuplukas smital9999-01-09swindon wildcatshomewon 4 - 21568league / cupneil liddiard9999-01-15sheffield scimitarsawaywon 7 - 4364league / cuprick plant9999-01-16milton keynes lightninghomelost 2 - 41161league / cupdavid savage9999-01-19romford raidershomewon 6 - 21016league / cupalex mettam9999-01-22wightlink raidersawaylost 5 - 4509league / cupstuart potts9999-01-23telford tigershomewon 4 - 21368leaguealex mettam / mark williams9999-01-29romford raidershomewon 7 - 21238leaguemartin bouz9999-01-30bracknell beesawaywon 4 - 0not reportedleague / cupjoe watkins\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT result FROM table_sql WHERE competition = 'league / cup' AND opponent = 'swindon wildcats') = 'lost 4 - 2' \n             AND (SELECT man_of_the_match FROM table_sql WHERE competition = 'league / cup' AND opponent = 'swindon wildcats') = 'neil liddiard' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-471.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: gene borek who played at t6 with a score of 73 + 69 = 142 belong to the united states\nInput Table: 1973 u.s. open (golf)\n\n\nplaceplayercountryscoreto_par1gary playersouth africa67 + 70 = 137- 52jim colbertunited states70 + 68 = 138- 4t3jack nicklausunited states71 + 69 = 140- 2t3johnny millerunited states71 + 69 = 140- 2t3bob charlesnew zealand71 + 69 = 140- 2t6gene borekunited states77 + 65 = 142et6julius borosunited states73 + 69 = 142et6tom weiskopfunited states73 + 69 = 142et6arnold palmerunited states71 + 71 = 142et6lee trevinounited states70 + 72 = 142e\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT country FROM table_sql WHERE place = 't6' AND player = 'gene borek' AND score = '73 + 69 = 142') = 'united states' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1637.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the best record listed is 29 - 7 , in 2012 , when they received a 5 seed\nInput Table: vcu rams men 's basketball\n\n\nyearrecordseedregionresults198018 - 1212eastl 72 - 86198124 - 55eastw 85 - 69 l 56 - 58 ot198324 - 75eastw 76 - 67 l 54 - 56198423 - 76eastw 70 - 69 l 63 - 78198526 - 62westw 81 - 65 l 59 - 63199624 - 912southeastl 51 - 58200423 - 813eastl 78 - 79200728 - 711westw 79 - 77 l 79 - 84 ot200924 - 1011eastl 64 - 65201128 - 1211southwestw 59 - 46 w 74 - 56 w 94 - 76 w 72 - 71 ot w 71 - 61 l 62 - 70201229 - 712midwestw 62 - 59 l 61 - 63201327 - 95southw 88 - 42 l 53 - 78\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MAX(record) FROM table_sql) = '29 - 7' \n             AND (SELECT year FROM table_sql WHERE record = '29 - 7') = 2012 \n             AND (SELECT seed FROM table_sql WHERE record = '29 - 7') = 5 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-380.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: coherence is the name when windows and web interface are partial\nInput Table: comparison of upnp av media servers\n\n\nnamelicenseos_xunix_-_likewindowsweb_interface360 media servergplnoyesyesyesavia media playerpropnonononobrisamitpartialpartialnoyescoherencemitpartialpartialpartialyesdivxpropyesnoyesnoelgato eyeconnectpropyesnononofoobar2000propnonoyesnofuppesgplyesyesyesyesgeexbox usharegplnoyesnoyesgmediaservergplnoyesnonohome media centergplv2nonoyesyesisedora media serverpropyesnoyesyesjriver media centerpropnonoyesyeskooraroo mediapropyesyesyesyeslximediagplyesyesyesnomajestic media serverpropyesnononomediatombgplpartialyesnoyesminidlnagpl / bsdpartialyesyespartialmezzmopropnonoyesnomyihomepropyesyesyesnomythtv with upnpgplyesyesnoyesnullriver medialinkpropyesnononoplayonpropnonoyesyesplexpropyesyesyesyesps3 media servergplyesyesyesyespymedsmitpartialpartialnonorygellgplv2noyesnonorivetpropyesnononoserviiopropyesyesyesyessimplecenter premiumpropnonoyesyesskiftapropyesyesyesnosongbirdgplv2yesnoyesnotvblepropnonoyesnotversitypropnonoyesyestvmobilipropyesyesyesyestvsharepropnonoyesnotwonkyserverpropyesyesyesyesuniversal media servergplyesyesyesyeswindows media connectpropnonoyesnowild media serverpropyesyesyesyesxbmc media centergplyesyesyesyesxupnpdgplv2noyesnoyesyazsoft playbackpropyesnonononamelicenseos xunix - likewindowsweb interface\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT name FROM table_sql WHERE windows = 'partial' AND web_interface = 'partial') = 'coherence' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1998.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the 31997 mintage was released in 2001\nInput Table: royal canadian mint numismatic coins (2000s)\n\n\nyearthemeartistmintageissue_price2000steam buggyjohn mardon4436759.952000the bluenosej franklin wrightincluded in steam buggy59.952000the torontojohn mardonincluded in steam buggy59.952001the russell light fourjohn mardon4182859.952001the marco poloj franklin wrightincluded in the russell59.952001the scotiadon curleyincluded in the russell59.952002the gray - dortjohn mardon3594459.952002the william lawrencebonnie rossincluded in the gray - dort59.952002d - 10 locomotivedan fellincluded in the gray - dort59.952003hmcs bras dordon curley3199759.952003cnr fa - 1 diesel electricjohn mardonincluded in hmcs bras dor59.952003bricklin sv - 1brian hughesincluded in hmcs bras dor59.95\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE mintage = 31997 \nAND year = 2001;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1966.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: 2 - 4 is the record in the game where austin daye (16) did the high rebounds\nInput Table: 2010 - 11 detroit pistons season\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord19999-10-05miamil 89 - 105 (ot)ben gordon (17)ben gordon , charlie villanueva (5)rodney stuckey (5)american airlines arena 196000 - 129999-10-08milwaukeew 115 - 110 (ot)austin daye (21)austin daye (7)will bynum (9)the palace of auburn hills 128211 - 139999-10-11atlantaw 94 - 85 (ot)rodney stuckey (16)greg monroe (7)richard hamilton (7)the palace of auburn hills 105912 - 149999-10-13dallasl 96 - 101 (ot)austin daye (16)ben wallace , jason maxiell (8)rodney stuckey (6)van andel arena 102072 - 259999-10-15minnesotal 88 - 99 (ot)austin daye (18)austin daye (11)will bynum (5)carrier dome 117472 - 369999-10-16charlottel 94 - 97 (ot)rodney stuckey (25)greg monroe (8)rodney stuckey , will bynum (5)colonial life arena 68472 - 479999-10-19washingtonw 98 - 92 (ot)rodney stuckey (34)ben wallace (11)rodney stuckey (7)huntington center 64243 - 4\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN record = '2 - 4' AND high_rebounds = 'austin daye (16)' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1160.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: rodney stuckey led the detroit pistons in points cored in only one game during this period of the 2010 - 2011 season\nInput Table: 2010 - 11 detroit pistons season\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord629999-03-01milwaukeel 90 - 92 (ot)rodney stuckey (25)greg monroe , charlie villanueva (9)rodney stuckey (5)bradley center 1136422 - 40639999-03-02minnesotal 105 - 116 (ot)austin daye (22)greg monroe (11)rodney stuckey (10)the palace of auburn hills 1312222 - 41649999-03-06washingtonw 113 - 102 (ot)tayshaun prince (20)greg monroe , rodney stuckey (7)rodney stuckey (9)the palace of auburn hills 1750623 - 41659999-03-09san antoniol 104 - 111 (ot)richard hamilton (20)greg monroe (10)tracy mcgrady (9)at&t center 1858123 - 42669999-03-11oklahoma cityl 94 - 104 (ot)richard hamilton (20)greg monroe (10)greg monroe , rodney stuckey (6)oklahoma city arena 1820323 - 43679999-03-12denverl 101 - 131 (ot)chris wilcox (21)austin daye , ben gordon , greg monroe (6)will bynum (10)pepsi center 1915523 - 44689999-03-16torontow 107 - 93 (ot)richard hamilton (24)greg monroe (10)rodney stuckey (14)the palace of auburn hills 1516624 - 44699999-03-18new yorkw 99 - 95 (ot)tayshaun prince (16)chris wilcox (12)will bynum (5)the palace of auburn hills 2207625 - 44709999-03-20atlantal 96 - 104 (ot)rodney stuckey (22)greg monroe (10)rodney stuckey (8)philips arena 1758025 - 45719999-03-23miamil 94 - 100 (ot)richard hamilton (27)greg monroe (12)rodney stuckey (6)the palace of auburn hills 2207625 - 46729999-03-25clevelandl 91 - 97 (ot)richard hamilton , tayshaun prince (15)chris wilcox , greg monroe (8)rodney stuckey (4)quicken loans arena 1990725 - 47739999-03-26indianaw 100 - 88 (ot)richard hamilton (23)greg monroe (13)richard hamilton , rodney stuckey (6)the palace of auburn hills 1921626 - 47\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 1 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE high_points = (SELECT MAX(high_points) FROM table_sql WHERE team = 'detroit pistons') \nAND team = 'detroit pistons';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1981.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: otto graham has won 44 more games than brady quinn\nInput Table: list of cleveland browns starting quarterbacks\n\n\nquarterbackuniform_no_(s)games_startedwinslossestieswinning_pctsipe , brian1711257550589.0kosar , bernie1910553511595.0ryan , frank137652222697.0graham , otto60 , 147157131810.0couch , tim25922370373.0nelsen , bill165134161676.0phipps , mike155124252490.0plum , milt165133162667.0anderson , derek33416180471.0testaverde , vinny123116150516.0mcdonald , paul16218130381.0mccoy , colt12216150286.0frye , charlie9196130316.0weeden , brandon3195140263.0o'connell , tommy15141031750.0holcomb , kelly1012480333.0quinn , brady1012390250.0ninowski , jim15 , 1111560455.0dilfer , trent811470364.0garcia , jeff510370300.0danielson , gary188530625.0tomczak , mike188440500.0pederson , doug188170125.0pagel , mike107250286.0wallace , seneca67160143.0ratterman , george12 , 165230400.0philcox , todd175230400.0delhomme , jake174220500.0mays , dave104130250.0zeier , eric104130250.0mccown , luke1240400.0parilli , babe183120333.0rypien , mark113210667.0dorsey , ken1130300.0hoyer , brian633001.0strock , don1222001.0christensen , jeff112110500.0detmer , ty1120200.0campbell , jason172110500.0gault , don1111001.0lane , gary1510100.0dawson , len1811001.0wynn , spergon1310100.0luck , terry710100.0cureton , will1610100.0gradkowski , bruce710100.0lewis , thaddeus910100.0\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT wins FROM table_sql WHERE quarterback = 'graham , otto') - \n             (SELECT wins FROM table_sql WHERE quarterback = 'quinn , brady') = 44 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-2010.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: collingwood had a home team score that was three times higher than that of geelong\nInput Table: 1954 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddategeelong13.12 (90)hawthorn7.6 (48)kardinia park168701954-08-14collingwood12.16 (88)south melbourne13.12 (90)victoria park185561954-08-14carlton10.16 (76)essendon11.14 (80)princes park297441954-08-14richmond10.18 (78)melbourne15.4 (94)punt road oval240001954-08-14north melbourne9.14 (68)footscray9.14 (68)arden street oval220001954-08-14st kilda13.14 (92)fitzroy9.15 (69)junction oval115001954-08-14\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT home_team_score FROM table_sql WHERE home_team = 'collingwood') = \n             3 * (SELECT home_team_score FROM table_sql WHERE home_team = 'geelong') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-24.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: wrestling is the sport with the latest date in 2008\nInput Table: iowa corn cy - hawk series\n\n\ndatesitesportwinning_teamseries2007-09-04cedar rapidsm golfiowa stateiowa state 2 - 02007-09-08des moinesvolleyballiowa stateiowa state 4 - 02007-09-09iowa cityw soccertieiowa state 5 - 12007-09-15amesfootballiowa stateiowa state 8 - 12007-11-10peoriam cross countryiowa stateiowa state 10 - 12007-11-10peoriaw cross countryiowaiowa state 10 - 32007-12-05amesw basketballiowa stateiowa state 12 - 32007-12-07amesw swimmingiowa stateiowa state 14 - 32007-12-08amesm basketballiowa stateiowa state 16 - 32007-12-09ameswrestlingiowaiowa state 16 - 52008-02-22amesw gymnasticsiowa stateiowa state 18 - 52008-03-07iowa cityw gymnasticsiowaiowa state 18 - 72008-04-01amessoftballiowaiowa state 18 - 9\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MAX(date) FROM table_sql WHERE sport = 'wrestling' AND date LIKE '2008%') = \n             (SELECT MAX(date) FROM table_sql WHERE date LIKE '2008%') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1256.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: china has won 40 more gold medals than iran for wushu at the asian games\nInput Table: wushu at the asian games\n\n\nranknationgoldsilverbronzetotal1china (chn)4373532iran (iri)435123malaysia (mas)31594hong kong (hkg)294155thailand (tha)236116japan (jpn)165127philippines (phi)158148macau (mac)154109south korea (kor)1461110chinese taipei (tpe)13111511myanmar (mya)112412vietnam (vie)0971613indonesia (ina)022414laos (lao)015615india (ind)012316pakistan (pak)011217singapore (sin)005518mongolia (mgl)003319kazakhstan (kaz)002220yemen (yem)0011totaltotal606187208\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT gold FROM table_sql WHERE nation = 'china (chn)') - \n             (SELECT gold FROM table_sql WHERE nation = 'iran (iri)') = 40 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-317.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the jazz had two players , both guards , with the last name dawkins but their time on the team did not overlap\nInput Table: utah jazz all - time roster\n\n\nplayernationalitypositionyears_for_jazzschool_/_club_teamadrian dantleyunited statesguard - forward1979-01-01notre damebrad davisunited statesguard1979-01-01marylanddarryl dawkinsunited statescenter1987-01-01maynard evans hspaul dawkinsunited statesguard1979-01-01northern illinoisgreg deaneunited statesguard1979-01-01utahjames donaldsonunited statescenter1993-01-01, 1994-01-01, 1995-01-01washington statejohn drewunited statesguard - forward1982-01-01gardner - webbjohn durenunited statesguard1980-01-01georgetown\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE position = 'guard' AND player LIKE '%dawkins%') = 2 \n             AND (SELECT COUNT(*) FROM table_sql WHERE position = 'guard' AND player LIKE '%dawkins%' AND years_for_jazz LIKE '%1987%') = 0 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1071.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there are two games that took place in the month of november and december\nInput Table: 1976 buffalo bills season\n\n\nweekdateopponentresultattendance11976-09-13miami dolphinsl 30 - 217768321976-09-19houston oilersl 13 - 36138431976-09-26tampa bay buccaneersw 14 - 94450541976-10-03kansas city chiefsw 50 - 175190951976-10-10new york jetsl 17 - 145911061976-10-17baltimore coltsl 31 - 137100971976-10-24new england patriotsl 26 - 224514481976-10-31new york jetsl 19 - 144128591976-11-07new england patriotsl 20 - 1061157101976-11-15dallas cowboysl 17 - 1051799111976-11-21san diego chargersl 34 - 1336539121976-11-25detroit lionsl 27 - 1466875131976-12-05miami dolphinsl 45 - 2743475141976-12-12baltimore coltsl 58 - 2050451\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 2 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE strftime('%m', date) IN ('11', '12');\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1499.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: two of the projects were proposed and listed during 1993 , but were never completed\nInput Table: list of superfund sites in mississippi\n\n\ncerclis_idnamecountyproposedlistedconstruction_completedpartially_deleteddeletedmsd004006995american creosote works , incwinston2001-06-142001-09-139999-01-01--msd008154486chemfax , incharrison1993-06-239999-01-019999-01-01--msd046497012davis timber companylamar2000-05-112000-07-279999-01-01--msd980710941flowood siterankin1983-09-081984-09-211993-09-17-02 / 16 / 1996msd980840045newsom brothers / old reichhold chemicals , incmarion1984-10-151986-06-101997-08-08-09 / 27 / 2000msd065490930picayune wood treatingpearl river2004-03-082004-07-229999-01-01--msd056029648potter cocopiah1993-05-109999-01-019999-01-01--msd086556388sonford productsrankin2006-09-272007-03-079999-01-01--msd980601736walcotte chemical co warehouseswashington9999-01-019999-01-011982-12-30-12 / 30 / 1982\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 2 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE proposed = '1993-01-01' \nAND listed = '1993-01-01' \nAND construction_completed = '9999-01-01';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1393.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: 0.17 is the highest swing to gain points in the scottish parliament election , 2007\nInput Table: scottish parliament general election , 2007\n\n\nrankconstituencywinning_party_2003swing_to_gainsnp_'s_place_2003result1galloway & upper nithsdaleconservative0.172ndcon hold2tweeddale , ettrick & lauderdaleliberal democrats1.012ndld hold3cumbernauld & kilsythlabour1.072ndlab hold4kilmarnock & loudounlabour1.922ndsnp gain5dundee westlabour2.132ndsnp gain6western isleslabour2.912ndsnp gain7glasgow govanlabour2.922ndsnp gain8aberdeen centrallabour2.962ndlab hold9linlithgowlabour3.562ndlab hold10west renfrewshirelabour4.412ndlab hold11paisley southlabour4.912ndlab hold\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN MAX(swing_to_gain) = 0.17 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE result = 'con hold';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-641.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there is more than one classic rock stations\nInput Table: media in kelowna\n\n\nfrequencycall_signbrandingformatowner1150 amckfram 1150news / talkastral media00 88.9 fmcbtk - fmcbc radio onepublic news / talkcanadian broadcasting corporation00 89.7 fmcbu - fm - 3cbc radio 2public musiccanadian broadcasting corporation00 90.5 fmcbuf - fm - 2premi\u00e8re cha\u00eenepublic news / talkcanadian broadcasting corporation00 96.3 fmckko - fmk96.3classic rocksun country cablevision00 99.9 fmchsu - fm99.9 sun fmcontemporary hits radiobell media0 101.5 fmcilk - fm101.5 ez rockadult contemporarybell media0 103.1 fmckqq - fmq103hot adult contemporaryjim pattison group0 103.9 fmcjui - fm103.9 the juiceadult hitsvista broadcast group0 104.7 fmcklz - fmpower 104active rockjim pattison group\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) > 1 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE format = 'classic rock';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-588.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there is 10 games in the 2005 milwaukee brewers season where one team scored no points\nInput Table: 2005 milwaukee brewers season\n\n\ndateopponentscorelossattendancerecord9999-09-01padres5 - 6davis (1 - 1)2478565 - 699999-09-02padres12 - 2lawrence (7 - 14)1823166 - 699999-09-03padres1 - 6obermueller (1 - 3)3202266 - 709999-09-04padres3 - 2otsuka (1 - 6)2004267 - 709999-09-05reds6 - 1belisle (3 - 7)1614468 - 709999-09-06reds1 - 2 (10)de la rosa (2 - 2)1335168 - 719999-09-07reds14 - 5milton (7 - 14)1588669 - 719999-09-09astros7 - 4clemens (11 - 7)1813070 - 719999-09-10astros5 - 7ohka (10 - 8)2443770 - 729999-09-11astros4 - 2oswalt (17 - 12)1739271 - 729999-09-13diamondbacks3 - 1v\u00e3\u00a1zquez (10 - 15)2370872 - 729999-09-14diamondbacks1 - 2 (12)lehr (0 - 1)2379372 - 739999-09-15diamondbacks14 - 2estes (7 - 8)2074173 - 739999-09-16astros1 - 2eveland (1 - 1)3376773 - 749999-09-17astros0 - 7obermueller (1 - 4)3775673 - 759999-09-18astros1 - 6capuano (17 - 10)3505273 - 769999-09-20cubs5 - 3williams (5 - 9)3013674 - 769999-09-21cubs7 - 6van buren (0 - 2)3004975 - 769999-09-22cubs0 - 3helling (2 - 1)3113775 - 779999-09-23cardinals9 - 6carpenter (21 - 5)2247276 - 779999-09-24cardinals8 - 7mulder (16 - 8)3350677 - 779999-09-25cardinals0 - 2davis (11 - 11)2015077 - 789999-09-26reds12 - 9coffey (4 - 1)1441278 - 789999-09-27reds6 - 2claussen (10 - 10)2803179 - 789999-09-28reds4 - 11capuano (18 - 11)2118179 - 799999-09-29reds2 - 0milton (8 - 15)1317380 - 799999-09-30pirates6 - 5vogelsong (2 - 2)2092281 - 79\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 10 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE score LIKE '0 - %';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-625.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: rank 7 has the sum of total for gold less than 1 and silver of 3 in the list\nInput Table: fivb volleyball world league\n\n\nrankgoldsilverbronzetotal194417283314335715415395112461113710128043790101total24242472\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT gold FROM table_sql WHERE rank = 7) < 1 \n             AND (SELECT silver FROM table_sql WHERE rank = 7) = 3 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-683.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: 66 + 68 + 71 = 211 was tom byrum score\nInput Table: 2002 u.s. open (golf)\n\n\nplaceplayercountryscoreto_par1tiger woodsunited states67 + 68 + 70 = 205- 52sergio garc\u00edaspain68 + 74 + 67 = 209- 1t3jeff maggertunited states69 + 73 + 68 = 210et3phil mickelsonunited states70 + 73 + 67 = 210et5robert allenbyaustralia74 + 70 + 67 = 211+ 1t5p\u00e1draig harringtonireland70 + 68 + 73 = 211+ 1t5billy mayfairunited states69 + 74 + 68 = 211+ 1t8nick faldoengland70 + 76 + 66 = 212+ 2t8justin leonardunited states73 + 71 + 68 = 212+ 2t10tom byrumunited states72 + 72 + 70 = 214+ 4t10davis love iiiunited states71 + 71 + 72 = 214+ 4t10scott mccarronunited states72 + 72 + 70 = 214+ 4\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT score FROM table_sql WHERE player = 'tom byrum') = '66 + 68 + 71 = 211' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-227.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: reasons to be pretty was nominated for best play more than one time\nInput Table: reasons to be pretty\n\n\nyearaward_ceremonycategorynomineeresult2009tony awardbest playneil labutenominated2009tony awardbest performance by a leading actor in a playthomas sadoskinominated2009tony awardbest performance by a featured actress in a playmarin irelandnominated2009drama desk awardoutstanding playoutstanding playnominated2009drama desk awardoutstanding actor in a playthomas sadoskinominated2009drama desk awardoutstanding director of a playterry kinneynominated2009theatre world awardtheatre world awardmarin irelandwon\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) > 1 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE category = 'best play' \nAND result = 'nominated';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1707.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: 46 is the value of blank ends when stolen ends is 7\nInput Table: 2005 tim hortons brier\n\n\nlocaleskipwlpfpaends_wonends_lostblank_endsstolen_endsshot_pctalbertarandy ferbey92905848437986%manitobarandy dutiaume8377694744101379%nova scotiashawn adams8380604741161383%quebecjean - michel m\u00e3nard747769544081580%british columbiadeane horning6572654745181280%ontariowayne middaugh657562424610782%newfoundland and labradorbrad gushue6576694845131079%saskatchewanpat simmons656661434512980%prince edward islandrod macdonald476785415112579%northern ontariomike jakubo38648641489679%new brunswickwade blanchard385683414517878%\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT blank_ends FROM table_sql WHERE stolen_ends = 7) = 46 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1186.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: set 3 was 25 - 13 when the total was 75 - 34\nInput Table: 2002 fivb women 's volleyball world championship qualification\n\n\ndatescoreset_1set_2set_3total9999-07-130 - 39 - 2517 - 2512 - 2538 - 759999-07-133 - 025 - 2325 - 1025 - 1375 - 469999-07-143 - 025 - 1325 - 1025 - 1175 - 349999-07-141 - 325 - 2216 - 2515 - 2570 - 979999-07-150 - 316 - 2519 - 2518 - 2553 - 759999-07-153 - 025 - 2325 - 1625 - 1475 - 53\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT set_3 FROM table_sql WHERE total = '75 - 34') = '25 - 13' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-368.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: curtis dickey and randy bielski were picked in round 2\nInput Table: indianapolis colts draft history\n\n\nroundpickoverallnamepositioncollege155curtis dickeyrunning backtexas a&m12424derrick hatchettcornerbacktexas2432ray donaldsoncentergeorgia22351tim foleyoffensive tacklenotre dame4588ray butlerwide receiverusc66144chris footecenterusc75170wes robertsdefensive endtcu82195ken walteroffensive tackletexas tech96227mark brightrunning backtemple105254larry stewartoffensive tacklemaryland113280ed whitleytight endkansas state126311randy bielskiplacekickertowson1219324marvin simsfullbackclemson\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT round FROM table_sql WHERE name = 'curtis dickey') = 2 \n             AND (SELECT round FROM table_sql WHERE name = 'randy bielski') = 2 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-751.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the yugoslavian national team lost the italy against romania with a aggregate score of 3:4\nInput Table: yugoslavia national football team results\n\n\ndatecityopponentresultstype_of_game9999-03-22sarajevouruguay2:1friendly9999-03-30belgraderomania2:0balkan cup9999-04-26borovopoland2:1friendly9999-08-27bucharest , romaniaromania1:4balkan cup9999-09-10luxembourgluxembourg5:01982 wcq9999-09-27ljubljanadenmark2:11982 wcq9999-11-15torino , italyitaly0:21982 wcq\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT results FROM table_sql WHERE opponent = 'italy' AND type_of_game = '1982 wcq') = '0:2' \n             AND (SELECT results FROM table_sql WHERE opponent = 'romania' AND type_of_game = 'balkan cup') = '1:4' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-642.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: bell media owns three separate radio stations like the cbc\nInput Table: media in kelowna\n\n\nfrequencycall_signbrandingformatowner1150 amckfram 1150news / talkastral media00 88.9 fmcbtk - fmcbc radio onepublic news / talkcanadian broadcasting corporation00 89.7 fmcbu - fm - 3cbc radio 2public musiccanadian broadcasting corporation00 90.5 fmcbuf - fm - 2premi\u00e8re cha\u00eenepublic news / talkcanadian broadcasting corporation00 96.3 fmckko - fmk96.3classic rocksun country cablevision00 99.9 fmchsu - fm99.9 sun fmcontemporary hits radiobell media0 101.5 fmcilk - fm101.5 ez rockadult contemporarybell media0 103.1 fmckqq - fmq103hot adult contemporaryjim pattison group0 103.9 fmcjui - fm103.9 the juiceadult hitsvista broadcast group0 104.7 fmcklz - fmpower 104active rockjim pattison group\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE owner = 'bell media') = 3 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-913.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: dwight phillips was the first person to set a long jump record\nInput Table: long jump\n\n\nmarkwindathletenationalityvenuedate8.95 m (29ft4\u00bcin)0.3mike powellunited statestokyo1991-08-308.90 m (29ft2\u00bcin) a2.0bob beamonunited statesmexico city1968-10-188.87 m (29ft1in)0.2carl lewisunited statestokyo1991-08-308.86 m (29ft0\u00bein) a1.9robert emmiyansoviet uniontsakhkadzor1987-05-228.74 m (28ft8in)1.4larry myricksunited statesindianapolis1988-07-188.74 m (28ft8in) a2.0erick walderunited statesel paso1994-04-028.74 m (28ft8in)1.2dwight phillipsunited stateseugene2009-06-078.73 m (28ft7\u00bdin)1.2irving saladinopanamahengelo2008-05-248.71 m (28ft6\u00bein)1.9iv\u00e1n pedrosocubasalamanca1995-07-188.66 m (28ft4\u00bein)1.6lo\u00fais ts\u00e1toumasgreecekalam\u00e1ta2007-06-02\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MIN(date) FROM table_sql) = (SELECT MIN(date) FROM table_sql WHERE athlete = 'dwight phillips') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-474.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: gene borek is from the united states with a score better than 77 + 65 = 142\nInput Table: 1973 u.s. open (golf)\n\n\nplaceplayercountryscoreto_par1gary playersouth africa67 + 70 = 137- 52jim colbertunited states70 + 68 = 138- 4t3jack nicklausunited states71 + 69 = 140- 2t3johnny millerunited states71 + 69 = 140- 2t3bob charlesnew zealand71 + 69 = 140- 2t6gene borekunited states77 + 65 = 142et6julius borosunited states73 + 69 = 142et6tom weiskopfunited states73 + 69 = 142et6arnold palmerunited states71 + 71 = 142et6lee trevinounited states70 + 72 = 142e\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT country FROM table_sql WHERE player = 'gene borek' AND score < 142) = 'united states' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1988.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the match with the highest attendance was against birmingham city\nInput Table: 2000 - 01 sheffield wednesday f.c. season\n\n\ndateopponentvenueresultattendance2000-08-13wolverhampton wanderersa1 - 1190862000-08-19huddersfield townh2 - 3227042000-08-26grimsby towna1 - 077552000-08-28blackburn roversh1 - 1156462000-09-09wimbledonh0 - 5158562000-09-13nottingham foresth0 - 1157002000-09-16tranmere roversa0 - 293522000-09-23preston north endh1 - 3173792000-09-30gillinghama0 - 290992000-10-08west bromwich albionh1 - 2153382000-10-14portsmoutha1 - 2133762000-10-17burnleya0 - 1163722000-10-22birmingham cityh1 - 0146952000-10-25queens park rangersa2 - 1103532000-10-28fulhamh3 - 3175592000-11-04crystal palacea1 - 4153332000-11-07watforda3 - 1111662000-11-01norwich cityh3 - 2169562000-11-18barnsleya0 - 1199892000-11-25crewe alexandraa0 - 171032000-12-02queens park rangersh5 - 2217822000-12-09stockport countyh2 - 4163372000-12-16sheffield uniteda1 - 1251562000-12-23wolverhampton wanderersh0 - 1177872000-12-26bolton wanderersa0 - 2213162000-12-30huddersfield towna0 - 0189312001-01-01grimsby townh1 - 0170042001-01-13blackburn roversa0 - 2193082001-01-20bolton wanderersh0 - 3176382001-02-03watfordh2 - 3161342001-02-10wimbledona1 - 467412001-02-13tranmere roversh1 - 0154442001-02-21nottingham foresta1 - 0232662001-02-24preston north enda0 - 2143792001-03-03gillinghamh2 - 1187022001-03-07portsmouthh0 - 0205032001-03-10west bromwich albiona2 - 1186622001-03-17burnleyh2 - 0201842001-03-24birmingham citya2 - 1197332001-04-01sheffield unitedh1 - 2384332001-04-07stockport countya1 - 296662001-04-14crystal palaceh4 - 1198772001-04-16fulhama1 - 1175002001-04-21barnsleyh2 - 1234982001-04-28norwich citya0 - 1212412001-05-06crewe alexandrah0 - 028007\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN attendance = (SELECT MAX(attendance) FROM table_sql) \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE opponent = 'birmingham city';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-696.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the october 17 , 2004 was the game for week 6 , played at m&t bank stadium\nInput Table: 2004 cleveland browns season\n\n\nweekdateopponentresultstadiumrecordattendance12004-09-12baltimore ravensw 20 - 3cleveland browns stadium1 - 073068.022004-09-19dallas cowboysl 12 - 19texas stadium1 - 163119.032004-09-26new york giantsl 10 - 27giants stadium1 - 278521.042004-10-03washington redskinsw 17 - 13cleveland browns stadium2 - 273348.052004-10-10pittsburgh steelersl 23 - 34heinz field2 - 363609.062004-10-17cincinnati bengalsw 34 - 17cleveland browns stadium3 - 373263.072004-10-24philadelphia eaglesl 31 - 34cleveland browns stadium3 - 473394.089999-01-01----nan92004-11-07baltimore ravensl 13 - 27m&t bank stadium3 - 569781.0102004-11-14pittsburgh steelersl 10 - 24cleveland browns stadium3 - 673703.0112004-11-21new york jetsl 7 - 10cleveland browns stadium3 - 772547.0122004-11-28cincinnati bengalsl 48 - 58paul brown stadium3 - 865677.0132004-12-05new england patriotsl 15 - 42cleveland browns stadium3 - 973028.0142004-12-12buffalo billsl 7 - 37ralph wilson stadium3 - 1072330.0152004-12-19san diego chargersl 0 - 21cleveland browns stadium3 - 1172489.0162004-12-26miami dolphinsl 7 - 10pro player stadium3 - 1273169.0172005-01-02houston texansw 22 - 14reliant stadium4 - 1270724.0\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE date = '2004-10-17' \nAND week = 6 \nAND stadium = 'm&t bank stadium';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "TN/test-1610.html": {
        "method": "Text2SQL",
        "subfolder": "TN",
        "LLM_analysis": "No",
        "Actual_Correctness": "Yes",
        "Model_Prediction": "False",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: during the 2007 - 08 minnesota wild season , the decision was harding more times than it was backstrom\nInput Table: 2007 - 08 minnesota wild season\n\n\ndatevisitorscorehomedecisionattendancerecord01-02-9999minnesota4 - 1columbusbackstrom1852930 - 19 - 39999-02-05detroit3 - 2minnesotabackstrom1856830 - 19 - 401-02-07dallas1 - 0minnesotabackstrom1856830 - 20 - 49999-02-09ny islanders3 - 4minnesotabackstrom1856831 - 20 - 401-02-10minnesota2 - 1st louisharding1647732 - 20 - 401-02-12minnesota2 - 4edmontonharding1683932 - 21 - 401-02-14minnesota5 - 4vancouverbackstrom1863033 - 21 - 49999-02-17nashville4 - 5minnesotabackstrom1856834 - 21 - 49999-02-19vancouver3 - 2minnesotabackstrom1856834 - 21 - 59999-02-20minnesota0 - 3chicagoharding1781234 - 22 - 59999-02-24calgary2 - 1minnesotabackstrom1856834 - 23 - 59999-02-26minnesota1 - 4washingtonbackstrom1739134 - 24 - 59999-02-27minnesota3 - 2tampa baybackstrom1721135 - 24 - 59999-02-29minnesota3 - 2floridabackstrom1692736 - 24 - 5\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE decision = 'harding') > \n             (SELECT COUNT(*) FROM table_sql WHERE decision = 'backstrom') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-1476.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: golden state warriors is the name of the team when the location attendances is hemisfair arena 16057\nInput Table: 1991 - 92 seattle supersonics season\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord589999-03-01cleveland cavaliersw 113 - 107e johnson , r pierce (22)b benjamin , m cage (14)r pierce (6)seattle center coliseum 1364732 - 26599999-03-03denver nuggetsw 111 - 92s kemp (21)s kemp (13)g payton (9)seattle center coliseum 986533 - 26609999-03-05phoenix sunsl 105 - 118r pierce (23)s kemp (19)g payton (12)arizona veterans memorial coliseum 1449633 - 27619999-03-07new jersey netsw 109 - 98r pierce (27)m cage (13)n mcmillan (7)seattle center coliseum 1341934 - 27620000-03-08portland trail blazersl 97 - 109r pierce (28)r pierce (10)g payton (7)memorial coliseum 1288834 - 28639999-03-10detroit pistonsl 92 - 98g payton (19)s kemp (9)n mcmillan (5)seattle center coliseum 1309834 - 29649999-03-11los angeles clippersw 104 - 96r pierce (19)b benjamin , m cage (6)g payton (9)los angeles memorial sports arena 1091235 - 296501-03-15dallas mavericksw 109 - 100r pierce (23)s kemp (15)g payton (8)seattle center coliseum 1216336 - 29660000-03-17golden state warriorsl 107 - 119r pierce (24)s kemp (15)r pierce (5)seattle center coliseum 1316336 - 30679999-03-19houston rocketsw 112 - 91r pierce (22)m cage , s kemp (14)g payton (11)the summit 1512237 - 30689999-03-21san antonio spursl 96 - 101e johnson (23)s kemp (13)d barros , m cage , n mcmillan (4)hemisfair arena 1605737 - 31699999-03-22dallas mavericksw 113 - 105e johnson (31)s kemp (17)n mcmillan (8)reunion arena 1434538 - 31709999-03-24houston rocketsw 128 - 106d mckey (23)m cage , s kemp (11)n mcmillan , g payton (7)seattle center coliseum 1137739 - 31719999-03-27milwaukee bucksw 96 - 95e johnson (21)n mcmillan (7)n mcmillan (6)seattle center coliseum 1145040 - 31729999-03-28new york knicksl 87 - 92s kemp (27)s kemp (12)n mcmillan (6)seattle center coliseum 1481240 - 32\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE location_attendance = 'hemisfair arena 16057' \nAND team = 'san antonio spurs';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-1867.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the solheim cup was hosted in the us on 7 occassions from 1990 through 2013\nInput Table: solheim cup\n\n\nyearvenuewinning_teamscoreusa_captaineurope_captain2013-01-01colorado golf club , colorado , usaeurope18 - 10meg mallonliselotte neumann2011-01-01killeen castle golf resort , irelandeurope15 - 13rosie jonesalison nicholas2009-01-01rich harvest farms , illinois , usaunited states16 - 12beth danielalison nicholas2007-01-01halmstad gk , swedenunited states16 - 12betsy kinghelen alfredsson2005-01-01crooked stick golf club , indiana , usaunited states15\u00bd - 12\u00bdnancy lopezcatrin nilsmark2003-01-01barseb\u00e4ck golf & country club , swedeneurope17\u00bd - 10\u00bdpatty sheehancatrin nilsmark2002-01-01interlachen country club , minnesota , usaunited states15\u00bd - 12\u00bdpatty sheehandale reid2000-01-01loch lomond golf club , scotlandeurope14\u00bd - 11\u00bdpat bradleydale reid1998-01-01muirfield village , ohio , usaunited states16 - 12judy rankinpia nilsson1996-01-01st pierre golf & country club , walesunited states17 - 11judy rankinmickey walker1994-01-01the greenbrier , west virginia , usaunited states13 - 7joanne carnermickey walker1992-01-01dalmahoy country club , scotlandeurope11\u00bd - 6\u00bdkathy whitworthmickey walker1990-01-01lake nona golf & country club , florida , usaunited states11\u00bd - 4\u00bdkathy whitworthmickey walker\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 7 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE venue LIKE '%usa%';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-149.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: all games in the 2007 season were played in the month of october\nInput Table: 2006 texas rangers season\n\n\ndateopponentscorelossattendancerecord9999-09-01indians7 - 2padilla (13 - 9)2377669 - 679999-09-02indians6 - 5volquez (1 - 4)4022269 - 689999-09-03indians5 - 2byrd1966770 - 689999-09-04athletics8 - 1zito2394971 - 689999-09-05athletics5 - 4saarloos2722572 - 689999-09-06athletics9 - 6rupe (0 - 1)1783872 - 699999-09-08mariners7 - 2millwood (14 - 10)2864672 - 709999-09-09mariners3 - 2rheinecker (4 - 6)3345472 - 719999-09-10mariners4 - 2huber3432173 - 719999-09-12tigers3 - 2mahay (1 - 3)2419673 - 729999-09-13tigers11 - 3verlander2467274 - 729999-09-14angels2 - 1volquez (1 - 5)2148874 - 739999-09-15angels2 - 1francisco (0 - 1)3078874 - 749999-09-16angels12 - 6lackey4019675 - 749999-09-17angels8 - 1santana2430376 - 749999-09-18mariners8 - 1hern\u00e1ndez1821477 - 749999-09-19mariners9 - 7wilson (2 - 3)1855177 - 759999-09-20mariners6 - 3tejeda (4 - 4)2600677 - 769999-09-22indians12 - 4byrd2628478 - 769999-09-23indians6 - 3padilla (14 - 10)3835178 - 779999-09-24indians11 - 6millwood (16 - 11)3661778 - 789999-09-25angels8 - 3volquez (1 - 6)3978178 - 799999-09-26angels5 - 2escobar3733979 - 799999-09-27angels6 - 5wilson (2 - 4)3803279 - 809999-09-29mariners6 - 5fruto3076680 - 809999-09-30mariners3 - 1millwood (16 - 12)2331080 - 819999-10-01mariners3 - 2tejeda (5 - 5)2836180 - 82\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE date LIKE '2007-10-%';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-850.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: team brazil is the only football club located on the european continent\nInput Table: list of superleague formula football clubs\n\n\nnofootball_clubcontinentassociated_football_clubseasonsracing_drivers3ac milaneuropeac milan2008 2009 2010robert doornbos giorgio pantano yelmer buurman4ac sparta pragueeuropeac sparta prague2011filip salaquarda5team luxembourgeuropenone2011fr\u00e9d\u00e9ric vervisch6team new zealandoceanianone2011earl bamber7team japanasianone2011duncan tappy8 1 (in 2011)rsc anderlechteuropersc anderlecht2008 2009 2010 2011craig dolby yelmer buurman davide rigon neel jani8team netherlandseuropenone2011robert doornbos10fc basel 1893europefc basel2008 2009 2010max wissel max wissel max wissel12 24 (in 2010)beijing guoanasiabeijing guoan fc2008 2010davide rigon john martin14team brazils americanone2011ant\u00f4nio pizzonia17rangers fceuroperangers fc2008 2009ryan dalziel , james walker john martin24fc midtjyllandeuropefc midtjylland2009kasper andersen24team australiaoceanianone2011john martin31team englandeuropenone2011craig dolby\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE continent = 'europe' \nAND football_club = 'team brazil';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-846.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: team australia is the only football club located in oceania\nInput Table: list of superleague formula football clubs\n\n\nnofootball_clubcontinentassociated_football_clubseasonsracing_drivers3ac milaneuropeac milan2008 2009 2010robert doornbos giorgio pantano yelmer buurman4ac sparta pragueeuropeac sparta prague2011filip salaquarda5team luxembourgeuropenone2011fr\u00e9d\u00e9ric vervisch6team new zealandoceanianone2011earl bamber7team japanasianone2011duncan tappy8 1 (in 2011)rsc anderlechteuropersc anderlecht2008 2009 2010 2011craig dolby yelmer buurman davide rigon neel jani8team netherlandseuropenone2011robert doornbos10fc basel 1893europefc basel2008 2009 2010max wissel max wissel max wissel12 24 (in 2010)beijing guoanasiabeijing guoan fc2008 2010davide rigon john martin14team brazils americanone2011ant\u00f4nio pizzonia17rangers fceuroperangers fc2008 2009ryan dalziel , james walker john martin24fc midtjyllandeuropefc midtjylland2009kasper andersen24team australiaoceanianone2011john martin31team englandeuropenone2011craig dolby\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 1 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE continent = 'oceania' \nAND football_club = 'team australia';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-1456.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: six games had an attendance of over 7000 during the 1993 new york jets season\nInput Table: 1993 new york jets season\n\n\nweekdateopponentresultgame_siteattendance11993-09-05denver broncosl 26 - 20the meadowlands6813021993-09-12miami dolphinsw 24 - 14joe robbie stadium7031441993-09-26new england patriotsw 45 - 7the meadowlands6483651993-10-03philadelphia eaglesl 35 - 30the meadowlands7259361993-10-10los angeles raidersl 24 - 20los angeles memorial coliseum4162781993-10-24buffalo billsl 19 - 10the meadowlands7154191993-10-31new york giantsw 10 - 6giants stadium71659101993-11-07miami dolphinsw 27 - 10the meadowlands71306111993-11-14indianapolis coltsw 31 - 17rca dome47351121993-11-21cincinnati bengalsw 17 - 12the meadowlands64264131993-11-28new england patriotsw 6 - 0foxboro stadium42810141993-12-05indianapolis coltsl 9 - 6the meadowlands45799151993-12-11washington redskinsw 3 - 0robert f kennedy memorial stadium47970161993-12-18dallas cowboysl 28 - 7the meadowlands73233171993-12-26buffalo billsl 16 - 14rich stadium70817181994-01-02houston oilersl 24 - 0houston astrodome61040\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) >= 6 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE attendance > 7000;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-737.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there are more than 2 games that had a scored higher than 10 points\nInput Table: 2008 arizona diamondbacks season\n\n\ndateopponentscorelossattendancerecord9999-09-01cardinals8 - 6mcclellan (2 - 7)3507570 - 679999-09-02cardinals8 - 2petit (3 - 4)2756870 - 689999-09-03cardinals4 - 3perez (2 - 2)2435071 - 689999-09-05dodgers7 - 0haren (14 - 8)5227071 - 699999-09-06dodgers7 - 2webb (19 - 7)4754371 - 709999-09-07dodgers5 - 3rauch (4 - 6)5413771 - 719999-09-08giants6 - 2petit (3 - 5)3025271 - 729999-09-09giants5 - 4rauch (4 - 7)3051871 - 739999-09-10giants4 - 3lyon (2 - 5)3099271 - 749999-09-12reds3 - 2harang (4 - 16)2904672 - 749999-09-13reds3 - 2 (10)pe\u00f1a (1 - 2)4507572 - 759999-09-14reds2 - 1 (10)rauch (4 - 8)2729772 - 769999-09-15giants3 - 1hennessey (1 - 2)2596973 - 769999-09-16giants2 - 0cain (8 - 13)3319574 - 769999-09-17giants7 - 6s\u00e1nchez (9 - 11)2261675 - 769999-09-18giants3 - 2lincecum (17 - 4)3432376 - 769999-09-19rockies3 - 2scherzer (0 - 3)4313776 - 779999-09-20rockies5 - 3fuentes (1 - 5)3828377 - 779999-09-21rockies13 - 4reynolds (2 - 8)3291578 - 779999-09-22cardinals4 - 2wellemeyer (12 - 9)4034979 - 779999-09-23cardinals7 - 4johnson (10 - 10)4001379 - 789999-09-24cardinals4 - 2scherzer (0 - 4)4002979 - 799999-09-25cardinals12 - 3rosales (1 - 1)4050279 - 809999-09-26rockies6 - 4grilli (3 - 3)3495080 - 809999-09-27rockies6 - 4corpas (3 - 4)3323481 - 809999-09-28rockies2 - 1vizca\u00edno (1 - 2)3590882 - 80\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) > 2 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE score > 10;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-814.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: neither team scored for only the first game of the world cup in france\nInput Table: 1998 in paraguayan football\n\n\ndatevenuescorecompreport1998-02-08estadio defensores del chaco asunci\u00f3n , paraguay4 - 0f4501998-03-14qualcomm stadium san diego , united states2 - 2f4511998-03-18estadio ol\u00edmpico universitario mexico city , mexico1 - 1f4521998-03-28yale bowl new haven , united states1 - 1f4531998-04-22stadio ennio tardini parma , italy3 - 1f4541998-05-17olympic stadium tokyo , japan1 - 1kirin cup4551998-05-21kobe universiade memorial stadium kobe , japan1 - 0kirin cup4561998-06-01philips stadion eindhoven , netherlands5 - 1f4571998-06-03steaua stadium bucharest , romania3 - 2f4581998-06-06king baudouin stadium brussels , belgium1 - 0f4591998-06-12stade de la mosson montpellier , france0 - 0world cupreport1998-06-19stade geoffroy - guichard saint - \u00e9tienne , france0 - 0world cupreport1998-06-24stade de toulouse toulouse , france1 - 3world cupreport1998-06-28stade f\u00e9lix bollaert lens , france0 - 0 ( 1 - 0 aet )world cupreport\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT score FROM table_sql WHERE comp = 'world cup' AND rowid = 11) = '0 - 0' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-801.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the only player not from the united states or canada is from norway\nInput Table: 2004 - 05 philadelphia flyers season\n\n\nroundplayerpositionnationalitycollege_/_junior_/_club_team_(league)3rob bellamyright wingunited statesnew england jr coyotes ( ejhl )4r j andersondefenseunited statescentennial high school (minn)4david laliberteright wingcanadaprince edward island rocket ( qmjhl )5chris zarbdefenseunited statestri - city storm ( ushl )5gino piselliniright wingunited statesplymouth whalers ( ohl )6ladislav scurkocenterslovakiaspi\u0161sk\u00e1 nov\u00e1 ves (slovakia)6frederik cabanacentercanadahalifax mooseheads (qmjhl)8martin houlegoaltendercanadacape breton screaming eagles (qmjhl)8travis gawryletzdefensecanadatrail smoke eaters ( bchl )9triston grantleft wingcanadavancouver giants ( whl )9john cartercenterunited statesbrewster bulldogs (emjhl)\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE nationality != 'united states' \nAND nationality != 'canada';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-1347.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the match between south melbourne and richmond drew the smallest crowds of the day\nInput Table: 1962 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddatemelbourne11.18 (84)st kilda11.6 (72)mcg489521962-06-23essendon15.17 (107)geelong10.7 (67)windy hill350001962-06-23collingwood10.14 (74)fitzroy9.11 (65)victoria park264881962-06-23carlton12.9 (81)footscray9.10 (64)princes park324001962-06-23south melbourne10.13 (73)richmond11.13 (79)lake oval170001962-06-23north melbourne10.8 (68)hawthorn10.7 (67)arden street oval84701962-06-23\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT crowd FROM table_sql WHERE home_team = 'south melbourne' AND away_team = 'richmond') = \n             (SELECT MIN(crowd) FROM table_sql) \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-720.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: sco had the lowest amount of transfers at 22\nInput Table: 2008 - 09 rangers f.c. season\n\n\nnatnamemoving_totypetransfer_windowtransfer_feesconicholas gallacher9999-01-01end of contract9999-06-01n / aivory coastlacine cherif9999-01-01end of contract9999-06-01n / ascoalistair park9999-01-01end of contract9999-06-01n / aengmichael donald9999-01-01end of contract9999-06-01n / ascocalum reidford9999-01-01end of contract9999-06-01n / ascochris smith9999-01-01end of contract9999-06-01n / abeljeroen van den broeck9999-01-01end of contract9999-06-01n / aslovakiafilip \u0161ebo9999-01-01transfer9999-06-011 mbelthomas buffel9999-01-01transfer9999-06-01n / aespcarlos cu\u00e9llar9999-01-01transfer9999-06-017.8 mscosteven lennon9999-01-01loan9999-06-01n / ascomark weir9999-01-01loan9999-06-01n / ascoandy webster9999-01-01loan9999-06-01n / arsadean furman9999-01-01loan9999-06-01n / ascoalan lowing9999-01-01loan9999-06-01n / ascopaul emslie9999-01-01loan9999-06-01n / ascoscott gallacher9999-01-01loan9999-06-01n / agabondaniel cousin9999-01-01transfer9999-06-013.5 mscoalan gow9999-01-01loan9999-06-01n / aenglee robinson9999-01-01loan9999-01-01n / ascoandrew shinnie9999-01-01loan9999-01-01n / ascosteven kinniburgh9999-01-01loan9999-01-01n / ascorory loy9999-01-01loan9999-01-01n / ascowilliam mclachlan9999-01-01loan9999-01-01n / ascolee robinson9999-01-01loan9999-01-01n / afrajean - claude darcheville9999-01-01transfer9999-01-01freescojordan mcmillan9999-01-01loan9999-01-01n / ascochris burke9999-01-01transfer9999-01-01freecypgeorgios efrem9999-01-01loan9999-01-01n / ascoalan gow9999-01-01loan9999-01-01n / ascocharlie adam9999-01-01loan9999-01-01n / ascoross harvey9999-01-01loan9999-01-01n / ascosteven kinniburgh9999-01-01loan9999-01-01n / a\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE nat = 'sco' AND type = 'transfer') < 22 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-1379.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: iran has the lowest mideast rank\nInput Table: list of asian and pacific countries by gdp (ppp)\n\n\nrank_mideastrank_asiarank_worldcountry2011_gdp_(ppp)_billions_of_usd1617iran930.2362923saudi arabia677.66331848united arab emirates261.18941950israel235.44652155qatar181.91262258kuwait150.00272360iraq127.34882666syria107.80392976oman81.005103083yemen63.344113184lebanon61.738123597jordan36.8971337104bahrain30.889\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT rank_mideast FROM table_sql WHERE country = 'iran') = \n             (SELECT MIN(rank_mideast) FROM table_sql) \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-1719.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the is no total overall with the name of calvin o'neal , and a round larger than 6\nInput Table: indianapolis colts draft history\n\n\nroundpickoverallnamepositioncollege12626randy burkewide receiverkentucky22553mike ozdowskidefensive endvirginia624163calvin o'neallinebackermichigan726193blanchard carteroffensive tackleunlv825220ken helmsoffensive tacklegeorgia924247glenn capriolarunning backboston college1026277ron bakerguardoklahoma state1125304brian rufflinebackerthe citadel1224331bill deutschrunning backnorth dakota\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE name = 'calvin o''neal' \nAND round > 6;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-193.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: all matches held in november in twickenham , london were tour matches\nInput Table: 1978 new zealand rugby union tour of britain and ireland\n\n\nopposing_teamagainstdatevenuestatuscambridge university121978-10-18grange road , cambridgetour matchcardiff71978-10-21cardiff arms park , cardifftour matchwest wales xv71978-10-25st helen 's , swanseatour matchlondon counties121978-10-28twickenham , londontour matchmunster121978-10-31thomond park , limericktour matchireland61978-11-04lansdowne road , dublintest matchulster71978-11-07ravenhill , belfasttour matchwales121978-11-01cardiff arms park , cardifftest matchsouth and south - west counties01978-11-15memorial ground , bristoltour matchmidland counties151978-11-18welford road , leicestertour matchcombined services61978-11-21aldershot military stadium , aldershottour matchengland61978-11-25twickenham , londontest matchmonmouthshire91978-11-29rodney parade , newporttour matchnorth of england61978-12-02birkenhead park , birkenheadtour matchnorth and midland of scotland31978-12-05linksfield stadium , aberdeentour matchscotland91978-12-09murrayfield , edinburghtest matchbridgend61978-12-13brewery field , bridgendtour matchbarbarians161978-12-16cardiff arms park , cardifftour match\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE venue = 'twickenham , london' \nAND strftime('%m', date) = '11' \nAND status = 'tour match';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-262.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: galina voskoboeva never played the same opponent more than one time except in 6 june 2006\nInput Table: galina voskoboeva\n\n\noutcomedatetournamentsurfaceopponentscorerunner - up2003-01-28tiptonhard (i)matea mezak6 - 4 , 4 - 6 , 4 - 6winner2003-06-29mont - de - marsanhard (i)oleksandra kravets6 - 4 , 6 - 2runner - up2003-10-03latinaclayroberta vinci3 - 6 , 4 - 6runner - up2005-11-08pittsburghhardlilia osterloh6 - 7 , 4 - 6winner2006-06-06cuneo , italyclayalice canepa6 - 1 , 6 - 2\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) > 1 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE opponent = 'alice canepa' \nAND date != '2006-06-06';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-738.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: rosales of arizona diamond have more losses than johnson\nInput Table: 2008 arizona diamondbacks season\n\n\ndateopponentscorelossattendancerecord9999-09-01cardinals8 - 6mcclellan (2 - 7)3507570 - 679999-09-02cardinals8 - 2petit (3 - 4)2756870 - 689999-09-03cardinals4 - 3perez (2 - 2)2435071 - 689999-09-05dodgers7 - 0haren (14 - 8)5227071 - 699999-09-06dodgers7 - 2webb (19 - 7)4754371 - 709999-09-07dodgers5 - 3rauch (4 - 6)5413771 - 719999-09-08giants6 - 2petit (3 - 5)3025271 - 729999-09-09giants5 - 4rauch (4 - 7)3051871 - 739999-09-10giants4 - 3lyon (2 - 5)3099271 - 749999-09-12reds3 - 2harang (4 - 16)2904672 - 749999-09-13reds3 - 2 (10)pe\u00f1a (1 - 2)4507572 - 759999-09-14reds2 - 1 (10)rauch (4 - 8)2729772 - 769999-09-15giants3 - 1hennessey (1 - 2)2596973 - 769999-09-16giants2 - 0cain (8 - 13)3319574 - 769999-09-17giants7 - 6s\u00e1nchez (9 - 11)2261675 - 769999-09-18giants3 - 2lincecum (17 - 4)3432376 - 769999-09-19rockies3 - 2scherzer (0 - 3)4313776 - 779999-09-20rockies5 - 3fuentes (1 - 5)3828377 - 779999-09-21rockies13 - 4reynolds (2 - 8)3291578 - 779999-09-22cardinals4 - 2wellemeyer (12 - 9)4034979 - 779999-09-23cardinals7 - 4johnson (10 - 10)4001379 - 789999-09-24cardinals4 - 2scherzer (0 - 4)4002979 - 799999-09-25cardinals12 - 3rosales (1 - 1)4050279 - 809999-09-26rockies6 - 4grilli (3 - 3)3495080 - 809999-09-27rockies6 - 4corpas (3 - 4)3323481 - 809999-09-28rockies2 - 1vizca\u00edno (1 - 2)3590882 - 80\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT loss FROM table_sql WHERE opponent = 'cardinals' AND record = '79 - 80') > \n             (SELECT loss FROM table_sql WHERE opponent = 'cardinals' AND record = '79 - 78') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-170.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: brazil has transport / utility and attack type aircrafts\nInput Table: uruguayan air force\n\n\naircraftorigintypeversionsin_servicecessna a - 37 dragonflyunited statesattack / fightera - 37b12 (16 delivered)fma ia 58 pucar\u00e3\u00a1argentinaattacka - 585 (6 delivered)lockheed c - 130 herculesunited statestransport / utilityc - 130b2embraer emb 110 bandeirantebraziltransport / utilityc - 953beechcraft twin bonanzaunited statestransport / utilityd501casa c - 212 aviocarspaintransportc - 212 - 2002embraer emb 120 brasiliabraziltransportemb 1201cessna 206 stationairunited statesutility / liaisonu206h10beechcraft b58 baronunited statestrainer / liaisonb - 582british aerospace 125united kingdomvip transport700a 600a2aermacchi sf260italytrainert - 260 eu12pilatus pc - 7 turbo trainerswitzerlandtrainer- 925 (6 delivered)cessna t - 41 mescalerounited statestrainert - 41d7aerospatiale as 365 dauphinfranceliaison / transportas 3651bell 212 twin hueyunited statestransport / utilitybell 2124bell uh - 1 iroquoisunited statestransport / utilityuh - 1h13\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE origin = 'brazil' AND (type = 'transport / utility' OR type = 'attack')) > 0 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-1961.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: 21.16 (142) home team score had a away team of fitzroy\nInput Table: 1982 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddatefootscray7.8 (50)richmond16.16 (112)western oval162591982-08-07fitzroy21.16 (142)st kilda11.12 (78)junction oval99871982-08-07north melbourne22.18 (150)geelong11.16 (82)arden street oval116341982-08-07hawthorn20.20 (140)collingwood16.22 (118)princes park186991982-08-07essendon20.17 (137)melbourne14.17 (101)vfl park283791982-08-07swans15.16 (106)carlton9.18 (72)scg256011982-08-01\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT home_team_score FROM table_sql WHERE home_team = 'fitzroy') = '21.16 (142)' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-1054.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: on may 7th , 1960 the crowd was larger than 23135 that watched an away team score of 3.8 (26) and a home team score of 5.12 (42)\nInput Table: 1960 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddatenorth melbourne5.12 (42)richmond3.8 (26)arden street oval90001960-05-07melbourne16.14 (110)south melbourne6.10 (46)mcg231351960-05-07fitzroy5.11 (41)geelong8.7 (55)brunswick street oval138021960-05-07hawthorn6.9 (45)footscray6.17 (53)glenferrie oval160001960-05-07essendon11.10 (76)collingwood11.8 (74)windy hill300001960-05-07st kilda5.11 (41)carlton7.3 (45)junction oval187001960-05-07\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT crowd FROM table_sql WHERE date = '1960-05-07' AND home_team_score = '5.12 (42)' AND away_team_score = '3.8 (26)') > 23135 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-1425.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: france 's competitors all finished better than 5th\nInput Table: 1976 world junior figure skating championships\n\n\nranknamenationsp_+_fspointsplaces1mark cockerellunited states1172.4211.02takashi murajapan2165.724.03brian pockarcanada3166.6223.04norbert schrammwest germany4159.840.05andrew bestwickunited kingdom5158.148.06stephan brilwest germany7155.7257.07patrice macrezfrance6151.7671.08pierre laminefrance8150.579.09shinji someyajapan10150.3474.510jozef sabov\u010d\u00edkczechoslovakia9148.8887.011daniel fuererswitzerland13146.1892.512gerald schranzaustria11143.04102.013helmut kristofics - binderaustria15137.32123.014michael pasfieldaustralia12136.6119.015francis demarteaubelgium14131.02140.016adrian vasileromania16127.74143.017miljan begovicyugoslavia17127.3143.018jeremy dowsonsouth africa18114.98166.019marc franquetbelgium19114.38167.0\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MIN(rank) FROM table_sql WHERE nation = 'france') < 5 \n        THEN 'FALSE' \n        ELSE 'TRUE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-1339.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the bobcats had a record of more wins than losses\nInput Table: 2009 - 10 charlotte bobcats season\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord4701-02-9999portlandl 79 - 98 (ot)raymond felton (23)gerald wallace (10)stephen jackson (4)rose garden 2010624 - 23489999-02-03la lakersl 97 - 99 (ot)stephen jackson (30)nazr mohammed (17)boris diaw (5)staples center 1899724 - 24499999-02-06new orleansl 99 - 104 (ot)stephen jackson (26)boris diaw (8)raymond felton (7)time warner cable arena 1916424 - 25509999-02-09washingtonw 94 - 92 (ot)stephen jackson (22)nazr mohammed (10)raymond felton (5)time warner cable arena 1237625 - 255101-02-10minnesotaw 93 - 92 (ot)stephen jackson (33)nazr mohammed (20)dj augustin (7)target center 1335226 - 255201-02-16new jerseyl 94 - 103 (ot)gerald wallace (21)gerald wallace , boris diaw (10)stephen jackson (5)time warner cable arena 1371226 - 26539999-02-19clevelandw 110 - 93 (ot)stephen jackson (29)tyrus thomas (12)boris diaw (9)time warner cable arena 1956827 - 26549999-02-20milwaukeel 88 - 93 (ot)stephen jackson (35)tyrus thomas (11)stephen jackson (5)bradley center 1717427 - 27559999-02-22la clippersl 94 - 98 (ot)gerald wallace (32)gerald wallace (12)boris diaw , raymond felton (9)staples center 1589227 - 28569999-02-24utahl 93 - 102 (ot)gerald wallace (27)gerald wallace (8)raymond felton (5)energysolutions arena 1991127 - 29\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE record LIKE '%-%') > \n             (SELECT COUNT(*) FROM table_sql WHERE record LIKE '%-%-%') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-55.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: agricultural panel has the most members from one party\nInput Table: members of the 5th seanad\n\n\npartyadministrative_panelagricultural_panelcultural_and_educational_panelindustrial_and_commercial_panellabour_panelnational_university_of_irelanduniversity_of_dublinnominated_by_the_taoiseachtotalfianna f\u00e1il4423010721fine gael132201009labour party000150028clann na talmhan020010003independent010101339total7115911331160\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MAX(agricultural_panel) FROM table_sql) = \n             (SELECT agricultural_panel FROM table_sql WHERE party = 'fianna f\u00e1il') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-912.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: bob beamon has recently set his long jump record\nInput Table: long jump\n\n\nmarkwindathletenationalityvenuedate8.95 m (29ft4\u00bcin)0.3mike powellunited statestokyo1991-08-308.90 m (29ft2\u00bcin) a2.0bob beamonunited statesmexico city1968-10-188.87 m (29ft1in)0.2carl lewisunited statestokyo1991-08-308.86 m (29ft0\u00bein) a1.9robert emmiyansoviet uniontsakhkadzor1987-05-228.74 m (28ft8in)1.4larry myricksunited statesindianapolis1988-07-188.74 m (28ft8in) a2.0erick walderunited statesel paso1994-04-028.74 m (28ft8in)1.2dwight phillipsunited stateseugene2009-06-078.73 m (28ft7\u00bdin)1.2irving saladinopanamahengelo2008-05-248.71 m (28ft6\u00bein)1.9iv\u00e1n pedrosocubasalamanca1995-07-188.66 m (28ft4\u00bein)1.6lo\u00fais ts\u00e1toumasgreecekalam\u00e1ta2007-06-02\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MAX(date) FROM table_sql WHERE athlete = 'bob beamon') = '1968-10-18' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-30.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: in a game on august 30 , mogler (1 - 10) won while in a game against oquist\nInput Table: 1997 colorado rockies season\n\n\ndateopponentscorelossattendancerecord9999-08-01pirates7 - 6rinc\u00f3n (4 - 5)2265752 - 589999-08-02pirates6 - 5swift (4 - 5)3238852 - 599999-08-03pirates8 - 4reed (3 - 5)2498952 - 609999-08-04phillies7 - 3castillo (8 - 10)1523052 - 619999-08-05phillies4 - 2bottalico (2 - 4)1642853 - 619999-08-06mets4 - 0mlicki (5 - 8)2663354 - 619999-08-07mets12 - 4swift (4 - 6)2953654 - 629999-08-08pirates5 - 3lieber (6 - 12)4826255 - 629999-08-09pirates8 - 7rinc\u00f3n (4 - 6)4832356 - 629999-08-10pirates8 - 7wilkins (7 - 3)4801857 - 629999-08-12phillies5 - 0thomson (4 - 7)4822857 - 639999-08-13phillies12 - 8wright (6 - 8)4849157 - 649999-08-15mets6 - 2reed (10 - 6)4830858 - 649999-08-16mets7 - 5mcmichael (7 - 10)4831159 - 649999-08-17mets6 - 4mlicki (5 - 10)4844060 - 649999-08-19reds6 - 5wright (6 - 9)3172260 - 659999-08-20reds5 - 3white (1 - 1)2196861 - 659999-08-21astros10 - 4bailey (9 - 9)2296261 - 669999-08-22astros9 - 1thomson (5 - 8)3306161 - 679999-08-23astros6 - 3hudek (0 - 2)3237462 - 679999-08-24astros3 - 1wright (6 - 10)2891862 - 689999-08-25reds7 - 6castillo (10 - 11)4814362 - 699999-08-25reds6 - 4hutton (3 - 2)4808162 - 709999-08-26reds9 - 5mart\u00ednez (1 - 1)4806363 - 709999-08-27reds7 - 5remlinger (6 - 6)4803264 - 709999-08-28mariners9 - 5olivares (6 - 9)4842265 - 709999-08-29mariners6 - 5timlin (3 - 3)4817866 - 709999-08-30athletics4 - 3mohler (1 - 10)4830867 - 709999-08-31athletics10 - 4oquist (2 - 5)4804168 - 70\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT loss FROM table_sql WHERE date = '9999-08-30' AND opponent = 'athletics') = 'mohler (1 - 10)' \n             AND (SELECT opponent FROM table_sql WHERE date = '9999-08-31' AND loss = 'oquist (2 - 5)') = 'athletics' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-1794.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: republican is the party with first elected being 1940\nInput Table: united states house of representatives elections , 1942\n\n\ndistrictincumbentpartyfirst_electedresultcandidatescalifornia 2harry lane englebrightrepublican1926-01-01re - electedharry lane englebright (r) unopposedcalifornia 4thomas rolphrepublican1940-01-01re - electedthomas rolph (r) 98.3% archie brown ( w / i ) 1.7%california 7john h tolandemocratic1934-01-01re - electedjohn h tolan (d) unopposedcalifornia 9bertrand w gearhartrepublican1934-01-01re - electedbertrand w gearhart (r) unopposedcalifornia 10alfred j elliottdemocratic1937-01-01re - electedalfred j elliott (d) unopposedcalifornia 17cecil r kingdemocratic1942-08-25re - electedcecil r king (d) unopposedcalifornia 22none (district created)none (district created)9999-01-01new seat republican gainjohn j phillips (r) 57.6% n e west (d) 42.4%\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE party = 'republican' \nAND first_elected = '1940-01-01';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-1956.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the boston celtics acheived their lowest scoring game against the philadelphia 76s\nInput Table: 1984 - 85 boston celtics season\n\n\ngamedateopponentscorelocationrecord339999-01-02new jersey nets110 - 95brendan byrne arena27 - 6349999-01-04new york knicks105 - 94boston garden28 - 6359999-01-07new york knicks108 - 97madison square garden29 - 6369999-01-09chicago bulls111 - 108boston garden30 - 6379999-01-11washington bullets103 - 101boston garden31 - 6389999-01-12atlanta hawks119 - 111the omni32 - 6399999-01-16los angeles lakers104 - 102boston garden33 - 6409999-01-18indiana pacers86 - 91market square arena33 - 7419999-01-20philadelphia 76ers113 - 97boston garden34 - 7429999-01-23seattle supersonics97 - 107boston garden34 - 8439999-01-25indiana pacers125 - 94boston garden35 - 8449999-01-27portland trail blazers128 - 127boston garden36 - 8459999-01-29detroit pistons131 - 130hartford civic center37 - 8469999-01-30philadelphia 76ers104 - 122the spectrum37 - 9\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MIN(score) FROM table_sql WHERE opponent = 'philadelphia 76ers') = \n             (SELECT score FROM table_sql WHERE opponent = 'philadelphia 76ers' ORDER BY score ASC LIMIT 1) \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-478.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: carlton was the away team when they played st kilda\nInput Table: 1927 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddatefootscray10.6 (66)melbourne10.13 (73)western oval110001927-09-10carlton15.16 (106)st kilda7.9 (51)princes park240001927-09-10richmond16.23 (119)hawthorn6.17 (53)punt road oval110001927-09-10south melbourne14.11 (95)geelong15.15 (105)lake oval150001927-09-10fitzroy5.13 (43)essendon14.10 (94)brunswick street oval110001927-09-10north melbourne7.14 (56)collingwood11.16 (82)arden street oval110001927-09-10\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE home_team = 'carlton' \nAND away_team = 'st kilda';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-1680.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: datia 's constituency number is lower than gohad 's by 10\nInput Table: bhind (lok sabha constituency)\n\n\nconstituency_numbernamereserved_for_(_sc_/_st_/_none)districtnumber_of_electorates_(2009)9aternonebhind17733410bhindnonebhind19718311laharnonebhind20583912mehgaonnonebhind21064913gohadscbhind16689320sewdanonedatia13016121bhanderscdatia13960022datianonedatia143593total :total :total :total :1371252\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT constituency_number FROM table_sql WHERE name = 'datia') < \n             (SELECT constituency_number FROM table_sql WHERE name = 'gohad') - 10\n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-1287.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: paphos is the player being released by mkd\nInput Table: 2008 - 09 apoel f.c. season\n\n\nnatnamemoving_totypetransfer_windowtransfer_feesourcegremachlasretiredretirementsummer-contragrcypmakridesmetalurh donetskend of contractsummerfreekerkidanetser\u010dorovi\u0107ael limassolloan returnsummer--cyploukaael limassolend of contractsummerfreekerkidanetgrekapsislevadiakosend of contractsummerfree-cypdaskalakisaek larnacaend of contractsummerfreeapoelnetbraz\u00e9 carlostrofensecontract terminationsummerfreeapoelfccomcycypvourkoudoxa katokopialoansummerfree-cyppanayiotoudigenis morphouloansummerfree-mkdnikolovskiaep paphosmutual consentwinterfree-cyppapathanasiouermis aradippouloanwinterfree-porpaulo costaanorthosis famagustamutual consent loan returnwinterfreeapoelfccomcy\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE nat = 'mkd' \nAND moving_to = 'paphos' \nAND type = 'end of contract';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-621.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the original airdate of episode 7 is 19 april 2008\nInput Table: none\n\n\nepisodeseriesepisode_titleoriginal_air_dateproduction_code271return to genesis2008-04-05201282the suspension2008-04-06202293a team reinvented2008-04-12203304the new captain2008-04-13204315the homecoming2008-04-19205326netherball rules!2008-04-20206337doubts within2008-04-26207348rocket 's decent2008-04-27208359the all - stars2008-05-032093610rocket vs sinedd2008-05-042103711the champions stumble2008-05-102113812last stand2008-05-112123913fluxless2008-05-172134014new order2008-07-262144115revelations2008-07-272154216new rules2008-08-022164317open doors2008-08-032174418warren steps in2008-08-092184519the technodroid v3s2008-08-102194620the fallen star2008-08-162204721coach artegor2008-08-172214822rocket , the midfielder2008-08-232224923destiny2008-08-242235024final preparations2008-08-312245125a team unravels2008-08-31225\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN original_air_date = '2008-04-26' THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE episode = 33;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-1651.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: fitzroy has a higher score than any of the other teams\nInput Table: 1975 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddategeelong14.20 (104)melbourne14.14 (98)kardinia park133281975-06-07st kilda15.9 (99)north melbourne17.19 (121)moorabbin oval178111975-06-07richmond19.14 (128)essendon12.9 (81)mcg494691975-06-07hawthorn19.24 (138)collingwood13.11 (89)princes park238301975-06-07fitzroy15.7 (97)carlton16.10 (106)junction oval162491975-06-07footscray13.11 (89)south melbourne12.15 (87)vfl park140561975-06-07\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MAX(home_team_score) FROM table_sql) > \n             (SELECT MAX(away_team_score) FROM table_sql) \n             AND (SELECT MAX(home_team_score) FROM table_sql) > \n             (SELECT MAX(away_team_score) FROM table_sql WHERE home_team != 'fitzroy') \n             AND (SELECT MAX(home_team_score) FROM table_sql) > \n             (SELECT MAX(away_team_score) FROM table_sql WHERE home_team != 'fitzroy' AND away_team != 'fitzroy') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-321.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the jazz had at least three guards that were on the team during 1979 - 80 , one being james donaldson\nInput Table: utah jazz all - time roster\n\n\nplayernationalitypositionyears_for_jazzschool_/_club_teamadrian dantleyunited statesguard - forward1979-01-01notre damebrad davisunited statesguard1979-01-01marylanddarryl dawkinsunited statescenter1987-01-01maynard evans hspaul dawkinsunited statesguard1979-01-01northern illinoisgreg deaneunited statesguard1979-01-01utahjames donaldsonunited statescenter1993-01-01, 1994-01-01, 1995-01-01washington statejohn drewunited statesguard - forward1982-01-01gardner - webbjohn durenunited statesguard1980-01-01georgetown\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE years_for_jazz LIKE '%1979%' AND position LIKE '%guard%') >= 3 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-514.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: rank 4 is lower than 6:40.02\nInput Table: rowing at the 2008 summer olympics - men 's lightweight double sculls\n\n\nrankrowerscountrytimenotes1pedro fraga , nuno mendesportugal6:39.07sa / b2eyder batista , yunior perezcuba6:40.15sa / b3kazushige ura , daisaku takedajapan6:43.03sc / d4zsolt hirling , tam\u00e3\u00a1s vargahungary6:50.48sc / d5devender kumar khandwal , manjeet singhindia7:02.06sc / d6jang kang - eun , kim hong - kyunsouth korea7:12.17sc / d\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT rank FROM table_sql WHERE rank = 4) < '6:40.02' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-1574.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: jb holmes from the united states and henrik stenson from sweden tied for third place with + 1 to par\nInput Table: 2008 pga championship\n\n\nplaceplayercountryscoreto_par1ben curtisunited states73 + 67 + 68 = 208- 2t2j b holmesunited states71 + 68 + 70 = 209- 1t2henrik stensonsweden71 + 70 + 68 = 209- 1t4sergio garc\u00edaspain69 + 73 + 69 = 211+ 1t4p\u00e1draig harringtonireland71 + 74 + 66 = 211+ 1t4charlie wisouth korea70 + 70 + 71 = 211+ 1t7andr\u00e9s romeroargentina69 + 78 + 65 = 212+ 2t7jeev milkha singhindia68 + 74 + 70 = 212+ 2t9aaron baddeleyaustralia71 + 71 + 71 = 213+ 3t9steve fleschunited states73 + 70 + 70 = 213+ 3t9david tomsunited states72 + 69 + 72 = 213+ 3t9camilo villegascolombia74 + 72 = 67 = 213+ 3\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT to_par FROM table_sql WHERE player = 'j b holmes' AND country = 'united states') = \n             (SELECT to_par FROM table_sql WHERE player = 'henrik stenson' AND country = 'sweden') \n             AND (SELECT place FROM table_sql WHERE player = 'j b holmes' AND country = 'united states') = 't2' \n             AND (SELECT place FROM table_sql WHERE player = 'henrik stenson' AND country = 'sweden') = 't2' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-1133.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: dave sutton has the list league goals in df positions\nInput Table: 1979 - 80 huddersfield town f.c. season\n\n\nnamepositionleague_appsleague_goalsfa_cup_appsfa_cup_goalsleague_cup_appsleague_cup_goalstotal_appstotal_goalsjim branagandf00000 (1)00 (1)0malcolm browndf4622041523david cowlingmf39 (1)10104044 (1)10peter fletcherfw30 (8)17203135 (8)18keith hanveydf3320040392peter hartmf4641140515ian holmesmf6 (4)3004110 (4)4steve kindonfw22 (1)14000022 (1)14mick laverickmf4542040514bernard purdiedf18 (4)0200020 (4)0andy rankingk2400000240ian robinsfw452520425127fred robinsondf3012040361tommy smithfw00001010brian stantonmf4192000439alan starlinggk2202040280dave suttondf4662041527chris toppingdf1302000150\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MAX(league_goals) FROM table_sql WHERE position = 'df') = (SELECT league_goals FROM table_sql WHERE name = 'dave sutton' AND position = 'df') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-909.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: few athletes from the united states have the longest mark\nInput Table: long jump\n\n\nmarkwindathletenationalityvenuedate8.95 m (29ft4\u00bcin)0.3mike powellunited statestokyo1991-08-308.90 m (29ft2\u00bcin) a2.0bob beamonunited statesmexico city1968-10-188.87 m (29ft1in)0.2carl lewisunited statestokyo1991-08-308.86 m (29ft0\u00bein) a1.9robert emmiyansoviet uniontsakhkadzor1987-05-228.74 m (28ft8in)1.4larry myricksunited statesindianapolis1988-07-188.74 m (28ft8in) a2.0erick walderunited statesel paso1994-04-028.74 m (28ft8in)1.2dwight phillipsunited stateseugene2009-06-078.73 m (28ft7\u00bdin)1.2irving saladinopanamahengelo2008-05-248.71 m (28ft6\u00bein)1.9iv\u00e1n pedrosocubasalamanca1995-07-188.66 m (28ft4\u00bein)1.6lo\u00fais ts\u00e1toumasgreecekalam\u00e1ta2007-06-02\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) > 0 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE nationality = 'united states' \nAND mark = (SELECT MAX(mark) FROM table_sql);\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-762.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: milcah chemos record is more than 19:15.06\nInput Table: memorial van damme\n\n\neventrecordathletenationalitydate100 m10.72 ( - 0.3 m / s)shelly - ann fraser - prycejamaica2013-09-06200 m21.64 ( + 0.8 m / s)merlene otteyjamaica1991-09-13400 m48.83sanya richardsunited states2009-09-04800 m1:55.16pamela jelimokenya2008-09-061000 m2:28.98svetlana masterkovarussia1996-08-231500 m3:55.33s\u00fcreyya ayhanturkey2003-09-05mile4:17.75maryam yusuf jamalbahrain2007-09-142000 m5:30.19gelete burkaethiopia2009-09-043000 m8:24.81 +meseret defarethiopia2007-09-14two miles8:58.58meseret defarethiopia2007-09-145000 m14:25.43vivian cheruiyotkenya2008-09-06100 m hurdles12.42 ( - 0.3 m / s)yordanka donkovabulgaria1986-09-05400 m hurdles53.43nezha bidouanemorocco1998-08-283000 m steeplechase9:15.06milcah chemoskenya2013-09-06high jump2.05 manna chicherovarussia2011-09-16pole vault4.93 myelena isinbayevarussia2005-08-26long jump7.25 m ( + 1.7 m / s)heike drechslergermany1991-09-13triple jump15.14 m ( + 0.3 m / s)tatyana lebedevarussia2003-09-05shot put20.57 mnatalya lisovskayasoviet union1987-09-11discus throw69.84 mtsvetanka christovabulgaria1986-09-05javelin throw72.18 m ( old design ) 67.76 m ( current design )fatima whitbread trine hattestadunited kingdom norway1986-09-054100 m relay42.97united statesunited states1988-08-19\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT record FROM table_sql WHERE athlete = 'milcah chemos') > '19:15.06' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-1277.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: attendance of all games at the pepsi center was over 19000\nInput Table: 2009 - 10 denver nuggets season\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord39999-11-01grizzliesw 133 - 123 (ot)carmelo anthony (42)nen\u00ea (9)chauncey billups (12)pepsi center 158233 - 049999-11-03pacersw 111 - 93 (ot)carmelo anthony (25)nen\u00ea (13)anthony carter (5)conseco fieldhouse 106274 - 059999-11-04netsw 122 - 94 (ot)ty lawson (23)kenyon martin (10)chauncey billups (5)izod center 153195 - 079999-11-07hawksl 100 - 125 (ot)carmelo anthony (30)chris andersen (11)chauncey billups (7)philips arena 178015 - 289999-11-10bullsw 90 - 89 (ot)carmelo anthony (20)nen\u00ea (12)chauncey billups (6)united center 214096 - 299999-11-11bucksl 102 - 108 (ot)carmelo anthony (32)carmelo anthony (10)chauncey billups , ty lawson (5)bradley center 129876 - 3109999-11-13lakersw 105 - 79 (ot)carmelo anthony (25)chris andersen (11)chauncey billups (8)pepsi center 191417 - 3119999-11-17raptorsw 130 - 112 (ot)carmelo anthony (32)nen\u00ea (10)chauncey billups (10)pepsi center 164468 - 3129999-11-20clippersl 99 - 106 (ot)carmelo anthony (37)nen\u00ea (12)chauncey billups (7)staples center 181558 - 4139999-11-21bullsw 112 - 93 (ot)carmelo anthony (30)carmelo anthony , kenyon martin (11)carmelo anthony (7)pepsi center 193599 - 4149999-11-24netsw 101 - 87 (ot)carmelo anthony (27)nen\u00ea (9)chauncey billups (7)pepsi center 1630710 - 4159999-11-25timberwolvesw 124 - 111 (ot)carmelo anthony (22)nen\u00ea (8)nen\u00ea , ty lawson (6)target center 1310111 - 4169999-11-27knicksw 128 - 125 (ot)carmelo anthony (50)nen\u00ea , kenyon martin (11)chauncey billups (8)pepsi center 1915512 - 4\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN MIN(location_attendance) > 19000 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE location_attendance != 'NA';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-1486.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: 25 - 26 january 2003 was the only game played in 2003\nInput Table: tsuyoshi fujita\n\n\nseasonevent_typelocationformatdaterank1997 - 98nationalstokyospecial1998-07-0441998 - 99grand prixkyotolimited1999-01-1641998 - 99apac region championshipsingaporespecial1999-03-2731999 - 00grand prixtaipeiextended2000-02-1222000 - 01grand prixkyotoextended2000-11-1212000 - 01grand prixhiroshimalimited2001-01-2762000 - 01pro tourtokyoblock constructed2001-03-1622001 - 02grand prixhong konglimited2001-11-1732001 - 02masterssan diegostandard2002-01-1172001 - 02grand prixfukuokalimited2002-02-1662001 - 02grand prixnagoyateam limited2002-05-1142002 - 03grand prixutsunomiyalimited2002-10-1232002 - 03grand prixhiroshimaextended2003-01-2572002 - 03grand prixbangkokstandard2003-07-1212003 - 04nationalsosakaspecial2004-06-1112003 - 04grand prixkuala lumpurstandard2004-07-2442005grand prixseattleextended2005-03-0572005invitationallos angelesspecial2005-05-1722005pro tourlondonbooster draft2005-07-0822005pro tourlos angelesextended2005-10-2852011pro tournagoyablock constructed and booster draft2011-06-105\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 1 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE date BETWEEN '2003-01-25' AND '2003-01-26';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-2011.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: fitzroy is the team with the highest away team score\nInput Table: 1954 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddategeelong13.12 (90)hawthorn7.6 (48)kardinia park168701954-08-14collingwood12.16 (88)south melbourne13.12 (90)victoria park185561954-08-14carlton10.16 (76)essendon11.14 (80)princes park297441954-08-14richmond10.18 (78)melbourne15.4 (94)punt road oval240001954-08-14north melbourne9.14 (68)footscray9.14 (68)arden street oval220001954-08-14st kilda13.14 (92)fitzroy9.15 (69)junction oval115001954-08-14\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MAX(away_team_score) FROM table_sql) = (SELECT away_team_score FROM table_sql WHERE away_team = 'fitzroy') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-1990.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the matches on april 14 , 2001 and february 24 , 2001 were both victories\nInput Table: 2000 - 01 sheffield wednesday f.c. season\n\n\ndateopponentvenueresultattendance2000-08-13wolverhampton wanderersa1 - 1190862000-08-19huddersfield townh2 - 3227042000-08-26grimsby towna1 - 077552000-08-28blackburn roversh1 - 1156462000-09-09wimbledonh0 - 5158562000-09-13nottingham foresth0 - 1157002000-09-16tranmere roversa0 - 293522000-09-23preston north endh1 - 3173792000-09-30gillinghama0 - 290992000-10-08west bromwich albionh1 - 2153382000-10-14portsmoutha1 - 2133762000-10-17burnleya0 - 1163722000-10-22birmingham cityh1 - 0146952000-10-25queens park rangersa2 - 1103532000-10-28fulhamh3 - 3175592000-11-04crystal palacea1 - 4153332000-11-07watforda3 - 1111662000-11-01norwich cityh3 - 2169562000-11-18barnsleya0 - 1199892000-11-25crewe alexandraa0 - 171032000-12-02queens park rangersh5 - 2217822000-12-09stockport countyh2 - 4163372000-12-16sheffield uniteda1 - 1251562000-12-23wolverhampton wanderersh0 - 1177872000-12-26bolton wanderersa0 - 2213162000-12-30huddersfield towna0 - 0189312001-01-01grimsby townh1 - 0170042001-01-13blackburn roversa0 - 2193082001-01-20bolton wanderersh0 - 3176382001-02-03watfordh2 - 3161342001-02-10wimbledona1 - 467412001-02-13tranmere roversh1 - 0154442001-02-21nottingham foresta1 - 0232662001-02-24preston north enda0 - 2143792001-03-03gillinghamh2 - 1187022001-03-07portsmouthh0 - 0205032001-03-10west bromwich albiona2 - 1186622001-03-17burnleyh2 - 0201842001-03-24birmingham citya2 - 1197332001-04-01sheffield unitedh1 - 2384332001-04-07stockport countya1 - 296662001-04-14crystal palaceh4 - 1198772001-04-16fulhama1 - 1175002001-04-21barnsleyh2 - 1234982001-04-28norwich citya0 - 1212412001-05-06crewe alexandrah0 - 028007\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT result FROM table_sql WHERE date = '2001-04-14') LIKE '%4 - 1%' \n             AND (SELECT result FROM table_sql WHERE date = '2001-02-24') LIKE '%0 - 2%' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-1604.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: during the 2007 - 08 minnesota wild season , minnesota played home two times less than they played away\nInput Table: 2007 - 08 minnesota wild season\n\n\ndatevisitorscorehomedecisionattendancerecord01-02-9999minnesota4 - 1columbusbackstrom1852930 - 19 - 39999-02-05detroit3 - 2minnesotabackstrom1856830 - 19 - 401-02-07dallas1 - 0minnesotabackstrom1856830 - 20 - 49999-02-09ny islanders3 - 4minnesotabackstrom1856831 - 20 - 401-02-10minnesota2 - 1st louisharding1647732 - 20 - 401-02-12minnesota2 - 4edmontonharding1683932 - 21 - 401-02-14minnesota5 - 4vancouverbackstrom1863033 - 21 - 49999-02-17nashville4 - 5minnesotabackstrom1856834 - 21 - 49999-02-19vancouver3 - 2minnesotabackstrom1856834 - 21 - 59999-02-20minnesota0 - 3chicagoharding1781234 - 22 - 59999-02-24calgary2 - 1minnesotabackstrom1856834 - 23 - 59999-02-26minnesota1 - 4washingtonbackstrom1739134 - 24 - 59999-02-27minnesota3 - 2tampa baybackstrom1721135 - 24 - 59999-02-29minnesota3 - 2floridabackstrom1692736 - 24 - 5\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE home = 'minnesota') < \n             (SELECT COUNT(*) FROM table_sql WHERE visitor = 'minnesota') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-717.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: chris burke , was the only player to have a free transfer fee\nInput Table: 2008 - 09 rangers f.c. season\n\n\nnatnamemoving_totypetransfer_windowtransfer_feesconicholas gallacher9999-01-01end of contract9999-06-01n / aivory coastlacine cherif9999-01-01end of contract9999-06-01n / ascoalistair park9999-01-01end of contract9999-06-01n / aengmichael donald9999-01-01end of contract9999-06-01n / ascocalum reidford9999-01-01end of contract9999-06-01n / ascochris smith9999-01-01end of contract9999-06-01n / abeljeroen van den broeck9999-01-01end of contract9999-06-01n / aslovakiafilip \u0161ebo9999-01-01transfer9999-06-011 mbelthomas buffel9999-01-01transfer9999-06-01n / aespcarlos cu\u00e9llar9999-01-01transfer9999-06-017.8 mscosteven lennon9999-01-01loan9999-06-01n / ascomark weir9999-01-01loan9999-06-01n / ascoandy webster9999-01-01loan9999-06-01n / arsadean furman9999-01-01loan9999-06-01n / ascoalan lowing9999-01-01loan9999-06-01n / ascopaul emslie9999-01-01loan9999-06-01n / ascoscott gallacher9999-01-01loan9999-06-01n / agabondaniel cousin9999-01-01transfer9999-06-013.5 mscoalan gow9999-01-01loan9999-06-01n / aenglee robinson9999-01-01loan9999-01-01n / ascoandrew shinnie9999-01-01loan9999-01-01n / ascosteven kinniburgh9999-01-01loan9999-01-01n / ascorory loy9999-01-01loan9999-01-01n / ascowilliam mclachlan9999-01-01loan9999-01-01n / ascolee robinson9999-01-01loan9999-01-01n / afrajean - claude darcheville9999-01-01transfer9999-01-01freescojordan mcmillan9999-01-01loan9999-01-01n / ascochris burke9999-01-01transfer9999-01-01freecypgeorgios efrem9999-01-01loan9999-01-01n / ascoalan gow9999-01-01loan9999-01-01n / ascocharlie adam9999-01-01loan9999-01-01n / ascoross harvey9999-01-01loan9999-01-01n / ascosteven kinniburgh9999-01-01loan9999-01-01n / a\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 1 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE transfer_fee = 'free' \nAND name = 'chris burke';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-431.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: november7 , 2003 is the air date of the episode titled boardroom and a parked place\nInput Table: will & grace (season 5)\n\n\nseriesseasontitledirected_bywritten_byoriginal_air_dateus_viewers_(millions)931and the horse he rode in onjames burrowsadam barr2002-09-2621.5942bacon and eggsjames burrowsalex herschlag2002-10-0320.6953the kid stays out of the picturejames burrowsjhoni marchinko2002-10-1020.2964humongous growthjames burrowskari lizer2002-10-1719.5975it 's the gay pumpkin , charlie brownjames burrowsgary janetti2002-10-3117.2986boardroom and a parked placejames burrowsgail lerner2002-11-0721.1997the needle and the omelet 's donejames burrowstracy poust & jon kinnally2002-11-1419.11008 - 9marry me a little , marry me a little morejames burrowsjeff greenstein & bill wrubel2002-11-2124.310110the honeymoon 's overjames burrowssally bradford2002-12-0519.310211all about christmas evejames burrowsadam barr2002-12-1216.210312field of queensjames burrowskatie palmer2003-01-0916.210413fagmalion part i : gay it forwardjames burrowstracy poust & jon kinnally2003-01-1616.010514fagmalion part ii : attack of the clonesjames burrowsgary janetti2003-01-3015.810615homojojames burrowsbill wrubel2003-02-0616.510716women and children firstjames burrowslaura kightlinger2003-02-1318.710817fagmalion part iii : bye , bye , beardyjames burrowsalex herschlag2003-02-2016.410918fagmalion part iv : the guy who loved mejames burrowsgail lerner2003-03-1315.011019sex , losers , and videotapejames burrowssteve gabriel2003-04-0315.011120leo unwrappedjames burrowssonja warfield2003-04-1714.711221dolls and dollsjames burrowskari lizer2003-04-2417.7\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE original_air_date = '2002-11-07' \nAND title = 'boardroom and a parked place';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-688.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: nick faldo was the only player from ireland\nInput Table: 2002 u.s. open (golf)\n\n\nplaceplayercountryscoreto_par1tiger woodsunited states67 + 68 + 70 = 205- 52sergio garc\u00edaspain68 + 74 + 67 = 209- 1t3jeff maggertunited states69 + 73 + 68 = 210et3phil mickelsonunited states70 + 73 + 67 = 210et5robert allenbyaustralia74 + 70 + 67 = 211+ 1t5p\u00e1draig harringtonireland70 + 68 + 73 = 211+ 1t5billy mayfairunited states69 + 74 + 68 = 211+ 1t8nick faldoengland70 + 76 + 66 = 212+ 2t8justin leonardunited states73 + 71 + 68 = 212+ 2t10tom byrumunited states72 + 72 + 70 = 214+ 4t10davis love iiiunited states71 + 71 + 72 = 214+ 4t10scott mccarronunited states72 + 72 + 70 = 214+ 4\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE country = 'ireland') = 1 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-433.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there are more fords then any other with alfa romeo and matra tying for the least\nInput Table: 1971 south african grand prix\n\n\ndriverconstructorlapstime_/_retiredgridmario andrettiferrari791:47:35.54jackie stewarttyrrell - ford79+ 20.91clay regazzoniferrari79+ 31.43reine wiselllotus - ford79+ 1:09.414chris amonmatra78+ 1 lap2denny hulmemclaren - ford78+ 1 lap7brian redmansurtees - ford78+ 1 lap17jacky ickxferrari78+ 1 lap8graham hillbrabham - ford77+ 2 laps19ronnie petersonmarch - ford77+ 2 laps13henri pescarolomarch - ford77+ 2 laps18rolf stommelensurtees - ford77+ 2 laps15andrea de adamichmarch - alfa romeo75+ 4 laps22emerson fittipaldilotus - ford58engine5john surteessurtees - ford56gearbox6fran\u00e7ois ceverttyrrell - ford45accident9howden ganleybrm42physical24pedro rodr\u00edguezbrm33overheating10dave charltonbrabham - ford31engine16jo siffertbrm31overheating12john lovemarch - ford30differential21jackie pretoriusbrabham - ford22engine20peter gethinmclaren - ford7fuel leak11jo bonniermclaren - ford5suspension23alex soler - roigmarch - ford5engine25\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE constructor LIKE '%ford%') > \n             (SELECT COUNT(*) FROM table_sql WHERE constructor LIKE '%alfa romeo%' OR constructor LIKE '%matra%') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-1073.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the smallest attendance was not at the game against the new england patriots but against baltimore colts\nInput Table: 1976 buffalo bills season\n\n\nweekdateopponentresultattendance11976-09-13miami dolphinsl 30 - 217768321976-09-19houston oilersl 13 - 36138431976-09-26tampa bay buccaneersw 14 - 94450541976-10-03kansas city chiefsw 50 - 175190951976-10-10new york jetsl 17 - 145911061976-10-17baltimore coltsl 31 - 137100971976-10-24new england patriotsl 26 - 224514481976-10-31new york jetsl 19 - 144128591976-11-07new england patriotsl 20 - 1061157101976-11-15dallas cowboysl 17 - 1051799111976-11-21san diego chargersl 34 - 1336539121976-11-25detroit lionsl 27 - 1466875131976-12-05miami dolphinsl 45 - 2743475141976-12-12baltimore coltsl 58 - 2050451\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MIN(attendance) FROM table_sql WHERE opponent = 'baltimore colts') = \n             (SELECT attendance FROM table_sql WHERE opponent = 'new england patriots') \n        THEN 'FALSE' \n        ELSE 'TRUE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-1043.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: takamiyama had the shortest time range between his first and last record , 13 years\nInput Table: list of sumo record holders\n\n\nnametotalfirstlasthighest_rankkotonishiki341990-09-011999-09-01sekiwakekai\u014d321994-05-012000-07-01\u014dzekimus\u014dyama311994-03-012000-09-01\u014dzekihasegawa301965-11-011974-09-01sekiwakekotomitsuki302001-01-012007-07-01\u014dzekiakinoshima271988-11-012000-09-01sekiwaketakamiyama271969-11-011982-09-01sekiwaketakat\u014driki261991-05-012000-05-01sekiwakewakanosato262000-11-012005-09-01sekiwakedaikirin221966-11-011970-09-01\u014dzekitochiazuma ii221997-07-012005-01-01\u014dzekikisenosato222006-07-012011-09-01\u014dzeki\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (julianday(last) - julianday(first)) <= 4745 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE name = 'takamiyama';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-38.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: steve stricker has the best score out of all of the players from the united states\nInput Table: 2006 u.s. open (golf)\n\n\nplaceplayercountryscoreto_par1steve strickerunited states70 + 69 = 139- 12colin montgomeriescotland69 + 71 = 140et3kenneth ferrieengland71 + 70 = 141+ 1t3geoff ogilvyaustralia71 + 70 = 141+ 1t5jim furykunited states70 + 72 = 142+ 2t5p\u00e1draig harringtonireland70 + 72 = 142+ 2t7jason dufnerunited states72 + 71 = 143+ 3t7graeme mcdowellnorthern ireland71 + 72 = 143+ 3t7phil mickelsonunited states70 + 73 = 143+ 3t7arron oberholserunited states75 + 68 = 143+ 3\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MIN(score) FROM table_sql WHERE country = 'united states') = \n             (SELECT score FROM table_sql WHERE player = 'steve stricker') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-1688.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: 34028 was the total attendance on september 11\nInput Table: east carolina pirates football , 1990 - 99\n\n\ndateopponentsiteresultattendance9999-09-05virginia techlane stadium blacksburg , val3 - 38481349999-09-12chattanoogadowdy - ficklen stadium greenville , ncw31 - 0340289999-09-19ohiopeden stadium athens , ohw21 - 14191869999-10-03armydowdy - ficklen stadium greenville , ncw30 - 25406079999-10-10uabdowdy - ficklen stadium greenville , ncw26 - 7310029999-10-17alabamalegion field birmingham , all22 - 23800799999-10-24southern missmm roberts stadium hattiesburg , msl7 - 41240209999-10-31houstondowdy - ficklen stadium greenville , ncl31 - 34268219999-11-05cincinnatinippert stadium cincinnati , ohw24 - 21190989999-11-14louisvilledowdy - ficklen stadium greenville , ncl45 - 63262589999-11-21memphisliberty bowl memorial stadium memphis , tnw34 - 31160529999-01-01all times are in easternall times are in easternall times are in easternall times are in eastern\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT attendance FROM table_sql WHERE date = '9999-09-12') = 34028 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-384.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: more than 100 games were played for the series with the sawhorse dollar trophy\nInput Table: none\n\n\nteamsnametrophyfirst_metgames_playedseries_recordcolumbia - cornellempire state bowlempire cup1889-01-019999-01-0135 - 60 - 3cornell - pennnonetrustee 's cup1893-01-019999-01-0145 - 68 - 5dartmouth - princetonnonesawhorse dollar1897-01-019999-01-0143 - 43 - 4harvard - yalethe gamenone1875-01-019999-01-0156 - 65 - 8princeton - yalenonenone1873-01-019999-01-0150 - 74 - 10\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT games_played FROM table_sql WHERE trophy = 'sawhorse dollar') > 100 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-1447.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the carlton center , in cape town , has 50 floors\nInput Table: list of tallest buildings in africa\n\n\nnamecityyears_as_tallestmetresfeetfloorscarlton centrejohannesburg1973-01-01 - present223.073250kwadukuza egoli hotel tower 1 , trust bank buildingjohannesburg1970-01-01 - 1973-01-01140.045931standard bank buildingjohannesburg1968-01-01 - 1970-01-01138.845534schlesinger buildingjohannesburg9999-01-01110.036121naspers centrecape town9999-01-0193.020522mutual heights buildingcape town1940-01-01 - 1962-01-0191.029818chamber of mines buildingjohannesburg1936-01-01 - 1940-01-0180.026218union buildingspretoria1913-01-01 - 1936-01-0160.019610\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE name = 'carlton centre' \nAND city = 'johannesburg' \nAND floors = 50;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-1392.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: glasgow govan is one the five constituency with result as snp gain\nInput Table: scottish parliament general election , 2007\n\n\nrankconstituencywinning_party_2003swing_to_gainsnp_'s_place_2003result1galloway & upper nithsdaleconservative0.172ndcon hold2tweeddale , ettrick & lauderdaleliberal democrats1.012ndld hold3cumbernauld & kilsythlabour1.072ndlab hold4kilmarnock & loudounlabour1.922ndsnp gain5dundee westlabour2.132ndsnp gain6western isleslabour2.912ndsnp gain7glasgow govanlabour2.922ndsnp gain8aberdeen centrallabour2.962ndlab hold9linlithgowlabour3.562ndlab hold10west renfrewshirelabour4.412ndlab hold11paisley southlabour4.912ndlab hold\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 1 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE result = 'snp gain' \nAND constituency = 'glasgow govan';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-320.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: james donaldson had two stints on the jazz 's roster , totaling five years in total\nInput Table: utah jazz all - time roster\n\n\nplayernationalitypositionyears_for_jazzschool_/_club_teamadrian dantleyunited statesguard - forward1979-01-01notre damebrad davisunited statesguard1979-01-01marylanddarryl dawkinsunited statescenter1987-01-01maynard evans hspaul dawkinsunited statesguard1979-01-01northern illinoisgreg deaneunited statesguard1979-01-01utahjames donaldsonunited statescenter1993-01-01, 1994-01-01, 1995-01-01washington statejohn drewunited statesguard - forward1982-01-01gardner - webbjohn durenunited statesguard1980-01-01georgetown\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE player = 'james donaldson' AND years_for_jazz LIKE '%1993%' AND years_for_jazz LIKE '%1994%' AND years_for_jazz LIKE '%1995%') = 1 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-915.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: on september 22nd 23 , 3380 people witnessed a win against the yankees of 8 - 1\nInput Table: 1997 toronto blue jays season\n\n\ndateopponentscorelossattendancerecord9999-09-01mets3 - 0hentgen (14 - 9)1919665 - 719999-09-02mets8 - 5clemens (20 - 5)1763565 - 729999-09-03mets4 - 2quantrill (6 - 6)1451365 - 739999-09-04rangers6 - 2carpenter (1 - 7)2617865 - 749999-09-05rangers5 - 1pavlik (2 - 4)2712166 - 749999-09-06rangers2 - 1burkett (7 - 12)3123267 - 749999-09-07rangers4 - 0oliver (11 - 11)3021268 - 749999-09-08angels12 - 10james (4 - 5)2577569 - 749999-09-09angels2 - 0hill (7 - 12)2567470 - 749999-09-10athletics3 - 2plesac (1 - 4)476470 - 759999-09-11athletics8 - 7escobar (2 - 1)613570 - 769999-09-12mariners7 - 3clemens (21 - 6)3704470 - 779999-09-13mariners6 - 3ayala (10 - 5)5163171 - 779999-09-14mariners3 - 2risley (0 - 1)4547771 - 789999-09-15mariners7 - 3williams (8 - 14)4168471 - 799999-09-17red sox4 - 3quantrill (6 - 7)2364871 - 809999-09-18red sox3 - 2escobar (3 - 2)2799071 - 819999-09-19yankees3 - 0gooden (8 - 5)3119572 - 819999-09-20yankees4 - 3 (11)janzen (1 - 1)3833272 - 829999-09-21yankees5 - 4 (10)almanzar (0 - 1)4003872 - 839999-09-22yankees8 - 1hentgen (15 - 10)2338072 - 849999-09-23orioles3 - 2clemens (21 - 7)2927672 - 859999-09-24orioles9 - 3daal (1 - 1)2744372 - 869999-09-25orioles4 - 3mussina (15 - 8)2832473 - 869999-09-26red sox3 - 0henry (7 - 3)3415574 - 869999-09-27red sox12 - 5corsi (5 - 3)3740175 - 869999-09-28red sox3 - 2gordon (6 - 10)4025176 - 86\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE date = '9999-09-22' \nAND opponent = 'yankees' \nAND score = '8 - 1';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-202.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: more attended the fitzroy vs north melbourne game than the essendon vs richmond game\nInput Table: 1972 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddatefootscray14.7 (91)st kilda9.11 (65)western oval186551972-07-15fitzroy16.14 (110)north melbourne9.12 (66)junction oval70071972-07-15essendon13.12 (90)richmond17.9 (111)windy hill222511972-07-15carlton20.8 (128)south melbourne8.15 (63)princes park144651972-07-15hawthorn19.14 (128)geelong15.8 (98)glenferrie oval124251972-07-15collingwood10.13 (73)melbourne8.10 (58)vfl park308831972-07-15\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT crowd FROM table_sql WHERE home_team = 'fitzroy' AND away_team = 'north melbourne') > \n             (SELECT crowd FROM table_sql WHERE home_team = 'essendon' AND away_team = 'richmond') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-1793.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there is only one party with candidates being harry lane englebright (r) 57.6% n e west (d) 42.4%\nInput Table: united states house of representatives elections , 1942\n\n\ndistrictincumbentpartyfirst_electedresultcandidatescalifornia 2harry lane englebrightrepublican1926-01-01re - electedharry lane englebright (r) unopposedcalifornia 4thomas rolphrepublican1940-01-01re - electedthomas rolph (r) 98.3% archie brown ( w / i ) 1.7%california 7john h tolandemocratic1934-01-01re - electedjohn h tolan (d) unopposedcalifornia 9bertrand w gearhartrepublican1934-01-01re - electedbertrand w gearhart (r) unopposedcalifornia 10alfred j elliottdemocratic1937-01-01re - electedalfred j elliott (d) unopposedcalifornia 17cecil r kingdemocratic1942-08-25re - electedcecil r king (d) unopposedcalifornia 22none (district created)none (district created)9999-01-01new seat republican gainjohn j phillips (r) 57.6% n e west (d) 42.4%\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 1 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE candidates LIKE '%(r)%' \nAND candidates LIKE '%(d)%';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-1082.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: detroit tied for the highest home team score\nInput Table: 2003 - 04 detroit red wings season\n\n\ndatevisitorscorehomedecisionattendancerecord0002-01-01detroit4 - 1carolinajoseph1705324 - 12 - 4 - 10001-01-03anaheim1 - 3detroitlegace2006625 - 12 - 4 - 10000-01-05nashville0 - 6detroitjoseph2006626 - 12 - 4 - 10001-01-07boston3 - 0detroitjoseph2006626 - 13 - 4 - 10000-01-10detroit1 - 2bostonjoseph1756526 - 13 - 4 - 29999-01-14chicago2 - 4detroitlegace2006627 - 13 - 4 - 20000-01-16phoenix3 - 3detroitjoseph2006627 - 13 - 5 - 29999-01-19detroit1 - 2san josejoseph1736127 - 14 - 5 - 29999-01-21detroit2 - 2anaheimlegace1717427 - 14 - 6 - 29999-01-22detroit5 - 4los angelesjoseph1811828 - 14 - 6 - 29999-01-24detroit2 - 5phoenixjoseph1901928 - 15 - 6 - 29999-01-26detroit2 - 2dallaslegace1853228 - 15 - 7 - 29999-01-29new jersey2 - 5detroitjoseph2006629 - 15 - 7 - 29999-01-31carolina4 - 4detroitlegace2006630 - 15 - 8 - 2\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN MAX(score) = (SELECT MAX(score) FROM table_sql WHERE home = 'detroit') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE home = 'detroit';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-600.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: multiple people were prison escapists and each left the cube alive\nInput Table: cube (film series)\n\n\nnameoccupationgenderprison_connectionplayed_bystatuskazanautistic savantmalekazan prison (russia)andrew milleralive after exiting the cubedavid wortharchitectmaleleavenworth prison (usa)david hewlettdeadquentinpolice officermalesan quentin state prison (usa)maurice dean wintdeadjoan leavenmathematics studentfemaleleavenworth prison (usa)nicole de boerdeaddr helen hollowayfree clinic doctorfemaleholloway women 's prison (uk)nicky guadagnideadrennesprison escapistmalecentre p\u00e3nitentiaire de rennes (france)wayne robsondead\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = (SELECT COUNT(*) FROM table_sql WHERE prison_connection IS NOT NULL AND status = 'alive after exiting the cube') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE prison_connection IS NOT NULL AND status = 'alive after exiting the cube';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-1162.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the detroit pistons won by over ten points in four games during this period of their 2010 - 2011 season\nInput Table: 2010 - 11 detroit pistons season\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord629999-03-01milwaukeel 90 - 92 (ot)rodney stuckey (25)greg monroe , charlie villanueva (9)rodney stuckey (5)bradley center 1136422 - 40639999-03-02minnesotal 105 - 116 (ot)austin daye (22)greg monroe (11)rodney stuckey (10)the palace of auburn hills 1312222 - 41649999-03-06washingtonw 113 - 102 (ot)tayshaun prince (20)greg monroe , rodney stuckey (7)rodney stuckey (9)the palace of auburn hills 1750623 - 41659999-03-09san antoniol 104 - 111 (ot)richard hamilton (20)greg monroe (10)tracy mcgrady (9)at&t center 1858123 - 42669999-03-11oklahoma cityl 94 - 104 (ot)richard hamilton (20)greg monroe (10)greg monroe , rodney stuckey (6)oklahoma city arena 1820323 - 43679999-03-12denverl 101 - 131 (ot)chris wilcox (21)austin daye , ben gordon , greg monroe (6)will bynum (10)pepsi center 1915523 - 44689999-03-16torontow 107 - 93 (ot)richard hamilton (24)greg monroe (10)rodney stuckey (14)the palace of auburn hills 1516624 - 44699999-03-18new yorkw 99 - 95 (ot)tayshaun prince (16)chris wilcox (12)will bynum (5)the palace of auburn hills 2207625 - 44709999-03-20atlantal 96 - 104 (ot)rodney stuckey (22)greg monroe (10)rodney stuckey (8)philips arena 1758025 - 45719999-03-23miamil 94 - 100 (ot)richard hamilton (27)greg monroe (12)rodney stuckey (6)the palace of auburn hills 2207625 - 46729999-03-25clevelandl 91 - 97 (ot)richard hamilton , tayshaun prince (15)chris wilcox , greg monroe (8)rodney stuckey (4)quicken loans arena 1990725 - 47739999-03-26indianaw 100 - 88 (ot)richard hamilton (23)greg monroe (13)richard hamilton , rodney stuckey (6)the palace of auburn hills 1921626 - 47\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) >= 4 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE score LIKE 'w%' \nAND CAST(SUBSTR(score, INSTR(score, ' ') + 1, INSTR(score, '-') - INSTR(score, ' ') - 1) AS INTEGER) > 10;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-1338.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: raymond felton led the team in assists less than four different times\nInput Table: 2009 - 10 charlotte bobcats season\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord4701-02-9999portlandl 79 - 98 (ot)raymond felton (23)gerald wallace (10)stephen jackson (4)rose garden 2010624 - 23489999-02-03la lakersl 97 - 99 (ot)stephen jackson (30)nazr mohammed (17)boris diaw (5)staples center 1899724 - 24499999-02-06new orleansl 99 - 104 (ot)stephen jackson (26)boris diaw (8)raymond felton (7)time warner cable arena 1916424 - 25509999-02-09washingtonw 94 - 92 (ot)stephen jackson (22)nazr mohammed (10)raymond felton (5)time warner cable arena 1237625 - 255101-02-10minnesotaw 93 - 92 (ot)stephen jackson (33)nazr mohammed (20)dj augustin (7)target center 1335226 - 255201-02-16new jerseyl 94 - 103 (ot)gerald wallace (21)gerald wallace , boris diaw (10)stephen jackson (5)time warner cable arena 1371226 - 26539999-02-19clevelandw 110 - 93 (ot)stephen jackson (29)tyrus thomas (12)boris diaw (9)time warner cable arena 1956827 - 26549999-02-20milwaukeel 88 - 93 (ot)stephen jackson (35)tyrus thomas (11)stephen jackson (5)bradley center 1717427 - 27559999-02-22la clippersl 94 - 98 (ot)gerald wallace (32)gerald wallace (12)boris diaw , raymond felton (9)staples center 1589227 - 28569999-02-24utahl 93 - 102 (ot)gerald wallace (27)gerald wallace (8)raymond felton (5)energysolutions arena 1991127 - 29\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE team = 'charlotte bobcats' AND high_assists < 4) < 4 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-407.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: secteur 6 won agains the enugu rangers\nInput Table: 1971 african cup of champions clubs\n\n\nteam_1aggteam_21st_leg2nd_legal - merrikh2 - 2 (5 - 4 pen)tele sc asmara9999-01-029999-01-01abaluhya united1 - 3great olympics9999-01-019999-01-01asc diaraf3 - 4stade malien9999-03-019999-01-01maseru united3 - 5mmm tamatave9999-01-029999-02-03as porto novo0 - 3victoria club mokanda9999-01-019999-01-02canon yaound\u00e99 - 4as solidarit\u00e99999-07-039999-01-02esp\u00e9rance1 - 0al - ahly (benghazi)9999-01-019999-01-01secteur 61 - 2enugu rangers9999-01-019999-01-01young africans2 - 0lavori publici9999-01-019999-01-01\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT team_1 FROM table_sql WHERE team_1 = 'secteur 6' AND team_2 = 'enugu rangers') IS NOT NULL \n             AND (SELECT agg FROM table_sql WHERE team_1 = 'secteur 6' AND team_2 = 'enugu rangers') = '1 - 2' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-1460.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: during the 1993 new york jets season , the new york jets played eight games at the game site name the robert f kennedy memorial stadium\nInput Table: 1993 new york jets season\n\n\nweekdateopponentresultgame_siteattendance11993-09-05denver broncosl 26 - 20the meadowlands6813021993-09-12miami dolphinsw 24 - 14joe robbie stadium7031441993-09-26new england patriotsw 45 - 7the meadowlands6483651993-10-03philadelphia eaglesl 35 - 30the meadowlands7259361993-10-10los angeles raidersl 24 - 20los angeles memorial coliseum4162781993-10-24buffalo billsl 19 - 10the meadowlands7154191993-10-31new york giantsw 10 - 6giants stadium71659101993-11-07miami dolphinsw 27 - 10the meadowlands71306111993-11-14indianapolis coltsw 31 - 17rca dome47351121993-11-21cincinnati bengalsw 17 - 12the meadowlands64264131993-11-28new england patriotsw 6 - 0foxboro stadium42810141993-12-05indianapolis coltsl 9 - 6the meadowlands45799151993-12-11washington redskinsw 3 - 0robert f kennedy memorial stadium47970161993-12-18dallas cowboysl 28 - 7the meadowlands73233171993-12-26buffalo billsl 16 - 14rich stadium70817181994-01-02houston oilersl 24 - 0houston astrodome61040\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE game_site = 'robert f kennedy memorial stadium';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-525.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: \u9322 and \u65a4 are the only characters that have metric values measured in g\nInput Table: chinese units of measurement\n\n\njyutpingcharacterportugueserelative_valuemetric_valueimperial_valuelei4\u5398liz1 / 160037.79931 mg~0.2133 drfan1\u5206condorim1 / 1600377.9936375 mg~0.2133 drcin4\u9322maz1 / 1603.779936375 g~2.1333drloeng2\u5169tael1 / 1637.79936375 g~1.3333ozgan1\u65a4cate1604.78982 g~1.3333lbdaam3\u62c5 / \u64d4pico10060.478982 kg~133.3333lb\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 2 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE metric_value LIKE '%g' \nAND character IN ('\u9322', '\u65a4');\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-921.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the blue jays scored twelve runs one time during the month\nInput Table: 1997 toronto blue jays season\n\n\ndateopponentscorelossattendancerecord9999-09-01mets3 - 0hentgen (14 - 9)1919665 - 719999-09-02mets8 - 5clemens (20 - 5)1763565 - 729999-09-03mets4 - 2quantrill (6 - 6)1451365 - 739999-09-04rangers6 - 2carpenter (1 - 7)2617865 - 749999-09-05rangers5 - 1pavlik (2 - 4)2712166 - 749999-09-06rangers2 - 1burkett (7 - 12)3123267 - 749999-09-07rangers4 - 0oliver (11 - 11)3021268 - 749999-09-08angels12 - 10james (4 - 5)2577569 - 749999-09-09angels2 - 0hill (7 - 12)2567470 - 749999-09-10athletics3 - 2plesac (1 - 4)476470 - 759999-09-11athletics8 - 7escobar (2 - 1)613570 - 769999-09-12mariners7 - 3clemens (21 - 6)3704470 - 779999-09-13mariners6 - 3ayala (10 - 5)5163171 - 779999-09-14mariners3 - 2risley (0 - 1)4547771 - 789999-09-15mariners7 - 3williams (8 - 14)4168471 - 799999-09-17red sox4 - 3quantrill (6 - 7)2364871 - 809999-09-18red sox3 - 2escobar (3 - 2)2799071 - 819999-09-19yankees3 - 0gooden (8 - 5)3119572 - 819999-09-20yankees4 - 3 (11)janzen (1 - 1)3833272 - 829999-09-21yankees5 - 4 (10)almanzar (0 - 1)4003872 - 839999-09-22yankees8 - 1hentgen (15 - 10)2338072 - 849999-09-23orioles3 - 2clemens (21 - 7)2927672 - 859999-09-24orioles9 - 3daal (1 - 1)2744372 - 869999-09-25orioles4 - 3mussina (15 - 8)2832473 - 869999-09-26red sox3 - 0henry (7 - 3)3415574 - 869999-09-27red sox12 - 5corsi (5 - 3)3740175 - 869999-09-28red sox3 - 2gordon (6 - 10)4025176 - 86\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE score LIKE '%12%'\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-77.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the latitude for the township janke is - 97.945530\nInput Table: list of townships in north dakota\n\n\ntownshipcountypop_(2010)land_(_sqmi_)water_(sqmi)latitudelongitudegeo_idansi_codejacksonsargent3335.8090.046.066276- 97.94553038081404601036797james hillmountrail3231.824.24348.423125- 102.42993438061405001037048james river valleydickey4028.5970.046.246641- 98.18832938021405401036767jankelogan2835.9950.16346.415512- 99.13170138047406201037193jeffersonpierce4535.0691.12548.232149- 100.18237038069407001759556jim river valleystutsman3834.1341.74647.112388- 98.77847838093407801036484johnsonwells3635.2990.90847.377745- 99.45867738103408201037137johnstowngrand forks7936.1990.048.151362- 97.44903338035409401036624joliettepembina6770.0440.77148.796545- 97.21722738067410201036723\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN latitude = 46.415512 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE township = 'janke';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-1324.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: thomas j , hatem was the incubant candidate for maryland district 1\nInput Table: united states house of representatives elections , 1974\n\n\ndistrictincumbentpartyfirst_electedresultcandidatesmaryland 1robert baumanrepublican1973-01-01re - electedrobert bauman (r) 53.0% thomas j hatem (d) 47.0%maryland 2clarence longdemocratic1962-01-01re - electedclarence long (d) 77.1% john m seney (r) 22.9%maryland 4marjorie holtrepublican1972-01-01re - electedmarjorie holt (r) 58.1% fred l wineland (d) 41.9%maryland 6goodloe byrondemocratic1970-01-01re - electedgoodloe byron (d) 73.7% elton r wampler (r) 26.3%maryland 7parren mitchelldemocratic1970-01-01re - electedparren mitchell (d) unopposed\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE district = 'maryland 1' \nAND candidates LIKE '%thomas j hatem%' \nAND result = 're - elected';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-666.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: march is featured more often as a month in the date than any other month , followed by the 4 games in april\nInput Table: 2008 - 09 bradford city a.f.c. season\n\n\ngamedateopponentvenueresultattendance12008-08-09notts countyhome2 - 11403822008-08-16macclesfield townaway2 - 0255632008-08-23rochdalehome2 - 01315442008-08-30aldershot townaway2 - 3380552008-09-06port valeaway2 - 0727362008-09-13exeter cityhome4 - 11268372008-09-20bournemouthhome1 - 31282482008-09-27shrewsbury townaway0 - 2651792008-10-04luton townhome1 - 113083102008-10-11accrington stanleyaway3 - 23012112008-10-18gillinghamhome2 - 212432122008-10-21darlingtonaway1 - 23034132008-10-24grimsby townaway3 - 14470142008-10-28buryhome1 - 012830152008-11-01barnethome3 - 312510162008-11-15wycombe wanderersaway0 - 15002172008-11-22rotherham unitedaway2 - 04586182008-11-25chesterfieldhome3 - 212145192008-12-06dagenham & redbridgehome1 - 112145202008-12-13brentfordaway1 - 24339212008-12-20chester cityhome0 - 012092222008-12-26lincoln cityaway0 - 06156232008-12-28morecambehome4 - 013105242009-01-03shrewsbury townhome0 - 012877252009-01-17accrington stanleyhome1 - 112172262009-01-24luton townaway3 - 36053272009-01-27buryaway0 - 14112282009-01-31grimsby townhome2 - 012816292009-02-07gillinghamaway2 - 04866302009-02-14wycombe wanderershome1 - 012689312009-02-17darlingtonhome0 - 012782322009-02-21barnetaway1 - 42445332009-02-28notts countyaway1 - 35138342009-03-01macclesfield townhome1 - 011908352009-03-07aldershot townhome5 - 012465362009-03-10rochdaleaway0 - 35157372009-03-14exeter cityaway0 - 15253382009-03-17bournemouthaway1 - 44847392009-03-21port valehome0 - 112436402009-03-28chester cityaway0 - 02735412009-04-04brentfordhome1 - 112832422009-04-10morecambeaway1 - 24546432009-04-13lincoln cityhome1 - 112932\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE date LIKE '%-03-%') > \n             (SELECT COUNT(*) FROM table_sql WHERE date LIKE '%-04-%') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-1470.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: emi watanabe was ranked third in the 1979 world figure skating championships , two places higher than dagmar lurz\nInput Table: 1979 world figure skating championships\n\n\nranknamenationsp_+_fspointsplaces1linda fratianneunited states1186.92112anett p\u00f6tzscheast germany3184.36183emi watanabejapan4180.52314dagmar lurzwest germany6179.96335denise biellmannswitzerland2177.28496lisa - marie allenunited states5176.68547claudia kristofics - binderaustria7175.44638susanna drianoitaly9173.46709carola wei\u00dfenbergeast germany11170.548810kristiina wegeliusfinland15169.269811carrie rughunited states10169.349712sanda dubrav\u010di\u0107yugoslavia8166.9611513natalia strelkovasoviet union16164.9413414deborah cottrillunited kingdom20164.813615karin riedigerwest germany17164.514216renata baierovaczechoslovakia13164.014417petra ernertwest germany14163.2414918kira ivanovasoviet union12164.0214719janet morrisseycanada18162.0416220reiko kobayashijapan21161.317021jeanne chapmannorway19161.816622anita siegfriedswitzerland26150.3420723astrid jansen in de walnetherlands25149.1821624franca bianconiitaly22149.0421825bodil olssonsweden23147.0222526corine wyrschswitzerland27146.7623327kim myo silnorth korea24145.4823728belinda coulthardaustralia28145.9223829katie symmondsnew zealand29134.5826130shin hae sooksouth korea30120.4427031gloria masspain31112.28279\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT rank FROM table_sql WHERE name = 'emi watanabe') < \n             (SELECT rank FROM table_sql WHERE name = 'dagmar lurz') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-121.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: luk\u00e1\u0161 melich 's highest finish was as a junior\nInput Table: luk\u00e1\u0161 melich\n\n\nyearcompetitionvenuepositionnotes1998-01-01world junior championshipsannecy , france10th61.51 m1999-01-01european junior championshipsriga , latvia5th64.20 m2001-01-01european u23 championshipsamsterdam , netherlands11th66.41 m2003-01-01universiadedaegu , south korea4th71.26 m2005-01-01world championshipshelsinki , finland14th74.53 m2006-01-01european championshipsgothenburg , sweden15th73.77 m2008-01-01olympic gamesbeijing , pr china29th70.56 m2009-01-01world championshipsberlin , germany14th74.47 m2012-01-01olympic gameslondon , great britain6th77.17 m2013-01-01world championshipsmoscow , russia3rd79.36 m\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MIN(position) FROM table_sql WHERE year < '2000-01-01') = (SELECT position FROM table_sql WHERE year < '2000-01-01' ORDER BY position ASC LIMIT 1) \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-204.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: more than half of the away teams had a score greater than 10\nInput Table: 1972 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddatefootscray14.7 (91)st kilda9.11 (65)western oval186551972-07-15fitzroy16.14 (110)north melbourne9.12 (66)junction oval70071972-07-15essendon13.12 (90)richmond17.9 (111)windy hill222511972-07-15carlton20.8 (128)south melbourne8.15 (63)princes park144651972-07-15hawthorn19.14 (128)geelong15.8 (98)glenferrie oval124251972-07-15collingwood10.13 (73)melbourne8.10 (58)vfl park308831972-07-15\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE away_team_score > 10) > (SELECT COUNT(*)/2 FROM table_sql) \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-1300.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: none of the athletes received a medal for pommel horse\nInput Table: list of multiple olympic medalists\n\n\nmedal_countdateathletenationsportrecord_medal_event11896-04-06james connollyunited statesathleticstriple jump g11896-04-06alexandre tuff\u00e8refranceathleticstriple jump s11896-04-06ioannis persakisgreeceathleticstriple jump b11896-04-06robert garrettunited statesathleticsdiscus g11896-04-06panagiotis paraskevopoulosgreeceathleticsdiscus s11896-04-06sotirios versisgreeceathleticsdiscus b21896-04-07robert garrettunited statesathleticslong jump s21896-04-07james connollyunited statesathleticslong jump b31896-04-07robert garrettunited statesathleticsshot put g31896-04-09carl schuhmanngermanygymnasticsvault g31896-04-09hermann weing\u00e4rtnergermanygymnasticsvault b41896-04-09hermann weing\u00e4rtnergermanygymnasticspommel horse s51896-04-09hermann weing\u00e4rtnergermanygymnasticsrings s61896-04-09hermann weing\u00e4rtnergermanygymnasticshorizontal bar g61900-07-16robert garrettunited statesathleticsstanding triple jump b61904-09-03ray ewryunited statesathleticsstanding triple jump g71908-07-20ray ewryunited statesathleticsstanding long jump g81908-07-23ray ewryunited statesathleticsstanding high jump g81920-07-29carl osburnunited statesshootingteam 300 m / 600 m military rifle , prone g91920-07-30carl osburnunited statesshooting300 m military rifle , standing g101920-07-31carl osburnunited statesshootingteam free rifle g111924-06-27carl osburnunited statesshooting600 m free rifle s111928-08-03paavo nurmifinlandathletics5000 m s121928-08-04paavo nurmifinlandathletics3000 m steeplechase s121960-09-02edoardo mangiarottiitalyfencingteam foil s131960-09-09edoardo mangiarottiitalyfencingteam \u00e9p\u00e9e g131964-10-21larisa latyninasoviet uniongymnasticsteam g141964-10-21larisa latyninasoviet uniongymnasticsall - around s151964-10-22larisa latyninasoviet uniongymnasticsvault s161964-10-22larisa latyninasoviet uniongymnasticsuneven bars b171964-10-23larisa latyninasoviet uniongymnasticsbalance beam b181964-10-23larisa latyninasoviet uniongymnasticsfloor exercise g182012-07-31michael phelpsunited statesswimming200 m butterfly s192012-07-31michael phelpsunited statesswimming4 x 200 m freestyle g202012-08-02michael phelpsunited statesswimming200 m individual medley g212012-08-03michael phelpsunited statesswimming100 m butterfly g222012-08-04michael phelpsunited statesswimming4 100 m medley relay g\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE record_medal_event = 'pommel horse';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-1875.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the solheim cup was hosted in the united states six times from 1990 - 2013\nInput Table: solheim cup\n\n\nyearvenuewinning_teamscoreusa_captaineurope_captain2013-01-01colorado golf club , colorado , usaeurope18 - 10meg mallonliselotte neumann2011-01-01killeen castle golf resort , irelandeurope15 - 13rosie jonesalison nicholas2009-01-01rich harvest farms , illinois , usaunited states16 - 12beth danielalison nicholas2007-01-01halmstad gk , swedenunited states16 - 12betsy kinghelen alfredsson2005-01-01crooked stick golf club , indiana , usaunited states15\u00bd - 12\u00bdnancy lopezcatrin nilsmark2003-01-01barseb\u00e4ck golf & country club , swedeneurope17\u00bd - 10\u00bdpatty sheehancatrin nilsmark2002-01-01interlachen country club , minnesota , usaunited states15\u00bd - 12\u00bdpatty sheehandale reid2000-01-01loch lomond golf club , scotlandeurope14\u00bd - 11\u00bdpat bradleydale reid1998-01-01muirfield village , ohio , usaunited states16 - 12judy rankinpia nilsson1996-01-01st pierre golf & country club , walesunited states17 - 11judy rankinmickey walker1994-01-01the greenbrier , west virginia , usaunited states13 - 7joanne carnermickey walker1992-01-01dalmahoy country club , scotlandeurope11\u00bd - 6\u00bdkathy whitworthmickey walker1990-01-01lake nona golf & country club , florida , usaunited states11\u00bd - 4\u00bdkathy whitworthmickey walker\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 6 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE venue LIKE '%usa%' \nAND year BETWEEN 1990 AND 2013;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-293.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: clubs belenenses , benfica and sporting cp are three of four places with lisbon as the city\nInput Table: 2004 - 05 primeira liga\n\n\nclubhead_coachcitystadium2003_-_2004_seasonacad\u00e9mica de coimbrajo\u00e3o carlos pereiracoimbraest\u00e1dio cidade de coimbra13th in the ligabelenensescarlos carvalhallisbonest\u00e1dio do restelo15th in the ligabenficagiovanni trapattonilisbonest\u00e1dio da luz2nd in the ligaboavistajaime pachecoportoest\u00e1dio do bessa - s\u00e9culo xxi8th in the ligabragajesualdo ferreirabragaest\u00e1dio municipal de braga - axa5th in the ligaestoril - praialitosestorilest\u00e1dio ant\u00f3nio coimbra da mota1st in the liga de honragil vicentelu\u00eds camposbarcelosest\u00e1dio cidade de barcelos12th in the ligauni\u00e3o de leiriav\u00edtor pontesleiriaest\u00e1dio dr magalh\u00e3es pessoa10th in the ligapenafielmanuel fernandespenafielest\u00e1dio municipal 25 de abril3rd in the liga de honramar\u00edtimomanuel cajudafunchalest\u00e1dio dos barreiros6th in the liganacionalcasemiro miorfunchalest\u00e1dio da madeira4th in the ligabeira - marmick wadsworthaveiroest\u00e1dio municipal de aveiro11th in the ligamoreirensev\u00edtor oliveiraguimar\u00e3esest\u00e1dio do moreirense9th in the ligaportoluigi delneriportoest\u00e1dio do drag\u00e3o1st in the ligasporting cpjos\u00e9 peseirolisbonest\u00e1dio jos\u00e9 alvalade - s\u00e9culo xxi3rd in the ligario avecarlos britovila do condeest\u00e1dio dos arcos7th in the ligavit\u00f3ria de guimar\u00e3esmanuel machadoguimar\u00e3esest\u00e1dio d afonso henriques14th in the ligavit\u00f3ria de set\u00fabaljos\u00e9 couceiroset\u00fabalest\u00e1dio do bonfim2nd in the liga de honra\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 3 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE city = 'lisbon' \nAND club IN ('belenenses', 'benfica', 'sporting cp');\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-532.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: kardinia park is one of the four venues that were put to use on 3 june , 1961\nInput Table: 1961 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddatenorth melbourne9.14 (68)st kilda11.16 (82)arden street oval130001961-06-03hawthorn10.13 (73)richmond8.12 (60)glenferrie oval150001961-06-03collingwood18.11 (119)essendon8.10 (58)victoria park282901961-06-03geelong13.13 (91)footscray4.14 (38)kardinia park186831961-06-03south melbourne7.8 (50)fitzroy17.15 (117)lake oval145001961-06-03melbourne15.14 (104)carlton11.13 (79)mcg496781961-06-03\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE date = '1961-06-03' \nAND (venue = 'kardinia park' OR venue = 'arden street oval' OR venue = 'glenferrie oval' OR venue = 'victoria park');\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-60.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: peter lowry 's pick number was 25\nInput Table: 2008 mls superdraft\n\n\npickmls_teamplayerpositionaffiliation15san jose earthquakesshea salinasmfurman carolina dynamo16new york red bullseric brunnerdohio state michigan bucks17real salt lakealex nimofgeneration adidas18new england revolutionmichael videiramduke cary railhawks u23 's19fc dallaseric avilamuc santa barbara ventura county fusion20columbus crewgeorge jostenm / fgonzaga michigan bucks21los angeles galaxyely allenf / mwashington22columbus crewricardo pierre - louisflee university cape cod crusaders23kansas city wizardsyomby williamdold dominion hampton roads piranhas24dc unitedandrew jacobsonmcalifornia25kansas city wizardsjonathan leathersdfurman atlanta silverbacks u23 's26chicago firepeter lowrym / fsanta clara san jose frogs27new england revolutionjoe germanesemduke cary railhawks u23 's28toronto fcbrian edwardsgkwake forest\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT pick FROM table_sql WHERE player = 'peter lowry') = 26 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-9.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the most the wildcats outscored an opponent is by 26 points\nInput Table: 1947 kentucky wildcats football team\n\n\ngamedateopponentresultwildcats_pointsopponentsrecord19999-09-20ole missloss7140 - 129999-09-27cincinnatiwin2001 - 139999-10-04xavierwin2072 - 149999-10-119 georgiawin2603 - 1 , 2059999-10-1810 vanderbiltwin1404 - 1 , 1469999-10-25michigan statewin765 - 1 , 1379999-11-0118 alabamaloss0135 - 289999-11-08west virginiawin1566 - 299999-11-15evansvillewin3607 - 2109999-11-22tennesseeloss6137 - 3\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MAX(wildcats_points - opponents) FROM table_sql) >= 26 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-279.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the toronto blue jays played in 8 games with an attendance lower than 5000 in may of the 1991 season\nInput Table: 1991 toronto blue jays season\n\n\ndateopponentscorelossattendancerecord9999-05-01rangers3 - 0key (4 - 1)3343912 - 109999-05-02royals3 - 1appier (1 - 4)2289613 - 109999-05-03royals5 - 1davis (2 - 2)2080914 - 109999-05-04royals6 - 5boucher (0 - 2)2262814 - 119999-05-05royals3 - 0gordon (1 - 2)2258815 - 119999-05-07rangers3 - 2key (4 - 2)4462215 - 129999-05-08rangers4 - 2ryan (3 - 3)4321116 - 129999-05-09white sox2 - 0p\u00e3rez (1 - 2)4723617 - 129999-05-10white sox5 - 3 (12)fraser (0 - 1)5019817 - 139999-05-11white sox5 - 2hough (0 - 2)5020618 - 139999-05-12white sox4 - 2hibbard (2 - 1)5010819 - 139999-05-13royals4 - 2davis (2 - 4)4427520 - 139999-05-14royals4 - 1gubicza (0 - 1)4335721 - 139999-05-15royals6 - 4boucher (0 - 3)5011321 - 149999-05-17white sox5 - 3timlin (3 - 1)3009521 - 159999-05-18white sox9 - 2hibbard (2 - 2)3486122 - 159999-05-19white sox5 - 4timlin (3 - 2)4101522 - 169999-05-20athletics1 - 0welch (4 - 3)2463123 - 169999-05-21athletics11 - 7dressendorfer (3 - 3)2273824 - 169999-05-22athletics2 - 1stieb (4 - 3)3402824 - 179999-05-24angels3 - 2finley (7 - 2)2640825 - 179999-05-25angels5 - 0stottlemyre (5 - 1)3673225 - 189999-05-26angels6 - 2wells (5 - 4)4530725 - 199999-05-28athletics8 - 4acker (1 - 2)5029925 - 209999-05-29athletics8 - 3slusarski (1 - 2)5026226 - 209999-05-30athletics8 - 6ward (0 - 2)5027126 - 219999-05-31angels5 - 1langston (6 - 2)5025227 - 21\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) >= 8 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE date LIKE '9999-05%' \nAND attendance < 5000;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-1292.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: michael phelps has more medals than larisa latyna\nInput Table: list of multiple olympic medalists\n\n\nmedal_countdateathletenationsportrecord_medal_event11896-04-06james connollyunited statesathleticstriple jump g11896-04-06alexandre tuff\u00e8refranceathleticstriple jump s11896-04-06ioannis persakisgreeceathleticstriple jump b11896-04-06robert garrettunited statesathleticsdiscus g11896-04-06panagiotis paraskevopoulosgreeceathleticsdiscus s11896-04-06sotirios versisgreeceathleticsdiscus b21896-04-07robert garrettunited statesathleticslong jump s21896-04-07james connollyunited statesathleticslong jump b31896-04-07robert garrettunited statesathleticsshot put g31896-04-09carl schuhmanngermanygymnasticsvault g31896-04-09hermann weing\u00e4rtnergermanygymnasticsvault b41896-04-09hermann weing\u00e4rtnergermanygymnasticspommel horse s51896-04-09hermann weing\u00e4rtnergermanygymnasticsrings s61896-04-09hermann weing\u00e4rtnergermanygymnasticshorizontal bar g61900-07-16robert garrettunited statesathleticsstanding triple jump b61904-09-03ray ewryunited statesathleticsstanding triple jump g71908-07-20ray ewryunited statesathleticsstanding long jump g81908-07-23ray ewryunited statesathleticsstanding high jump g81920-07-29carl osburnunited statesshootingteam 300 m / 600 m military rifle , prone g91920-07-30carl osburnunited statesshooting300 m military rifle , standing g101920-07-31carl osburnunited statesshootingteam free rifle g111924-06-27carl osburnunited statesshooting600 m free rifle s111928-08-03paavo nurmifinlandathletics5000 m s121928-08-04paavo nurmifinlandathletics3000 m steeplechase s121960-09-02edoardo mangiarottiitalyfencingteam foil s131960-09-09edoardo mangiarottiitalyfencingteam \u00e9p\u00e9e g131964-10-21larisa latyninasoviet uniongymnasticsteam g141964-10-21larisa latyninasoviet uniongymnasticsall - around s151964-10-22larisa latyninasoviet uniongymnasticsvault s161964-10-22larisa latyninasoviet uniongymnasticsuneven bars b171964-10-23larisa latyninasoviet uniongymnasticsbalance beam b181964-10-23larisa latyninasoviet uniongymnasticsfloor exercise g182012-07-31michael phelpsunited statesswimming200 m butterfly s192012-07-31michael phelpsunited statesswimming4 x 200 m freestyle g202012-08-02michael phelpsunited statesswimming200 m individual medley g212012-08-03michael phelpsunited statesswimming100 m butterfly g222012-08-04michael phelpsunited statesswimming4 100 m medley relay g\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT medal_count FROM table_sql WHERE athlete = 'michael phelps') > \n             (SELECT medal_count FROM table_sql WHERE athlete = 'larisa latynina') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-824.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: frank nobilo is the only player from zimbabwe\nInput Table: 1996 pga championship\n\n\nplaceplayercountryscoreto_parmoney1mark brooksunited states68 + 70 + 69 + 70 = 277- 114300002kenny perryunited states66 + 72 + 71 + 68 = 277- 11260000t3steve elkingtonaustralia67 + 74 + 67 + 70 = 278- 10140000t3tommy tollesunited states69 + 71 + 71 + 67 = 278- 10140000t5justin leonardunited states71 + 66 + 72 + 70 = 279- 986667t5jesper parneviksweden73 + 67 + 69 + 70 = 279- 986667t5vijay singhfiji69 + 69 + 69 + 72 = 279- 986667t8lee janzenunited states68 + 71 + 71 + 70 = 280- 857500t8per - ulrik johanssonsweden73 + 72 + 66 + 69 = 280- 857500t8phil mickelsonunited states67 + 67 + 74 + 72 = 280- 857500t8larry mizeunited states71 + 70 + 69 + 70 = 280- 857500t8frank nobilonew zealand69 + 72 + 71 + 68 = 280- 857500t8nick pricezimbabwe68 + 71 + 69 + 72 = 280- 857500\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 1 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE country = 'zimbabwe' \nAND player != 'frank nobilo';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-236.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: irregular galaxy is the object type having 2.1 more apparent magnitude than globular galaxy\nInput Table: list of ngc objects (5001 - 6000)\n\n\nngc_numberobject_typeconstellationright_ascension_(_j2000_)declination_(_j2000_)apparent_magnitude5408irregular galaxycentaurus14h03 m21.0s degree22\u203244\u203314.05457spiral galaxyursa major14h03 m12.5s degree20\u203253\u20338.75466globular clusterbo\u00f6tes14h05 m27.4s degree32\u203204\u203310.55474spiral galaxyursa major14h05 m01.5s degree39\u203245\u203311.95477irregular galaxyursa major14h05 m33.1s degree27\u203240\u203314.5\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT apparent_magnitude FROM table_sql WHERE object_type = 'irregular galaxy') > \n             (SELECT apparent_magnitude FROM table_sql WHERE object_type = 'globular cluster') + 2.1 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-1132.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the only player that doesn't have 0 fa cup goals is peter hart\nInput Table: 1979 - 80 huddersfield town f.c. season\n\n\nnamepositionleague_appsleague_goalsfa_cup_appsfa_cup_goalsleague_cup_appsleague_cup_goalstotal_appstotal_goalsjim branagandf00000 (1)00 (1)0malcolm browndf4622041523david cowlingmf39 (1)10104044 (1)10peter fletcherfw30 (8)17203135 (8)18keith hanveydf3320040392peter hartmf4641140515ian holmesmf6 (4)3004110 (4)4steve kindonfw22 (1)14000022 (1)14mick laverickmf4542040514bernard purdiedf18 (4)0200020 (4)0andy rankingk2400000240ian robinsfw452520425127fred robinsondf3012040361tommy smithfw00001010brian stantonmf4192000439alan starlinggk2202040280dave suttondf4662041527chris toppingdf1302000150\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT fa_cup_goals FROM table_sql WHERE name = 'peter hart') != 0 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-590.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: in the 2005 milwaukee brewers season were attended by more than 30000 people for every game\nInput Table: 2005 milwaukee brewers season\n\n\ndateopponentscorelossattendancerecord9999-09-01padres5 - 6davis (1 - 1)2478565 - 699999-09-02padres12 - 2lawrence (7 - 14)1823166 - 699999-09-03padres1 - 6obermueller (1 - 3)3202266 - 709999-09-04padres3 - 2otsuka (1 - 6)2004267 - 709999-09-05reds6 - 1belisle (3 - 7)1614468 - 709999-09-06reds1 - 2 (10)de la rosa (2 - 2)1335168 - 719999-09-07reds14 - 5milton (7 - 14)1588669 - 719999-09-09astros7 - 4clemens (11 - 7)1813070 - 719999-09-10astros5 - 7ohka (10 - 8)2443770 - 729999-09-11astros4 - 2oswalt (17 - 12)1739271 - 729999-09-13diamondbacks3 - 1v\u00e3\u00a1zquez (10 - 15)2370872 - 729999-09-14diamondbacks1 - 2 (12)lehr (0 - 1)2379372 - 739999-09-15diamondbacks14 - 2estes (7 - 8)2074173 - 739999-09-16astros1 - 2eveland (1 - 1)3376773 - 749999-09-17astros0 - 7obermueller (1 - 4)3775673 - 759999-09-18astros1 - 6capuano (17 - 10)3505273 - 769999-09-20cubs5 - 3williams (5 - 9)3013674 - 769999-09-21cubs7 - 6van buren (0 - 2)3004975 - 769999-09-22cubs0 - 3helling (2 - 1)3113775 - 779999-09-23cardinals9 - 6carpenter (21 - 5)2247276 - 779999-09-24cardinals8 - 7mulder (16 - 8)3350677 - 779999-09-25cardinals0 - 2davis (11 - 11)2015077 - 789999-09-26reds12 - 9coffey (4 - 1)1441278 - 789999-09-27reds6 - 2claussen (10 - 10)2803179 - 789999-09-28reds4 - 11capuano (18 - 11)2118179 - 799999-09-29reds2 - 0milton (8 - 15)1317380 - 799999-09-30pirates6 - 5vogelsong (2 - 2)2092281 - 79\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN MIN(attendance) > 30000 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-1488.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: seasons 2001 - 02 , 2002 - 03 and 2003 - 04 were in the limited format\nInput Table: tsuyoshi fujita\n\n\nseasonevent_typelocationformatdaterank1997 - 98nationalstokyospecial1998-07-0441998 - 99grand prixkyotolimited1999-01-1641998 - 99apac region championshipsingaporespecial1999-03-2731999 - 00grand prixtaipeiextended2000-02-1222000 - 01grand prixkyotoextended2000-11-1212000 - 01grand prixhiroshimalimited2001-01-2762000 - 01pro tourtokyoblock constructed2001-03-1622001 - 02grand prixhong konglimited2001-11-1732001 - 02masterssan diegostandard2002-01-1172001 - 02grand prixfukuokalimited2002-02-1662001 - 02grand prixnagoyateam limited2002-05-1142002 - 03grand prixutsunomiyalimited2002-10-1232002 - 03grand prixhiroshimaextended2003-01-2572002 - 03grand prixbangkokstandard2003-07-1212003 - 04nationalsosakaspecial2004-06-1112003 - 04grand prixkuala lumpurstandard2004-07-2442005grand prixseattleextended2005-03-0572005invitationallos angelesspecial2005-05-1722005pro tourlondonbooster draft2005-07-0822005pro tourlos angelesextended2005-10-2852011pro tournagoyablock constructed and booster draft2011-06-105\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE format = 'limited' AND season IN ('2001 - 02', '2002 - 03', '2003 - 04')) = 3 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-1314.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: fred couples had a score larger than 210\nInput Table: 1988 u.s. open (golf)\n\n\nplaceplayercountryscoreto_par1curtis strangeunited states70 + 67 + 69 = 206- 7t2nick faldoengland72 + 67 + 68 = 207- 6t2bob gilderunited states68 + 69 + 70 = 207- 6t2scott simpsonunited states69 + 66 + 72 = 207- 6t5larry mizeunited states69 + 67 + 72 = 208- 5t5d a weibringunited states71 + 69 + 68 = 208- 57mark o'mearaunited states71 + 72 + 66 = 209- 48fred couplesunited states72 + 67 + 71 = 210- 39lanny wadkinsunited states70 + 71 + 70 = 211- 210ken greenunited states72 + 70 + 70 = 212- 1\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT score FROM table_sql WHERE player = 'fred couples') > 210 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-1954.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the new york knicks won all home games played against the boston celtics in the 1984 - 1985 season\nInput Table: 1984 - 85 boston celtics season\n\n\ngamedateopponentscorelocationrecord339999-01-02new jersey nets110 - 95brendan byrne arena27 - 6349999-01-04new york knicks105 - 94boston garden28 - 6359999-01-07new york knicks108 - 97madison square garden29 - 6369999-01-09chicago bulls111 - 108boston garden30 - 6379999-01-11washington bullets103 - 101boston garden31 - 6389999-01-12atlanta hawks119 - 111the omni32 - 6399999-01-16los angeles lakers104 - 102boston garden33 - 6409999-01-18indiana pacers86 - 91market square arena33 - 7419999-01-20philadelphia 76ers113 - 97boston garden34 - 7429999-01-23seattle supersonics97 - 107boston garden34 - 8439999-01-25indiana pacers125 - 94boston garden35 - 8449999-01-27portland trail blazers128 - 127boston garden36 - 8459999-01-29detroit pistons131 - 130hartford civic center37 - 8469999-01-30philadelphia 76ers104 - 122the spectrum37 - 9\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE opponent = 'new york knicks' \nAND location LIKE '%boston garden%' \nAND score NOT LIKE '%-' \nAND score NOT LIKE '%-%';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-1044.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the only total that appears more than two times is 31\nInput Table: list of sumo record holders\n\n\nnametotalfirstlasthighest_rankkotonishiki341990-09-011999-09-01sekiwakekai\u014d321994-05-012000-07-01\u014dzekimus\u014dyama311994-03-012000-09-01\u014dzekihasegawa301965-11-011974-09-01sekiwakekotomitsuki302001-01-012007-07-01\u014dzekiakinoshima271988-11-012000-09-01sekiwaketakamiyama271969-11-011982-09-01sekiwaketakat\u014driki261991-05-012000-05-01sekiwakewakanosato262000-11-012005-09-01sekiwakedaikirin221966-11-011970-09-01\u014dzekitochiazuma ii221997-07-012005-01-01\u014dzekikisenosato222006-07-012011-09-01\u014dzeki\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) > 2 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nGROUP BY total \nHAVING COUNT(*) > 2;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-1345.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: in 1962 , the vfl began in july\nInput Table: 1962 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddatemelbourne11.18 (84)st kilda11.6 (72)mcg489521962-06-23essendon15.17 (107)geelong10.7 (67)windy hill350001962-06-23collingwood10.14 (74)fitzroy9.11 (65)victoria park264881962-06-23carlton12.9 (81)footscray9.10 (64)princes park324001962-06-23south melbourne10.13 (73)richmond11.13 (79)lake oval170001962-06-23north melbourne10.8 (68)hawthorn10.7 (67)arden street oval84701962-06-23\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE date < '1962-07-01';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-1075.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the buffalo bills lost 3 more games than they won\nInput Table: 1976 buffalo bills season\n\n\nweekdateopponentresultattendance11976-09-13miami dolphinsl 30 - 217768321976-09-19houston oilersl 13 - 36138431976-09-26tampa bay buccaneersw 14 - 94450541976-10-03kansas city chiefsw 50 - 175190951976-10-10new york jetsl 17 - 145911061976-10-17baltimore coltsl 31 - 137100971976-10-24new england patriotsl 26 - 224514481976-10-31new york jetsl 19 - 144128591976-11-07new england patriotsl 20 - 1061157101976-11-15dallas cowboysl 17 - 1051799111976-11-21san diego chargersl 34 - 1336539121976-11-25detroit lionsl 27 - 1466875131976-12-05miami dolphinsl 45 - 2743475141976-12-12baltimore coltsl 58 - 2050451\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE result = 'w') < \n             (SELECT COUNT(*) FROM table_sql WHERE result = 'l') + 3 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-1210.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the score of the game when birmingham city was the home team was 0 - 0\nInput Table: 1983 - 84 fa cup\n\n\ntie_nohome_teamscoreaway_teamdate1notts county1 - 2everton1984-03-102sheffield wednesday0 - 0southampton1984-03-11replaysouthampton5 - 1sheffield wednesday1984-03-203plymouth argyle0 - 0derby county1984-03-10replayderby county0 - 1plymouth argyle1984-03-144birmingham city1 - 3watford1984-03-10\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE home_team = 'birmingham city' \nAND score = '0 - 0';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-1161.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the detroit pistons lost over eight games during this period of their 2010 - 2011 season\nInput Table: 2010 - 11 detroit pistons season\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord629999-03-01milwaukeel 90 - 92 (ot)rodney stuckey (25)greg monroe , charlie villanueva (9)rodney stuckey (5)bradley center 1136422 - 40639999-03-02minnesotal 105 - 116 (ot)austin daye (22)greg monroe (11)rodney stuckey (10)the palace of auburn hills 1312222 - 41649999-03-06washingtonw 113 - 102 (ot)tayshaun prince (20)greg monroe , rodney stuckey (7)rodney stuckey (9)the palace of auburn hills 1750623 - 41659999-03-09san antoniol 104 - 111 (ot)richard hamilton (20)greg monroe (10)tracy mcgrady (9)at&t center 1858123 - 42669999-03-11oklahoma cityl 94 - 104 (ot)richard hamilton (20)greg monroe (10)greg monroe , rodney stuckey (6)oklahoma city arena 1820323 - 43679999-03-12denverl 101 - 131 (ot)chris wilcox (21)austin daye , ben gordon , greg monroe (6)will bynum (10)pepsi center 1915523 - 44689999-03-16torontow 107 - 93 (ot)richard hamilton (24)greg monroe (10)rodney stuckey (14)the palace of auburn hills 1516624 - 44699999-03-18new yorkw 99 - 95 (ot)tayshaun prince (16)chris wilcox (12)will bynum (5)the palace of auburn hills 2207625 - 44709999-03-20atlantal 96 - 104 (ot)rodney stuckey (22)greg monroe (10)rodney stuckey (8)philips arena 1758025 - 45719999-03-23miamil 94 - 100 (ot)richard hamilton (27)greg monroe (12)rodney stuckey (6)the palace of auburn hills 2207625 - 46729999-03-25clevelandl 91 - 97 (ot)richard hamilton , tayshaun prince (15)chris wilcox , greg monroe (8)rodney stuckey (4)quicken loans arena 1990725 - 47739999-03-26indianaw 100 - 88 (ot)richard hamilton (23)greg monroe (13)richard hamilton , rodney stuckey (6)the palace of auburn hills 1921626 - 47\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) > 8 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE record LIKE '% - %' \nAND CAST(SUBSTR(record, INSTR(record, '-') + 2) AS INTEGER) > CAST(SUBSTR(record, 1, INSTR(record, '-') - 1) AS INTEGER);\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-160.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: after 2000 , only brazil and england contributed one player to the utah jazz\nInput Table: utah jazz all - time roster\n\n\nplayernationalitypositionyears_for_jazzschool_/_club_teamrick adelmanunited statesguard1974-01-01loyola (ca)john amaechienglandcenter / forward2001-03-01penn statelouis amundsonunited statesforward2007-01-01unlvj j andersonunited statesforward1982-01-01bradleyshandon andersonunited statesguard / forward9999-01-01georgiarafael ara\u00e3jobrazilcenter2006-01-01byucarlos arroyopuerto ricoguard2002-05-01florida internationalisaac austinunited statescenter1991-01-01arizona stateanthony aventunited statesforward1998-01-01seton hall\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 2 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE years_for_jazz > '2000-01-01' \nAND (nationality = 'brazil' OR nationality = 'england');\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-438.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there are more brm then any other with alfa romeo and matra tying for the least\nInput Table: 1971 south african grand prix\n\n\ndriverconstructorlapstime_/_retiredgridmario andrettiferrari791:47:35.54jackie stewarttyrrell - ford79+ 20.91clay regazzoniferrari79+ 31.43reine wiselllotus - ford79+ 1:09.414chris amonmatra78+ 1 lap2denny hulmemclaren - ford78+ 1 lap7brian redmansurtees - ford78+ 1 lap17jacky ickxferrari78+ 1 lap8graham hillbrabham - ford77+ 2 laps19ronnie petersonmarch - ford77+ 2 laps13henri pescarolomarch - ford77+ 2 laps18rolf stommelensurtees - ford77+ 2 laps15andrea de adamichmarch - alfa romeo75+ 4 laps22emerson fittipaldilotus - ford58engine5john surteessurtees - ford56gearbox6fran\u00e7ois ceverttyrrell - ford45accident9howden ganleybrm42physical24pedro rodr\u00edguezbrm33overheating10dave charltonbrabham - ford31engine16jo siffertbrm31overheating12john lovemarch - ford30differential21jackie pretoriusbrabham - ford22engine20peter gethinmclaren - ford7fuel leak11jo bonniermclaren - ford5suspension23alex soler - roigmarch - ford5engine25\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE constructor = 'brm') > \n             (SELECT COUNT(*) FROM table_sql WHERE constructor = 'alfa romeo' OR constructor = 'matra') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FP/test-494.html": {
        "method": "Text2SQL",
        "subfolder": "FP",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "True",
        "Actual_Answer": "False",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: anne street is located in plymouth county and has no major junctions for mileposts or roads intersected\nInput Table: massachusetts route 139\n\n\ncountylocationstreet_namesmilepostroads_intersectednotesnorfolkstoughtonpleasant street turnpike street lindelof avenue3.0route 24route 24 exit 20norfolkweymouthanne street(no major junctions)(no major junctions)(no major junctions)plymouthrocklandnorth avenue plain street market street12.2route 123western terminus of route 123 / 139 concurrencyplymouthrocklandnorth avenue plain street market street12.8route 123eastern terminus of route 123 / 139 concurrencyplymouthhanoverhanover street rockland street columbia road17.9route 53northern terminus of route 53 / 139 concurrency\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE county = 'plymouth' \nAND location = 'weymouth' \nAND street_names = 'anne street' \nAND milepost = '(no major junctions)' \nAND roads_intersected = '(no major junctions)' \nAND notes = '(no major junctions)';\nPrediction: True\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-47.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the agricultural panel and labour panel both have 11 total members\nInput Table: members of the 5th seanad\n\n\npartyadministrative_panelagricultural_panelcultural_and_educational_panelindustrial_and_commercial_panellabour_panelnational_university_of_irelanduniversity_of_dublinnominated_by_the_taoiseachtotalfianna f\u00e1il4423010721fine gael132201009labour party000150028clann na talmhan020010003independent010101339total7115911331160\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT total FROM table_sql WHERE administrative_panel = 11 AND party = 'agricultural_panel') = \n             (SELECT total FROM table_sql WHERE labour_panel = 11 AND party = 'labour_panel') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-715.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: sco had the highest amount of transfers at 22 , more than every other team combined\nInput Table: 2008 - 09 rangers f.c. season\n\n\nnatnamemoving_totypetransfer_windowtransfer_feesconicholas gallacher9999-01-01end of contract9999-06-01n / aivory coastlacine cherif9999-01-01end of contract9999-06-01n / ascoalistair park9999-01-01end of contract9999-06-01n / aengmichael donald9999-01-01end of contract9999-06-01n / ascocalum reidford9999-01-01end of contract9999-06-01n / ascochris smith9999-01-01end of contract9999-06-01n / abeljeroen van den broeck9999-01-01end of contract9999-06-01n / aslovakiafilip \u0161ebo9999-01-01transfer9999-06-011 mbelthomas buffel9999-01-01transfer9999-06-01n / aespcarlos cu\u00e9llar9999-01-01transfer9999-06-017.8 mscosteven lennon9999-01-01loan9999-06-01n / ascomark weir9999-01-01loan9999-06-01n / ascoandy webster9999-01-01loan9999-06-01n / arsadean furman9999-01-01loan9999-06-01n / ascoalan lowing9999-01-01loan9999-06-01n / ascopaul emslie9999-01-01loan9999-06-01n / ascoscott gallacher9999-01-01loan9999-06-01n / agabondaniel cousin9999-01-01transfer9999-06-013.5 mscoalan gow9999-01-01loan9999-06-01n / aenglee robinson9999-01-01loan9999-01-01n / ascoandrew shinnie9999-01-01loan9999-01-01n / ascosteven kinniburgh9999-01-01loan9999-01-01n / ascorory loy9999-01-01loan9999-01-01n / ascowilliam mclachlan9999-01-01loan9999-01-01n / ascolee robinson9999-01-01loan9999-01-01n / afrajean - claude darcheville9999-01-01transfer9999-01-01freescojordan mcmillan9999-01-01loan9999-01-01n / ascochris burke9999-01-01transfer9999-01-01freecypgeorgios efrem9999-01-01loan9999-01-01n / ascoalan gow9999-01-01loan9999-01-01n / ascocharlie adam9999-01-01loan9999-01-01n / ascoross harvey9999-01-01loan9999-01-01n / ascosteven kinniburgh9999-01-01loan9999-01-01n / a\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE nat = 'sco' AND type = 'transfer') > \n             (SELECT COUNT(*) FROM table_sql WHERE type = 'transfer') - (SELECT COUNT(*) FROM table_sql WHERE nat = 'sco' AND type = 'transfer') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1077.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: detroit had the highest home team score , at 6 points\nInput Table: 2003 - 04 detroit red wings season\n\n\ndatevisitorscorehomedecisionattendancerecord0002-01-01detroit4 - 1carolinajoseph1705324 - 12 - 4 - 10001-01-03anaheim1 - 3detroitlegace2006625 - 12 - 4 - 10000-01-05nashville0 - 6detroitjoseph2006626 - 12 - 4 - 10001-01-07boston3 - 0detroitjoseph2006626 - 13 - 4 - 10000-01-10detroit1 - 2bostonjoseph1756526 - 13 - 4 - 29999-01-14chicago2 - 4detroitlegace2006627 - 13 - 4 - 20000-01-16phoenix3 - 3detroitjoseph2006627 - 13 - 5 - 29999-01-19detroit1 - 2san josejoseph1736127 - 14 - 5 - 29999-01-21detroit2 - 2anaheimlegace1717427 - 14 - 6 - 29999-01-22detroit5 - 4los angelesjoseph1811828 - 14 - 6 - 29999-01-24detroit2 - 5phoenixjoseph1901928 - 15 - 6 - 29999-01-26detroit2 - 2dallaslegace1853228 - 15 - 7 - 29999-01-29new jersey2 - 5detroitjoseph2006629 - 15 - 7 - 29999-01-31carolina4 - 4detroitlegace2006630 - 15 - 8 - 2\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN MAX(score) = 6 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE home = 'detroit';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1419.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: pierre lamine has a mere 0.16 more points than shinji someya\nInput Table: 1976 world junior figure skating championships\n\n\nranknamenationsp_+_fspointsplaces1mark cockerellunited states1172.4211.02takashi murajapan2165.724.03brian pockarcanada3166.6223.04norbert schrammwest germany4159.840.05andrew bestwickunited kingdom5158.148.06stephan brilwest germany7155.7257.07patrice macrezfrance6151.7671.08pierre laminefrance8150.579.09shinji someyajapan10150.3474.510jozef sabov\u010d\u00edkczechoslovakia9148.8887.011daniel fuererswitzerland13146.1892.512gerald schranzaustria11143.04102.013helmut kristofics - binderaustria15137.32123.014michael pasfieldaustralia12136.6119.015francis demarteaubelgium14131.02140.016adrian vasileromania16127.74143.017miljan begovicyugoslavia17127.3143.018jeremy dowsonsouth africa18114.98166.019marc franquetbelgium19114.38167.0\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT points FROM table_sql WHERE name = 'pierre lamine') - \n             (SELECT points FROM table_sql WHERE name = 'shinji someya') > 0.16 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1218.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: jonathan legear scored four more goals than matias suarez , the next highest ranked player in the belgian first dvision a league who played in the belgian cup\nInput Table: 2008 - 09 r.s.c. anderlecht season\n\n\nplayerleaguetitle_playoffsuper_cuptotalmbark boussoufa110011tom de sutter9009guillaume gillet8009marcin wasilewski8008jonathan legear5107nicol\u00e1s frutos6006thomas chatelle4004roland juh\u00e1sz4004stanislav vl\u010dek4004lucas biglia2003dmitri bulykin3003jan pol\u00e1k2003mat\u00edas su\u00e1rez1013jelle van damme3003oleksandr iakovenko2002hern\u00e1n losada1002v\u00edctor bern\u00e1rdez1001bart goor1001nemanja rni\u01070001\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT league FROM table_sql WHERE player = 'jonathan legear') - \n             (SELECT league FROM table_sql WHERE player = 'mat\u00edas su\u00e1rez') > 4 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1950.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: in the 1984 - 85 season the boston celtics played eight games at the boston garden\nInput Table: 1984 - 85 boston celtics season\n\n\ngamedateopponentscorelocationrecord339999-01-02new jersey nets110 - 95brendan byrne arena27 - 6349999-01-04new york knicks105 - 94boston garden28 - 6359999-01-07new york knicks108 - 97madison square garden29 - 6369999-01-09chicago bulls111 - 108boston garden30 - 6379999-01-11washington bullets103 - 101boston garden31 - 6389999-01-12atlanta hawks119 - 111the omni32 - 6399999-01-16los angeles lakers104 - 102boston garden33 - 6409999-01-18indiana pacers86 - 91market square arena33 - 7419999-01-20philadelphia 76ers113 - 97boston garden34 - 7429999-01-23seattle supersonics97 - 107boston garden34 - 8439999-01-25indiana pacers125 - 94boston garden35 - 8449999-01-27portland trail blazers128 - 127boston garden36 - 8459999-01-29detroit pistons131 - 130hartford civic center37 - 8469999-01-30philadelphia 76ers104 - 122the spectrum37 - 9\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 8 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE location = 'boston garden' \nAND record LIKE '___ - __';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-584.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the milwaukee brewers in the 2005 season played cardinals one day before reds\nInput Table: 2005 milwaukee brewers season\n\n\ndateopponentscorelossattendancerecord9999-09-01padres5 - 6davis (1 - 1)2478565 - 699999-09-02padres12 - 2lawrence (7 - 14)1823166 - 699999-09-03padres1 - 6obermueller (1 - 3)3202266 - 709999-09-04padres3 - 2otsuka (1 - 6)2004267 - 709999-09-05reds6 - 1belisle (3 - 7)1614468 - 709999-09-06reds1 - 2 (10)de la rosa (2 - 2)1335168 - 719999-09-07reds14 - 5milton (7 - 14)1588669 - 719999-09-09astros7 - 4clemens (11 - 7)1813070 - 719999-09-10astros5 - 7ohka (10 - 8)2443770 - 729999-09-11astros4 - 2oswalt (17 - 12)1739271 - 729999-09-13diamondbacks3 - 1v\u00e3\u00a1zquez (10 - 15)2370872 - 729999-09-14diamondbacks1 - 2 (12)lehr (0 - 1)2379372 - 739999-09-15diamondbacks14 - 2estes (7 - 8)2074173 - 739999-09-16astros1 - 2eveland (1 - 1)3376773 - 749999-09-17astros0 - 7obermueller (1 - 4)3775673 - 759999-09-18astros1 - 6capuano (17 - 10)3505273 - 769999-09-20cubs5 - 3williams (5 - 9)3013674 - 769999-09-21cubs7 - 6van buren (0 - 2)3004975 - 769999-09-22cubs0 - 3helling (2 - 1)3113775 - 779999-09-23cardinals9 - 6carpenter (21 - 5)2247276 - 779999-09-24cardinals8 - 7mulder (16 - 8)3350677 - 779999-09-25cardinals0 - 2davis (11 - 11)2015077 - 789999-09-26reds12 - 9coffey (4 - 1)1441278 - 789999-09-27reds6 - 2claussen (10 - 10)2803179 - 789999-09-28reds4 - 11capuano (18 - 11)2118179 - 799999-09-29reds2 - 0milton (8 - 15)1317380 - 799999-09-30pirates6 - 5vogelsong (2 - 2)2092281 - 79\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT date FROM table_sql WHERE opponent = 'cardinals') < \n             (SELECT date FROM table_sql WHERE opponent = 'reds') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1145.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the format of season 6 is q145\nInput Table: none\n\n\nepisodeseasonformattitleoriginal_airdate2171h75lost smurf1988-09-102182h76archives of evil1988-09-102193q143bigmouth 's roommate / bungling babysitters1988-09-172204q144clockwork 's powerplay / clumsy in command1988-09-172215h77don smurfo 's uninvited guests1988-09-242226q145denisa 's greedy doll / denisa 's slumber party1988-09-242237q146grandpa 's nemesis / grandpa 's walking stick1988-10-012248h78a house for nanny1988-10-012259q147it 's a smurfy life / land of lost and found1988-10-0822610h79long live brainy1988-10-0822711h80a maze of mirrors1988-10-1522812q148memory melons / nanny 's way1988-10-1522913q149pappy 's puppy / shutterbug smurfs1988-10-2223014q150smoogle sings the blues / a smurf for denisa1988-10-2223115h81smurf the presses1988-10-2923216h82stealing grandpa 's thunder1988-10-29\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN format = 'q145' AND season = 6 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1588.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the result of the away match versus the wightlink raiders was a 5 - 4 loss\nInput Table: 2008 - 09 guildford flames season\n\n\ndateopponentvenueresultattendancecompetitionman_of_the_match9999-01-01slough jetshomelost 2 - 31308league / cuplukas smital9999-01-02slough jetsawaylost 5 - 6 (ot)320leaguepaul dixon9999-01-08swindon wildcatsawaywon 6 - 3754league / cuplukas smital9999-01-09swindon wildcatshomewon 4 - 21568league / cupneil liddiard9999-01-15sheffield scimitarsawaywon 7 - 4364league / cuprick plant9999-01-16milton keynes lightninghomelost 2 - 41161league / cupdavid savage9999-01-19romford raidershomewon 6 - 21016league / cupalex mettam9999-01-22wightlink raidersawaylost 5 - 4509league / cupstuart potts9999-01-23telford tigershomewon 4 - 21368leaguealex mettam / mark williams9999-01-29romford raidershomewon 7 - 21238leaguemartin bouz9999-01-30bracknell beesawaywon 4 - 0not reportedleague / cupjoe watkins\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN result = 'lost 5 - 4' AND venue = 'away' AND opponent = 'wightlink raiders' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1684.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there were 31002 people in attendance when uab was the opponent\nInput Table: east carolina pirates football , 1990 - 99\n\n\ndateopponentsiteresultattendance9999-09-05virginia techlane stadium blacksburg , val3 - 38481349999-09-12chattanoogadowdy - ficklen stadium greenville , ncw31 - 0340289999-09-19ohiopeden stadium athens , ohw21 - 14191869999-10-03armydowdy - ficklen stadium greenville , ncw30 - 25406079999-10-10uabdowdy - ficklen stadium greenville , ncw26 - 7310029999-10-17alabamalegion field birmingham , all22 - 23800799999-10-24southern missmm roberts stadium hattiesburg , msl7 - 41240209999-10-31houstondowdy - ficklen stadium greenville , ncl31 - 34268219999-11-05cincinnatinippert stadium cincinnati , ohw24 - 21190989999-11-14louisvilledowdy - ficklen stadium greenville , ncl45 - 63262589999-11-21memphisliberty bowl memorial stadium memphis , tnw34 - 31160529999-01-01all times are in easternall times are in easternall times are in easternall times are in eastern\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN attendance = 31002 AND opponent = 'uab' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-924.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there were 2.4 blocks per game during the season where the field goal percentage was 594 (2nd)\nInput Table: list of career achievements by dwight howard\n\n\nselectionmonthseasonteam_recordpoints_per_gamefield_goal_percentagerebounds_per_gameblocks_per_game9999-01-012006-04-012005-06-017-218.153114.00.79999-01-022006-10-012006-07-0112-417.157613.61.99999-01-032007-10-012007-08-0114-423.861815.02.79999-01-042007-12-012007-08-018-721.759816.12.99999-01-052010-10-012010-11-0113-421.8 (5th)594 (2nd)12.1 (4th in league)2.4\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT blocks_per_game FROM table_sql WHERE field_goal_percentage = 594 AND selection = '9999-01-05') = 2.4 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1080.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the highest point gap was on january 5 , with a spread of 6 points\nInput Table: 2003 - 04 detroit red wings season\n\n\ndatevisitorscorehomedecisionattendancerecord0002-01-01detroit4 - 1carolinajoseph1705324 - 12 - 4 - 10001-01-03anaheim1 - 3detroitlegace2006625 - 12 - 4 - 10000-01-05nashville0 - 6detroitjoseph2006626 - 12 - 4 - 10001-01-07boston3 - 0detroitjoseph2006626 - 13 - 4 - 10000-01-10detroit1 - 2bostonjoseph1756526 - 13 - 4 - 29999-01-14chicago2 - 4detroitlegace2006627 - 13 - 4 - 20000-01-16phoenix3 - 3detroitjoseph2006627 - 13 - 5 - 29999-01-19detroit1 - 2san josejoseph1736127 - 14 - 5 - 29999-01-21detroit2 - 2anaheimlegace1717427 - 14 - 6 - 29999-01-22detroit5 - 4los angelesjoseph1811828 - 14 - 6 - 29999-01-24detroit2 - 5phoenixjoseph1901928 - 15 - 6 - 29999-01-26detroit2 - 2dallaslegace1853228 - 15 - 7 - 29999-01-29new jersey2 - 5detroitjoseph2006629 - 15 - 7 - 29999-01-31carolina4 - 4detroitlegace2006630 - 15 - 8 - 2\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MAX(record) FROM table_sql) = '26 - 12 - 4 - 1' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1342.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the match between south melbourne and richmond drew a bigger crowd than the game between hawthorn and north melbourne\nInput Table: 1962 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddatemelbourne11.18 (84)st kilda11.6 (72)mcg489521962-06-23essendon15.17 (107)geelong10.7 (67)windy hill350001962-06-23collingwood10.14 (74)fitzroy9.11 (65)victoria park264881962-06-23carlton12.9 (81)footscray9.10 (64)princes park324001962-06-23south melbourne10.13 (73)richmond11.13 (79)lake oval170001962-06-23north melbourne10.8 (68)hawthorn10.7 (67)arden street oval84701962-06-23\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT crowd FROM table_sql WHERE home_team = 'south melbourne' AND away_team = 'richmond') > \n             (SELECT crowd FROM table_sql WHERE home_team = 'north melbourne' AND away_team = 'hawthorn') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-286.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: jos\u00e9 couceiro was the head coach in set\u00fabal , and it was manuel machado in guimar\u00e3es\nInput Table: 2004 - 05 primeira liga\n\n\nclubhead_coachcitystadium2003_-_2004_seasonacad\u00e9mica de coimbrajo\u00e3o carlos pereiracoimbraest\u00e1dio cidade de coimbra13th in the ligabelenensescarlos carvalhallisbonest\u00e1dio do restelo15th in the ligabenficagiovanni trapattonilisbonest\u00e1dio da luz2nd in the ligaboavistajaime pachecoportoest\u00e1dio do bessa - s\u00e9culo xxi8th in the ligabragajesualdo ferreirabragaest\u00e1dio municipal de braga - axa5th in the ligaestoril - praialitosestorilest\u00e1dio ant\u00f3nio coimbra da mota1st in the liga de honragil vicentelu\u00eds camposbarcelosest\u00e1dio cidade de barcelos12th in the ligauni\u00e3o de leiriav\u00edtor pontesleiriaest\u00e1dio dr magalh\u00e3es pessoa10th in the ligapenafielmanuel fernandespenafielest\u00e1dio municipal 25 de abril3rd in the liga de honramar\u00edtimomanuel cajudafunchalest\u00e1dio dos barreiros6th in the liganacionalcasemiro miorfunchalest\u00e1dio da madeira4th in the ligabeira - marmick wadsworthaveiroest\u00e1dio municipal de aveiro11th in the ligamoreirensev\u00edtor oliveiraguimar\u00e3esest\u00e1dio do moreirense9th in the ligaportoluigi delneriportoest\u00e1dio do drag\u00e3o1st in the ligasporting cpjos\u00e9 peseirolisbonest\u00e1dio jos\u00e9 alvalade - s\u00e9culo xxi3rd in the ligario avecarlos britovila do condeest\u00e1dio dos arcos7th in the ligavit\u00f3ria de guimar\u00e3esmanuel machadoguimar\u00e3esest\u00e1dio d afonso henriques14th in the ligavit\u00f3ria de set\u00fabaljos\u00e9 couceiroset\u00fabalest\u00e1dio do bonfim2nd in the liga de honra\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT head_coach FROM table_sql WHERE city = 'set\u00fabal') = 'jos\u00e9 couceiro' \n             AND (SELECT head_coach FROM table_sql WHERE city = 'guimar\u00e3es') = 'manuel machado' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-826.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: in the 1981 open championship no player finished under par\nInput Table: 1981 open championship\n\n\nplaceplayercountryscoreto_part1vicente fern\u00e3\u00a1ndezargentina70et1nick jobengland70et3isao aokijapan71+ 1t3david grahamaustralia71+ 1t3tony jacklinengland71+ 1t3johnny millerunited states71+ 1t3simon owennew zealand71+ 1t3hal sutton (a)united states71+ 1t9howard clarkengland72+ 2t9ben crenshawunited states72+ 2t9david jaggerengland72+ 2t9mark jamesengland72+ 2t9greg normanaustralia72+ 2t9arnold palmerunited states72+ 2t9bill rogersunited states72+ 2t9sam torrancescotland72+ 2\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE to_par < '0';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1975.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: only ten cleveland brown 's quarterbacks have won more than 10 games\nInput Table: list of cleveland browns starting quarterbacks\n\n\nquarterbackuniform_no_(s)games_startedwinslossestieswinning_pctsipe , brian1711257550589.0kosar , bernie1910553511595.0ryan , frank137652222697.0graham , otto60 , 147157131810.0couch , tim25922370373.0nelsen , bill165134161676.0phipps , mike155124252490.0plum , milt165133162667.0anderson , derek33416180471.0testaverde , vinny123116150516.0mcdonald , paul16218130381.0mccoy , colt12216150286.0frye , charlie9196130316.0weeden , brandon3195140263.0o'connell , tommy15141031750.0holcomb , kelly1012480333.0quinn , brady1012390250.0ninowski , jim15 , 1111560455.0dilfer , trent811470364.0garcia , jeff510370300.0danielson , gary188530625.0tomczak , mike188440500.0pederson , doug188170125.0pagel , mike107250286.0wallace , seneca67160143.0ratterman , george12 , 165230400.0philcox , todd175230400.0delhomme , jake174220500.0mays , dave104130250.0zeier , eric104130250.0mccown , luke1240400.0parilli , babe183120333.0rypien , mark113210667.0dorsey , ken1130300.0hoyer , brian633001.0strock , don1222001.0christensen , jeff112110500.0detmer , ty1120200.0campbell , jason172110500.0gault , don1111001.0lane , gary1510100.0dawson , len1811001.0wynn , spergon1310100.0luck , terry710100.0cureton , will1610100.0gradkowski , bruce710100.0lewis , thaddeus910100.0\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE wins > 10) = 10 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1964.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: player austin daye (16) scored the highest number of points in the game and the team was dallas\nInput Table: 2010 - 11 detroit pistons season\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord19999-10-05miamil 89 - 105 (ot)ben gordon (17)ben gordon , charlie villanueva (5)rodney stuckey (5)american airlines arena 196000 - 129999-10-08milwaukeew 115 - 110 (ot)austin daye (21)austin daye (7)will bynum (9)the palace of auburn hills 128211 - 139999-10-11atlantaw 94 - 85 (ot)rodney stuckey (16)greg monroe (7)richard hamilton (7)the palace of auburn hills 105912 - 149999-10-13dallasl 96 - 101 (ot)austin daye (16)ben wallace , jason maxiell (8)rodney stuckey (6)van andel arena 102072 - 259999-10-15minnesotal 88 - 99 (ot)austin daye (18)austin daye (11)will bynum (5)carrier dome 117472 - 369999-10-16charlottel 94 - 97 (ot)rodney stuckey (25)greg monroe (8)rodney stuckey , will bynum (5)colonial life arena 68472 - 479999-10-19washingtonw 98 - 92 (ot)rodney stuckey (34)ben wallace (11)rodney stuckey (7)huntington center 64243 - 4\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT high_points FROM table_sql WHERE team = 'dallas') = \n             (SELECT MAX(high_points) FROM table_sql) \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-411.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: when the grid is 5 , the least amount of laps is 43.0\nInput Table: 1987 hungarian grand prix\n\n\ndriverconstructorlapstime_/_retiredgridnelson piquetwilliams - honda761:59:26.7933ayrton sennalotus - honda76+ 37.7276alain prostmclaren - tag76+ 1:27.4564thierry boutsenbenetton - ford75+ 1 lap7riccardo patresebrabham - bmw75+ 1 lap10derek warwickarrows - megatron74+ 2 laps9jonathan palmertyrrell - ford74+ 2 laps16eddie cheeverarrows - megatron74+ 2 laps11philippe streifftyrrell - ford74+ 2 laps14ivan capellimarch - ford74+ 2 laps18alessandro nanniniminardi - motori moderni73+ 3 laps20piercarlo ghinzaniligier - megatron73+ 3 laps25pascal fabreags - ford71+ 5 laps26nigel mansellwilliams - honda70wheel1alex caffiosella - alfa romeo64fuel system21ren\u00e9 arnouxligier - megatron57electrical19philippe alliotlola - ford48accident15martin brundlezakspeed45turbo22michele alboretoferrari43engine5andrea de cesarisbrabham - bmw43gearbox13stefan johanssonmclaren - tag14gearbox8teo fabibenetton - ford14gearbox12adri\u00e1n camposminardi - motori moderni14spun off24gerhard bergerferrari13differential2christian dannerzakspeed3engine23satoru nakajimalotus - honda1drive - shaft17\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MIN(laps) FROM table_sql WHERE grid = 5) = 43.0 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-128.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: greg ostertag played the center position for the jazz from 1995 to 2004 and then from 2005 to 2006\nInput Table: utah jazz all - time roster\n\n\nplayernationalitypositionyears_for_jazzschool_/_club_teammehmet okurturkeyforward - center2004 - 11efes pilsen ( turkey )jos\u00e3 ortizpuerto ricocenter1988 - 90oregon stategreg ostertagunited statescenter1995 - 2004 , 2005 - 06kansasdan o 'sullivanunited statescenter1990 - 91fordhamandre owensunited statesguard2005 - 06houston\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE player = 'greg ostertag' AND position = 'center' AND years_for_jazz = '1995-2004, 2005-2006') > 0 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1330.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the lowest attendance figure for a game was 12376\nInput Table: 2009 - 10 charlotte bobcats season\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord4701-02-9999portlandl 79 - 98 (ot)raymond felton (23)gerald wallace (10)stephen jackson (4)rose garden 2010624 - 23489999-02-03la lakersl 97 - 99 (ot)stephen jackson (30)nazr mohammed (17)boris diaw (5)staples center 1899724 - 24499999-02-06new orleansl 99 - 104 (ot)stephen jackson (26)boris diaw (8)raymond felton (7)time warner cable arena 1916424 - 25509999-02-09washingtonw 94 - 92 (ot)stephen jackson (22)nazr mohammed (10)raymond felton (5)time warner cable arena 1237625 - 255101-02-10minnesotaw 93 - 92 (ot)stephen jackson (33)nazr mohammed (20)dj augustin (7)target center 1335226 - 255201-02-16new jerseyl 94 - 103 (ot)gerald wallace (21)gerald wallace , boris diaw (10)stephen jackson (5)time warner cable arena 1371226 - 26539999-02-19clevelandw 110 - 93 (ot)stephen jackson (29)tyrus thomas (12)boris diaw (9)time warner cable arena 1956827 - 26549999-02-20milwaukeel 88 - 93 (ot)stephen jackson (35)tyrus thomas (11)stephen jackson (5)bradley center 1717427 - 27559999-02-22la clippersl 94 - 98 (ot)gerald wallace (32)gerald wallace (12)boris diaw , raymond felton (9)staples center 1589227 - 28569999-02-24utahl 93 - 102 (ot)gerald wallace (27)gerald wallace (8)raymond felton (5)energysolutions arena 1991127 - 29\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN MIN(location_attendance) = 12376 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1896.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: jerry mitchell is one of two winners of a tony award\nInput Table: la cage aux folles (musical)\n\n\nyearawardcategorynomineeresult2005tony awardbest revival of a musicalbest revival of a musicalwon2005tony awardbest performance by a leading actor in a musicalgary beachnominated2005tony awardbest choreographyjerry mitchellwon2005tony awardbest costume designwilliam ivey longnominated2005drama desk awardoutstanding revival of a musicaloutstanding revival of a musicalwon2005drama desk awardoutstanding choreographyjerry mitchellwon2005drama desk awardoutstanding costume designwilliam ivey longnominated\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE award = 'tony award' AND category = 'best choreography' AND result = 'won') = 2 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-735.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the average number of people in the game is 31 521 during the 2008 arizona diamondbacks season\nInput Table: 2008 arizona diamondbacks season\n\n\ndateopponentscorelossattendancerecord9999-09-01cardinals8 - 6mcclellan (2 - 7)3507570 - 679999-09-02cardinals8 - 2petit (3 - 4)2756870 - 689999-09-03cardinals4 - 3perez (2 - 2)2435071 - 689999-09-05dodgers7 - 0haren (14 - 8)5227071 - 699999-09-06dodgers7 - 2webb (19 - 7)4754371 - 709999-09-07dodgers5 - 3rauch (4 - 6)5413771 - 719999-09-08giants6 - 2petit (3 - 5)3025271 - 729999-09-09giants5 - 4rauch (4 - 7)3051871 - 739999-09-10giants4 - 3lyon (2 - 5)3099271 - 749999-09-12reds3 - 2harang (4 - 16)2904672 - 749999-09-13reds3 - 2 (10)pe\u00f1a (1 - 2)4507572 - 759999-09-14reds2 - 1 (10)rauch (4 - 8)2729772 - 769999-09-15giants3 - 1hennessey (1 - 2)2596973 - 769999-09-16giants2 - 0cain (8 - 13)3319574 - 769999-09-17giants7 - 6s\u00e1nchez (9 - 11)2261675 - 769999-09-18giants3 - 2lincecum (17 - 4)3432376 - 769999-09-19rockies3 - 2scherzer (0 - 3)4313776 - 779999-09-20rockies5 - 3fuentes (1 - 5)3828377 - 779999-09-21rockies13 - 4reynolds (2 - 8)3291578 - 779999-09-22cardinals4 - 2wellemeyer (12 - 9)4034979 - 779999-09-23cardinals7 - 4johnson (10 - 10)4001379 - 789999-09-24cardinals4 - 2scherzer (0 - 4)4002979 - 799999-09-25cardinals12 - 3rosales (1 - 1)4050279 - 809999-09-26rockies6 - 4grilli (3 - 3)3495080 - 809999-09-27rockies6 - 4corpas (3 - 4)3323481 - 809999-09-28rockies2 - 1vizca\u00edno (1 - 2)3590882 - 80\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN AVG(attendance) = 31521 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1394.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: allen had the most points scored on november 17 with 12 points\nInput Table: 2009 - 10 temple owls men 's basketball team\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord19999-11-14delawarew 76 - 56ryan brooks - 23lavoy allen - 15juan fernandez - 5bob carpenter center , newark , de (3080)1 - 029999-11-17georgetown (19)l 46 - 45allen - 12allen - 14luiz guzman - 6verizon center , washington , dc (8712)1 - 139999-11-21sienaw 73 - 69fernandez - 20allen - 7allen - 5liacouras center , philadelphia , pa (6759)2 - 149999-11-24ball statew 66 - 46brooks - 17allen - 9allen / brooks - 7liacouras center , philadelphia , pa (3597)3 - 159999-11-27virginia techw 61 - 50allen - 18allen - 10fernandez - 6palestra , philadelphia , pa (3750)4 - 1\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT high_points FROM table_sql WHERE date = '9999-11-17') = 12 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1296.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: three athletes received medals in gymnastics\nInput Table: list of multiple olympic medalists\n\n\nmedal_countdateathletenationsportrecord_medal_event11896-04-06james connollyunited statesathleticstriple jump g11896-04-06alexandre tuff\u00e8refranceathleticstriple jump s11896-04-06ioannis persakisgreeceathleticstriple jump b11896-04-06robert garrettunited statesathleticsdiscus g11896-04-06panagiotis paraskevopoulosgreeceathleticsdiscus s11896-04-06sotirios versisgreeceathleticsdiscus b21896-04-07robert garrettunited statesathleticslong jump s21896-04-07james connollyunited statesathleticslong jump b31896-04-07robert garrettunited statesathleticsshot put g31896-04-09carl schuhmanngermanygymnasticsvault g31896-04-09hermann weing\u00e4rtnergermanygymnasticsvault b41896-04-09hermann weing\u00e4rtnergermanygymnasticspommel horse s51896-04-09hermann weing\u00e4rtnergermanygymnasticsrings s61896-04-09hermann weing\u00e4rtnergermanygymnasticshorizontal bar g61900-07-16robert garrettunited statesathleticsstanding triple jump b61904-09-03ray ewryunited statesathleticsstanding triple jump g71908-07-20ray ewryunited statesathleticsstanding long jump g81908-07-23ray ewryunited statesathleticsstanding high jump g81920-07-29carl osburnunited statesshootingteam 300 m / 600 m military rifle , prone g91920-07-30carl osburnunited statesshooting300 m military rifle , standing g101920-07-31carl osburnunited statesshootingteam free rifle g111924-06-27carl osburnunited statesshooting600 m free rifle s111928-08-03paavo nurmifinlandathletics5000 m s121928-08-04paavo nurmifinlandathletics3000 m steeplechase s121960-09-02edoardo mangiarottiitalyfencingteam foil s131960-09-09edoardo mangiarottiitalyfencingteam \u00e9p\u00e9e g131964-10-21larisa latyninasoviet uniongymnasticsteam g141964-10-21larisa latyninasoviet uniongymnasticsall - around s151964-10-22larisa latyninasoviet uniongymnasticsvault s161964-10-22larisa latyninasoviet uniongymnasticsuneven bars b171964-10-23larisa latyninasoviet uniongymnasticsbalance beam b181964-10-23larisa latyninasoviet uniongymnasticsfloor exercise g182012-07-31michael phelpsunited statesswimming200 m butterfly s192012-07-31michael phelpsunited statesswimming4 x 200 m freestyle g202012-08-02michael phelpsunited statesswimming200 m individual medley g212012-08-03michael phelpsunited statesswimming100 m butterfly g222012-08-04michael phelpsunited statesswimming4 100 m medley relay g\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(DISTINCT athlete) = 3 AND sport = 'gymnastics' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1717.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: glenn capriola was not selected before round 6\nInput Table: indianapolis colts draft history\n\n\nroundpickoverallnamepositioncollege12626randy burkewide receiverkentucky22553mike ozdowskidefensive endvirginia624163calvin o'neallinebackermichigan726193blanchard carteroffensive tackleunlv825220ken helmsoffensive tacklegeorgia924247glenn capriolarunning backboston college1026277ron bakerguardoklahoma state1125304brian rufflinebackerthe citadel1224331bill deutschrunning backnorth dakota\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT round FROM table_sql WHERE name = 'glenn capriola') >= 6 \n        THEN 'FALSE' \n        ELSE 'TRUE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1237.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: episode no 53 in the series was directed by paul holahan\nInput Table: list of white collar episodes\n\n\nno_in_seriesno_in_seasontitledirected_bywritten_byus_viewers_(million)original_air_dateproduction_code471wantedpaul holahanjeff eastin3.212012-07-10bcw401482most wantedpaul holahanmark goffman2.982012-07-17bcw402493diminishing returnsstefan schwartzjim campolongo3.012012-07-24bcw403504parting shotsrobert duncan mcneillalexandra mcnally2.822012-07-31bcw404515honor among thievesarlene sanfordjoe henderson2.932012-08-14bcw405526identity crisisdavid straitonchanning powell3.892012-08-21bcw406537compromising positionspaul holahanmatthew negrete3.362012-08-28bcw407548ancient historyrussell lee finedaniel shattuck3.382012-09-04bcw408559gloves offrenny harlinmark goffman3.82012-09-11bcw4095610vested interestrussell lee finejeff eastin3.412012-09-18bcw4105711family businesspaul holahanjoe henderson2.772013-01-22bcw4115812brass tacksanton cropperjim campolongo & alexandra mcnally2.612013-01-29bcw4125913empire citytim dekaychanning powell & daniel shattuck2.282013-02-05bcw4136014shoot the moonrussell lee finematthew negrete & bob derosa2.422013-02-19bcw4146115the originaljohn kretchmermark goffman2.122013-02-26bcw415\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN directed_by = 'paul holahan' AND no_in_series = 53 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1965.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: player will bynum (5) scored the highest number of assists in the game and the attendance was 11747 people at the carrier dome\nInput Table: 2010 - 11 detroit pistons season\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord19999-10-05miamil 89 - 105 (ot)ben gordon (17)ben gordon , charlie villanueva (5)rodney stuckey (5)american airlines arena 196000 - 129999-10-08milwaukeew 115 - 110 (ot)austin daye (21)austin daye (7)will bynum (9)the palace of auburn hills 128211 - 139999-10-11atlantaw 94 - 85 (ot)rodney stuckey (16)greg monroe (7)richard hamilton (7)the palace of auburn hills 105912 - 149999-10-13dallasl 96 - 101 (ot)austin daye (16)ben wallace , jason maxiell (8)rodney stuckey (6)van andel arena 102072 - 259999-10-15minnesotal 88 - 99 (ot)austin daye (18)austin daye (11)will bynum (5)carrier dome 117472 - 369999-10-16charlottel 94 - 97 (ot)rodney stuckey (25)greg monroe (8)rodney stuckey , will bynum (5)colonial life arena 68472 - 479999-10-19washingtonw 98 - 92 (ot)rodney stuckey (34)ben wallace (11)rodney stuckey (7)huntington center 64243 - 4\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT high_assists FROM table_sql WHERE game = 5) = 5 \n             AND (SELECT location_attendance FROM table_sql WHERE game = 5) = 11747 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1395.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the final score was 61 - 50 when the temple owls beat virginia tech\nInput Table: 2009 - 10 temple owls men 's basketball team\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord19999-11-14delawarew 76 - 56ryan brooks - 23lavoy allen - 15juan fernandez - 5bob carpenter center , newark , de (3080)1 - 029999-11-17georgetown (19)l 46 - 45allen - 12allen - 14luiz guzman - 6verizon center , washington , dc (8712)1 - 139999-11-21sienaw 73 - 69fernandez - 20allen - 7allen - 5liacouras center , philadelphia , pa (6759)2 - 149999-11-24ball statew 66 - 46brooks - 17allen - 9allen / brooks - 7liacouras center , philadelphia , pa (3597)3 - 159999-11-27virginia techw 61 - 50allen - 18allen - 10fernandez - 6palestra , philadelphia , pa (3750)4 - 1\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT score FROM table_sql WHERE team = 'temple owls' AND game = 5) = 'w 61 - 50' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-818.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: nick price is the only player from zimbabwe\nInput Table: 1996 pga championship\n\n\nplaceplayercountryscoreto_parmoney1mark brooksunited states68 + 70 + 69 + 70 = 277- 114300002kenny perryunited states66 + 72 + 71 + 68 = 277- 11260000t3steve elkingtonaustralia67 + 74 + 67 + 70 = 278- 10140000t3tommy tollesunited states69 + 71 + 71 + 67 = 278- 10140000t5justin leonardunited states71 + 66 + 72 + 70 = 279- 986667t5jesper parneviksweden73 + 67 + 69 + 70 = 279- 986667t5vijay singhfiji69 + 69 + 69 + 72 = 279- 986667t8lee janzenunited states68 + 71 + 71 + 70 = 280- 857500t8per - ulrik johanssonsweden73 + 72 + 66 + 69 = 280- 857500t8phil mickelsonunited states67 + 67 + 74 + 72 = 280- 857500t8larry mizeunited states71 + 70 + 69 + 70 = 280- 857500t8frank nobilonew zealand69 + 72 + 71 + 68 = 280- 857500t8nick pricezimbabwe68 + 71 + 69 + 72 = 280- 857500\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 1 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE country = 'zimbabwe' \nAND player != 'nick price';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1702.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: 10 is the lowest value of blank ends when the win (w) is 6\nInput Table: 2005 tim hortons brier\n\n\nlocaleskipwlpfpaends_wonends_lostblank_endsstolen_endsshot_pctalbertarandy ferbey92905848437986%manitobarandy dutiaume8377694744101379%nova scotiashawn adams8380604741161383%quebecjean - michel m\u00e3nard747769544081580%british columbiadeane horning6572654745181280%ontariowayne middaugh657562424610782%newfoundland and labradorbrad gushue6576694845131079%saskatchewanpat simmons656661434512980%prince edward islandrod macdonald476785415112579%northern ontariomike jakubo38648641489679%new brunswickwade blanchard385683414517878%\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MIN(blank_ends) FROM table_sql WHERE w = 6) = 10 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1131.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the player with the highest number of total goals is ian robins\nInput Table: 1979 - 80 huddersfield town f.c. season\n\n\nnamepositionleague_appsleague_goalsfa_cup_appsfa_cup_goalsleague_cup_appsleague_cup_goalstotal_appstotal_goalsjim branagandf00000 (1)00 (1)0malcolm browndf4622041523david cowlingmf39 (1)10104044 (1)10peter fletcherfw30 (8)17203135 (8)18keith hanveydf3320040392peter hartmf4641140515ian holmesmf6 (4)3004110 (4)4steve kindonfw22 (1)14000022 (1)14mick laverickmf4542040514bernard purdiedf18 (4)0200020 (4)0andy rankingk2400000240ian robinsfw452520425127fred robinsondf3012040361tommy smithfw00001010brian stantonmf4192000439alan starlinggk2202040280dave suttondf4662041527chris toppingdf1302000150\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MAX(total_goals) FROM table_sql) = (SELECT total_goals FROM table_sql WHERE name = 'ian robins') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1248.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: 66084 people attended the indianapolis colts game on december 30 , 2001\nInput Table: 2001 st. louis rams season\n\n\nweekdateopponentresultrecordtv_timeattendance12001-09-09philadelphia eaglesw 20 - 17 (ot)1 - 0fox 3:15 pm66243.022001-09-23san francisco 49ersw 30 - 262 - 0fox 3:15 pm67536.032001-09-30miami dolphinsw 42 - 103 - 0cbs 12:00 pm66046.042001-10-08detroit lionsw 35 - 04 - 0abc 8:00 pm77765.052001-10-14new york giantsw 15 - 145 - 0fox 12:00 pm65992.062001-10-21new york jetsw 34 - 146 - 0fox 12:00 pm78766.072001-10-28new orleans saintsl 34 - 316 - 1fox 12:00 pm66189.089999-01-01----nan92001-11-11carolina panthersw 48 - 147 - 1fox 12:00 pm66069.0102001-11-18new england patriotsw 24 - 178 - 1espn 7:30 pm60292.0112001-11-26tampa bay buccaneersl 24 - 178 - 2abc 8:00 pm66198.0122001-12-02atlanta falconsw 35 - 69 - 2fox 3:15 pm60787.0132001-12-09san francisco 49ersw 27 - 1410 - 2fox 12:00 pm66218.0142001-12-17new orleans saintsw 34 - 2111 - 2abc 8:00 pm70332.0152001-12-23carolina panthersw 38 - 3212 - 2fox 12:00 pm72438.0162001-12-30indianapolis coltsw 42 - 1713 - 2cbs 12:00 pm66084.0172002-01-06atlanta falconsw 31 - 1314 - 2fox 3:15 pm66033.0\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN attendance = 66084 AND opponent = 'indianapolis colts' AND date = '2001-12-30' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1591.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the game played against the slough jets on the 2nd , was attended by 320 fans\nInput Table: 2008 - 09 guildford flames season\n\n\ndateopponentvenueresultattendancecompetitionman_of_the_match9999-01-01slough jetshomelost 2 - 31308league / cuplukas smital9999-01-02slough jetsawaylost 5 - 6 (ot)320leaguepaul dixon9999-01-08swindon wildcatsawaywon 6 - 3754league / cuplukas smital9999-01-09swindon wildcatshomewon 4 - 21568league / cupneil liddiard9999-01-15sheffield scimitarsawaywon 7 - 4364league / cuprick plant9999-01-16milton keynes lightninghomelost 2 - 41161league / cupdavid savage9999-01-19romford raidershomewon 6 - 21016league / cupalex mettam9999-01-22wightlink raidersawaylost 5 - 4509league / cupstuart potts9999-01-23telford tigershomewon 4 - 21368leaguealex mettam / mark williams9999-01-29romford raidershomewon 7 - 21238leaguemartin bouz9999-01-30bracknell beesawaywon 4 - 0not reportedleague / cupjoe watkins\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN attendance = 320 AND opponent = 'slough jets' AND date = '9999-01-02' THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-48.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the party with 21 total members has 18 more members than the party with the fewest total members\nInput Table: members of the 5th seanad\n\n\npartyadministrative_panelagricultural_panelcultural_and_educational_panelindustrial_and_commercial_panellabour_panelnational_university_of_irelanduniversity_of_dublinnominated_by_the_taoiseachtotalfianna f\u00e1il4423010721fine gael132201009labour party000150028clann na talmhan020010003independent010101339total7115911331160\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT total FROM table_sql WHERE party = 'fianna f\u00e1il') - \n             (SELECT MIN(total) FROM table_sql) >= 18 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-390.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: saint - louis fc game had the highest combined agg of any of the featured games\nInput Table: 1992 african cup of champions clubs\n\n\nteam_1aggteam_21st_leg2nd_legbotswana defence force xi1 - 2mbabane highlanders1 - 10 - 1arsenal (maseru)4 - 0eleven arrows fc3 - 01 - 0cd el\u00e1 nguema2 - 6primeiro de agosto2 - 30 - 3 1lprc oilers2 - 3mighty blackpool1 - 01 - 3asc police2 - 2 (4 - 5)as real bamako1 - 11 - 1port autonome0 - 0 (1 - 3)sporting clube da praia0 - 00 - 0saint - george sa2 - 4al ittihad2 - 10 - 3saint - louis fc2 - 7young africans1 - 31 - 4sahel sc4 - 2postel sport2 - 12 - 1tourbillon fc1 - 1forces arm\u00e9es ca0 - 01 - 1\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MAX(agg) FROM table_sql) = (SELECT agg FROM table_sql WHERE team_1 = 'saint - louis fc' OR team_2 = 'saint - louis fc') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1948.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the boston celtics only lost three games in the 1984 - 85 season\nInput Table: 1984 - 85 boston celtics season\n\n\ngamedateopponentscorelocationrecord339999-01-02new jersey nets110 - 95brendan byrne arena27 - 6349999-01-04new york knicks105 - 94boston garden28 - 6359999-01-07new york knicks108 - 97madison square garden29 - 6369999-01-09chicago bulls111 - 108boston garden30 - 6379999-01-11washington bullets103 - 101boston garden31 - 6389999-01-12atlanta hawks119 - 111the omni32 - 6399999-01-16los angeles lakers104 - 102boston garden33 - 6409999-01-18indiana pacers86 - 91market square arena33 - 7419999-01-20philadelphia 76ers113 - 97boston garden34 - 7429999-01-23seattle supersonics97 - 107boston garden34 - 8439999-01-25indiana pacers125 - 94boston garden35 - 8449999-01-27portland trail blazers128 - 127boston garden36 - 8459999-01-29detroit pistons131 - 130hartford civic center37 - 8469999-01-30philadelphia 76ers104 - 122the spectrum37 - 9\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 3 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE record LIKE '% - 8';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-955.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: on april 10 the chicago black hawks vs detroit red wings 's record was 1 - 1\nInput Table: 1965 - 66 chicago black hawks season\n\n\ndatevisitorscorehomerecord'9999-04-07'detroit red wings1 - 2chicago black hawks1 - 0'9999-04-10'detroit red wings7 - 0chicago black hawks1 - 1'9999-04-12'chicago black hawks2 - 1detroit red wings2 - 19999-04-14chicago black hawks1 - 5detroit red wings2 - 20000-04-17detroit red wings5 - 3chicago black hawks2 - 39999-04-19chicago black hawks2 - 3detroit red wings2 - 4\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE date = '9999-04-10' \nAND home = 'chicago black hawks' \nAND visitor = 'detroit red wings' \nAND record = '1 - 1';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the wildcats never scored more than 7 in any game they lost\nInput Table: 1947 kentucky wildcats football team\n\n\ngamedateopponentresultwildcats_pointsopponentsrecord19999-09-20ole missloss7140 - 129999-09-27cincinnatiwin2001 - 139999-10-04xavierwin2072 - 149999-10-119 georgiawin2603 - 1 , 2059999-10-1810 vanderbiltwin1404 - 1 , 1469999-10-25michigan statewin765 - 1 , 1379999-11-0118 alabamaloss0135 - 289999-11-08west virginiawin1566 - 299999-11-15evansvillewin3607 - 2109999-11-22tennesseeloss6137 - 3\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MAX(wildcats_points) FROM table_sql WHERE result = 'loss') <= 7 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-545.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the final episode for dea agent was titled vengeance\nInput Table: list of csi : miami characters\n\n\ncharacterpositionactorfirst_episodefinal_episodedurationfinal_episode_countdr tom lomanmedical examinerchristian clemenson9999-01-019999-01-0108x03 - 10x1952maxine valeradna technicianboti bliss9999-01-019999-01-0102x01 - 08x1176dan cooperav technicianbrendan fehr9999-01-019999-01-0104x01 - 06x1635tyler jensonav technicianbrian pothYYYY-MM-DD9999-10-0701x19 - 03x2429aaron peterstrace technicianarmando kennedy9999-01-019999-01-0103x07 - 04x2516cynthia wellsqd technicianbrooke bloom9999-01-012023-09-2002x16 - 05x1814jake berkeleydetectivejohnny whitworth9999-01-012022-01-0105x02 - 08x2112john hagendetectiveholt mccallany9999-01-019999-10-0701x17 - 03x2411adelle sevilladetectivewanda de jesus9999-01-019999-01-0101x03 - 01x1710rebecca nevinsasachristina chang9999-01-019999-01-0103x06 - 08x2310joseph kaylefingerprints technicianleslie odom , jr9999-01-019999-01-0102x05 - 03x20 , 04x22 - 04x249aaron jessopofficerjoel west9999-01-019999-01-0102x20 - 04x258sam belmontestrace technicianchristian de la fuente9999-01-012022-01-0102x03 - 03x057peter elliottsecret service agentmichael b silver9999-01-019999-01-0102x17 - 05x037monica westasabellamy young9999-01-019999-01-0104x10 - 04x256glen colefbi agentmark rolston9999-01-019999-01-0104x25 - 06x123bob keatondea agentmax martini9999-01-019999-01-0102x08 , 03x20 - 03x223mac taylornypd csigary sinise9999-01-019999-01-0102x23 , 04x072stella bonaseranypd csimelina kanakaredes9999-01-019999-01-0102x231aiden burnnypd csivanessa ferlito9999-01-019999-01-0102x231danny messernypd csicarmine giovinazzo9999-01-019999-01-0102x231sheldon hawkesnypd medical examinerhill harper9999-01-019999-01-0102x231\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT final_episode FROM table_sql WHERE character = 'bob keaton' AND position = 'dea agent') = 'vengeance' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1081.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: detroit had one of the lowest visitor scores this season\nInput Table: 2003 - 04 detroit red wings season\n\n\ndatevisitorscorehomedecisionattendancerecord0002-01-01detroit4 - 1carolinajoseph1705324 - 12 - 4 - 10001-01-03anaheim1 - 3detroitlegace2006625 - 12 - 4 - 10000-01-05nashville0 - 6detroitjoseph2006626 - 12 - 4 - 10001-01-07boston3 - 0detroitjoseph2006626 - 13 - 4 - 10000-01-10detroit1 - 2bostonjoseph1756526 - 13 - 4 - 29999-01-14chicago2 - 4detroitlegace2006627 - 13 - 4 - 20000-01-16phoenix3 - 3detroitjoseph2006627 - 13 - 5 - 29999-01-19detroit1 - 2san josejoseph1736127 - 14 - 5 - 29999-01-21detroit2 - 2anaheimlegace1717427 - 14 - 6 - 29999-01-22detroit5 - 4los angelesjoseph1811828 - 14 - 6 - 29999-01-24detroit2 - 5phoenixjoseph1901928 - 15 - 6 - 29999-01-26detroit2 - 2dallaslegace1853228 - 15 - 7 - 29999-01-29new jersey2 - 5detroitjoseph2006629 - 15 - 7 - 29999-01-31carolina4 - 4detroitlegace2006630 - 15 - 8 - 2\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MIN(score) FROM table_sql WHERE visitor = 'detroit') = \n             (SELECT MIN(score) FROM table_sql) \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1642.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: episode 4 is the earliest episode number that originally aired on june 8th , 2008\nInput Table: none\n\n\nepisodeoriginal_airdatetimeslot_(approx)viewers_(millions)nightly_rank12008-05-18sunday 6:30 - 7:30 pm1.351522008-05-25sunday 6:30 - 7:30 pm1.481432008-06-01sunday 6:30 - 7:30 pm1.514442008-06-08sunday 6:30 - 7:30 pm1.364452008-06-15sunday 6:30 - 7:30 pm1.515362008-06-22sunday 6:30 - 7:30 pm1.506472008-06-29sunday 6:30 - 7:30 pm1.512482008-07-06sunday 6:30 - 7:30 pm1.578292008-07-13sunday 6:30 - 7:30 pm1.682102008-07-20sunday 6:30 - 7:30 pm1.4323112008-07-27sunday 6:30 - 7:30 pm1.5474122008-08-31sunday 6:30 - 7:30 pm1.4624132008-09-07sunday 6:30 - 7:30 pm1.3494142008-11-10monday 7:30 - 9:00 pm1.6771152008-11-17monday 7:30 - 8:30 pm1.3244\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN episode = 4 AND original_airdate = '2008-06-08' THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1805.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: equestrian at the asian games happened every four years from 1982 to 2010 , except for in 1990\nInput Table: equestrian at the asian games\n\n\nyearlocationgoldsilverbronze1982new delhinadia al - moutawaajamila al - moutawaabariaa salem al - sabbah1986seoultakashi tomurashuichi tokiryuzo okuno1994hiroshimakonoshin kuwahararyuzo okunonatya chantrasmi1998bangkokjin kannosohn bong - gakquzier ambak fathil2002busanmikaela mar\u00e3\u00ada jaworskilee jin - kyungtadayoshi hayashi2006dohaali yousuf al - rumaihijasmine chen - shao manjoo jung - hyun2010guangzhouramzy al duhamilatifa al maktomkhaled al - eid\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE year >= 1982 \nAND year <= 2010 \nAND year != 1990;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-701.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: macoto cobras is the opponent of diegomar markwell\nInput Table: 2007 uni - president lions season\n\n\ndateopponentscorelosssave9999-03-17la new bears4 - 5pan wei - lunhuang chun - chung9999-03-18la new bears4 - 1horacio estradatseng yi - cheng9999-03-22chinatrust whales7 - 9kao lung - weini fu - deh9999-03-23chinatrust whales4 - 5pan wei - lunmiguel saladin9999-03-24la new bears1 - 5jeriome robertson||30089999-03-25la new bears1 - 6rob cordemanshuang chun - chung9999-03-27brother elephantspostponed rescheduled for june 19postponed rescheduled for june 19postponed rescheduled for june 199999-03-28brother elephants0 - 4tsao chun - yangchuang wei - chuan9999-03-31macoto cobras11 - 5diegomar markwell||2275\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN opponent = 'macoto cobras' AND save = 'diegomar markwell' THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1297.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: michael phelps has less medals than larisa latyna\nInput Table: list of multiple olympic medalists\n\n\nmedal_countdateathletenationsportrecord_medal_event11896-04-06james connollyunited statesathleticstriple jump g11896-04-06alexandre tuff\u00e8refranceathleticstriple jump s11896-04-06ioannis persakisgreeceathleticstriple jump b11896-04-06robert garrettunited statesathleticsdiscus g11896-04-06panagiotis paraskevopoulosgreeceathleticsdiscus s11896-04-06sotirios versisgreeceathleticsdiscus b21896-04-07robert garrettunited statesathleticslong jump s21896-04-07james connollyunited statesathleticslong jump b31896-04-07robert garrettunited statesathleticsshot put g31896-04-09carl schuhmanngermanygymnasticsvault g31896-04-09hermann weing\u00e4rtnergermanygymnasticsvault b41896-04-09hermann weing\u00e4rtnergermanygymnasticspommel horse s51896-04-09hermann weing\u00e4rtnergermanygymnasticsrings s61896-04-09hermann weing\u00e4rtnergermanygymnasticshorizontal bar g61900-07-16robert garrettunited statesathleticsstanding triple jump b61904-09-03ray ewryunited statesathleticsstanding triple jump g71908-07-20ray ewryunited statesathleticsstanding long jump g81908-07-23ray ewryunited statesathleticsstanding high jump g81920-07-29carl osburnunited statesshootingteam 300 m / 600 m military rifle , prone g91920-07-30carl osburnunited statesshooting300 m military rifle , standing g101920-07-31carl osburnunited statesshootingteam free rifle g111924-06-27carl osburnunited statesshooting600 m free rifle s111928-08-03paavo nurmifinlandathletics5000 m s121928-08-04paavo nurmifinlandathletics3000 m steeplechase s121960-09-02edoardo mangiarottiitalyfencingteam foil s131960-09-09edoardo mangiarottiitalyfencingteam \u00e9p\u00e9e g131964-10-21larisa latyninasoviet uniongymnasticsteam g141964-10-21larisa latyninasoviet uniongymnasticsall - around s151964-10-22larisa latyninasoviet uniongymnasticsvault s161964-10-22larisa latyninasoviet uniongymnasticsuneven bars b171964-10-23larisa latyninasoviet uniongymnasticsbalance beam b181964-10-23larisa latyninasoviet uniongymnasticsfloor exercise g182012-07-31michael phelpsunited statesswimming200 m butterfly s192012-07-31michael phelpsunited statesswimming4 x 200 m freestyle g202012-08-02michael phelpsunited statesswimming200 m individual medley g212012-08-03michael phelpsunited statesswimming100 m butterfly g222012-08-04michael phelpsunited statesswimming4 100 m medley relay g\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT medal_count FROM table_sql WHERE athlete = 'michael phelps') < \n             (SELECT medal_count FROM table_sql WHERE athlete = 'larisa latynina') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1926.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: stage 1 was the only stage where a mountains classification wasn't awarded\nInput Table: 2010 vuelta a espa\u00f1a\n\n\nstagewinnergeneral_classificationpoints_classificationmountains_classificationcombination_classificationteam_classification1team htc - columbiamark cavendishmark cavendish 1not awardedmark cavendishteam htc - columbia2yauheni hutarovichmark cavendishyauheni hutarovichmicka\u00ebl delagejavier ram\u00edrezteam htc - columbia3philippe gilbertphilippe gilbertphilippe gilbertseraf\u00edn mart\u00ednezseraf\u00edn mart\u00ednezteam htc - columbia4igor ant\u00f3nphilippe gilbertigor ant\u00f3nseraf\u00edn mart\u00ednezvincenzo nibalicaisse d'epargne5tyler farrarphilippe gilbertigor ant\u00f3nseraf\u00edn mart\u00ednezvincenzo nibalicaisse d'epargne6thor hushovdphilippe gilbertphilippe gilbertseraf\u00edn mart\u00ednezphilippe gilbertcaisse d'epargne7alessandro petacchiphilippe gilbertmark cavendishseraf\u00edn mart\u00ednezphilippe gilbertcaisse d'epargne8david moncouti\u00e9igor ant\u00f3nmark cavendishseraf\u00edn mart\u00ednezvincenzo nibalicaisse d'epargne9david l\u00f3pezigor ant\u00f3nmark cavendishdavid moncouti\u00e9vincenzo nibalicaisse d'epargne10imanol ervitijoaquim rodr\u00edguezmark cavendishdavid moncouti\u00e9david moncouti\u00e9caisse d'epargne11igor ant\u00f3nigor ant\u00f3nigor ant\u00f3ndavid moncouti\u00e9igor ant\u00f3ncaisse d'epargne12mark cavendishigor ant\u00f3nmark cavendishdavid moncouti\u00e9igor ant\u00f3ncaisse d'epargne13mark cavendishigor ant\u00f3nmark cavendishdavid moncouti\u00e9igor ant\u00f3ncaisse d'epargne14joaquim rodr\u00edguezvincenzo nibalimark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezcaisse d'epargne15carlos barredovincenzo nibalimark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezteam katusha16mikel nievejoaquim rodr\u00edguezmark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezteam katusha17peter velitsvincenzo nibalimark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezteam katusha18mark cavendishvincenzo nibalimark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezteam katusha19philippe gilbertvincenzo nibalimark cavendishdavid moncouti\u00e9joaquim rodr\u00edguezteam katusha20ezequiel mosquera 2vincenzo nibalimark cavendishdavid moncouti\u00e9vincenzo nibaliteam katusha21tyler farrarvincenzo nibalimark cavendishdavid moncouti\u00e9vincenzo nibaliteam katusha\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE stage = 1 \nAND mountains_classification = 'not awarded';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1505.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: suki to ietara iinoni had the 2nd most recent broadcast date\nInput Table: tsuki no koibito\n\n\nUnnamed:_0episode_titleromanized_titletranslation_of_titlebroadcast_dateratingsep 1\u304a\u307e\u3048\u304c\u6b32\u3057\u3044omae ga hosiii want you2010-05-1022.4%ep 2\u3042\u308a\u3048\u306a\u3044\u30ad\u30b9arienai kisuthe unthinkable kiss2010-05-1719.2%ep 3\u5fa9\u8b90\u306e\u30d7\u30ed\u30dd\u30fc\u30bafukusy\u016b no purop\u014dzuthe proposal out of revenge2010-05-2415.6%ep 4\u3053\u3093\u306a\u306b\u597d\u304d\u3060\u3063\u305f\u3093\u3060\u2026konna ni suki dattanda\u2026that 's how much i liked you2010-05-3115.5%ep 5\u597d\u304d\u3068\u8a00\u3048\u305f\u3089\u3044\u3044\u306e\u306bsuki to ietara iinoniif only i could say , i like you2010-06-0717.4%ep 6\u6700\u7d42\u7ae0\u5e8f\u5e55\u30fb\u5225\u308csaish\u016bsh\u014djomakuwakarea prologue of final chapter , farewell2010-06-1413.4%\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MAX(broadcast_date) FROM table_sql) = '2010-06-07' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-455.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: 9 of the dolphins final 10 games were victories\nInput Table: 1983 miami dolphins season\n\n\nweekdateopponentresultattendance11983-09-04buffalo billsw 12 - 07871521983-09-11new england patriotsw 34 - 245934331983-09-19los angeles raidersl 27 - 145779641983-09-25kansas city chiefsw 14 - 65078551983-10-02new orleans saintsl 17 - 76648961983-10-09buffalo billsl 38 - 355994871983-10-16new york jetsw 32 - 145861581983-10-23baltimore coltsw 21 - 73234391983-10-30los angeles ramsw 30 - 1472175101983-11-06san francisco 49ersw 20 - 1757832111983-11-13new england patriotsl 17 - 660771121983-11-20baltimore coltsw 37 - 054482131983-11-28cincinnati bengalsw 38 - 1474506141983-12-04houston oilersw 24 - 1739434151983-12-10atlanta falconsw 31 - 2456725161983-12-16new york jetsw 34 - 1459975\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE result = 'w' AND week > 6) = 9 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1000.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: in tokyo , japan , hikaru sato 's match ended before round 2\nInput Table: katsuya inoue\n\n\nresrecordopponentmethodeventroundtimelocationloss19 - 9 - 4naoyuki kotanisubmission (armbar)9999-01-019999-01-019999-01-019999-01-01loss19 - 8 - 4kota okazawako (punch)9999-01-019999-01-019999-01-019999-01-01win19 - 7 - 4katsuhiko nagatadecision (unanimous)9999-01-019999-01-039999-01-019999-01-01loss18 - 7 - 4maximo blancotko (strikes)9999-01-019999-01-029999-01-019999-01-01draw18 - 6 - 4mizuto hirotadraw9999-01-019999-01-039999-01-019999-01-01win17 - 6 - 3koji oishidecision (unanimous)9999-01-019999-01-039999-01-019999-01-01win18 - 6 - 3daisuke hanazawadecision (unanimous)9999-01-019999-01-039999-01-019999-01-01loss16 - 6 - 3nick diaztko (corner stoppage)9999-01-019999-01-019999-01-019999-01-01draw16 - 5 - 3djamal kurbanovdraw9999-01-019999-01-039999-01-019999-01-01win16 - 5 - 2satoru kitaokadecision (split)9999-01-019999-01-039999-01-019999-01-01draw15 - 5 - 2shigetoshi iwasedraw2007-01-019999-01-039999-01-019999-01-01win15 - 5 - 1fabricio nascimentotko (punches)2007-01-019999-01-029999-01-019999-01-01win14 - 5 - 1koji oishiko (punches)9999-01-019999-01-029999-01-019999-01-01x loss13 - 5 - 1yoshiyuki yoshidako (punch)9999-01-019999-01-019999-01-019999-01-01win13 - 4 - 1takefume hanaitko (punches)9999-01-019999-01-029999-01-019999-01-01x loss12 - 4 - 1daizo ishigedecision (unanimous)9999-01-069999-01-039999-01-019999-01-01win12 - 3 - 1kim haeng kitko (punches)9999-03-019999-01-039999-01-019999-01-01draw11 - 3 - 1satoru kitaokadraw9999-01-019999-01-039999-01-019999-01-01win11 - 3daisuke hanazawadecision (majority)9999-01-049999-01-039999-01-019999-01-01x loss10 - 3akira kikuchitko (punches)9999-01-029999-01-019999-01-019999-01-01win10 - 2kenji araiko (punch)9999-01-019999-01-029999-01-019999-01-01win9 - 2heath simstko (punches)9999-01-019999-01-019999-01-019999-01-01win8 - 2kyle nokedecision (split)9999-01-019999-01-039999-01-019999-01-01win7 - 2satoru kitaokadecision (unanimous)9999-01-019999-01-039999-01-019999-01-01win6 - 2takuya wadadecision (unanimous)9999-01-019999-01-039999-01-019999-01-01win5 - 2hikaru satotko (punches)9999-01-019999-01-019999-01-019999-01-01win4 - 2ichiro kanaidecision (majority)9999-01-019999-01-029999-01-019999-01-01x loss3 - 2eiji ishikawadecision (majority)9999-01-019999-01-029999-01-019999-01-01win3 - 1taro minatodecision (unanimous)9999-01-129999-01-029999-01-019999-01-01win2 - 1ichiro kanaidecision (unanimous)9999-01-079999-01-029999-01-019999-01-01win1 - 1motohiro tachiharadecision (unanimous)9999-01-059999-01-029999-01-019999-01-01x loss0 - 1yoshinori onikitko (strikes)9999-01-049999-01-019999-01-099999-01-01\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT time FROM table_sql WHERE location = 'tokyo' AND opponent = 'hikaru sato') < '9999-01-02' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1333.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: raymond felton led the team in assists 4 different times\nInput Table: 2009 - 10 charlotte bobcats season\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord4701-02-9999portlandl 79 - 98 (ot)raymond felton (23)gerald wallace (10)stephen jackson (4)rose garden 2010624 - 23489999-02-03la lakersl 97 - 99 (ot)stephen jackson (30)nazr mohammed (17)boris diaw (5)staples center 1899724 - 24499999-02-06new orleansl 99 - 104 (ot)stephen jackson (26)boris diaw (8)raymond felton (7)time warner cable arena 1916424 - 25509999-02-09washingtonw 94 - 92 (ot)stephen jackson (22)nazr mohammed (10)raymond felton (5)time warner cable arena 1237625 - 255101-02-10minnesotaw 93 - 92 (ot)stephen jackson (33)nazr mohammed (20)dj augustin (7)target center 1335226 - 255201-02-16new jerseyl 94 - 103 (ot)gerald wallace (21)gerald wallace , boris diaw (10)stephen jackson (5)time warner cable arena 1371226 - 26539999-02-19clevelandw 110 - 93 (ot)stephen jackson (29)tyrus thomas (12)boris diaw (9)time warner cable arena 1956827 - 26549999-02-20milwaukeel 88 - 93 (ot)stephen jackson (35)tyrus thomas (11)stephen jackson (5)bradley center 1717427 - 27559999-02-22la clippersl 94 - 98 (ot)gerald wallace (32)gerald wallace (12)boris diaw , raymond felton (9)staples center 1589227 - 28569999-02-24utahl 93 - 102 (ot)gerald wallace (27)gerald wallace (8)raymond felton (5)energysolutions arena 1991127 - 29\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 4 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE high_assists = (SELECT MAX(high_assists) FROM table_sql) \nAND high_assists >= 4;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1700.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: skip ron macdonald had a pf of 67 and ends lost of 51\nInput Table: 2005 tim hortons brier\n\n\nlocaleskipwlpfpaends_wonends_lostblank_endsstolen_endsshot_pctalbertarandy ferbey92905848437986%manitobarandy dutiaume8377694744101379%nova scotiashawn adams8380604741161383%quebecjean - michel m\u00e3nard747769544081580%british columbiadeane horning6572654745181280%ontariowayne middaugh657562424610782%newfoundland and labradorbrad gushue6576694845131079%saskatchewanpat simmons656661434512980%prince edward islandrod macdonald476785415112579%northern ontariomike jakubo38648641489679%new brunswickwade blanchard385683414517878%\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT pf FROM table_sql WHERE skip = 'ron macdonald') = 67 \n             AND (SELECT ends_lost FROM table_sql WHERE skip = 'ron macdonald') = 51 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1869.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: patty sheehan , judy rankin , and kathy whitworth were all captains that won the cup two times\nInput Table: solheim cup\n\n\nyearvenuewinning_teamscoreusa_captaineurope_captain2013-01-01colorado golf club , colorado , usaeurope18 - 10meg mallonliselotte neumann2011-01-01killeen castle golf resort , irelandeurope15 - 13rosie jonesalison nicholas2009-01-01rich harvest farms , illinois , usaunited states16 - 12beth danielalison nicholas2007-01-01halmstad gk , swedenunited states16 - 12betsy kinghelen alfredsson2005-01-01crooked stick golf club , indiana , usaunited states15\u00bd - 12\u00bdnancy lopezcatrin nilsmark2003-01-01barseb\u00e4ck golf & country club , swedeneurope17\u00bd - 10\u00bdpatty sheehancatrin nilsmark2002-01-01interlachen country club , minnesota , usaunited states15\u00bd - 12\u00bdpatty sheehandale reid2000-01-01loch lomond golf club , scotlandeurope14\u00bd - 11\u00bdpat bradleydale reid1998-01-01muirfield village , ohio , usaunited states16 - 12judy rankinpia nilsson1996-01-01st pierre golf & country club , walesunited states17 - 11judy rankinmickey walker1994-01-01the greenbrier , west virginia , usaunited states13 - 7joanne carnermickey walker1992-01-01dalmahoy country club , scotlandeurope11\u00bd - 6\u00bdkathy whitworthmickey walker1990-01-01lake nona golf & country club , florida , usaunited states11\u00bd - 4\u00bdkathy whitworthmickey walker\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE usa_captain = 'patty sheehan' AND winning_team = 'united states') = 2 \n             AND (SELECT COUNT(*) FROM table_sql WHERE usa_captain = 'judy rankin' AND winning_team = 'united states') = 2 \n             AND (SELECT COUNT(*) FROM table_sql WHERE usa_captain = 'kathy whitworth' AND winning_team = 'united states') = 2 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1524.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: north melbourne 's home opponent was st kilda\nInput Table: 1969 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddategeelong16.14 (110)hawthorn14.11 (95)kardinia park315691969-08-23collingwood19.15 (129)south melbourne6.22 (58)victoria park194281969-08-23carlton20.7 (127)richmond24.12 (156)princes park276571969-08-23st kilda21.18 (144)north melbourne8.10 (58)moorabbin oval111091969-08-23melbourne14.13 (97)fitzroy14.15 (99)mcg177901969-08-23footscray14.10 (94)essendon12.10 (82)western oval160431969-08-23\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE home_team = 'north melbourne' \nAND away_team = 'st kilda';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-136.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: during march 13 , the toronto maple leafs were the opponent with 63 points\nInput Table: none\n\n\ngamemarchopponentscorerecordpoints639999-01-04detroit red wings2 - 224 - 28 - 1159649999-01-06california golden seals4 - 424 - 28 - 1260659999-01-07minnesota north stars1 - 324 - 29 - 1260669999-01-10pittsburgh penguins2 - 224 - 29 - 1361679999-01-12new york rangers2 - 724 - 30 - 1361689999-01-13toronto maple leafs3 - 225 - 30 - 1363699999-01-18new york rangers2 - 126 - 30 - 1365709999-01-20boston bruins3 - 526 - 31 - 1365719999-01-21toronto maple leafs1 - 126 - 31 - 1466729999-01-24montreal canadiens3 - 526 - 32 - 1466739999-01-25minnesota north stars2 - 226 - 32 - 1567749999-01-27chicago black hawks1 - 326 - 33 - 1567759999-01-28pittsburgh penguins3 - 127 - 33 - 1569\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT opponent FROM table_sql WHERE march = '9999-03-13') = 'toronto maple leafs' \n             AND (SELECT points FROM table_sql WHERE march = '9999-03-13') = 63 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1421.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the gap between first and last was a total of 58.04\nInput Table: 1976 world junior figure skating championships\n\n\nranknamenationsp_+_fspointsplaces1mark cockerellunited states1172.4211.02takashi murajapan2165.724.03brian pockarcanada3166.6223.04norbert schrammwest germany4159.840.05andrew bestwickunited kingdom5158.148.06stephan brilwest germany7155.7257.07patrice macrezfrance6151.7671.08pierre laminefrance8150.579.09shinji someyajapan10150.3474.510jozef sabov\u010d\u00edkczechoslovakia9148.8887.011daniel fuererswitzerland13146.1892.512gerald schranzaustria11143.04102.013helmut kristofics - binderaustria15137.32123.014michael pasfieldaustralia12136.6119.015francis demarteaubelgium14131.02140.016adrian vasileromania16127.74143.017miljan begovicyugoslavia17127.3143.018jeremy dowsonsouth africa18114.98166.019marc franquetbelgium19114.38167.0\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT points FROM table_sql WHERE rank = 1) - (SELECT points FROM table_sql WHERE rank = 19) = 58.04 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-208.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: in 1997 , jeff gordon finished with a time of 3:34:33\nInput Table: pocono 400\n\n\nyeardatedriverteammanufacturerlaps-race_timeaverage_speed_(mph)report1982-01-019999-06-06bobby allisondigard motorsportsbuick200500 (804.672)4:24:08113.579report1983-01-019999-06-12bobby allisondigard motorsportsbuick200500 (804.672)3:53:13128.636report1984-01-019999-06-10cale yarboroughranier - lundychevrolet200500 (804.672)3:37:08138.164report1985-01-019999-06-09bill elliottmelling racingford200500 (804.672)3:35:48138.974report1986-01-019999-06-08tim richmondhendrick motorsportschevrolet200500 (804.672)4:24:50113.279report1987-01-019999-06-14tim richmondhendrick motorsportschevrolet200500 (804.672)4:05:57122.166report1988-01-019999-06-19geoffrey bodinehendrick motorsportschevrolet200500 (804.672)3:58:21126.147report1989-01-019999-06-18terry labontejunior johnson & associatesford200500 (804.672)3:48:27131.32report1990-01-019999-06-17harry gantleo jackson racingoldsmobile200500 (804.672)4:08:25120.6report1991-01-019999-06-16darrell waltripdarwal , incchevrolet200500 (804.672)4:04:34122.666report1992-01-019999-06-14alan kulwickiak racingford200500 (804.672)3:28:18144.023report1993-01-019999-06-13kyle pettysabco racingpontiac200500 (804.672)3:37:23138.005report1994-01-019999-06-12rusty wallacepenske racingford200500 (804.672)3:52:55128.801report1995-01-019999-06-11terry labontehendrick motorsportschevrolet200500 (804.672)3:37:50137.72report1996-01-019999-06-16jeff gordonhendrick motorsportschevrolet200500 (804.672)3:35:40139.104report1997-01-019999-06-08jeff gordonhendrick motorsportschevrolet200500 (804.672)3:34:33139.828report1998-01-019999-06-21jeremy mayfieldpenske racingford200500 (804.672)4:14:39117.809report1999-01-019999-06-20bobby labontejoe gibbs racingpontiac200500 (804.672)4:12:19118.898report2000-01-019999-06-19jeremy mayfieldpenske racingford200500 (804.672)3:34:41139.741report2001-01-019999-06-17ricky ruddrobert yates racingford200500 (804.672)3:43:14134.389report2002-01-019999-06-09dale jarrettrobert yates racingford200500 (804.672)3:29:10143.426report2003-01-019999-06-08tony stewartjoe gibbs racingchevrolet200500 (804.672)3:42:24134.892report2004-01-019999-06-13jimmie johnsonhendrick motorsportschevrolet200500 (804.672)4:27:33112.129report2005-01-019999-06-12carl edwardsroush racingford201502.5 (808.695)3:53:24129.177report2006-01-019999-06-11denny hamlinjoe gibbs racingchevrolet200500 (804.672)3:47:52131.656report2007-01-019999-06-10jeff gordonhendrick motorsportschevrolet106265 (426.476)1:57:15135.608report2008-01-019999-06-08kasey kahnegillett evernham motorsportsdodge200500 (804.672)3:59:36125.209report2009-01-019999-06-07tony stewartstewart - haas racingchevrolet200500 (804.672)3:36:35138.515report2010-01-019999-06-06denny hamlinjoe gibbs racingtoyota204510 (820.765)3:44:30136.303report2011-01-019999-06-12jeff gordonhendrick motorsportschevrolet200500 (804.672)3:26:21145.384report2012-01-019999-06-10joey loganojoe gibbs racingtoyota160400 (643.737)3:03:12131.004report\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE year = 1997 \nAND driver = 'jeff gordon' \nAND race_time = '3:34:33';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1076.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: detroit had the highest visitor score , with 5 points\nInput Table: 2003 - 04 detroit red wings season\n\n\ndatevisitorscorehomedecisionattendancerecord0002-01-01detroit4 - 1carolinajoseph1705324 - 12 - 4 - 10001-01-03anaheim1 - 3detroitlegace2006625 - 12 - 4 - 10000-01-05nashville0 - 6detroitjoseph2006626 - 12 - 4 - 10001-01-07boston3 - 0detroitjoseph2006626 - 13 - 4 - 10000-01-10detroit1 - 2bostonjoseph1756526 - 13 - 4 - 29999-01-14chicago2 - 4detroitlegace2006627 - 13 - 4 - 20000-01-16phoenix3 - 3detroitjoseph2006627 - 13 - 5 - 29999-01-19detroit1 - 2san josejoseph1736127 - 14 - 5 - 29999-01-21detroit2 - 2anaheimlegace1717427 - 14 - 6 - 29999-01-22detroit5 - 4los angelesjoseph1811828 - 14 - 6 - 29999-01-24detroit2 - 5phoenixjoseph1901928 - 15 - 6 - 29999-01-26detroit2 - 2dallaslegace1853228 - 15 - 7 - 29999-01-29new jersey2 - 5detroitjoseph2006629 - 15 - 7 - 29999-01-31carolina4 - 4detroitlegace2006630 - 15 - 8 - 2\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MAX(score) FROM table_sql WHERE visitor = 'detroit') = 5 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1332.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the most rebounds by a bobcats player in one game was 20\nInput Table: 2009 - 10 charlotte bobcats season\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord4701-02-9999portlandl 79 - 98 (ot)raymond felton (23)gerald wallace (10)stephen jackson (4)rose garden 2010624 - 23489999-02-03la lakersl 97 - 99 (ot)stephen jackson (30)nazr mohammed (17)boris diaw (5)staples center 1899724 - 24499999-02-06new orleansl 99 - 104 (ot)stephen jackson (26)boris diaw (8)raymond felton (7)time warner cable arena 1916424 - 25509999-02-09washingtonw 94 - 92 (ot)stephen jackson (22)nazr mohammed (10)raymond felton (5)time warner cable arena 1237625 - 255101-02-10minnesotaw 93 - 92 (ot)stephen jackson (33)nazr mohammed (20)dj augustin (7)target center 1335226 - 255201-02-16new jerseyl 94 - 103 (ot)gerald wallace (21)gerald wallace , boris diaw (10)stephen jackson (5)time warner cable arena 1371226 - 26539999-02-19clevelandw 110 - 93 (ot)stephen jackson (29)tyrus thomas (12)boris diaw (9)time warner cable arena 1956827 - 26549999-02-20milwaukeel 88 - 93 (ot)stephen jackson (35)tyrus thomas (11)stephen jackson (5)bradley center 1717427 - 27559999-02-22la clippersl 94 - 98 (ot)gerald wallace (32)gerald wallace (12)boris diaw , raymond felton (9)staples center 1589227 - 28569999-02-24utahl 93 - 102 (ot)gerald wallace (27)gerald wallace (8)raymond felton (5)energysolutions arena 1991127 - 29\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MAX(high_rebounds) FROM table_sql) = 20 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1871.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the highest score for a winning team was 18 and the lowest score was 11.5\nInput Table: solheim cup\n\n\nyearvenuewinning_teamscoreusa_captaineurope_captain2013-01-01colorado golf club , colorado , usaeurope18 - 10meg mallonliselotte neumann2011-01-01killeen castle golf resort , irelandeurope15 - 13rosie jonesalison nicholas2009-01-01rich harvest farms , illinois , usaunited states16 - 12beth danielalison nicholas2007-01-01halmstad gk , swedenunited states16 - 12betsy kinghelen alfredsson2005-01-01crooked stick golf club , indiana , usaunited states15\u00bd - 12\u00bdnancy lopezcatrin nilsmark2003-01-01barseb\u00e4ck golf & country club , swedeneurope17\u00bd - 10\u00bdpatty sheehancatrin nilsmark2002-01-01interlachen country club , minnesota , usaunited states15\u00bd - 12\u00bdpatty sheehandale reid2000-01-01loch lomond golf club , scotlandeurope14\u00bd - 11\u00bdpat bradleydale reid1998-01-01muirfield village , ohio , usaunited states16 - 12judy rankinpia nilsson1996-01-01st pierre golf & country club , walesunited states17 - 11judy rankinmickey walker1994-01-01the greenbrier , west virginia , usaunited states13 - 7joanne carnermickey walker1992-01-01dalmahoy country club , scotlandeurope11\u00bd - 6\u00bdkathy whitworthmickey walker1990-01-01lake nona golf & country club , florida , usaunited states11\u00bd - 4\u00bdkathy whitworthmickey walker\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MAX(CAST(SUBSTR(score, 1, INSTR(score, '-')-1) AS INTEGER)) FROM table_sql WHERE winning_team = 'europe') = 18 \n             AND (SELECT MIN(CAST(SUBSTR(score, 1, INSTR(score, '-')-1) AS INTEGER)) FROM table_sql WHERE winning_team = 'europe') = 11.5 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1274.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: chauncey billups led or was tied for the lead in assists for 10 out of 13 games\nInput Table: 2009 - 10 denver nuggets season\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord39999-11-01grizzliesw 133 - 123 (ot)carmelo anthony (42)nen\u00ea (9)chauncey billups (12)pepsi center 158233 - 049999-11-03pacersw 111 - 93 (ot)carmelo anthony (25)nen\u00ea (13)anthony carter (5)conseco fieldhouse 106274 - 059999-11-04netsw 122 - 94 (ot)ty lawson (23)kenyon martin (10)chauncey billups (5)izod center 153195 - 079999-11-07hawksl 100 - 125 (ot)carmelo anthony (30)chris andersen (11)chauncey billups (7)philips arena 178015 - 289999-11-10bullsw 90 - 89 (ot)carmelo anthony (20)nen\u00ea (12)chauncey billups (6)united center 214096 - 299999-11-11bucksl 102 - 108 (ot)carmelo anthony (32)carmelo anthony (10)chauncey billups , ty lawson (5)bradley center 129876 - 3109999-11-13lakersw 105 - 79 (ot)carmelo anthony (25)chris andersen (11)chauncey billups (8)pepsi center 191417 - 3119999-11-17raptorsw 130 - 112 (ot)carmelo anthony (32)nen\u00ea (10)chauncey billups (10)pepsi center 164468 - 3129999-11-20clippersl 99 - 106 (ot)carmelo anthony (37)nen\u00ea (12)chauncey billups (7)staples center 181558 - 4139999-11-21bullsw 112 - 93 (ot)carmelo anthony (30)carmelo anthony , kenyon martin (11)carmelo anthony (7)pepsi center 193599 - 4149999-11-24netsw 101 - 87 (ot)carmelo anthony (27)nen\u00ea (9)chauncey billups (7)pepsi center 1630710 - 4159999-11-25timberwolvesw 124 - 111 (ot)carmelo anthony (22)nen\u00ea (8)nen\u00ea , ty lawson (6)target center 1310111 - 4169999-11-27knicksw 128 - 125 (ot)carmelo anthony (50)nen\u00ea , kenyon martin (11)chauncey billups (8)pepsi center 1915512 - 4\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE high_assists >= (SELECT MAX(high_assists) FROM table_sql)) = 10 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1438.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the dallas cowboys lost at texas stadium on december 10 to the new orleans saints\nInput Table: nbc sunday night football results (2006 - present)\n\n\ndatevisiting_teamfinal_scorehost_teamstadium9999-09-07miami dolphins17 - 28pittsburgh steelersheinz field9999-09-10indianapolis colts26 - 21new york giantsgiants stadium9999-09-17washington redskins10 - 27dallas cowboystexas stadium9999-09-24denver broncos17 - 7new england patriotsgillette stadium9999-10-01seattle seahawks6 - 37chicago bearssoldier field9999-10-08pittsburgh steelers13 - 23san diego chargersqualcomm stadium9999-10-15oakland raiders3 - 13denver broncosinvesco field at mile high9999-10-29dallas cowboys35 - 14carolina panthersbank of america stadium9999-11-05indianapolis colts27 - 20new england patriotsgillette stadium9999-11-12chicago bears38 - 20new york giantsgiants stadium9999-11-19san diego chargers35 - 27denver broncosinvesco field at mile high9999-11-26philadelphia eagles21 - 45indianapolis coltsrca dome9999-12-03seattle seahawks23 - 20denver broncosinvesco field at mile high9999-12-10new orleans saints42 - 17dallas cowboystexas stadium9999-12-17kansas city chiefs9 - 20san diego chargersqualcomm stadium9999-12-25philadelphia eagles23 - 7dallas cowboystexas stadium9999-12-31green bay packers26 - 7chicago bearssoldier field0001-01-06kansas city chiefs8 - 23indianapolis coltsrca dome0001-01-06dallas cowboys20 - 21seattle seahawksqwest field\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE date = '9999-12-10' \nAND host_team = 'dallas cowboys' \nAND stadium = 'texas stadium' \nAND visiting_team = 'new orleans saints' \nAND final_score = '42 - 17' \nAND final_score NOT LIKE '% - %';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-513.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the player ranked sixth is from south korea and the notes indicate sc / d\nInput Table: rowing at the 2008 summer olympics - men 's lightweight double sculls\n\n\nrankrowerscountrytimenotes1pedro fraga , nuno mendesportugal6:39.07sa / b2eyder batista , yunior perezcuba6:40.15sa / b3kazushige ura , daisaku takedajapan6:43.03sc / d4zsolt hirling , tam\u00e3\u00a1s vargahungary6:50.48sc / d5devender kumar khandwal , manjeet singhindia7:02.06sc / d6jang kang - eun , kim hong - kyunsouth korea7:12.17sc / d\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT rowers FROM table_sql WHERE rank = 6) LIKE '%south korea%' \n             AND (SELECT notes FROM table_sql WHERE rank = 6) = 'sc / d' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1776.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: from 1965 - 1970 , there were 998000 deaths per year and 3330000 live births per year\nInput Table: none\n\n\nperiodlive_births_per_yeardeaths_per_yearnatural_change_per_yearcbrcdrnctfrimrlife_expectancy_totallife_expectancy_maleslife_expectancy_females1950-01-01 - 1955-01-012 572 000900 0001 672 00044.115.528.66.1513550.949.252.61955-01-01 - 1960-01-012 918 000947 0001 971 00043.214.029.16.1512253.351.555.21960-01-01 - 1965-01-013 303 000986 0002 317 00042.212.629.66.1510955.753.857.69999-01-01 - 1970-01-013 330 000998 0002 332 00037.011.125.95.3810057.655.759.61970-01-01 - 1975-01-013 441 0001 014 0002 427 00033.79.923.84.729159.557.361.81975-01-01 - 1980-01-013 741 0001 043 0002 698 00032.59.023.54.317961.559.263.91980-01-01 - 1985-01-013 974 0001 064 0002 910 00030.88.222.63.86363.460.466.81985-01-01 - 1990-01-013 757 0001 055 0002 702 00026.37.418.93.15265.361.969.11990-01-01 - 1995-01-013 519 0001 058 0002 461 00022.66.815.82.64367.363.671.21995-01-01 - 2000-01-013 624 0001 086 0002 538 00021.56.515.12.453469.365.573.32000-01-01 - 2005-01-013 572 0001 147 0002 425 00019.86.413.42.252770.967.274.8\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE period = '1965-01-01 - 1970-01-01' \nAND deaths_per_year = 998000 \nAND live_births_per_year = 3330000;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1228.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the lowest attendance figure for a game was 42048\nInput Table: 1976 detroit lions season\n\n\nweekdateopponentresultattendance11976-09-12chicago bearsl 10 - 35412521976-09-19atlanta falconsw 24 - 105084031976-09-26minnesota vikingsl 10 - 97729241976-10-03green bay packersl 24 - 145504151976-10-10new england patriotsw 30 - 106017461976-10-17washington redskinsl 20 - 74590871976-10-24seattle seahawksw 41 - 146128081976-10-31green bay packersw 27 - 67499291976-11-07minnesota vikingsl 31 - 2346735101976-11-14new orleans saintsl 17 - 1642048111976-11-21chicago bearsw 14 - 1078042121976-11-25buffalo billsw 27 - 1466875131976-12-05new york giantsl 24 - 1066069141976-12-11los angeles ramsl 20 - 1773470\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN MIN(attendance) = 42048 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-680.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: justin leonard scores a 212 , making him tied for 8th place\nInput Table: 2002 u.s. open (golf)\n\n\nplaceplayercountryscoreto_par1tiger woodsunited states67 + 68 + 70 = 205- 52sergio garc\u00edaspain68 + 74 + 67 = 209- 1t3jeff maggertunited states69 + 73 + 68 = 210et3phil mickelsonunited states70 + 73 + 67 = 210et5robert allenbyaustralia74 + 70 + 67 = 211+ 1t5p\u00e1draig harringtonireland70 + 68 + 73 = 211+ 1t5billy mayfairunited states69 + 74 + 68 = 211+ 1t8nick faldoengland70 + 76 + 66 = 212+ 2t8justin leonardunited states73 + 71 + 68 = 212+ 2t10tom byrumunited states72 + 72 + 70 = 214+ 4t10davis love iiiunited states71 + 71 + 72 = 214+ 4t10scott mccarronunited states72 + 72 + 70 = 214+ 4\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT place FROM table_sql WHERE player = 'justin leonard' AND score = 212) = 't8' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1344.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: collingwood scored more points than fitzroy in their 1962 vfl match\nInput Table: 1962 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddatemelbourne11.18 (84)st kilda11.6 (72)mcg489521962-06-23essendon15.17 (107)geelong10.7 (67)windy hill350001962-06-23collingwood10.14 (74)fitzroy9.11 (65)victoria park264881962-06-23carlton12.9 (81)footscray9.10 (64)princes park324001962-06-23south melbourne10.13 (73)richmond11.13 (79)lake oval170001962-06-23north melbourne10.8 (68)hawthorn10.7 (67)arden street oval84701962-06-23\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT home_team_score FROM table_sql WHERE home_team = 'collingwood' AND date = '1962-06-23') > \n             (SELECT away_team_score FROM table_sql WHERE away_team = 'fitzroy' AND date = '1962-06-23') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-875.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: annika s\u00f6renstam and yani tseng won with the lowest number of strokes\nInput Table: women 's british open\n\n\nyeardatesvenuechampioncountryscoreto_parmargin_of_victoryrunner_(s)_-_uppursewinner_'s_share20139999-08-01old course at st andrewsstacy lewisunited states280- 82 strokesna yeon choi hee young park275000040258320129999-09-13royal liverpool golf clubjiyai shinsouth korea279- 99 strokesinbee park275000042865020119999-07-28carnoustie golf linksyani tsengtaiwan272- 164 strokesbrittany lang250000039213320109999-07-29 - 9999-08-01royal birkdale golf clubyani tsengtaiwan277- 111 strokekatherine hull250000040871420099999-07-30 - 9999-08-02royal lytham & st annes golf clubcatriona matthewscotland285- 33 strokeskarrie webb220000033500020089999-07-31 - 9999-08-03sunningdale golf clubjiyai shinsouth korea270- 183 strokesyani tseng210000031446420079999-08-02old course at st andrewslorena ochoamexico287- 54 strokesmaria hjorth jee young lee200000032051220069999-08-03royal lytham & st annes golf clubsherri steinhauerunited states281- 73 strokessophie gustafson cristie kerr180000030544020059999-07-28royal birkdale golf clubjeong jangsouth korea272- 164 strokessophie gustafson180000028020820049999-07-29 - 9999-08-01sunningdale golf clubkaren stupplesengland269- 195 strokesrachel hetherington160000029088020039999-07-31 - 9999-08-03royal lytham & st annes golf clubannika s\u00f6renstamsweden278- 101 strokese ri pak160000025488020029999-08-08turnberry - ailsa coursekarrie webbaustralia273- 152 strokesmichelle ellis paula mart\u00ed150000023638320019999-08-02sunningdale golf clubse ri paksouth korea277- 112 strokesmi hyun kim1500000221650\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MIN(score) FROM table_sql WHERE champion = 'annika s\u00f6renstam') = \n             (SELECT MIN(score) FROM table_sql WHERE champion = 'yani tseng') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-819.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: frank nobilo is the only player from new zealand\nInput Table: 1996 pga championship\n\n\nplaceplayercountryscoreto_parmoney1mark brooksunited states68 + 70 + 69 + 70 = 277- 114300002kenny perryunited states66 + 72 + 71 + 68 = 277- 11260000t3steve elkingtonaustralia67 + 74 + 67 + 70 = 278- 10140000t3tommy tollesunited states69 + 71 + 71 + 67 = 278- 10140000t5justin leonardunited states71 + 66 + 72 + 70 = 279- 986667t5jesper parneviksweden73 + 67 + 69 + 70 = 279- 986667t5vijay singhfiji69 + 69 + 69 + 72 = 279- 986667t8lee janzenunited states68 + 71 + 71 + 70 = 280- 857500t8per - ulrik johanssonsweden73 + 72 + 66 + 69 = 280- 857500t8phil mickelsonunited states67 + 67 + 74 + 72 = 280- 857500t8larry mizeunited states71 + 70 + 69 + 70 = 280- 857500t8frank nobilonew zealand69 + 72 + 71 + 68 = 280- 857500t8nick pricezimbabwe68 + 71 + 69 + 72 = 280- 857500\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 1 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE country = 'new zealand' \nAND player != 'frank nobilo';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-217.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the maximum number discs is 1\nInput Table: none\n\n\nvolumediscsepisodesregion_1region_2region_41142006-01-312007-02-192007-03-152142006-03-282007-06-042007-07-053142006-05-302007-09-032008-03-134142006-07-182008-02-182008-06-195142006-09-192008-05-262009-03-05\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN MAX(discs) = 1 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1334.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the bobcats had a record of 3 wins and 7 losses\nInput Table: 2009 - 10 charlotte bobcats season\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord4701-02-9999portlandl 79 - 98 (ot)raymond felton (23)gerald wallace (10)stephen jackson (4)rose garden 2010624 - 23489999-02-03la lakersl 97 - 99 (ot)stephen jackson (30)nazr mohammed (17)boris diaw (5)staples center 1899724 - 24499999-02-06new orleansl 99 - 104 (ot)stephen jackson (26)boris diaw (8)raymond felton (7)time warner cable arena 1916424 - 25509999-02-09washingtonw 94 - 92 (ot)stephen jackson (22)nazr mohammed (10)raymond felton (5)time warner cable arena 1237625 - 255101-02-10minnesotaw 93 - 92 (ot)stephen jackson (33)nazr mohammed (20)dj augustin (7)target center 1335226 - 255201-02-16new jerseyl 94 - 103 (ot)gerald wallace (21)gerald wallace , boris diaw (10)stephen jackson (5)time warner cable arena 1371226 - 26539999-02-19clevelandw 110 - 93 (ot)stephen jackson (29)tyrus thomas (12)boris diaw (9)time warner cable arena 1956827 - 26549999-02-20milwaukeel 88 - 93 (ot)stephen jackson (35)tyrus thomas (11)stephen jackson (5)bradley center 1717427 - 27559999-02-22la clippersl 94 - 98 (ot)gerald wallace (32)gerald wallace (12)boris diaw , raymond felton (9)staples center 1589227 - 28569999-02-24utahl 93 - 102 (ot)gerald wallace (27)gerald wallace (8)raymond felton (5)energysolutions arena 1991127 - 29\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE record = '3 - 7') = 1 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1250.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: both pakistan and yemen have won one bronze medal for wushu at the asian games\nInput Table: wushu at the asian games\n\n\nranknationgoldsilverbronzetotal1china (chn)4373532iran (iri)435123malaysia (mas)31594hong kong (hkg)294155thailand (tha)236116japan (jpn)165127philippines (phi)158148macau (mac)154109south korea (kor)1461110chinese taipei (tpe)13111511myanmar (mya)112412vietnam (vie)0971613indonesia (ina)022414laos (lao)015615india (ind)012316pakistan (pak)011217singapore (sin)005518mongolia (mgl)003319kazakhstan (kaz)002220yemen (yem)0011totaltotal606187208\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT bronze FROM table_sql WHERE nation = 'pakistan') = 1 \n             AND (SELECT bronze FROM table_sql WHERE nation = 'yemen') = 1 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1983.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the match with the highest attendance was against sheffield united\nInput Table: 2000 - 01 sheffield wednesday f.c. season\n\n\ndateopponentvenueresultattendance2000-08-13wolverhampton wanderersa1 - 1190862000-08-19huddersfield townh2 - 3227042000-08-26grimsby towna1 - 077552000-08-28blackburn roversh1 - 1156462000-09-09wimbledonh0 - 5158562000-09-13nottingham foresth0 - 1157002000-09-16tranmere roversa0 - 293522000-09-23preston north endh1 - 3173792000-09-30gillinghama0 - 290992000-10-08west bromwich albionh1 - 2153382000-10-14portsmoutha1 - 2133762000-10-17burnleya0 - 1163722000-10-22birmingham cityh1 - 0146952000-10-25queens park rangersa2 - 1103532000-10-28fulhamh3 - 3175592000-11-04crystal palacea1 - 4153332000-11-07watforda3 - 1111662000-11-01norwich cityh3 - 2169562000-11-18barnsleya0 - 1199892000-11-25crewe alexandraa0 - 171032000-12-02queens park rangersh5 - 2217822000-12-09stockport countyh2 - 4163372000-12-16sheffield uniteda1 - 1251562000-12-23wolverhampton wanderersh0 - 1177872000-12-26bolton wanderersa0 - 2213162000-12-30huddersfield towna0 - 0189312001-01-01grimsby townh1 - 0170042001-01-13blackburn roversa0 - 2193082001-01-20bolton wanderersh0 - 3176382001-02-03watfordh2 - 3161342001-02-10wimbledona1 - 467412001-02-13tranmere roversh1 - 0154442001-02-21nottingham foresta1 - 0232662001-02-24preston north enda0 - 2143792001-03-03gillinghamh2 - 1187022001-03-07portsmouthh0 - 0205032001-03-10west bromwich albiona2 - 1186622001-03-17burnleyh2 - 0201842001-03-24birmingham citya2 - 1197332001-04-01sheffield unitedh1 - 2384332001-04-07stockport countya1 - 296662001-04-14crystal palaceh4 - 1198772001-04-16fulhama1 - 1175002001-04-21barnsleyh2 - 1234982001-04-28norwich citya0 - 1212412001-05-06crewe alexandrah0 - 028007\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN attendance = (SELECT MAX(attendance) FROM table_sql WHERE opponent = 'sheffield united') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-250.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: sweden placed lower than austria in the total medal count for the 1988 olympics\nInput Table: 1988 winter olympics\n\n\nranknationgoldsilverbronzetotal1soviet union (urs)1199292east germany (gdr)9106253switzerland (sui)555154finland (fin)41275sweden (swe)40266austria (aut)352107netherlands (ned)32278west germany (frg)24289united states (usa)213610italy (ita)212513canada (can)0235\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT rank FROM table_sql WHERE nation = 'sweden') > \n             (SELECT rank FROM table_sql WHERE nation = 'austria') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-246.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: six different countries received the same number of bronze medals\nInput Table: 1988 winter olympics\n\n\nranknationgoldsilverbronzetotal1soviet union (urs)1199292east germany (gdr)9106253switzerland (sui)555154finland (fin)41275sweden (swe)40266austria (aut)352107netherlands (ned)32278west germany (frg)24289united states (usa)213610italy (ita)212513canada (can)0235\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(DISTINCT nation) = 6 AND COUNT(bronze) = 1 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE bronze = (SELECT bronze FROM table_sql GROUP BY bronze HAVING COUNT(*) = 6);\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1348.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: collingwood scored more points than hawthorn in the 1962 vfl match\nInput Table: 1962 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddatemelbourne11.18 (84)st kilda11.6 (72)mcg489521962-06-23essendon15.17 (107)geelong10.7 (67)windy hill350001962-06-23collingwood10.14 (74)fitzroy9.11 (65)victoria park264881962-06-23carlton12.9 (81)footscray9.10 (64)princes park324001962-06-23south melbourne10.13 (73)richmond11.13 (79)lake oval170001962-06-23north melbourne10.8 (68)hawthorn10.7 (67)arden street oval84701962-06-23\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT home_team_score FROM table_sql WHERE home_team = 'collingwood') > \n             (SELECT away_team_score FROM table_sql WHERE away_team = 'hawthorn') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1986.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the shortest time between two consecutive matches was 2 days\nInput Table: 2000 - 01 sheffield wednesday f.c. season\n\n\ndateopponentvenueresultattendance2000-08-13wolverhampton wanderersa1 - 1190862000-08-19huddersfield townh2 - 3227042000-08-26grimsby towna1 - 077552000-08-28blackburn roversh1 - 1156462000-09-09wimbledonh0 - 5158562000-09-13nottingham foresth0 - 1157002000-09-16tranmere roversa0 - 293522000-09-23preston north endh1 - 3173792000-09-30gillinghama0 - 290992000-10-08west bromwich albionh1 - 2153382000-10-14portsmoutha1 - 2133762000-10-17burnleya0 - 1163722000-10-22birmingham cityh1 - 0146952000-10-25queens park rangersa2 - 1103532000-10-28fulhamh3 - 3175592000-11-04crystal palacea1 - 4153332000-11-07watforda3 - 1111662000-11-01norwich cityh3 - 2169562000-11-18barnsleya0 - 1199892000-11-25crewe alexandraa0 - 171032000-12-02queens park rangersh5 - 2217822000-12-09stockport countyh2 - 4163372000-12-16sheffield uniteda1 - 1251562000-12-23wolverhampton wanderersh0 - 1177872000-12-26bolton wanderersa0 - 2213162000-12-30huddersfield towna0 - 0189312001-01-01grimsby townh1 - 0170042001-01-13blackburn roversa0 - 2193082001-01-20bolton wanderersh0 - 3176382001-02-03watfordh2 - 3161342001-02-10wimbledona1 - 467412001-02-13tranmere roversh1 - 0154442001-02-21nottingham foresta1 - 0232662001-02-24preston north enda0 - 2143792001-03-03gillinghamh2 - 1187022001-03-07portsmouthh0 - 0205032001-03-10west bromwich albiona2 - 1186622001-03-17burnleyh2 - 0201842001-03-24birmingham citya2 - 1197332001-04-01sheffield unitedh1 - 2384332001-04-07stockport countya1 - 296662001-04-14crystal palaceh4 - 1198772001-04-16fulhama1 - 1175002001-04-21barnsleyh2 - 1234982001-04-28norwich citya0 - 1212412001-05-06crewe alexandrah0 - 028007\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT strftime('%s', date) - strftime('%s', LAG(date) OVER (ORDER BY date)) FROM table_sql) / 86400 <= 2 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-503.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: at auckland , new zealand on october 10 , 2004 , the playing surface was hard\nInput Table: ji\u0159\u00ed nov\u00e1k\n\n\ndatetournamentsurfaceopponentscore1996-01-14auckland , new zealandhardbrett steven6 - 4 , 6 - 41998-11-01mexico city , mexicoclayxavier malisse6 - 3 , 6 - 32001-05-06munich , germanyclayantony dupuis6 - 4 , 7 - 52001-07-15gstaad , switzerlandclayjuan carlos ferrero6 - 1 , 6 - 7 (5 - 7) , 7 - 52003-07-13gstaad , switzerlandclayroger federer5 - 7 , 6 - 3 , 6 - 3 , 1 - 6 , 6 - 32004-10-10tokyo , japanhardtaylor dent5 - 7 , 6 - 1 , 6 - 32004-11-03basel , switzerlandcarpet (i)david nalbandian5 - 7 , 6 - 3 , 6 - 4 , 1 - 6 , 6 - 2\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN surface = 'hard' AND tournament = 'auckland , new zealand' AND date = '2004-10-10' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1825.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: at punt road oval , richmond was melbourne 's home team opponent\nInput Table: 1943 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddatehawthorn13.10 (88)south melbourne7.14 (56)glenferrie oval150001943-08-21collingwood16.17 (113)fitzroy9.9 (63)victoria park65001943-08-21carlton15.23 (113)north melbourne7.5 (47)princes park80001943-08-21richmond15.19 (109)melbourne12.13 (85)punt road oval90001943-08-21footscray9.10 (64)essendon6.15 (51)western oval60001943-08-21\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE venue = 'punt road oval' \nAND home_team = 'melbourne' \nAND away_team = 'richmond';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-2009.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: kardinia park was one of two venues where the home team score was higher than the away team score\nInput Table: 1954 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddategeelong13.12 (90)hawthorn7.6 (48)kardinia park168701954-08-14collingwood12.16 (88)south melbourne13.12 (90)victoria park185561954-08-14carlton10.16 (76)essendon11.14 (80)princes park297441954-08-14richmond10.18 (78)melbourne15.4 (94)punt road oval240001954-08-14north melbourne9.14 (68)footscray9.14 (68)arden street oval220001954-08-14st kilda13.14 (92)fitzroy9.15 (69)junction oval115001954-08-14\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE venue = 'kardinia park' AND home_team_score > away_team_score) = 2 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1270.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: carmelo anthony was the leading scorer on the nuggets for 12 out of the 13 games played in november\nInput Table: 2009 - 10 denver nuggets season\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord39999-11-01grizzliesw 133 - 123 (ot)carmelo anthony (42)nen\u00ea (9)chauncey billups (12)pepsi center 158233 - 049999-11-03pacersw 111 - 93 (ot)carmelo anthony (25)nen\u00ea (13)anthony carter (5)conseco fieldhouse 106274 - 059999-11-04netsw 122 - 94 (ot)ty lawson (23)kenyon martin (10)chauncey billups (5)izod center 153195 - 079999-11-07hawksl 100 - 125 (ot)carmelo anthony (30)chris andersen (11)chauncey billups (7)philips arena 178015 - 289999-11-10bullsw 90 - 89 (ot)carmelo anthony (20)nen\u00ea (12)chauncey billups (6)united center 214096 - 299999-11-11bucksl 102 - 108 (ot)carmelo anthony (32)carmelo anthony (10)chauncey billups , ty lawson (5)bradley center 129876 - 3109999-11-13lakersw 105 - 79 (ot)carmelo anthony (25)chris andersen (11)chauncey billups (8)pepsi center 191417 - 3119999-11-17raptorsw 130 - 112 (ot)carmelo anthony (32)nen\u00ea (10)chauncey billups (10)pepsi center 164468 - 3129999-11-20clippersl 99 - 106 (ot)carmelo anthony (37)nen\u00ea (12)chauncey billups (7)staples center 181558 - 4139999-11-21bullsw 112 - 93 (ot)carmelo anthony (30)carmelo anthony , kenyon martin (11)carmelo anthony (7)pepsi center 193599 - 4149999-11-24netsw 101 - 87 (ot)carmelo anthony (27)nen\u00ea (9)chauncey billups (7)pepsi center 1630710 - 4159999-11-25timberwolvesw 124 - 111 (ot)carmelo anthony (22)nen\u00ea (8)nen\u00ea , ty lawson (6)target center 1310111 - 4169999-11-27knicksw 128 - 125 (ot)carmelo anthony (50)nen\u00ea , kenyon martin (11)chauncey billups (8)pepsi center 1915512 - 4\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE high_points = (SELECT MAX(high_points) FROM table_sql WHERE team = 'nuggets' AND date LIKE '9999-11%')) = 12 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-817.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: mark brooks and kenny perry tied for having the lowest to par\nInput Table: 1996 pga championship\n\n\nplaceplayercountryscoreto_parmoney1mark brooksunited states68 + 70 + 69 + 70 = 277- 114300002kenny perryunited states66 + 72 + 71 + 68 = 277- 11260000t3steve elkingtonaustralia67 + 74 + 67 + 70 = 278- 10140000t3tommy tollesunited states69 + 71 + 71 + 67 = 278- 10140000t5justin leonardunited states71 + 66 + 72 + 70 = 279- 986667t5jesper parneviksweden73 + 67 + 69 + 70 = 279- 986667t5vijay singhfiji69 + 69 + 69 + 72 = 279- 986667t8lee janzenunited states68 + 71 + 71 + 70 = 280- 857500t8per - ulrik johanssonsweden73 + 72 + 66 + 69 = 280- 857500t8phil mickelsonunited states67 + 67 + 74 + 72 = 280- 857500t8larry mizeunited states71 + 70 + 69 + 70 = 280- 857500t8frank nobilonew zealand69 + 72 + 71 + 68 = 280- 857500t8nick pricezimbabwe68 + 71 + 69 + 72 = 280- 857500\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MIN(to_par) FROM table_sql) = -11 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1035.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: february 21 had a score of 5 - 4\nInput Table: 2003 - 04 philadelphia flyers season\n\n\ngamefebruaryopponentscorerecordpoints549999-01-02tampa bay lightning1 - 226 - 12 - 11 - 568559999-01-04washington capitals5 - 127 - 12 - 11 - 570569999-01-05atlanta thrashers5 - 128 - 12 - 11 - 572579999-01-10new jersey devils4 - 129 - 12 - 11 - 574589999-01-12new york rangers2 - 130 - 12 - 11 - 576599999-01-14new york rangers6 - 231 - 12 - 11 - 578609999-01-16san jose sharks2 - 531 - 13 - 11 - 578619999-01-17tampa bay lightning2 - 531 - 14 - 11 - 578629999-01-19boston bruins3 - 431 - 15 - 11 - 578639999-01-21atlanta thrashers5 - 432 - 15 - 11 - 580649999-01-24chicago blackhawks3 - 133 - 15 - 11 - 582659999-01-26ottawa senators1 - 1 ot33 - 15 - 12 - 583669999-01-28boston bruins2 - 3 ot33 - 15 - 12 - 684679999-01-29detroit red wings2 - 433 - 16 - 12 - 684\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT score FROM table_sql WHERE february = '9999-02-21') = '5 - 4' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1922.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: 4 - 1 was the 2nd leg for 2004\nInput Table: copa san isidro de curuguaty\n\n\nyearwinnerrunners_-_upaggregate1st_leg2nd_leg1956trinidadliga central4 - 22 - 12 - 11959fray bentosvilleta7 - 13 - 04 - 11963coloniaypacara\u00ed3 - 30 - 13 - 21966tacuaremb\u00f3coronel oviedo4 - 12 - 02 - 11978federaci\u00f3n misioneramelo4 - 01 - 03 - 01980federaci\u00f3n misioneratacuaremb\u00f35 - 5 , 3 - 2 p2 - 13 - 41982maldonadovillarrica1 - 1 , 4 - 3 p1 - 00 - 11984san pedrorocha4 - 31 - 33 - 01988paysand\u00faparanaense4 - 31 - 23 - 11990ypacara\u00edflorida2 - 11 - 01 - 11992liga del sudminas6 - 12 - 04 - 11994maldonadocaaguaz\u00fa9 - 24 - 05 - 21996paranaensemaldonado interior3 - 32 - 21 - 11998itaugu\u00e1melo4 - 31 - 13 - 22000san jos\u00e9 liga mayorcarapegu\u00e12 - 2 , 4 - 2 p1 - 11 - 12002limpiodurazno5 - 45 - 40 - 02004san jos\u00e9 de los arroyosdurazno4 - 30 - 24 - 12006piray\u00famaldonado liga mayor3 - 3 , 4 - 2 p1 - 22 - 12008colonia departamentalcaaguaz\u00fa4 - 23 - 11 - 12008liga caacupe\u00f1aartigas3 - 11 - 12 - 0\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN aggregate LIKE '%4 - 1%' AND year = 2004 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-714.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: carlos cu\u00e9llar had the highest transfer fee of any player at 7.8 m\nInput Table: 2008 - 09 rangers f.c. season\n\n\nnatnamemoving_totypetransfer_windowtransfer_feesconicholas gallacher9999-01-01end of contract9999-06-01n / aivory coastlacine cherif9999-01-01end of contract9999-06-01n / ascoalistair park9999-01-01end of contract9999-06-01n / aengmichael donald9999-01-01end of contract9999-06-01n / ascocalum reidford9999-01-01end of contract9999-06-01n / ascochris smith9999-01-01end of contract9999-06-01n / abeljeroen van den broeck9999-01-01end of contract9999-06-01n / aslovakiafilip \u0161ebo9999-01-01transfer9999-06-011 mbelthomas buffel9999-01-01transfer9999-06-01n / aespcarlos cu\u00e9llar9999-01-01transfer9999-06-017.8 mscosteven lennon9999-01-01loan9999-06-01n / ascomark weir9999-01-01loan9999-06-01n / ascoandy webster9999-01-01loan9999-06-01n / arsadean furman9999-01-01loan9999-06-01n / ascoalan lowing9999-01-01loan9999-06-01n / ascopaul emslie9999-01-01loan9999-06-01n / ascoscott gallacher9999-01-01loan9999-06-01n / agabondaniel cousin9999-01-01transfer9999-06-013.5 mscoalan gow9999-01-01loan9999-06-01n / aenglee robinson9999-01-01loan9999-01-01n / ascoandrew shinnie9999-01-01loan9999-01-01n / ascosteven kinniburgh9999-01-01loan9999-01-01n / ascorory loy9999-01-01loan9999-01-01n / ascowilliam mclachlan9999-01-01loan9999-01-01n / ascolee robinson9999-01-01loan9999-01-01n / afrajean - claude darcheville9999-01-01transfer9999-01-01freescojordan mcmillan9999-01-01loan9999-01-01n / ascochris burke9999-01-01transfer9999-01-01freecypgeorgios efrem9999-01-01loan9999-01-01n / ascoalan gow9999-01-01loan9999-01-01n / ascocharlie adam9999-01-01loan9999-01-01n / ascoross harvey9999-01-01loan9999-01-01n / ascosteven kinniburgh9999-01-01loan9999-01-01n / a\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MAX(transfer_fee) FROM table_sql WHERE type = 'transfer') = 7.8 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1923.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: 3 - 0 was the 2nd leg the year san pedro was the winner\nInput Table: copa san isidro de curuguaty\n\n\nyearwinnerrunners_-_upaggregate1st_leg2nd_leg1956trinidadliga central4 - 22 - 12 - 11959fray bentosvilleta7 - 13 - 04 - 11963coloniaypacara\u00ed3 - 30 - 13 - 21966tacuaremb\u00f3coronel oviedo4 - 12 - 02 - 11978federaci\u00f3n misioneramelo4 - 01 - 03 - 01980federaci\u00f3n misioneratacuaremb\u00f35 - 5 , 3 - 2 p2 - 13 - 41982maldonadovillarrica1 - 1 , 4 - 3 p1 - 00 - 11984san pedrorocha4 - 31 - 33 - 01988paysand\u00faparanaense4 - 31 - 23 - 11990ypacara\u00edflorida2 - 11 - 01 - 11992liga del sudminas6 - 12 - 04 - 11994maldonadocaaguaz\u00fa9 - 24 - 05 - 21996paranaensemaldonado interior3 - 32 - 21 - 11998itaugu\u00e1melo4 - 31 - 13 - 22000san jos\u00e9 liga mayorcarapegu\u00e12 - 2 , 4 - 2 p1 - 11 - 12002limpiodurazno5 - 45 - 40 - 02004san jos\u00e9 de los arroyosdurazno4 - 30 - 24 - 12006piray\u00famaldonado liga mayor3 - 3 , 4 - 2 p1 - 22 - 12008colonia departamentalcaaguaz\u00fa4 - 23 - 11 - 12008liga caacupe\u00f1aartigas3 - 11 - 12 - 0\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN aggregate = '3 - 0' AND winner = 'san pedro' THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE year = '1984';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1190.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: ettore meini won two races in a row , on may 24th and 25th , during the 1933 giro d'italia\nInput Table: 1933 giro d'italia\n\n\ndatecoursedistancewinnerrace_leader9999-05-06milan to turin-learco guerra ( ita )learco guerra ( ita )9999-05-07turin to genoa-alfredo binda ( ita )alfredo binda ( ita )9999-05-08genoa to pisa-learco guerra ( ita )alfredo binda ( ita )9999-05-09rest dayrest dayrest dayrest day9999-05-10pisa to florence-giuseppe olmo ( ita )alfredo binda ( ita )9999-05-11florence to grosseto-learco guerra ( ita )jef demuysere ( bel )9999-05-12grosseto to rome-mario cipriani ( ita )jef demuysere ( bel )9999-05-13rest dayrest dayrest dayrest day9999-05-14rome to naples-gerard loncke ( bel )jef demuysere ( bel )9999-05-15naples to foggia-alfredo binda ( ita )alfredo binda ( ita )9999-05-16rest dayrest dayrest dayrest day9999-05-17foggia to chieti-alfredo binda ( ita )alfredo binda ( ita )9999-05-18chieti to ascoli piceno-alfredo binda ( ita )alfredo binda ( ita )9999-05-19rest dayrest dayrest dayrest day9999-05-20ascoli piceno to riccione-fernand cornez ( fra )alfredo binda ( ita )9999-05-21riccione to bologna-giuseppe olmo ( ita )alfredo binda ( ita )9999-05-22bologna to ferrara-alfredo binda ( ita )alfredo binda ( ita )9999-05-23rest dayrest dayrest dayrest day9999-05-24ferrara to udine-ettore meini ( ita )alfredo binda ( ita )9999-05-25udine to bassano del grappa-ettore meini ( ita )alfredo binda ( ita )9999-05-26bassano del grappa to bolzano-gerard loncke ( bel )alfredo binda ( ita )9999-05-27rest dayrest dayrest dayrest day9999-05-28bolzano to milan-alfredo binda ( ita )alfredo binda ( ita )2023-09-20-km (mi)-km (mi)\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE winner = 'ettore meini' AND date = '9999-05-24') = 1 \n             AND (SELECT COUNT(*) FROM table_sql WHERE winner = 'ettore meini' AND date = '9999-05-25') = 1 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-198.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the average of all the home team scores is 15.67\nInput Table: 1972 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddatefootscray14.7 (91)st kilda9.11 (65)western oval186551972-07-15fitzroy16.14 (110)north melbourne9.12 (66)junction oval70071972-07-15essendon13.12 (90)richmond17.9 (111)windy hill222511972-07-15carlton20.8 (128)south melbourne8.15 (63)princes park144651972-07-15hawthorn19.14 (128)geelong15.8 (98)glenferrie oval124251972-07-15collingwood10.13 (73)melbourne8.10 (58)vfl park308831972-07-15\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN AVG(home_team_score) = 15.67 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-447.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: 3 home teams had higher scores than the away teams that they were playing\nInput Table: 1938 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddategeelong11.23 (89)hawthorn6.13 (49)corio oval70001938-06-18fitzroy16.12 (108)south melbourne8.8 (56)brunswick street oval120001938-06-18st kilda14.12 (96)melbourne16.16 (112)junction oval140001938-06-18richmond15.14 (104)essendon15.9 (99)punt road oval200001938-06-18footscray13.9 (87)collingwood10.5 (65)western oval180001938-06-18north melbourne11.5 (71)carlton16.25 (121)arden street oval130001938-06-18\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT home_team_score FROM table_sql WHERE home_team = 'geelong') > \n             (SELECT away_team_score FROM table_sql WHERE away_team = 'geelong') \n             AND (SELECT home_team_score FROM table_sql WHERE home_team = 'fitzroy') > \n             (SELECT away_team_score FROM table_sql WHERE away_team = 'fitzroy') \n             AND (SELECT home_team_score FROM table_sql WHERE home_team = 'st kilda') > \n             (SELECT away_team_score FROM table_sql WHERE away_team = 'st kilda') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1012.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the home team scored 17.5 (107) on sunday , january 30th\nInput Table: 2000 ansett australia cup\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scoregroundcrowddateadelaide17.5 (107)melbourne19.11 (125)football park122399999-01-30geelong10.14 (74)st kilda11.12 (78)waverley park73949999-01-30st kilda9.12 (66)melbourne13.14 (92)waverley park105339999-02-05adelaide19.10 (124)geelong15.12 (102)football park113269999-02-06adelaide14.11 (95)st kilda15.12 (102)football park130869999-02-13geelong17.12 (114)melbourne11.16 (82)waverley park495201-14-9999\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE home_team_score = '17.5 (107)' \nAND date = '9999-01-30' \nAND strftime('%w', date) = '0';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-770.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the total attendance for week 8 was 61603\nInput Table: 2000 cincinnati bengals season\n\n\nweekdateopponentresultattendance22000-09-10cleveland brownsl 24 - 76400632000-09-17jacksonville jaguarsl 13 - 04565342000-09-24baltimore ravensl 37 - 06848152000-10-01miami dolphinsl 31 - 166153562000-10-08tennessee titansl 23 - 146340672000-10-15pittsburgh steelersl 15 - 05432882000-10-22denver broncosw 31 - 216160392000-10-29cleveland brownsw 12 - 373118102000-11-05baltimore ravensl 27 - 754759112000-11-12dallas cowboysl 23 - 662170122000-11-19new england patriotsl 16 - 1360292132000-11-26pittsburgh steelersl 48 - 2863925142000-12-03arizona cardinalsw 24 - 1350289152000-12-10tennessee titansl 35 - 368498162000-12-17jacksonville jaguarsw 17 - 1450469172000-12-24philadelphia eaglesl 16 - 764902\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN attendance = 61603 AND week = 8 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1667.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: a majority of the people who scored over par are from the united states\nInput Table: 1989 u.s. open (golf)\n\n\nplaceplayercountryscoreto_parmoney1curtis strangeunited states71 + 64 + 73 + 70 = 278- 2200000t2chip beckunited states71 + 69 + 71 + 68 = 279- 167823t2mark mccumberunited states70 + 68 + 72 + 69 = 279- 167823t2ian woosnamwales70 + 68 + 73 + 68 = 279- 1678235brian claarunited states71 + 72 + 68 + 69 = 280e34345t6masashi ozakijapan70 + 71 + 68 + 72 = 281+ 128220t6scott simpsonunited states67 + 70 + 69 + 75 = 281+ 1282208peter jacobsenunited states71 + 70 + 71 + 70 = 282+ 224307t9paul azingerunited states71 + 72 + 70 + 70 = 283+ 319968t9hubert greenunited states69 + 72 + 74 + 68 = 283+ 319968t9tom kiteunited states67 + 69 + 69 + 78 = 283+ 319968t9jos\u00e9 mar\u00eda olaz\u00e1balspain69 + 72 + 70 + 72 = 283+ 319968\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) > (SELECT COUNT(*) FROM table_sql WHERE to_par > 0 AND country = 'united states') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE to_par > 0 AND country = 'united states';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1590.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: neil liddiard was named the man of the match in the 4 - 2 win against the swindon wildcats\nInput Table: 2008 - 09 guildford flames season\n\n\ndateopponentvenueresultattendancecompetitionman_of_the_match9999-01-01slough jetshomelost 2 - 31308league / cuplukas smital9999-01-02slough jetsawaylost 5 - 6 (ot)320leaguepaul dixon9999-01-08swindon wildcatsawaywon 6 - 3754league / cuplukas smital9999-01-09swindon wildcatshomewon 4 - 21568league / cupneil liddiard9999-01-15sheffield scimitarsawaywon 7 - 4364league / cuprick plant9999-01-16milton keynes lightninghomelost 2 - 41161league / cupdavid savage9999-01-19romford raidershomewon 6 - 21016league / cupalex mettam9999-01-22wightlink raidersawaylost 5 - 4509league / cupstuart potts9999-01-23telford tigershomewon 4 - 21368leaguealex mettam / mark williams9999-01-29romford raidershomewon 7 - 21238leaguemartin bouz9999-01-30bracknell beesawaywon 4 - 0not reportedleague / cupjoe watkins\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN man_of_the_match = 'neil liddiard' AND result = 'won 4 - 2' AND opponent = 'swindon wildcats' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1475.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the game on march 19th had a score of 112 - 91\nInput Table: 1991 - 92 seattle supersonics season\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord589999-03-01cleveland cavaliersw 113 - 107e johnson , r pierce (22)b benjamin , m cage (14)r pierce (6)seattle center coliseum 1364732 - 26599999-03-03denver nuggetsw 111 - 92s kemp (21)s kemp (13)g payton (9)seattle center coliseum 986533 - 26609999-03-05phoenix sunsl 105 - 118r pierce (23)s kemp (19)g payton (12)arizona veterans memorial coliseum 1449633 - 27619999-03-07new jersey netsw 109 - 98r pierce (27)m cage (13)n mcmillan (7)seattle center coliseum 1341934 - 27620000-03-08portland trail blazersl 97 - 109r pierce (28)r pierce (10)g payton (7)memorial coliseum 1288834 - 28639999-03-10detroit pistonsl 92 - 98g payton (19)s kemp (9)n mcmillan (5)seattle center coliseum 1309834 - 29649999-03-11los angeles clippersw 104 - 96r pierce (19)b benjamin , m cage (6)g payton (9)los angeles memorial sports arena 1091235 - 296501-03-15dallas mavericksw 109 - 100r pierce (23)s kemp (15)g payton (8)seattle center coliseum 1216336 - 29660000-03-17golden state warriorsl 107 - 119r pierce (24)s kemp (15)r pierce (5)seattle center coliseum 1316336 - 30679999-03-19houston rocketsw 112 - 91r pierce (22)m cage , s kemp (14)g payton (11)the summit 1512237 - 30689999-03-21san antonio spursl 96 - 101e johnson (23)s kemp (13)d barros , m cage , n mcmillan (4)hemisfair arena 1605737 - 31699999-03-22dallas mavericksw 113 - 105e johnson (31)s kemp (17)n mcmillan (8)reunion arena 1434538 - 31709999-03-24houston rocketsw 128 - 106d mckey (23)m cage , s kemp (11)n mcmillan , g payton (7)seattle center coliseum 1137739 - 31719999-03-27milwaukee bucksw 96 - 95e johnson (21)n mcmillan (7)n mcmillan (6)seattle center coliseum 1145040 - 31729999-03-28new york knicksl 87 - 92s kemp (27)s kemp (12)n mcmillan (6)seattle center coliseum 1481240 - 32\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN score = '112 - 91' AND date = '9999-03-19' THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-404.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: canon yaound\u00e9 scored five more points than their opponent\nInput Table: 1971 african cup of champions clubs\n\n\nteam_1aggteam_21st_leg2nd_legal - merrikh2 - 2 (5 - 4 pen)tele sc asmara9999-01-029999-01-01abaluhya united1 - 3great olympics9999-01-019999-01-01asc diaraf3 - 4stade malien9999-03-019999-01-01maseru united3 - 5mmm tamatave9999-01-029999-02-03as porto novo0 - 3victoria club mokanda9999-01-019999-01-02canon yaound\u00e99 - 4as solidarit\u00e99999-07-039999-01-02esp\u00e9rance1 - 0al - ahly (benghazi)9999-01-019999-01-01secteur 61 - 2enugu rangers9999-01-019999-01-01young africans2 - 0lavori publici9999-01-019999-01-01\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT SUM(agg) FROM table_sql WHERE team_1 = 'canon yaound\u00e9') - \n             (SELECT SUM(agg) FROM table_sql WHERE team_2 = 'canon yaound\u00e9') > 5 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1962.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: greg monroe had the high of 8 rebounds against charlotte on october 16th making thier record 2 - 4\nInput Table: 2010 - 11 detroit pistons season\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord19999-10-05miamil 89 - 105 (ot)ben gordon (17)ben gordon , charlie villanueva (5)rodney stuckey (5)american airlines arena 196000 - 129999-10-08milwaukeew 115 - 110 (ot)austin daye (21)austin daye (7)will bynum (9)the palace of auburn hills 128211 - 139999-10-11atlantaw 94 - 85 (ot)rodney stuckey (16)greg monroe (7)richard hamilton (7)the palace of auburn hills 105912 - 149999-10-13dallasl 96 - 101 (ot)austin daye (16)ben wallace , jason maxiell (8)rodney stuckey (6)van andel arena 102072 - 259999-10-15minnesotal 88 - 99 (ot)austin daye (18)austin daye (11)will bynum (5)carrier dome 117472 - 369999-10-16charlottel 94 - 97 (ot)rodney stuckey (25)greg monroe (8)rodney stuckey , will bynum (5)colonial life arena 68472 - 479999-10-19washingtonw 98 - 92 (ot)rodney stuckey (34)ben wallace (11)rodney stuckey (7)huntington center 64243 - 4\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT high_rebounds FROM table_sql WHERE team = 'charlotte' AND date = '9999-10-16') = 8 \n             AND (SELECT record FROM table_sql WHERE team = 'charlotte' AND date = '9999-10-16') = '2 - 4' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1247.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: 66189 people attended the new orleans saints game with a record of 6 - 1\nInput Table: 2001 st. louis rams season\n\n\nweekdateopponentresultrecordtv_timeattendance12001-09-09philadelphia eaglesw 20 - 17 (ot)1 - 0fox 3:15 pm66243.022001-09-23san francisco 49ersw 30 - 262 - 0fox 3:15 pm67536.032001-09-30miami dolphinsw 42 - 103 - 0cbs 12:00 pm66046.042001-10-08detroit lionsw 35 - 04 - 0abc 8:00 pm77765.052001-10-14new york giantsw 15 - 145 - 0fox 12:00 pm65992.062001-10-21new york jetsw 34 - 146 - 0fox 12:00 pm78766.072001-10-28new orleans saintsl 34 - 316 - 1fox 12:00 pm66189.089999-01-01----nan92001-11-11carolina panthersw 48 - 147 - 1fox 12:00 pm66069.0102001-11-18new england patriotsw 24 - 178 - 1espn 7:30 pm60292.0112001-11-26tampa bay buccaneersl 24 - 178 - 2abc 8:00 pm66198.0122001-12-02atlanta falconsw 35 - 69 - 2fox 3:15 pm60787.0132001-12-09san francisco 49ersw 27 - 1410 - 2fox 12:00 pm66218.0142001-12-17new orleans saintsw 34 - 2111 - 2abc 8:00 pm70332.0152001-12-23carolina panthersw 38 - 3212 - 2fox 12:00 pm72438.0162001-12-30indianapolis coltsw 42 - 1713 - 2cbs 12:00 pm66084.0172002-01-06atlanta falconsw 31 - 1314 - 2fox 3:15 pm66033.0\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 1 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE attendance = 66189 \nAND record = '6 - 1' \nAND opponent = 'new orleans saints';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1703.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: 48 is the value of ends lost when the blank ends is 9\nInput Table: 2005 tim hortons brier\n\n\nlocaleskipwlpfpaends_wonends_lostblank_endsstolen_endsshot_pctalbertarandy ferbey92905848437986%manitobarandy dutiaume8377694744101379%nova scotiashawn adams8380604741161383%quebecjean - michel m\u00e3nard747769544081580%british columbiadeane horning6572654745181280%ontariowayne middaugh657562424610782%newfoundland and labradorbrad gushue6576694845131079%saskatchewanpat simmons656661434512980%prince edward islandrod macdonald476785415112579%northern ontariomike jakubo38648641489679%new brunswickwade blanchard385683414517878%\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN ends_lost = 48 AND blank_ends = 9 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-174.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there are no games that have rebounds larger than 1048\nInput Table: none\n\n\nrankplayeryearsgamesreb_avgtotal_rebounds1jim nowers1972-01-01 - 1976-01-011129.410482kenny sanders1985-01-01 - 1989-01-011079.610263will thomas2004-01-01 - 2008-01-011317.69934george evans1997-01-01 - 2001-01-011168.29535robert dykes1987-01-01 - 1991-01-011227.59256andre gaddy1977-01-01 - 1982-01-01989.39167jai lewis2002-01-01 - 2006-01-011257.28958rob rose1982-01-01 - 1986-01-011137.18059herb estes1973-01-01 - 1976-01-01809.273410jesse young1999-01-01 - 2003-01-011156.2708\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE total_rebounds > 1048;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-679.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: tiger woods score was 205\nInput Table: 2002 u.s. open (golf)\n\n\nplaceplayercountryscoreto_par1tiger woodsunited states67 + 68 + 70 = 205- 52sergio garc\u00edaspain68 + 74 + 67 = 209- 1t3jeff maggertunited states69 + 73 + 68 = 210et3phil mickelsonunited states70 + 73 + 67 = 210et5robert allenbyaustralia74 + 70 + 67 = 211+ 1t5p\u00e1draig harringtonireland70 + 68 + 73 = 211+ 1t5billy mayfairunited states69 + 74 + 68 = 211+ 1t8nick faldoengland70 + 76 + 66 = 212+ 2t8justin leonardunited states73 + 71 + 68 = 212+ 2t10tom byrumunited states72 + 72 + 70 = 214+ 4t10davis love iiiunited states71 + 71 + 72 = 214+ 4t10scott mccarronunited states72 + 72 + 70 = 214+ 4\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT score FROM table_sql WHERE player = 'tiger woods') = 205 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-446.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: no game on the 18th of june drew a crowd of more than 20000\nInput Table: 1938 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddategeelong11.23 (89)hawthorn6.13 (49)corio oval70001938-06-18fitzroy16.12 (108)south melbourne8.8 (56)brunswick street oval120001938-06-18st kilda14.12 (96)melbourne16.16 (112)junction oval140001938-06-18richmond15.14 (104)essendon15.9 (99)punt road oval200001938-06-18footscray13.9 (87)collingwood10.5 (65)western oval180001938-06-18north melbourne11.5 (71)carlton16.25 (121)arden street oval130001938-06-18\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE date = '1938-06-18' \nAND crowd > 20000;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1205.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: on march 19 , 1984 , plymouth argyle played derby county\nInput Table: 1983 - 84 fa cup\n\n\ntie_nohome_teamscoreaway_teamdate1notts county1 - 2everton1984-03-102sheffield wednesday0 - 0southampton1984-03-11replaysouthampton5 - 1sheffield wednesday1984-03-203plymouth argyle0 - 0derby county1984-03-10replayderby county0 - 1plymouth argyle1984-03-144birmingham city1 - 3watford1984-03-10\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE date = '1984-03-19' \nAND (home_team = 'plymouth argyle' OR away_team = 'plymouth argyle') \nAND (home_team = 'derby county' OR away_team = 'derby county');\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-143.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: in the 2006 season the texas rangers played the mariners nine times\nInput Table: 2006 texas rangers season\n\n\ndateopponentscorelossattendancerecord9999-09-01indians7 - 2padilla (13 - 9)2377669 - 679999-09-02indians6 - 5volquez (1 - 4)4022269 - 689999-09-03indians5 - 2byrd1966770 - 689999-09-04athletics8 - 1zito2394971 - 689999-09-05athletics5 - 4saarloos2722572 - 689999-09-06athletics9 - 6rupe (0 - 1)1783872 - 699999-09-08mariners7 - 2millwood (14 - 10)2864672 - 709999-09-09mariners3 - 2rheinecker (4 - 6)3345472 - 719999-09-10mariners4 - 2huber3432173 - 719999-09-12tigers3 - 2mahay (1 - 3)2419673 - 729999-09-13tigers11 - 3verlander2467274 - 729999-09-14angels2 - 1volquez (1 - 5)2148874 - 739999-09-15angels2 - 1francisco (0 - 1)3078874 - 749999-09-16angels12 - 6lackey4019675 - 749999-09-17angels8 - 1santana2430376 - 749999-09-18mariners8 - 1hern\u00e1ndez1821477 - 749999-09-19mariners9 - 7wilson (2 - 3)1855177 - 759999-09-20mariners6 - 3tejeda (4 - 4)2600677 - 769999-09-22indians12 - 4byrd2628478 - 769999-09-23indians6 - 3padilla (14 - 10)3835178 - 779999-09-24indians11 - 6millwood (16 - 11)3661778 - 789999-09-25angels8 - 3volquez (1 - 6)3978178 - 799999-09-26angels5 - 2escobar3733979 - 799999-09-27angels6 - 5wilson (2 - 4)3803279 - 809999-09-29mariners6 - 5fruto3076680 - 809999-09-30mariners3 - 1millwood (16 - 12)2331080 - 819999-10-01mariners3 - 2tejeda (5 - 5)2836180 - 82\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 9 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE opponent = 'mariners' \nAND date LIKE '2006-%'\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-980.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: during season 2000 - 1 , kanto gakuin university was the winner , the title was 37th and the attendance was not available\nInput Table: all - japan university rugby championship\n\n\ntitleseasonwinnerscorerunner_-_upvenueattendance9999-01-301993-04-019999-01-0141 - 12hoseinational stadium , tokyo , tokyon / a9999-01-311994-05-019999-01-0122 - 17meijinational stadium , tokyo , tokyon / a9999-01-011995-06-019999-01-0143 - 9wasedanational stadium , tokyo , tokyon / a9999-01-331996-07-019999-01-0132 - 22wasedanational stadium , tokyo , tokyon / a9999-01-011997-08-019999-01-0130 - 17meijinational stadium , tokyo , tokyon / a9999-01-351998-09-019999-01-0147 - 28meijinational stadium , tokyo , tokyon / a9999-01-019999-01-019999-01-0142 - 15kanto gakuin universitynational stadium , tokyo , tokyon / a9999-01-372000-01-019999-01-0142 - 15hoseinational stadium , tokyo , tokyon / a9999-01-012001-02-019999-01-0121 - 16wasedanational stadium , tokyo , tokyon / a9999-01-012002-03-019999-01-0127 - 22kanto gakuin universitynational stadium , tokyo , tokyon / a9999-01-012003-04-019999-01-0133 - 7wasedanational stadium , tokyo , tokyon / a9999-01-412004-05-019999-01-0131 - 19kanto gakuin universitynational stadium , tokyo , tokyo354629999-01-012005-06-019999-01-0141 - 5kanto gakuin universitynational stadium , tokyo , tokyo301639999-01-432006-07-019999-01-0133 - 26wasedanational stadium , tokyo , tokyo319549999-01-012007-08-019999-01-0126 - 6keionational stadium , tokyo , tokyo236949999-01-012008-09-019999-01-0120 - 10teikyonational stadium , tokyo , tokyo223449999-01-012009-10-019999-01-0114 - 13tokainational stadium , tokyo , tokyo175699999-01-012010-11-019999-01-0117 - 14wasedanational stadium , tokyo , tokyo254589999-01-012011-12-019999-01-0115 - 12tenrinational stadium , tokyo , tokyo144079999-01-019999-01-019999-01-0139 - 22tsukubanational stadium , tokyo , tokyo20050\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 1 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE season = '2000-01-01' \nAND winner = 'kanto gakuin university' \nAND title = '9999-01-37' \nAND attendance = 'n/a';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1496.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the first project proposed was potter co in copiah , but it has not yet been listed\nInput Table: list of superfund sites in mississippi\n\n\ncerclis_idnamecountyproposedlistedconstruction_completedpartially_deleteddeletedmsd004006995american creosote works , incwinston2001-06-142001-09-139999-01-01--msd008154486chemfax , incharrison1993-06-239999-01-019999-01-01--msd046497012davis timber companylamar2000-05-112000-07-279999-01-01--msd980710941flowood siterankin1983-09-081984-09-211993-09-17-02 / 16 / 1996msd980840045newsom brothers / old reichhold chemicals , incmarion1984-10-151986-06-101997-08-08-09 / 27 / 2000msd065490930picayune wood treatingpearl river2004-03-082004-07-229999-01-01--msd056029648potter cocopiah1993-05-109999-01-019999-01-01--msd086556388sonford productsrankin2006-09-272007-03-079999-01-01--msd980601736walcotte chemical co warehouseswashington9999-01-019999-01-011982-12-30-12 / 30 / 1982\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT name FROM table_sql WHERE proposed = (SELECT MIN(proposed) FROM table_sql) AND county = 'copiah') = 'potter co' \n             AND (SELECT listed FROM table_sql WHERE proposed = (SELECT MIN(proposed) FROM table_sql) AND county = 'copiah') = '9999-01-01' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-247.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: sweden and canada were the only countries on the table that did not receive a medal in one of the categories\nInput Table: 1988 winter olympics\n\n\nranknationgoldsilverbronzetotal1soviet union (urs)1199292east germany (gdr)9106253switzerland (sui)555154finland (fin)41275sweden (swe)40266austria (aut)352107netherlands (ned)32278west germany (frg)24289united states (usa)213610italy (ita)212513canada (can)0235\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE nation = 'sweden' AND (gold = 0 OR silver = 0 OR bronze = 0)) > 0 \n             AND (SELECT COUNT(*) FROM table_sql WHERE nation = 'canada' AND (gold = 0 OR silver = 0 OR bronze = 0)) > 0 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1663.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the average score for players from japan is 281\nInput Table: 1989 u.s. open (golf)\n\n\nplaceplayercountryscoreto_parmoney1curtis strangeunited states71 + 64 + 73 + 70 = 278- 2200000t2chip beckunited states71 + 69 + 71 + 68 = 279- 167823t2mark mccumberunited states70 + 68 + 72 + 69 = 279- 167823t2ian woosnamwales70 + 68 + 73 + 68 = 279- 1678235brian claarunited states71 + 72 + 68 + 69 = 280e34345t6masashi ozakijapan70 + 71 + 68 + 72 = 281+ 128220t6scott simpsonunited states67 + 70 + 69 + 75 = 281+ 1282208peter jacobsenunited states71 + 70 + 71 + 70 = 282+ 224307t9paul azingerunited states71 + 72 + 70 + 70 = 283+ 319968t9hubert greenunited states69 + 72 + 74 + 68 = 283+ 319968t9tom kiteunited states67 + 69 + 69 + 78 = 283+ 319968t9jos\u00e9 mar\u00eda olaz\u00e1balspain69 + 72 + 70 + 72 = 283+ 319968\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT AVG(score) FROM table_sql WHERE country = 'japan') = 281 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-443.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: only two teams (hawthorn and south melbourne) scored less than 10\nInput Table: 1938 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddategeelong11.23 (89)hawthorn6.13 (49)corio oval70001938-06-18fitzroy16.12 (108)south melbourne8.8 (56)brunswick street oval120001938-06-18st kilda14.12 (96)melbourne16.16 (112)junction oval140001938-06-18richmond15.14 (104)essendon15.9 (99)punt road oval200001938-06-18footscray13.9 (87)collingwood10.5 (65)western oval180001938-06-18north melbourne11.5 (71)carlton16.25 (121)arden street oval130001938-06-18\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE home_team_score < 10 OR away_team_score < 10) = 2 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1577.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the screening that started march 29th , 2006 , was completed may 3rd , 2006\nInput Table: none\n\n\nscreening_startedscreening_completedchapter_unfrozenchapter_openedchapter_closed2005-11-252005-12-229999-01-012008-12-199999-01-012006-06-212006-07-209999-01-012008-06-179999-01-012006-02-062006-03-039999-01-012008-06-179999-01-012006-06-122006-07-149999-01-012008-12-199999-01-012006-03-092006-04-289999-01-012010-06-309999-01-012006-06-062006-07-129999-01-012009-06-309999-01-012006-02-162006-03-239999-01-019999-01-019999-01-012006-06-192006-07-189999-01-012007-06-259999-01-012006-02-082006-03-229999-01-019999-01-019999-01-012006-03-272006-05-019999-01-012007-03-299999-01-012006-06-302006-09-299999-01-012007-12-199999-01-012006-09-112006-10-102013-02-122013-06-259999-01-012006-09-072006-10-139999-01-019999-01-019999-01-012005-10-202005-11-149999-01-012006-06-122006-06-122006-04-032006-06-029999-01-012009-12-219999-01-012006-06-082006-07-119999-01-012007-12-199999-01-012006-05-182006-06-309999-01-012007-07-269999-01-019999-01-019999-01-019999-01-019999-01-019999-01-01\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN screening_started = '2006-03-29' AND screening_completed = '2006-05-03' THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1738.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the pentium dual - core t3200 has a frequency of 2 ghz\nInput Table: list of intel pentium dual - core microprocessors\n\n\nmodel_numbersspec_numberfrequencyl2_cachefsbmultvoltagetdpsocketrelease_datepart_number_(s)release_price_(_usd_)pentium dual - core t2310slaec (m0)1.47 ghz1 mb533 mt / s111.075 - 1.175v35 wsocket p2007-10-01lf80537 ge0201 m90pentium dual - core t2330sla4k (m0)1.6 ghz1 mb533 mt / s121.075 - 1.175v35 wsocket p2007-10-01lf80537 ge0251 mnoempentium dual - core t2370sla4j (m0)1.73 ghz1 mb533 mt / s131.075 - 1.175v35 wsocket p2007-10-01lf80537 ge0301 moempentium dual - core t2390sla4h (m0)1.87 ghz1 mb533 mt / s141.075 - 1.175v35 wsocket p2008-04-01lf80537 ge0361 moempentium dual - core t2410sla4 g (m0)2 ghz1 mb533 mt / s151.075 - 1.175v35 wsocket p2008-07-01lf80537 ge0411 moempentium dual - core t3200slavg (m0)2 ghz1 mb667 mt / s121.075 - 1.175v35 wsocket p2008-10-01lf80537 gf0411 moem\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN frequency = '2 ghz' AND model_number = 'pentium dual - core t3200' THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1503.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: arienai kisu was broadcasted 7 days after the title with the earliest broadcast date\nInput Table: tsuki no koibito\n\n\nUnnamed:_0episode_titleromanized_titletranslation_of_titlebroadcast_dateratingsep 1\u304a\u307e\u3048\u304c\u6b32\u3057\u3044omae ga hosiii want you2010-05-1022.4%ep 2\u3042\u308a\u3048\u306a\u3044\u30ad\u30b9arienai kisuthe unthinkable kiss2010-05-1719.2%ep 3\u5fa9\u8b90\u306e\u30d7\u30ed\u30dd\u30fc\u30bafukusy\u016b no purop\u014dzuthe proposal out of revenge2010-05-2415.6%ep 4\u3053\u3093\u306a\u306b\u597d\u304d\u3060\u3063\u305f\u3093\u3060\u2026konna ni suki dattanda\u2026that 's how much i liked you2010-05-3115.5%ep 5\u597d\u304d\u3068\u8a00\u3048\u305f\u3089\u3044\u3044\u306e\u306bsuki to ietara iinoniif only i could say , i like you2010-06-0717.4%ep 6\u6700\u7d42\u7ae0\u5e8f\u5e55\u30fb\u5225\u308csaish\u016bsh\u014djomakuwakarea prologue of final chapter , farewell2010-06-1413.4%\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT broadcast_date FROM table_sql WHERE episode_title = '\u3042\u308a\u3048\u306a\u3044\u30ad\u30b9') = \n             (SELECT MIN(broadcast_date) FROM table_sql) + 7 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1356.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the highest average for atletico ciudad was 0.61\nInput Table: 2008 - 09 segunda divisi\u00f3n b\n\n\ngoalkeepergoalsmatchesaverageteammiguel zapata17280.61atl\u00e9tico ciudadrub\u00e9n mart\u00ednez24320.75cartagenaorlando quintana29340.85lorca deportiva\u00e1lvaro campos24280.86real murcia bmat\u00edas garavano26300.87m\u00e9rida\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MAX(average) FROM table_sql WHERE team = 'atl\u00e9tico ciudad') = 0.61 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1041.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the last record for both the highest totalling name and the lowest totalling name were recorded in the month of september\nInput Table: list of sumo record holders\n\n\nnametotalfirstlasthighest_rankkotonishiki341990-09-011999-09-01sekiwakekai\u014d321994-05-012000-07-01\u014dzekimus\u014dyama311994-03-012000-09-01\u014dzekihasegawa301965-11-011974-09-01sekiwakekotomitsuki302001-01-012007-07-01\u014dzekiakinoshima271988-11-012000-09-01sekiwaketakamiyama271969-11-011982-09-01sekiwaketakat\u014driki261991-05-012000-05-01sekiwakewakanosato262000-11-012005-09-01sekiwakedaikirin221966-11-011970-09-01\u014dzekitochiazuma ii221997-07-012005-01-01\u014dzekikisenosato222006-07-012011-09-01\u014dzeki\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MAX(total) FROM table_sql WHERE total = (SELECT MAX(total) FROM table_sql)) = 'september' \n             AND (SELECT MIN(total) FROM table_sql WHERE total = (SELECT MIN(total) FROM table_sql)) = 'september' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-362.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: no players in the running back position were picked after the 10th round\nInput Table: indianapolis colts draft history\n\n\nroundpickoverallnamepositioncollege155curtis dickeyrunning backtexas a&m12424derrick hatchettcornerbacktexas2432ray donaldsoncentergeorgia22351tim foleyoffensive tacklenotre dame4588ray butlerwide receiverusc66144chris footecenterusc75170wes robertsdefensive endtcu82195ken walteroffensive tackletexas tech96227mark brightrunning backtemple105254larry stewartoffensive tacklemaryland113280ed whitleytight endkansas state126311randy bielskiplacekickertowson1219324marvin simsfullbackclemson\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE position = 'running back' \nAND round > 10;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-101.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: t9 place has a score of 67 + 68 + 78 + 77 = 290\nInput Table: 1975 u.s. open (golf)\n\n\nplaceplayercountryscoreto_parmoneyt1lou grahamunited states74 + 72 + 68 + 73 = 287+ 3playofft1john mahaffeyunited states73 + 71 + 72 + 71 = 287+ 3playofft3frank beardunited states74 + 69 + 67 + 78 = 288+ 410875t3ben crenshawunited states70 + 68 + 76 + 74 = 288+ 410875t3hale irwinunited states74 + 71 + 73 + 70 = 288+ 410875t3bob murphyunited states74 + 73 + 72 + 69 = 288+ 410875t7jack nicklausunited states72 + 70 + 75 + 72 = 289+ 57500t7peter oosterhuisengland69 + 73 + 72 + 75 = 289+ 57500t9pat fitzsimonsunited states67 + 73 + 73 + 77 = 290+ 65000t9arnold palmerunited states69 + 75 + 73 + 73 = 290+ 65000t9tom watsonunited states67 + 68 + 78 + 77 = 290+ 65000\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT score FROM table_sql WHERE place = 't9') = '67 + 68 + 78 + 77 = 290' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-605.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: brook lopez led the team in both points and rebounds in a single game 3 different times\nInput Table: 2010 - 11 new jersey nets season\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord759999-04-01philadelphial 90 - 115 (ot)brandan wright (15)brandan wright (11)deron williams (7)wells fargo center 1669523 - 52769999-04-03miamil 94 - 108 (ot)deron williams (18)travis outlaw (9)deron williams (9)prudential center 1871123 - 5377'9999-04-05'minnesotaw 107 - 105 (ot)brook lopez (30)brook lopez (12)deron williams (21)prudential center 1346124 - 53789999-04-06detroitl 109 - 116 (ot)brook lopez (39)brook lopez (7)jordan farmar (11)the palace of auburn hills 1455424 - 54799999-04-08new yorkl 93 - 116 (ot)brook lopez (27)jordan farmar (8)jordan farmar (9)prudential center 1802324 - 5580'9999-04-10'torontol 92 - 99 (ot)brook lopez (35)brook lopez (11)jordan farmar (7)air canada centre 1775524 - 56819999-04-11charlottel 103 - 105 (ot)brook lopez (31)dan gadzuric (8)jordan farmar (9)prudential center 1385324 - 57\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE high_points = (SELECT MAX(high_points) FROM table_sql) AND high_rebounds = (SELECT MAX(high_rebounds) FROM table_sql)) >= 3 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1474.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the team with a record of 34 - 27 had 7 high assists by n mcmillan\nInput Table: 1991 - 92 seattle supersonics season\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord589999-03-01cleveland cavaliersw 113 - 107e johnson , r pierce (22)b benjamin , m cage (14)r pierce (6)seattle center coliseum 1364732 - 26599999-03-03denver nuggetsw 111 - 92s kemp (21)s kemp (13)g payton (9)seattle center coliseum 986533 - 26609999-03-05phoenix sunsl 105 - 118r pierce (23)s kemp (19)g payton (12)arizona veterans memorial coliseum 1449633 - 27619999-03-07new jersey netsw 109 - 98r pierce (27)m cage (13)n mcmillan (7)seattle center coliseum 1341934 - 27620000-03-08portland trail blazersl 97 - 109r pierce (28)r pierce (10)g payton (7)memorial coliseum 1288834 - 28639999-03-10detroit pistonsl 92 - 98g payton (19)s kemp (9)n mcmillan (5)seattle center coliseum 1309834 - 29649999-03-11los angeles clippersw 104 - 96r pierce (19)b benjamin , m cage (6)g payton (9)los angeles memorial sports arena 1091235 - 296501-03-15dallas mavericksw 109 - 100r pierce (23)s kemp (15)g payton (8)seattle center coliseum 1216336 - 29660000-03-17golden state warriorsl 107 - 119r pierce (24)s kemp (15)r pierce (5)seattle center coliseum 1316336 - 30679999-03-19houston rocketsw 112 - 91r pierce (22)m cage , s kemp (14)g payton (11)the summit 1512237 - 30689999-03-21san antonio spursl 96 - 101e johnson (23)s kemp (13)d barros , m cage , n mcmillan (4)hemisfair arena 1605737 - 31699999-03-22dallas mavericksw 113 - 105e johnson (31)s kemp (17)n mcmillan (8)reunion arena 1434538 - 31709999-03-24houston rocketsw 128 - 106d mckey (23)m cage , s kemp (11)n mcmillan , g payton (7)seattle center coliseum 1137739 - 31719999-03-27milwaukee bucksw 96 - 95e johnson (21)n mcmillan (7)n mcmillan (6)seattle center coliseum 1145040 - 31729999-03-28new york knicksl 87 - 92s kemp (27)s kemp (12)n mcmillan (6)seattle center coliseum 1481240 - 32\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT high_assists FROM table_sql WHERE record = '34 - 27') = 7 \n             AND (SELECT team FROM table_sql WHERE record = '34 - 27') = 'n mcmillan' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1078.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the highest score of the season was detroit , on january 5 with 6 points\nInput Table: 2003 - 04 detroit red wings season\n\n\ndatevisitorscorehomedecisionattendancerecord0002-01-01detroit4 - 1carolinajoseph1705324 - 12 - 4 - 10001-01-03anaheim1 - 3detroitlegace2006625 - 12 - 4 - 10000-01-05nashville0 - 6detroitjoseph2006626 - 12 - 4 - 10001-01-07boston3 - 0detroitjoseph2006626 - 13 - 4 - 10000-01-10detroit1 - 2bostonjoseph1756526 - 13 - 4 - 29999-01-14chicago2 - 4detroitlegace2006627 - 13 - 4 - 20000-01-16phoenix3 - 3detroitjoseph2006627 - 13 - 5 - 29999-01-19detroit1 - 2san josejoseph1736127 - 14 - 5 - 29999-01-21detroit2 - 2anaheimlegace1717427 - 14 - 6 - 29999-01-22detroit5 - 4los angelesjoseph1811828 - 14 - 6 - 29999-01-24detroit2 - 5phoenixjoseph1901928 - 15 - 6 - 29999-01-26detroit2 - 2dallaslegace1853228 - 15 - 7 - 29999-01-29new jersey2 - 5detroitjoseph2006629 - 15 - 7 - 29999-01-31carolina4 - 4detroitlegace2006630 - 15 - 8 - 2\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MAX(score) FROM table_sql WHERE home = 'detroit') = 6 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-816.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: mark brooks is the player who earned the most money\nInput Table: 1996 pga championship\n\n\nplaceplayercountryscoreto_parmoney1mark brooksunited states68 + 70 + 69 + 70 = 277- 114300002kenny perryunited states66 + 72 + 71 + 68 = 277- 11260000t3steve elkingtonaustralia67 + 74 + 67 + 70 = 278- 10140000t3tommy tollesunited states69 + 71 + 71 + 67 = 278- 10140000t5justin leonardunited states71 + 66 + 72 + 70 = 279- 986667t5jesper parneviksweden73 + 67 + 69 + 70 = 279- 986667t5vijay singhfiji69 + 69 + 69 + 72 = 279- 986667t8lee janzenunited states68 + 71 + 71 + 70 = 280- 857500t8per - ulrik johanssonsweden73 + 72 + 66 + 69 = 280- 857500t8phil mickelsonunited states67 + 67 + 74 + 72 = 280- 857500t8larry mizeunited states71 + 70 + 69 + 70 = 280- 857500t8frank nobilonew zealand69 + 72 + 71 + 68 = 280- 857500t8nick pricezimbabwe68 + 71 + 69 + 72 = 280- 857500\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MAX(money) FROM table_sql) = (SELECT money FROM table_sql WHERE player = 'mark brooks') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-632.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the call sign for astral media 's radio station is ckfr\nInput Table: media in kelowna\n\n\nfrequencycall_signbrandingformatowner1150 amckfram 1150news / talkastral media00 88.9 fmcbtk - fmcbc radio onepublic news / talkcanadian broadcasting corporation00 89.7 fmcbu - fm - 3cbc radio 2public musiccanadian broadcasting corporation00 90.5 fmcbuf - fm - 2premi\u00e8re cha\u00eenepublic news / talkcanadian broadcasting corporation00 96.3 fmckko - fmk96.3classic rocksun country cablevision00 99.9 fmchsu - fm99.9 sun fmcontemporary hits radiobell media0 101.5 fmcilk - fm101.5 ez rockadult contemporarybell media0 103.1 fmckqq - fmq103hot adult contemporaryjim pattison group0 103.9 fmcjui - fm103.9 the juiceadult hitsvista broadcast group0 104.7 fmcklz - fmpower 104active rockjim pattison group\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE owner = 'astral media' \nAND branding = 'ckfr';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-463.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: players from the united states and new zealand are tied for 3rd place\nInput Table: 1973 u.s. open (golf)\n\n\nplaceplayercountryscoreto_par1gary playersouth africa67 + 70 = 137- 52jim colbertunited states70 + 68 = 138- 4t3jack nicklausunited states71 + 69 = 140- 2t3johnny millerunited states71 + 69 = 140- 2t3bob charlesnew zealand71 + 69 = 140- 2t6gene borekunited states77 + 65 = 142et6julius borosunited states73 + 69 = 142et6tom weiskopfunited states73 + 69 = 142et6arnold palmerunited states71 + 71 = 142et6lee trevinounited states70 + 72 = 142e\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE place = 't3' AND country IN ('united states', 'new zealand')) = 2 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1778.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there are 3624000 live births per year in the period where the life expectancy for females was 73.3\nInput Table: none\n\n\nperiodlive_births_per_yeardeaths_per_yearnatural_change_per_yearcbrcdrnctfrimrlife_expectancy_totallife_expectancy_maleslife_expectancy_females1950-01-01 - 1955-01-012 572 000900 0001 672 00044.115.528.66.1513550.949.252.61955-01-01 - 1960-01-012 918 000947 0001 971 00043.214.029.16.1512253.351.555.21960-01-01 - 1965-01-013 303 000986 0002 317 00042.212.629.66.1510955.753.857.69999-01-01 - 1970-01-013 330 000998 0002 332 00037.011.125.95.3810057.655.759.61970-01-01 - 1975-01-013 441 0001 014 0002 427 00033.79.923.84.729159.557.361.81975-01-01 - 1980-01-013 741 0001 043 0002 698 00032.59.023.54.317961.559.263.91980-01-01 - 1985-01-013 974 0001 064 0002 910 00030.88.222.63.86363.460.466.81985-01-01 - 1990-01-013 757 0001 055 0002 702 00026.37.418.93.15265.361.969.11990-01-01 - 1995-01-013 519 0001 058 0002 461 00022.66.815.82.64367.363.671.21995-01-01 - 2000-01-013 624 0001 086 0002 538 00021.56.515.12.453469.365.573.32000-01-01 - 2005-01-013 572 0001 147 0002 425 00019.86.413.42.252770.967.274.8\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN live_births_per_year = 3624000 AND life_expectancy_females = 73.3 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE period = '2000-01-01 - 2005-01-01';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-672.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: orlando won game 65 with a score of 79 - 92\nInput Table: 2001 - 02 toronto raptors season\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord609999-03-01portlandl 81 - 91 (ot)vince carter (25)antonio davis , hakeem olajuwon (8)chris childs (7)air canada centre 1980029 - 31619999-03-03philadelphial 84 - 96 (ot)antonio davis (26)antonio davis (9)alvin williams (6)air canada centre 1980029 - 32629999-03-05houstonl 109 - 112 (ot)vince carter (43)vince carter , hakeem olajuwon (7)alvin williams (9)compaq center 1422129 - 33639999-03-07dallasl 103 - 122 (ot)vince carter (19)keon clark , antonio davis (15)alvin williams (7)american airlines center 1994529 - 34640000-03-08miamiw 83 - 74 (ot)antonio davis (23)antonio davis (10)chris childs (6)american airlines arena 1650030 - 34659999-03-10orlandol 79 - 92 (ot)vince carter (16)antonio davis (12)chris childs (7)td waterhouse centre 1617130 - 35669999-03-12new jerseyl 84 - 86 (ot)antonio davis (27)antonio davis , jerome williams (13)vince carter (4)continental airlines arena 1610530 - 36670000-03-17sacramentol 113 - 116 (ot)vince carter (22)hakeem olajuwon (13)chris childs (7)air canada centre 1980030 - 37689999-03-19minnesotal 80 - 112 (ot)morris peterson (19)antonio davis (13)alvin williams (7)target center 1701030 - 38699999-03-22clevelandw 94 - 80 (ot)morris peterson (18)keon clark (10)alvin williams (4)gund arena 1784731 - 38709999-03-24washingtonw 92 - 91 (ot)morris peterson (26)antonio davis (9)alvin williams (9)air canada centre 1980032 - 38719999-03-27miamiw 81 - 80 (ot)morris peterson (21)antonio davis , jerome williams (10)chris childs (6)air canada centre 1980033 - 38729999-03-28atlantaw 85 - 83 (ot)antonio davis , morris peterson (15)antonio davis (9)chris childs (7)philips arena 1203634 - 38739999-03-31philadelphiaw 72 - 70 (ot)antonio davis (16)jerome williams (9)chris childs (9)first union center 2065035 - 38\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT team FROM table_sql WHERE game = 65) = 'orlando' \n             AND (SELECT score FROM table_sql WHERE game = 65) = '79 - 92' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1155.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: rodney stuckey led the detroit pistons in points scored in two games during this period of the 2010 - 2011 season\nInput Table: 2010 - 11 detroit pistons season\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord629999-03-01milwaukeel 90 - 92 (ot)rodney stuckey (25)greg monroe , charlie villanueva (9)rodney stuckey (5)bradley center 1136422 - 40639999-03-02minnesotal 105 - 116 (ot)austin daye (22)greg monroe (11)rodney stuckey (10)the palace of auburn hills 1312222 - 41649999-03-06washingtonw 113 - 102 (ot)tayshaun prince (20)greg monroe , rodney stuckey (7)rodney stuckey (9)the palace of auburn hills 1750623 - 41659999-03-09san antoniol 104 - 111 (ot)richard hamilton (20)greg monroe (10)tracy mcgrady (9)at&t center 1858123 - 42669999-03-11oklahoma cityl 94 - 104 (ot)richard hamilton (20)greg monroe (10)greg monroe , rodney stuckey (6)oklahoma city arena 1820323 - 43679999-03-12denverl 101 - 131 (ot)chris wilcox (21)austin daye , ben gordon , greg monroe (6)will bynum (10)pepsi center 1915523 - 44689999-03-16torontow 107 - 93 (ot)richard hamilton (24)greg monroe (10)rodney stuckey (14)the palace of auburn hills 1516624 - 44699999-03-18new yorkw 99 - 95 (ot)tayshaun prince (16)chris wilcox (12)will bynum (5)the palace of auburn hills 2207625 - 44709999-03-20atlantal 96 - 104 (ot)rodney stuckey (22)greg monroe (10)rodney stuckey (8)philips arena 1758025 - 45719999-03-23miamil 94 - 100 (ot)richard hamilton (27)greg monroe (12)rodney stuckey (6)the palace of auburn hills 2207625 - 46729999-03-25clevelandl 91 - 97 (ot)richard hamilton , tayshaun prince (15)chris wilcox , greg monroe (8)rodney stuckey (4)quicken loans arena 1990725 - 47739999-03-26indianaw 100 - 88 (ot)richard hamilton (23)greg monroe (13)richard hamilton , rodney stuckey (6)the palace of auburn hills 1921626 - 47\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE high_points = (SELECT MAX(high_points) FROM table_sql WHERE team = 'detroit pistons')) = 2 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-604.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: jordan farmar led the team in assists for more games than deron williams did\nInput Table: 2010 - 11 new jersey nets season\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord759999-04-01philadelphial 90 - 115 (ot)brandan wright (15)brandan wright (11)deron williams (7)wells fargo center 1669523 - 52769999-04-03miamil 94 - 108 (ot)deron williams (18)travis outlaw (9)deron williams (9)prudential center 1871123 - 5377'9999-04-05'minnesotaw 107 - 105 (ot)brook lopez (30)brook lopez (12)deron williams (21)prudential center 1346124 - 53789999-04-06detroitl 109 - 116 (ot)brook lopez (39)brook lopez (7)jordan farmar (11)the palace of auburn hills 1455424 - 54799999-04-08new yorkl 93 - 116 (ot)brook lopez (27)jordan farmar (8)jordan farmar (9)prudential center 1802324 - 5580'9999-04-10'torontol 92 - 99 (ot)brook lopez (35)brook lopez (11)jordan farmar (7)air canada centre 1775524 - 56819999-04-11charlottel 103 - 105 (ot)brook lopez (31)dan gadzuric (8)jordan farmar (9)prudential center 1385324 - 57\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE high_assists > high_assists AND team = 'new jersey nets') > \n             (SELECT COUNT(*) FROM table_sql WHERE high_assists > high_assists AND team = 'new jersey nets') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-867.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: when the engine was maserati l4s and the driver was prince bira the entrant was enrico plate\nInput Table: 1950 swiss grand prix\n\n\ndriverentrantconstructorchassisenginetyrenello paganiscuderia achille varzimaseratimaserati 4clt - 48maserati l4spjohnny claesecurie belgetalbot - lagotalbot - lago t26ctalbot l6dyves giraud - cabantousautomobiles talbot - darracq satalbot - lagotalbot - lago t26c - datalbot l6deug\u00e8ne martinautomobiles talbot - darracq satalbot - lagotalbot - lago t26c - datalbot l6dlouis rosierautomobiles talbot - darracq satalbot - lagotalbot - lago t26c - datalbot l6dluigi fagiolisa alfa romeoalfa romeoalfa romeo 158alfa romeo l8spjuan manuel fangiosa alfa romeoalfa romeoalfa romeo 158alfa romeo l8spnino farinasa alfa romeoalfa romeoalfa romeo 158alfa romeo l8spalberto ascariscuderia ferrariferrariferrari 125ferrari v12spraymond sommerscuderia ferrariferrariferrari 125ferrari v12spluigi villoresiscuderia ferrariferrariferrari 125ferrari v12sppeter whiteheadscuderia ferrariferrariferrari 125ferrari v12splouis chironofficine alfieri maseratimaseratimaserati 4clt - 48maserati l4spfranco rolofficine alfieri maseratimaseratimaserati 4clt - 48maserati l4spprince biraenrico plat\u00e9maseratimaserati 4clt - 48maserati l4sptoulo de graffenriedenrico plat\u00e9maseratimaserati 4clt - 48maserati l4spfelice bonettoscuderia milanomaseratimaserati milano 4clt - 50maserati l4spreg parnellscuderia ambrosianamaseratimaserati 4clt - 48maserati l4sdrudi fischerecurie espadonsva - fiatsva 1500fiat l4sptoni brancaprivatemaseratimaserati 4clmaserati l4spphilippe \u00e9tancelinprivatetalbot - lagotalbot - lago t26ctalbot l6dharry schellecurie bleuetalbot - lagotalbot - lago t26ctalbot l6d\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN entrant = 'enrico plat\u00e9' AND engine = 'maserati l4s' AND driver = 'prince bira' THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-530.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: glenferrie oval venue recorded 2000 more crowd participants than that of the arden street oval venue\nInput Table: 1961 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddatenorth melbourne9.14 (68)st kilda11.16 (82)arden street oval130001961-06-03hawthorn10.13 (73)richmond8.12 (60)glenferrie oval150001961-06-03collingwood18.11 (119)essendon8.10 (58)victoria park282901961-06-03geelong13.13 (91)footscray4.14 (38)kardinia park186831961-06-03south melbourne7.8 (50)fitzroy17.15 (117)lake oval145001961-06-03melbourne15.14 (104)carlton11.13 (79)mcg496781961-06-03\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT crowd FROM table_sql WHERE venue = 'glenferrie oval') - \n             (SELECT crowd FROM table_sql WHERE venue = 'arden street oval') > 2000 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-176.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: 7.2 is the rebound average when games is 125 and the rank is 7\nInput Table: none\n\n\nrankplayeryearsgamesreb_avgtotal_rebounds1jim nowers1972-01-01 - 1976-01-011129.410482kenny sanders1985-01-01 - 1989-01-011079.610263will thomas2004-01-01 - 2008-01-011317.69934george evans1997-01-01 - 2001-01-011168.29535robert dykes1987-01-01 - 1991-01-011227.59256andre gaddy1977-01-01 - 1982-01-01989.39167jai lewis2002-01-01 - 2006-01-011257.28958rob rose1982-01-01 - 1986-01-011137.18059herb estes1973-01-01 - 1976-01-01809.273410jesse young1999-01-01 - 2003-01-011156.2708\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN reb_avg = 7.2 AND games = 125 AND rank = 7 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-196.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the collingwood vs melbourne game has the largest crowd size\nInput Table: 1972 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddatefootscray14.7 (91)st kilda9.11 (65)western oval186551972-07-15fitzroy16.14 (110)north melbourne9.12 (66)junction oval70071972-07-15essendon13.12 (90)richmond17.9 (111)windy hill222511972-07-15carlton20.8 (128)south melbourne8.15 (63)princes park144651972-07-15hawthorn19.14 (128)geelong15.8 (98)glenferrie oval124251972-07-15collingwood10.13 (73)melbourne8.10 (58)vfl park308831972-07-15\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MAX(crowd) FROM table_sql) = (SELECT crowd FROM table_sql WHERE home_team = 'collingwood' AND away_team = 'melbourne') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-889.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: in the 2002 - 2003 season there were 6 cashes , a match play smaller than 13 and 7 events\nInput Table: none\n\n\nseasoneventscashesmatch_playtv_finalspba_titlesaverageearnings2002-03-0176200210.8895002003-04-011815910217.53458502004-05-0119191310219.55566752005-06-0122221841221.831302702006-07-0120201761226.491484252007-08-0118181561223.771089002008-09-0120181693222.981746802009-10-0118161350221.33855702010-11-01129520215.96336902011-12-011310721224.62393809999-01-011310541229.5113259\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN cashes = 6 AND match_play < 13 AND events = 7 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE season = '2002-03-01';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-206.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: on june 8th , 1997 , jeff gordon drove for 200 laps\nInput Table: pocono 400\n\n\nyeardatedriverteammanufacturerlaps-race_timeaverage_speed_(mph)report1982-01-019999-06-06bobby allisondigard motorsportsbuick200500 (804.672)4:24:08113.579report1983-01-019999-06-12bobby allisondigard motorsportsbuick200500 (804.672)3:53:13128.636report1984-01-019999-06-10cale yarboroughranier - lundychevrolet200500 (804.672)3:37:08138.164report1985-01-019999-06-09bill elliottmelling racingford200500 (804.672)3:35:48138.974report1986-01-019999-06-08tim richmondhendrick motorsportschevrolet200500 (804.672)4:24:50113.279report1987-01-019999-06-14tim richmondhendrick motorsportschevrolet200500 (804.672)4:05:57122.166report1988-01-019999-06-19geoffrey bodinehendrick motorsportschevrolet200500 (804.672)3:58:21126.147report1989-01-019999-06-18terry labontejunior johnson & associatesford200500 (804.672)3:48:27131.32report1990-01-019999-06-17harry gantleo jackson racingoldsmobile200500 (804.672)4:08:25120.6report1991-01-019999-06-16darrell waltripdarwal , incchevrolet200500 (804.672)4:04:34122.666report1992-01-019999-06-14alan kulwickiak racingford200500 (804.672)3:28:18144.023report1993-01-019999-06-13kyle pettysabco racingpontiac200500 (804.672)3:37:23138.005report1994-01-019999-06-12rusty wallacepenske racingford200500 (804.672)3:52:55128.801report1995-01-019999-06-11terry labontehendrick motorsportschevrolet200500 (804.672)3:37:50137.72report1996-01-019999-06-16jeff gordonhendrick motorsportschevrolet200500 (804.672)3:35:40139.104report1997-01-019999-06-08jeff gordonhendrick motorsportschevrolet200500 (804.672)3:34:33139.828report1998-01-019999-06-21jeremy mayfieldpenske racingford200500 (804.672)4:14:39117.809report1999-01-019999-06-20bobby labontejoe gibbs racingpontiac200500 (804.672)4:12:19118.898report2000-01-019999-06-19jeremy mayfieldpenske racingford200500 (804.672)3:34:41139.741report2001-01-019999-06-17ricky ruddrobert yates racingford200500 (804.672)3:43:14134.389report2002-01-019999-06-09dale jarrettrobert yates racingford200500 (804.672)3:29:10143.426report2003-01-019999-06-08tony stewartjoe gibbs racingchevrolet200500 (804.672)3:42:24134.892report2004-01-019999-06-13jimmie johnsonhendrick motorsportschevrolet200500 (804.672)4:27:33112.129report2005-01-019999-06-12carl edwardsroush racingford201502.5 (808.695)3:53:24129.177report2006-01-019999-06-11denny hamlinjoe gibbs racingchevrolet200500 (804.672)3:47:52131.656report2007-01-019999-06-10jeff gordonhendrick motorsportschevrolet106265 (426.476)1:57:15135.608report2008-01-019999-06-08kasey kahnegillett evernham motorsportsdodge200500 (804.672)3:59:36125.209report2009-01-019999-06-07tony stewartstewart - haas racingchevrolet200500 (804.672)3:36:35138.515report2010-01-019999-06-06denny hamlinjoe gibbs racingtoyota204510 (820.765)3:44:30136.303report2011-01-019999-06-12jeff gordonhendrick motorsportschevrolet200500 (804.672)3:26:21145.384report2012-01-019999-06-10joey loganojoe gibbs racingtoyota160400 (643.737)3:03:12131.004report\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE date = '1997-06-08' \nAND driver = 'jeff gordon' \nAND laps = 200;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-629.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "Yes",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: bell media 's call sign was chsu - fm on the frequency 99.9 fm\nInput Table: media in kelowna\n\n\nfrequencycall_signbrandingformatowner1150 amckfram 1150news / talkastral media00 88.9 fmcbtk - fmcbc radio onepublic news / talkcanadian broadcasting corporation00 89.7 fmcbu - fm - 3cbc radio 2public musiccanadian broadcasting corporation00 90.5 fmcbuf - fm - 2premi\u00e8re cha\u00eenepublic news / talkcanadian broadcasting corporation00 96.3 fmckko - fmk96.3classic rocksun country cablevision00 99.9 fmchsu - fm99.9 sun fmcontemporary hits radiobell media0 101.5 fmcilk - fm101.5 ez rockadult contemporarybell media0 103.1 fmckqq - fmq103hot adult contemporaryjim pattison group0 103.9 fmcjui - fm103.9 the juiceadult hitsvista broadcast group0 104.7 fmcklz - fmpower 104active rockjim pattison group\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE owner = 'bell media' \nAND call_sign = 'chsu - fm' \nAND frequency = '99.9 fm';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1271.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the nuggets won all six games played at the pepsi center during this span\nInput Table: 2009 - 10 denver nuggets season\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord39999-11-01grizzliesw 133 - 123 (ot)carmelo anthony (42)nen\u00ea (9)chauncey billups (12)pepsi center 158233 - 049999-11-03pacersw 111 - 93 (ot)carmelo anthony (25)nen\u00ea (13)anthony carter (5)conseco fieldhouse 106274 - 059999-11-04netsw 122 - 94 (ot)ty lawson (23)kenyon martin (10)chauncey billups (5)izod center 153195 - 079999-11-07hawksl 100 - 125 (ot)carmelo anthony (30)chris andersen (11)chauncey billups (7)philips arena 178015 - 289999-11-10bullsw 90 - 89 (ot)carmelo anthony (20)nen\u00ea (12)chauncey billups (6)united center 214096 - 299999-11-11bucksl 102 - 108 (ot)carmelo anthony (32)carmelo anthony (10)chauncey billups , ty lawson (5)bradley center 129876 - 3109999-11-13lakersw 105 - 79 (ot)carmelo anthony (25)chris andersen (11)chauncey billups (8)pepsi center 191417 - 3119999-11-17raptorsw 130 - 112 (ot)carmelo anthony (32)nen\u00ea (10)chauncey billups (10)pepsi center 164468 - 3129999-11-20clippersl 99 - 106 (ot)carmelo anthony (37)nen\u00ea (12)chauncey billups (7)staples center 181558 - 4139999-11-21bullsw 112 - 93 (ot)carmelo anthony (30)carmelo anthony , kenyon martin (11)carmelo anthony (7)pepsi center 193599 - 4149999-11-24netsw 101 - 87 (ot)carmelo anthony (27)nen\u00ea (9)chauncey billups (7)pepsi center 1630710 - 4159999-11-25timberwolvesw 124 - 111 (ot)carmelo anthony (22)nen\u00ea (8)nen\u00ea , ty lawson (6)target center 1310111 - 4169999-11-27knicksw 128 - 125 (ot)carmelo anthony (50)nen\u00ea , kenyon martin (11)chauncey billups (8)pepsi center 1915512 - 4\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 6 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE location_attendance LIKE 'pepsi center%' \nAND record LIKE '% - 0';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-606.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the nets' only win came at the prudential center\nInput Table: 2010 - 11 new jersey nets season\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord759999-04-01philadelphial 90 - 115 (ot)brandan wright (15)brandan wright (11)deron williams (7)wells fargo center 1669523 - 52769999-04-03miamil 94 - 108 (ot)deron williams (18)travis outlaw (9)deron williams (9)prudential center 1871123 - 5377'9999-04-05'minnesotaw 107 - 105 (ot)brook lopez (30)brook lopez (12)deron williams (21)prudential center 1346124 - 53789999-04-06detroitl 109 - 116 (ot)brook lopez (39)brook lopez (7)jordan farmar (11)the palace of auburn hills 1455424 - 54799999-04-08new yorkl 93 - 116 (ot)brook lopez (27)jordan farmar (8)jordan farmar (9)prudential center 1802324 - 5580'9999-04-10'torontol 92 - 99 (ot)brook lopez (35)brook lopez (11)jordan farmar (7)air canada centre 1775524 - 56819999-04-11charlottel 103 - 105 (ot)brook lopez (31)dan gadzuric (8)jordan farmar (9)prudential center 1385324 - 57\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 1 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE team = 'new jersey nets' \nAND location_attendance LIKE '%prudential center%' \nAND record LIKE '%1 -%'\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1868.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the united states team won 8 of the solheim cups starting in 1990 and the last was in 2009\nInput Table: solheim cup\n\n\nyearvenuewinning_teamscoreusa_captaineurope_captain2013-01-01colorado golf club , colorado , usaeurope18 - 10meg mallonliselotte neumann2011-01-01killeen castle golf resort , irelandeurope15 - 13rosie jonesalison nicholas2009-01-01rich harvest farms , illinois , usaunited states16 - 12beth danielalison nicholas2007-01-01halmstad gk , swedenunited states16 - 12betsy kinghelen alfredsson2005-01-01crooked stick golf club , indiana , usaunited states15\u00bd - 12\u00bdnancy lopezcatrin nilsmark2003-01-01barseb\u00e4ck golf & country club , swedeneurope17\u00bd - 10\u00bdpatty sheehancatrin nilsmark2002-01-01interlachen country club , minnesota , usaunited states15\u00bd - 12\u00bdpatty sheehandale reid2000-01-01loch lomond golf club , scotlandeurope14\u00bd - 11\u00bdpat bradleydale reid1998-01-01muirfield village , ohio , usaunited states16 - 12judy rankinpia nilsson1996-01-01st pierre golf & country club , walesunited states17 - 11judy rankinmickey walker1994-01-01the greenbrier , west virginia , usaunited states13 - 7joanne carnermickey walker1992-01-01dalmahoy country club , scotlandeurope11\u00bd - 6\u00bdkathy whitworthmickey walker1990-01-01lake nona golf & country club , florida , usaunited states11\u00bd - 4\u00bdkathy whitworthmickey walker\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE winning_team = 'united states' AND year >= 1990 AND year <= 2009) = 8 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-583.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there are 4 games in the 2005 milwaukee brewers season where one team scored no points\nInput Table: 2005 milwaukee brewers season\n\n\ndateopponentscorelossattendancerecord9999-09-01padres5 - 6davis (1 - 1)2478565 - 699999-09-02padres12 - 2lawrence (7 - 14)1823166 - 699999-09-03padres1 - 6obermueller (1 - 3)3202266 - 709999-09-04padres3 - 2otsuka (1 - 6)2004267 - 709999-09-05reds6 - 1belisle (3 - 7)1614468 - 709999-09-06reds1 - 2 (10)de la rosa (2 - 2)1335168 - 719999-09-07reds14 - 5milton (7 - 14)1588669 - 719999-09-09astros7 - 4clemens (11 - 7)1813070 - 719999-09-10astros5 - 7ohka (10 - 8)2443770 - 729999-09-11astros4 - 2oswalt (17 - 12)1739271 - 729999-09-13diamondbacks3 - 1v\u00e3\u00a1zquez (10 - 15)2370872 - 729999-09-14diamondbacks1 - 2 (12)lehr (0 - 1)2379372 - 739999-09-15diamondbacks14 - 2estes (7 - 8)2074173 - 739999-09-16astros1 - 2eveland (1 - 1)3376773 - 749999-09-17astros0 - 7obermueller (1 - 4)3775673 - 759999-09-18astros1 - 6capuano (17 - 10)3505273 - 769999-09-20cubs5 - 3williams (5 - 9)3013674 - 769999-09-21cubs7 - 6van buren (0 - 2)3004975 - 769999-09-22cubs0 - 3helling (2 - 1)3113775 - 779999-09-23cardinals9 - 6carpenter (21 - 5)2247276 - 779999-09-24cardinals8 - 7mulder (16 - 8)3350677 - 779999-09-25cardinals0 - 2davis (11 - 11)2015077 - 789999-09-26reds12 - 9coffey (4 - 1)1441278 - 789999-09-27reds6 - 2claussen (10 - 10)2803179 - 789999-09-28reds4 - 11capuano (18 - 11)2118179 - 799999-09-29reds2 - 0milton (8 - 15)1317380 - 799999-09-30pirates6 - 5vogelsong (2 - 2)2092281 - 79\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 4 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE score = '0 - 0';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-316.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the jazz had at least three guards that were on the team 1979 - 80\nInput Table: utah jazz all - time roster\n\n\nplayernationalitypositionyears_for_jazzschool_/_club_teamadrian dantleyunited statesguard - forward1979-01-01notre damebrad davisunited statesguard1979-01-01marylanddarryl dawkinsunited statescenter1987-01-01maynard evans hspaul dawkinsunited statesguard1979-01-01northern illinoisgreg deaneunited statesguard1979-01-01utahjames donaldsonunited statescenter1993-01-01, 1994-01-01, 1995-01-01washington statejohn drewunited statesguard - forward1982-01-01gardner - webbjohn durenunited statesguard1980-01-01georgetown\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) >= 3 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE years_for_jazz LIKE '%1979-80%' \nAND position LIKE '%guard%';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-457.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the lowest attendance figure for a game was 32343\nInput Table: 1983 miami dolphins season\n\n\nweekdateopponentresultattendance11983-09-04buffalo billsw 12 - 07871521983-09-11new england patriotsw 34 - 245934331983-09-19los angeles raidersl 27 - 145779641983-09-25kansas city chiefsw 14 - 65078551983-10-02new orleans saintsl 17 - 76648961983-10-09buffalo billsl 38 - 355994871983-10-16new york jetsw 32 - 145861581983-10-23baltimore coltsw 21 - 73234391983-10-30los angeles ramsw 30 - 1472175101983-11-06san francisco 49ersw 20 - 1757832111983-11-13new england patriotsl 17 - 660771121983-11-20baltimore coltsw 37 - 054482131983-11-28cincinnati bengalsw 38 - 1474506141983-12-04houston oilersw 24 - 1739434151983-12-10atlanta falconsw 31 - 2456725161983-12-16new york jetsw 34 - 1459975\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN MIN(attendance) = 32343 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-504.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the surface for october 10 , 2004 was hard\nInput Table: ji\u0159\u00ed nov\u00e1k\n\n\ndatetournamentsurfaceopponentscore1996-01-14auckland , new zealandhardbrett steven6 - 4 , 6 - 41998-11-01mexico city , mexicoclayxavier malisse6 - 3 , 6 - 32001-05-06munich , germanyclayantony dupuis6 - 4 , 7 - 52001-07-15gstaad , switzerlandclayjuan carlos ferrero6 - 1 , 6 - 7 (5 - 7) , 7 - 52003-07-13gstaad , switzerlandclayroger federer5 - 7 , 6 - 3 , 6 - 3 , 1 - 6 , 6 - 32004-10-10tokyo , japanhardtaylor dent5 - 7 , 6 - 1 , 6 - 32004-11-03basel , switzerlandcarpet (i)david nalbandian5 - 7 , 6 - 3 , 6 - 4 , 1 - 6 , 6 - 2\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN surface = 'hard' AND date = '2004-10-10' THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-822.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: mark brooks and kenny perry tied for having the lowest to par\nInput Table: 1996 pga championship\n\n\nplaceplayercountryscoreto_parmoney1mark brooksunited states68 + 70 + 69 + 70 = 277- 114300002kenny perryunited states66 + 72 + 71 + 68 = 277- 11260000t3steve elkingtonaustralia67 + 74 + 67 + 70 = 278- 10140000t3tommy tollesunited states69 + 71 + 71 + 67 = 278- 10140000t5justin leonardunited states71 + 66 + 72 + 70 = 279- 986667t5jesper parneviksweden73 + 67 + 69 + 70 = 279- 986667t5vijay singhfiji69 + 69 + 69 + 72 = 279- 986667t8lee janzenunited states68 + 71 + 71 + 70 = 280- 857500t8per - ulrik johanssonsweden73 + 72 + 66 + 69 = 280- 857500t8phil mickelsonunited states67 + 67 + 74 + 72 = 280- 857500t8larry mizeunited states71 + 70 + 69 + 70 = 280- 857500t8frank nobilonew zealand69 + 72 + 71 + 68 = 280- 857500t8nick pricezimbabwe68 + 71 + 69 + 72 = 280- 857500\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MIN(to_par) FROM table_sql) = -11 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-681.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: nick faldo was the only player from england\nInput Table: 2002 u.s. open (golf)\n\n\nplaceplayercountryscoreto_par1tiger woodsunited states67 + 68 + 70 = 205- 52sergio garc\u00edaspain68 + 74 + 67 = 209- 1t3jeff maggertunited states69 + 73 + 68 = 210et3phil mickelsonunited states70 + 73 + 67 = 210et5robert allenbyaustralia74 + 70 + 67 = 211+ 1t5p\u00e1draig harringtonireland70 + 68 + 73 = 211+ 1t5billy mayfairunited states69 + 74 + 68 = 211+ 1t8nick faldoengland70 + 76 + 66 = 212+ 2t8justin leonardunited states73 + 71 + 68 = 212+ 2t10tom byrumunited states72 + 72 + 70 = 214+ 4t10davis love iiiunited states71 + 71 + 72 = 214+ 4t10scott mccarronunited states72 + 72 + 70 = 214+ 4\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 1 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE country = 'england' \nAND player != 'nick faldo';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1937.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the android browser for android has a theora version of 2.3 and an h264 version of 3.0\nInput Table: html5 video\n\n\nbrowseroperating_systemlatest_stable_releasetheorah264vp8_(_webm_)vp9_(_webm_)android browserandroid2012-11-279999-02-039999-01-039999-02-039999-01-01chromiumall supported9999-01-019999-01-019999-01-019999-01-019999-01-01google chrome30.0.1599.101 (october 15 , 2013 )2013-10-159999-01-039999-01-039999-01-069999-01-29internet explorerwindows2013-10-179999-01-019999-09-019999-01-019999-01-01internet explorerwindows phone2012-11-219999-01-019999-09-019999-01-019999-01-01internet explorerwindows rt9999-01-109999-01-019999-01-109999-01-019999-01-01konquerorall supported2013-10-019999-04-019999-04-019999-04-019999-01-01safariios2013-10-249999-01-019999-03-019999-01-019999-01-01safarimacos x2013-10-249999-01-019999-03-019999-01-019999-01-01\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN theora = '2.3' AND h264 = '3.0' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE browser = 'android browser' \nAND operating_system = 'android';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1459.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the new york jets had 992 more people in attendance in their second game against the miami dolphins then from their first game played against them during the 1993 season\nInput Table: 1993 new york jets season\n\n\nweekdateopponentresultgame_siteattendance11993-09-05denver broncosl 26 - 20the meadowlands6813021993-09-12miami dolphinsw 24 - 14joe robbie stadium7031441993-09-26new england patriotsw 45 - 7the meadowlands6483651993-10-03philadelphia eaglesl 35 - 30the meadowlands7259361993-10-10los angeles raidersl 24 - 20los angeles memorial coliseum4162781993-10-24buffalo billsl 19 - 10the meadowlands7154191993-10-31new york giantsw 10 - 6giants stadium71659101993-11-07miami dolphinsw 27 - 10the meadowlands71306111993-11-14indianapolis coltsw 31 - 17rca dome47351121993-11-21cincinnati bengalsw 17 - 12the meadowlands64264131993-11-28new england patriotsw 6 - 0foxboro stadium42810141993-12-05indianapolis coltsl 9 - 6the meadowlands45799151993-12-11washington redskinsw 3 - 0robert f kennedy memorial stadium47970161993-12-18dallas cowboysl 28 - 7the meadowlands73233171993-12-26buffalo billsl 16 - 14rich stadium70817181994-01-02houston oilersl 24 - 0houston astrodome61040\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT attendance FROM table_sql WHERE opponent = 'miami dolphins' AND week = 2) - \n             (SELECT attendance FROM table_sql WHERE opponent = 'miami dolphins' AND week = 1) = 992 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-157.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: after 1985 , the united states contributed four players with louis amundson being the most recent\nInput Table: utah jazz all - time roster\n\n\nplayernationalitypositionyears_for_jazzschool_/_club_teamrick adelmanunited statesguard1974-01-01loyola (ca)john amaechienglandcenter / forward2001-03-01penn statelouis amundsonunited statesforward2007-01-01unlvj j andersonunited statesforward1982-01-01bradleyshandon andersonunited statesguard / forward9999-01-01georgiarafael ara\u00e3jobrazilcenter2006-01-01byucarlos arroyopuerto ricoguard2002-05-01florida internationalisaac austinunited statescenter1991-01-01arizona stateanthony aventunited statesforward1998-01-01seton hall\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 1 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE nationality = 'united states' \nAND years_for_jazz > '1985-01-01' \nAND player != 'louis amundson';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-256.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: galina voskoboeva has an equal winrate between both clay and hard courts\nInput Table: galina voskoboeva\n\n\noutcomedatetournamentsurfaceopponentscorerunner - up2003-01-28tiptonhard (i)matea mezak6 - 4 , 4 - 6 , 4 - 6winner2003-06-29mont - de - marsanhard (i)oleksandra kravets6 - 4 , 6 - 2runner - up2003-10-03latinaclayroberta vinci3 - 6 , 4 - 6runner - up2005-11-08pittsburghhardlilia osterloh6 - 7 , 4 - 6winner2006-06-06cuneo , italyclayalice canepa6 - 1 , 6 - 2\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE surface = 'clay' AND outcome = 'winner') = \n             (SELECT COUNT(*) FROM table_sql WHERE surface = 'hard' AND outcome = 'winner') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-952.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: pdip - 20 is the package when eeprom is less than 128 on one occasion\nInput Table: none\n\n\nchipflash_sizeeepromsramfrequencypackageat90s12001k64012pdip - 20at90s23132k12812810pdip - 20at90s / ls23232k12812810pdip - 8at90s / ls23432k12812810pdip - 8at90s44144k2562568pdip - 40at90s / ls44344k2562568pdip - 40at90s85158k5125128pdip - 40at90s / ls85358k5125128pdip - 40\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE package = 'pdip - 20' \nAND eeprom < 128;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1908.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: three teams tie on points but are separated by goal difference\nInput Table: 1940 in brazilian football\n\n\npositionteampointsplayedagainstdifference1flamengo1381282fluminense13815103corinthians981544palestra it\u00e1lia881935portuguesa7823- 106botafogo682507vasco da gama6819- 28am\u00e9rica6825- 109s\u00e3o paulo4824- 13\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE points = 13) > 1 \n             AND (SELECT COUNT(*) FROM table_sql WHERE difference = 8) > 1 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-682.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: robert allenby scores a 211 , making him tied for 5th place\nInput Table: 2002 u.s. open (golf)\n\n\nplaceplayercountryscoreto_par1tiger woodsunited states67 + 68 + 70 = 205- 52sergio garc\u00edaspain68 + 74 + 67 = 209- 1t3jeff maggertunited states69 + 73 + 68 = 210et3phil mickelsonunited states70 + 73 + 67 = 210et5robert allenbyaustralia74 + 70 + 67 = 211+ 1t5p\u00e1draig harringtonireland70 + 68 + 73 = 211+ 1t5billy mayfairunited states69 + 74 + 68 = 211+ 1t8nick faldoengland70 + 76 + 66 = 212+ 2t8justin leonardunited states73 + 71 + 68 = 212+ 2t10tom byrumunited states72 + 72 + 70 = 214+ 4t10davis love iiiunited states71 + 71 + 72 = 214+ 4t10scott mccarronunited states72 + 72 + 70 = 214+ 4\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT place FROM table_sql WHERE player = 'robert allenby' AND score = '211') = 't5' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1331.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: stephen jackson led the team in points for the most games\nInput Table: 2009 - 10 charlotte bobcats season\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord4701-02-9999portlandl 79 - 98 (ot)raymond felton (23)gerald wallace (10)stephen jackson (4)rose garden 2010624 - 23489999-02-03la lakersl 97 - 99 (ot)stephen jackson (30)nazr mohammed (17)boris diaw (5)staples center 1899724 - 24499999-02-06new orleansl 99 - 104 (ot)stephen jackson (26)boris diaw (8)raymond felton (7)time warner cable arena 1916424 - 25509999-02-09washingtonw 94 - 92 (ot)stephen jackson (22)nazr mohammed (10)raymond felton (5)time warner cable arena 1237625 - 255101-02-10minnesotaw 93 - 92 (ot)stephen jackson (33)nazr mohammed (20)dj augustin (7)target center 1335226 - 255201-02-16new jerseyl 94 - 103 (ot)gerald wallace (21)gerald wallace , boris diaw (10)stephen jackson (5)time warner cable arena 1371226 - 26539999-02-19clevelandw 110 - 93 (ot)stephen jackson (29)tyrus thomas (12)boris diaw (9)time warner cable arena 1956827 - 26549999-02-20milwaukeel 88 - 93 (ot)stephen jackson (35)tyrus thomas (11)stephen jackson (5)bradley center 1717427 - 27559999-02-22la clippersl 94 - 98 (ot)gerald wallace (32)gerald wallace (12)boris diaw , raymond felton (9)staples center 1589227 - 28569999-02-24utahl 93 - 102 (ot)gerald wallace (27)gerald wallace (8)raymond felton (5)energysolutions arena 1991127 - 29\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE high_points = (SELECT MAX(high_points) FROM table_sql)) > 1 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1561.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: after 2005 , the winners of the lifetime achievement award were andrew rule , john silvester , sandra harvey , lindsay simpson , marele day , shane maloney , and peter doyle\nInput Table: ned kelly awards\n\n\nyearbest_teenage_/_young_adultreader_'s_votebest_non_-_fictionlifetime_achievement1996-01-01nananajon cleary1997-01-01nanahow to write crime edited by marele dayalan yates (aka carter brown )1998-01-01nananana1999-01-01nananapeter corris2000-01-01nananana2001-01-01nableeding hearts by lindy cameronnaprofessor stephen knight2002-01-01blue murder by ken catranapartment 255 by bunty aviesonnapatrick gallagher2003-01-01nananakerry greenwood2004-01-01nananabob bottom2005-01-01nananastuart coupe2006-01-01nananaandrew rule and john silvester2007-01-01nananasandra harvey and lindsay simpson2008-01-01nananamarele day2009-01-01nananashane maloney2010-01-01nananapeter doyle2011-01-01nananana\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE year > '2005-01-01' AND lifetime_achievement IN ('andrew rule', 'john silvester', 'sandra harvey', 'lindsay simpson', 'marele day', 'shane maloney', 'peter doyle')) = 7 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1039.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the only total that appears more than two times is 22\nInput Table: list of sumo record holders\n\n\nnametotalfirstlasthighest_rankkotonishiki341990-09-011999-09-01sekiwakekai\u014d321994-05-012000-07-01\u014dzekimus\u014dyama311994-03-012000-09-01\u014dzekihasegawa301965-11-011974-09-01sekiwakekotomitsuki302001-01-012007-07-01\u014dzekiakinoshima271988-11-012000-09-01sekiwaketakamiyama271969-11-011982-09-01sekiwaketakat\u014driki261991-05-012000-05-01sekiwakewakanosato262000-11-012005-09-01sekiwakedaikirin221966-11-011970-09-01\u014dzekitochiazuma ii221997-07-012005-01-01\u014dzekikisenosato222006-07-012011-09-01\u014dzeki\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) > 2 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM \n    (SELECT total, COUNT(*) as count FROM table_sql GROUP BY total) \nWHERE \n    count > 2;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-607.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: brook lopez led the team in points for 5 straight games\nInput Table: 2010 - 11 new jersey nets season\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord759999-04-01philadelphial 90 - 115 (ot)brandan wright (15)brandan wright (11)deron williams (7)wells fargo center 1669523 - 52769999-04-03miamil 94 - 108 (ot)deron williams (18)travis outlaw (9)deron williams (9)prudential center 1871123 - 5377'9999-04-05'minnesotaw 107 - 105 (ot)brook lopez (30)brook lopez (12)deron williams (21)prudential center 1346124 - 53789999-04-06detroitl 109 - 116 (ot)brook lopez (39)brook lopez (7)jordan farmar (11)the palace of auburn hills 1455424 - 54799999-04-08new yorkl 93 - 116 (ot)brook lopez (27)jordan farmar (8)jordan farmar (9)prudential center 1802324 - 5580'9999-04-10'torontol 92 - 99 (ot)brook lopez (35)brook lopez (11)jordan farmar (7)air canada centre 1775524 - 56819999-04-11charlottel 103 - 105 (ot)brook lopez (31)dan gadzuric (8)jordan farmar (9)prudential center 1385324 - 57\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE high_points = (SELECT MAX(high_points) FROM table_sql) AND game >= 75 AND game <= 79) = 5 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-323.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there were more republican than democratic incumbents who were first elected in 1974\nInput Table: united states house of representatives elections , 1994\n\n\ndistrictincumbentpartyfirst_electedstatusopponentpennsylvania4ron klinkdemocratic1992-01-01re - electedron klink (d) 64.2% ed peglow (r) 35.8%pennsylvania5william f clinger , jrrepublican1978-01-01re - electedwilliam f clinger , jr (r) unopposedpennsylvania7curt weldonrepublican1986-01-01re - electedcurt weldon (r) 69.7% sara r nichols (d) 30.3%pennsylvania9bud shusterrepublican1972-01-01re - electedbud shuster (r) unopposedpennsylvania12john murthademocratic1974-01-01re - electedjohn murtha (d) 68.9% bill choby (r) 31.1%pennsylvania17george gekasrepublican1982-01-01re - electedgeorge gekas (r) unopposedpennsylvania18rick santorumrepublican1990-01-01retired to run for us senate democratic gainmichael f doyle (d) 54.8% john mccarty (r) 45.2%pennsylvania19william f goodlingrepublican1974-01-01re - electedwilliam f goodling (r) unopposed\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE party = 'republican' AND first_elected = '1974-01-01' AND incumbent = 'republican') > \n             (SELECT COUNT(*) FROM table_sql WHERE party = 'democratic' AND first_elected = '1974-01-01' AND incumbent = 'democratic') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-906.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: only four of the athletes had a mark greater than 29 feet\nInput Table: long jump\n\n\nmarkwindathletenationalityvenuedate8.95 m (29ft4\u00bcin)0.3mike powellunited statestokyo1991-08-308.90 m (29ft2\u00bcin) a2.0bob beamonunited statesmexico city1968-10-188.87 m (29ft1in)0.2carl lewisunited statestokyo1991-08-308.86 m (29ft0\u00bein) a1.9robert emmiyansoviet uniontsakhkadzor1987-05-228.74 m (28ft8in)1.4larry myricksunited statesindianapolis1988-07-188.74 m (28ft8in) a2.0erick walderunited statesel paso1994-04-028.74 m (28ft8in)1.2dwight phillipsunited stateseugene2009-06-078.73 m (28ft7\u00bdin)1.2irving saladinopanamahengelo2008-05-248.71 m (28ft6\u00bein)1.9iv\u00e1n pedrosocubasalamanca1995-07-188.66 m (28ft4\u00bein)1.6lo\u00fais ts\u00e1toumasgreecekalam\u00e1ta2007-06-02\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 4 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE mark > '29ft';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1985.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the match on 14 april 2001 was a victory , while the one on 24 february 2001 was a loss\nInput Table: 2000 - 01 sheffield wednesday f.c. season\n\n\ndateopponentvenueresultattendance2000-08-13wolverhampton wanderersa1 - 1190862000-08-19huddersfield townh2 - 3227042000-08-26grimsby towna1 - 077552000-08-28blackburn roversh1 - 1156462000-09-09wimbledonh0 - 5158562000-09-13nottingham foresth0 - 1157002000-09-16tranmere roversa0 - 293522000-09-23preston north endh1 - 3173792000-09-30gillinghama0 - 290992000-10-08west bromwich albionh1 - 2153382000-10-14portsmoutha1 - 2133762000-10-17burnleya0 - 1163722000-10-22birmingham cityh1 - 0146952000-10-25queens park rangersa2 - 1103532000-10-28fulhamh3 - 3175592000-11-04crystal palacea1 - 4153332000-11-07watforda3 - 1111662000-11-01norwich cityh3 - 2169562000-11-18barnsleya0 - 1199892000-11-25crewe alexandraa0 - 171032000-12-02queens park rangersh5 - 2217822000-12-09stockport countyh2 - 4163372000-12-16sheffield uniteda1 - 1251562000-12-23wolverhampton wanderersh0 - 1177872000-12-26bolton wanderersa0 - 2213162000-12-30huddersfield towna0 - 0189312001-01-01grimsby townh1 - 0170042001-01-13blackburn roversa0 - 2193082001-01-20bolton wanderersh0 - 3176382001-02-03watfordh2 - 3161342001-02-10wimbledona1 - 467412001-02-13tranmere roversh1 - 0154442001-02-21nottingham foresta1 - 0232662001-02-24preston north enda0 - 2143792001-03-03gillinghamh2 - 1187022001-03-07portsmouthh0 - 0205032001-03-10west bromwich albiona2 - 1186622001-03-17burnleyh2 - 0201842001-03-24birmingham citya2 - 1197332001-04-01sheffield unitedh1 - 2384332001-04-07stockport countya1 - 296662001-04-14crystal palaceh4 - 1198772001-04-16fulhama1 - 1175002001-04-21barnsleyh2 - 1234982001-04-28norwich citya0 - 1212412001-05-06crewe alexandrah0 - 028007\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT result FROM table_sql WHERE date = '2001-04-14') LIKE '%victory%' \n             AND (SELECT result FROM table_sql WHERE date = '2001-02-24') LIKE '%loss%' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-2006.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: melbourne is the team with the highest away team score\nInput Table: 1954 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddategeelong13.12 (90)hawthorn7.6 (48)kardinia park168701954-08-14collingwood12.16 (88)south melbourne13.12 (90)victoria park185561954-08-14carlton10.16 (76)essendon11.14 (80)princes park297441954-08-14richmond10.18 (78)melbourne15.4 (94)punt road oval240001954-08-14north melbourne9.14 (68)footscray9.14 (68)arden street oval220001954-08-14st kilda13.14 (92)fitzroy9.15 (69)junction oval115001954-08-14\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MAX(away_team_score) FROM table_sql) = (SELECT away_team_score FROM table_sql WHERE away_team = 'melbourne') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1701.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: skip jean - michel m\u00e9nard has a shot pct of 80% and 8 blank ends\nInput Table: 2005 tim hortons brier\n\n\nlocaleskipwlpfpaends_wonends_lostblank_endsstolen_endsshot_pctalbertarandy ferbey92905848437986%manitobarandy dutiaume8377694744101379%nova scotiashawn adams8380604741161383%quebecjean - michel m\u00e3nard747769544081580%british columbiadeane horning6572654745181280%ontariowayne middaugh657562424610782%newfoundland and labradorbrad gushue6576694845131079%saskatchewanpat simmons656661434512980%prince edward islandrod macdonald476785415112579%northern ontariomike jakubo38648641489679%new brunswickwade blanchard385683414517878%\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT shot_pct FROM table_sql WHERE skip = 'jean - michel m\u00e3nard') = 80 \n             AND (SELECT blank_ends FROM table_sql WHERE skip = 'jean - michel m\u00e3nard') = 8 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1598.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: jean - fran\u00e7ois bouvery france is fourth when anders martinson usa is second\nInput Table: cleveland international piano competition\n\n\nyearfirstsecondthirdfourth2013stanislav khristenko russiaarseny tarasevich - nikolaev russiafran\u00e7ois dumont francejiayan sun china2011alexander schimpf germanyalexei chernov russiaeric zuber usakyu yeon kim south korea2009martina filjak croatiadmitri levkovich canadawilliam youn south koreaevgeny brakhman russia2007alexander ghindin russiayaron kohlberg israelalexandre moutouzkine russiaran dank israel2005chu - fang huang chinasergey kuznetsov russiastanislav khristenko russiaspencer myer usa2003kotaro fukuma japansoyeon lee south koreakonstantin soukhovetski russiaandrius zlabys lithuania2001roberto plano italyminsoo sohn south korea\u00f6zg\u00fcr aydin turkeygilles vonsattel switzerland1999antonio pompa - baldi italyvassily primakov russiashoko inoue japansean botkin usa1997per tengstrand swedengulnora alimova uzbekistanning an chinadror biran israel1995margarita shevchenko russiamarina lomazov / ukraine / usadmitri teterin russiagiampaolo stuani italy1993amir katz israelnot awardedseizo azuma and japan yuko nakamichi japankatsunori ishii japan1991ilya itin russiaanders martinson usamarkus pawlik germanyjean - fran\u00e7ois bouvery france1989sergei babayan armenia ( ussr )nicholas angelich usamegumi kaneko japanpascal godart france1987thierry huillet franceasaf zohar israeljonathan bass usabeatrice hsin - chen long / taiwan / china1985daejin kim south koreabenedetto lupo italyh\u00e9l\u00e8ne jeanney franceneil rutman usa1983youngshin an south koreamayumi kameda japanst\u00e9phane lemelin canadaroy kogan usa1981philippe bianconi francedan riddle usar\u00e9my loumbrozo franceroy kogan usa1979edward newman usajean - yves thibaudet franceangela hewitt canadafrederick blum usa1977nathalie bera - tagrine francebarry salwen usadouglas montgomery usalaura silverman usa1975john owings usajulian martin usajohn - patrick millow franceroe van boskirk usa\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT fourth FROM table_sql WHERE first = 'jean - fran\u00e7ois bouvery france') = 'anders martinson usa' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1821.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: washington has a record of 41 - 36 and played at the verizon center with 20173 people in attendance\nInput Table: 2008 - 09 miami heat season\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord759999-04-01dallasl 96 - 98 (ot)dwyane wade (23)jermaine o'neal , udonis haslem (7)dwyane wade (6)american airlines center 2002139 - 36769999-04-03charlottew 97 - 92 (ot)dwyane wade (27)daequan cook (7)dwyane wade (10)time warner cable arena 1956840 - 36779999-04-04washingtonw 118 - 104 (ot)dwyane wade (33)jermaine o'neal , jamaal magloire (6)dwyane wade (8)verizon center 2017341 - 3678'9999-04-07'new orleansl 87 - 93 (ot)dwyane wade (32)jamaal magloire (10)dwyane wade (6)american airlines arena 1960041 - 3779'9999-04-10'bostonl 98 - 105 (ot)dwyane wade (31)michael beasley (13)dwyane wade (9)td banknorth garden 1862441 - 3880'9999-04-12'new yorkw 122 - 105 (ot)dwyane wade (55)michael beasley (16)mario chalmers (9)american airlines arena 1960042 - 38819999-04-14atlantal 79 - 81 (ot)michael beasley (23)michael beasley (13)chris quinn (7)philips arena42 - 3982'9999-04-15'detroitw 102 - 96 (ot)chris quinn (26)dorell wright (10)mario chalmers (10)american airlines arena43 - 39\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT record FROM table_sql WHERE team = 'washington') = '41 - 36' \n             AND (SELECT location_attendance FROM table_sql WHERE team = 'washington') = 20173 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1665.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the most amount of money won by someone from wales is 67823\nInput Table: 1989 u.s. open (golf)\n\n\nplaceplayercountryscoreto_parmoney1curtis strangeunited states71 + 64 + 73 + 70 = 278- 2200000t2chip beckunited states71 + 69 + 71 + 68 = 279- 167823t2mark mccumberunited states70 + 68 + 72 + 69 = 279- 167823t2ian woosnamwales70 + 68 + 73 + 68 = 279- 1678235brian claarunited states71 + 72 + 68 + 69 = 280e34345t6masashi ozakijapan70 + 71 + 68 + 72 = 281+ 128220t6scott simpsonunited states67 + 70 + 69 + 75 = 281+ 1282208peter jacobsenunited states71 + 70 + 71 + 70 = 282+ 224307t9paul azingerunited states71 + 72 + 70 + 70 = 283+ 319968t9hubert greenunited states69 + 72 + 74 + 68 = 283+ 319968t9tom kiteunited states67 + 69 + 69 + 78 = 283+ 319968t9jos\u00e9 mar\u00eda olaz\u00e1balspain69 + 72 + 70 + 72 = 283+ 319968\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MAX(money) FROM table_sql WHERE country = 'wales') = 67823 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1204.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the score for the game where birmingham city was the home team on 10 march 1984 was 1 - 3\nInput Table: 1983 - 84 fa cup\n\n\ntie_nohome_teamscoreaway_teamdate1notts county1 - 2everton1984-03-102sheffield wednesday0 - 0southampton1984-03-11replaysouthampton5 - 1sheffield wednesday1984-03-203plymouth argyle0 - 0derby county1984-03-10replayderby county0 - 1plymouth argyle1984-03-144birmingham city1 - 3watford1984-03-10\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN score = '1 - 3' AND home_team = 'birmingham city' AND date = '1984-03-10' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-617.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: episode 40 , series 14 is titled new order\nInput Table: none\n\n\nepisodeseriesepisode_titleoriginal_air_dateproduction_code271return to genesis2008-04-05201282the suspension2008-04-06202293a team reinvented2008-04-12203304the new captain2008-04-13204315the homecoming2008-04-19205326netherball rules!2008-04-20206337doubts within2008-04-26207348rocket 's decent2008-04-27208359the all - stars2008-05-032093610rocket vs sinedd2008-05-042103711the champions stumble2008-05-102113812last stand2008-05-112123913fluxless2008-05-172134014new order2008-07-262144115revelations2008-07-272154216new rules2008-08-022164317open doors2008-08-032174418warren steps in2008-08-092184519the technodroid v3s2008-08-102194620the fallen star2008-08-162204721coach artegor2008-08-172214822rocket , the midfielder2008-08-232224923destiny2008-08-242235024final preparations2008-08-312245125a team unravels2008-08-31225\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN episode_title = 'new order' AND episode = 40 AND series = 14 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-500.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: sergio luis henao was given the general classification award and the points classification award\nInput Table: 2010 vuelta a colombia\n\n\nstagewinnergeneral_classificationpoints_classificationmountains_classificationsprints_classificationteam_classification1ind ant - idea - fla - lot de medell\u00ednsergio luis henaono awardno awardno awardind ant - idea - fla - lot de medell\u00edn2jaime casta\u00f1eda\u00f3scar sevillajaime casta\u00f1edajaime vergaracamilo g\u00f3mezind ant - idea - fla - lot de medell\u00edn3jairo p\u00e9rezjairo p\u00e9rezjaime casta\u00f1edajaime vergarajulian lopezind ant - idea - fla - lot de medell\u00edn4sergio luis henao\u00f3scar sevilla\u00f3scar sevillajaime vergarajulian lopezind ant - idea - fla - lot de medell\u00edn5fabio duarte\u00f3scar sevilla\u00f3scar sevillajaime vergarajulian lopezind ant - idea - fla - lot de medell\u00edn6luis felipe laverde\u00f3scar sevilla\u00f3scar sevillajaime vergarajaime suazaind ant - idea - fla - lot de medell\u00edn7freddy gonzalez\u00f3scar sevilla\u00f3scar sevillajaime vergaracamilo g\u00f3mezcol es pasion caf\u00e9 de colombia 4728diego calder\u00f3n\u00f3scar sevilla\u00f3scar sevillaoscar solisjuan alejandro garciaind ant - idea - fla - lot de medell\u00edn9jos\u00e9 rujanosergio luis henaosergio luis henaooscar solisjuan alejandro garciaind ant - idea - fla - lot de medell\u00edn10sergio luis henaosergio luis henaosergio luis henaooscar solisjuan alejandro garciaepm - une11jaime vergarasergio luis henaosergio luis henaooscar solisjuan alejandro garciaepm - une12fabio duartesergio luis henaosergio luis henaooscar solisjuan alejandro garciacol es pasion caf\u00e9 de colombia 47213javier gonzalezsergio luis henaosergio luis henaojos\u00e9 rujanojuan alejandro garciaepm - une\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT general_classification FROM table_sql WHERE winner = 'sergio luis henao') = 'sergio luis henao' \n             AND (SELECT points_classification FROM table_sql WHERE winner = 'sergio luis henao') = 'sergio luis henao' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1959.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: 21.16 (142) was the home team score for fitzroy\nInput Table: 1982 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddatefootscray7.8 (50)richmond16.16 (112)western oval162591982-08-07fitzroy21.16 (142)st kilda11.12 (78)junction oval99871982-08-07north melbourne22.18 (150)geelong11.16 (82)arden street oval116341982-08-07hawthorn20.20 (140)collingwood16.22 (118)princes park186991982-08-07essendon20.17 (137)melbourne14.17 (101)vfl park283791982-08-07swans15.16 (106)carlton9.18 (72)scg256011982-08-01\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN home_team_score = '21.16 (142)' AND home_team = 'fitzroy' THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1420.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: france 's competitors finished in consecutive positions of 7th and 8th respectively\nInput Table: 1976 world junior figure skating championships\n\n\nranknamenationsp_+_fspointsplaces1mark cockerellunited states1172.4211.02takashi murajapan2165.724.03brian pockarcanada3166.6223.04norbert schrammwest germany4159.840.05andrew bestwickunited kingdom5158.148.06stephan brilwest germany7155.7257.07patrice macrezfrance6151.7671.08pierre laminefrance8150.579.09shinji someyajapan10150.3474.510jozef sabov\u010d\u00edkczechoslovakia9148.8887.011daniel fuererswitzerland13146.1892.512gerald schranzaustria11143.04102.013helmut kristofics - binderaustria15137.32123.014michael pasfieldaustralia12136.6119.015francis demarteaubelgium14131.02140.016adrian vasileromania16127.74143.017miljan begovicyugoslavia17127.3143.018jeremy dowsonsouth africa18114.98166.019marc franquetbelgium19114.38167.0\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT rank FROM table_sql WHERE nation = 'france' AND places = 7) = \n             (SELECT rank FROM table_sql WHERE nation = 'france' AND places = 8) - 1 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1906.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: four of the teams have a minus goal difference while only four have scored more goals than those against them\nInput Table: 1940 in brazilian football\n\n\npositionteampointsplayedagainstdifference1flamengo1381282fluminense13815103corinthians981544palestra it\u00e1lia881935portuguesa7823- 106botafogo682507vasco da gama6819- 28am\u00e9rica6825- 109s\u00e3o paulo4824- 13\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE difference < 0) = 4 \n             AND (SELECT COUNT(*) FROM table_sql WHERE played > against) = 4 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-718.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: nineteen players were transferred during the summer window as opposed to six during the winter window\nInput Table: 2008 - 09 rangers f.c. season\n\n\nnatnamemoving_totypetransfer_windowtransfer_feesconicholas gallacher9999-01-01end of contract9999-06-01n / aivory coastlacine cherif9999-01-01end of contract9999-06-01n / ascoalistair park9999-01-01end of contract9999-06-01n / aengmichael donald9999-01-01end of contract9999-06-01n / ascocalum reidford9999-01-01end of contract9999-06-01n / ascochris smith9999-01-01end of contract9999-06-01n / abeljeroen van den broeck9999-01-01end of contract9999-06-01n / aslovakiafilip \u0161ebo9999-01-01transfer9999-06-011 mbelthomas buffel9999-01-01transfer9999-06-01n / aespcarlos cu\u00e9llar9999-01-01transfer9999-06-017.8 mscosteven lennon9999-01-01loan9999-06-01n / ascomark weir9999-01-01loan9999-06-01n / ascoandy webster9999-01-01loan9999-06-01n / arsadean furman9999-01-01loan9999-06-01n / ascoalan lowing9999-01-01loan9999-06-01n / ascopaul emslie9999-01-01loan9999-06-01n / ascoscott gallacher9999-01-01loan9999-06-01n / agabondaniel cousin9999-01-01transfer9999-06-013.5 mscoalan gow9999-01-01loan9999-06-01n / aenglee robinson9999-01-01loan9999-01-01n / ascoandrew shinnie9999-01-01loan9999-01-01n / ascosteven kinniburgh9999-01-01loan9999-01-01n / ascorory loy9999-01-01loan9999-01-01n / ascowilliam mclachlan9999-01-01loan9999-01-01n / ascolee robinson9999-01-01loan9999-01-01n / afrajean - claude darcheville9999-01-01transfer9999-01-01freescojordan mcmillan9999-01-01loan9999-01-01n / ascochris burke9999-01-01transfer9999-01-01freecypgeorgios efrem9999-01-01loan9999-01-01n / ascoalan gow9999-01-01loan9999-01-01n / ascocharlie adam9999-01-01loan9999-01-01n / ascoross harvey9999-01-01loan9999-01-01n / ascosteven kinniburgh9999-01-01loan9999-01-01n / a\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE transfer_window = '9999-06-01' AND type = 'transfer') = 19 \n             AND (SELECT COUNT(*) FROM table_sql WHERE transfer_window = '9999-01-01' AND type = 'transfer') = 6 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-676.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: justin leonard from the united states scored 73 + 71 + 68 = 212\nInput Table: 2002 u.s. open (golf)\n\n\nplaceplayercountryscoreto_par1tiger woodsunited states67 + 68 + 70 = 205- 52sergio garc\u00edaspain68 + 74 + 67 = 209- 1t3jeff maggertunited states69 + 73 + 68 = 210et3phil mickelsonunited states70 + 73 + 67 = 210et5robert allenbyaustralia74 + 70 + 67 = 211+ 1t5p\u00e1draig harringtonireland70 + 68 + 73 = 211+ 1t5billy mayfairunited states69 + 74 + 68 = 211+ 1t8nick faldoengland70 + 76 + 66 = 212+ 2t8justin leonardunited states73 + 71 + 68 = 212+ 2t10tom byrumunited states72 + 72 + 70 = 214+ 4t10davis love iiiunited states71 + 71 + 72 = 214+ 4t10scott mccarronunited states72 + 72 + 70 = 214+ 4\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT score FROM table_sql WHERE player = 'justin leonard' AND country = 'united states') = 212 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-732.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: 2 games had a score of more than 10 points\nInput Table: 2008 arizona diamondbacks season\n\n\ndateopponentscorelossattendancerecord9999-09-01cardinals8 - 6mcclellan (2 - 7)3507570 - 679999-09-02cardinals8 - 2petit (3 - 4)2756870 - 689999-09-03cardinals4 - 3perez (2 - 2)2435071 - 689999-09-05dodgers7 - 0haren (14 - 8)5227071 - 699999-09-06dodgers7 - 2webb (19 - 7)4754371 - 709999-09-07dodgers5 - 3rauch (4 - 6)5413771 - 719999-09-08giants6 - 2petit (3 - 5)3025271 - 729999-09-09giants5 - 4rauch (4 - 7)3051871 - 739999-09-10giants4 - 3lyon (2 - 5)3099271 - 749999-09-12reds3 - 2harang (4 - 16)2904672 - 749999-09-13reds3 - 2 (10)pe\u00f1a (1 - 2)4507572 - 759999-09-14reds2 - 1 (10)rauch (4 - 8)2729772 - 769999-09-15giants3 - 1hennessey (1 - 2)2596973 - 769999-09-16giants2 - 0cain (8 - 13)3319574 - 769999-09-17giants7 - 6s\u00e1nchez (9 - 11)2261675 - 769999-09-18giants3 - 2lincecum (17 - 4)3432376 - 769999-09-19rockies3 - 2scherzer (0 - 3)4313776 - 779999-09-20rockies5 - 3fuentes (1 - 5)3828377 - 779999-09-21rockies13 - 4reynolds (2 - 8)3291578 - 779999-09-22cardinals4 - 2wellemeyer (12 - 9)4034979 - 779999-09-23cardinals7 - 4johnson (10 - 10)4001379 - 789999-09-24cardinals4 - 2scherzer (0 - 4)4002979 - 799999-09-25cardinals12 - 3rosales (1 - 1)4050279 - 809999-09-26rockies6 - 4grilli (3 - 3)3495080 - 809999-09-27rockies6 - 4corpas (3 - 4)3323481 - 809999-09-28rockies2 - 1vizca\u00edno (1 - 2)3590882 - 80\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) >= 2 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE score LIKE '%-%' \nAND CAST(SUBSTR(score, 1, INSTR(score, ' - ') - 1) AS INTEGER) > 10 \nAND CAST(SUBSTR(score, INSTR(score, ' - ') + 3) AS INTEGER) > 10;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1675.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: datia 's constituency number is higher than gohad 's by 9\nInput Table: bhind (lok sabha constituency)\n\n\nconstituency_numbernamereserved_for_(_sc_/_st_/_none)districtnumber_of_electorates_(2009)9aternonebhind17733410bhindnonebhind19718311laharnonebhind20583912mehgaonnonebhind21064913gohadscbhind16689320sewdanonedatia13016121bhanderscdatia13960022datianonedatia143593total :total :total :total :1371252\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT constituency_number FROM table_sql WHERE name = 'datia') > \n             (SELECT constituency_number FROM table_sql WHERE name = 'gohad') + 9\n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-315.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: james donaldson had two stints on the jazz 's roster\nInput Table: utah jazz all - time roster\n\n\nplayernationalitypositionyears_for_jazzschool_/_club_teamadrian dantleyunited statesguard - forward1979-01-01notre damebrad davisunited statesguard1979-01-01marylanddarryl dawkinsunited statescenter1987-01-01maynard evans hspaul dawkinsunited statesguard1979-01-01northern illinoisgreg deaneunited statesguard1979-01-01utahjames donaldsonunited statescenter1993-01-01, 1994-01-01, 1995-01-01washington statejohn drewunited statesguard - forward1982-01-01gardner - webbjohn durenunited statesguard1980-01-01georgetown\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE player = 'james donaldson' AND years_for_jazz LIKE '%1993%' AND years_for_jazz LIKE '%1994%') = 2 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1159.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: there were four instances where there was a tie for most rebounds by detroit pistons players during this period of the 2010 - 2011 season\nInput Table: 2010 - 11 detroit pistons season\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord629999-03-01milwaukeel 90 - 92 (ot)rodney stuckey (25)greg monroe , charlie villanueva (9)rodney stuckey (5)bradley center 1136422 - 40639999-03-02minnesotal 105 - 116 (ot)austin daye (22)greg monroe (11)rodney stuckey (10)the palace of auburn hills 1312222 - 41649999-03-06washingtonw 113 - 102 (ot)tayshaun prince (20)greg monroe , rodney stuckey (7)rodney stuckey (9)the palace of auburn hills 1750623 - 41659999-03-09san antoniol 104 - 111 (ot)richard hamilton (20)greg monroe (10)tracy mcgrady (9)at&t center 1858123 - 42669999-03-11oklahoma cityl 94 - 104 (ot)richard hamilton (20)greg monroe (10)greg monroe , rodney stuckey (6)oklahoma city arena 1820323 - 43679999-03-12denverl 101 - 131 (ot)chris wilcox (21)austin daye , ben gordon , greg monroe (6)will bynum (10)pepsi center 1915523 - 44689999-03-16torontow 107 - 93 (ot)richard hamilton (24)greg monroe (10)rodney stuckey (14)the palace of auburn hills 1516624 - 44699999-03-18new yorkw 99 - 95 (ot)tayshaun prince (16)chris wilcox (12)will bynum (5)the palace of auburn hills 2207625 - 44709999-03-20atlantal 96 - 104 (ot)rodney stuckey (22)greg monroe (10)rodney stuckey (8)philips arena 1758025 - 45719999-03-23miamil 94 - 100 (ot)richard hamilton (27)greg monroe (12)rodney stuckey (6)the palace of auburn hills 2207625 - 46729999-03-25clevelandl 91 - 97 (ot)richard hamilton , tayshaun prince (15)chris wilcox , greg monroe (8)rodney stuckey (4)quicken loans arena 1990725 - 47739999-03-26indianaw 100 - 88 (ot)richard hamilton (23)greg monroe (13)richard hamilton , rodney stuckey (6)the palace of auburn hills 1921626 - 47\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 4 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM (\n    SELECT \n        COUNT(*) \n    FROM table_sql \n    WHERE high_rebounds = (\n        SELECT MAX(high_rebounds) \n        FROM table_sql \n        WHERE team = 'detroit pistons'\n    ) \n    GROUP BY date, high_rebounds \n    HAVING COUNT(*) > 1\n) AS subquery;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-207.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: on jun 16 , 1996 , jeff gordon drove for hendrick motorsports\nInput Table: pocono 400\n\n\nyeardatedriverteammanufacturerlaps-race_timeaverage_speed_(mph)report1982-01-019999-06-06bobby allisondigard motorsportsbuick200500 (804.672)4:24:08113.579report1983-01-019999-06-12bobby allisondigard motorsportsbuick200500 (804.672)3:53:13128.636report1984-01-019999-06-10cale yarboroughranier - lundychevrolet200500 (804.672)3:37:08138.164report1985-01-019999-06-09bill elliottmelling racingford200500 (804.672)3:35:48138.974report1986-01-019999-06-08tim richmondhendrick motorsportschevrolet200500 (804.672)4:24:50113.279report1987-01-019999-06-14tim richmondhendrick motorsportschevrolet200500 (804.672)4:05:57122.166report1988-01-019999-06-19geoffrey bodinehendrick motorsportschevrolet200500 (804.672)3:58:21126.147report1989-01-019999-06-18terry labontejunior johnson & associatesford200500 (804.672)3:48:27131.32report1990-01-019999-06-17harry gantleo jackson racingoldsmobile200500 (804.672)4:08:25120.6report1991-01-019999-06-16darrell waltripdarwal , incchevrolet200500 (804.672)4:04:34122.666report1992-01-019999-06-14alan kulwickiak racingford200500 (804.672)3:28:18144.023report1993-01-019999-06-13kyle pettysabco racingpontiac200500 (804.672)3:37:23138.005report1994-01-019999-06-12rusty wallacepenske racingford200500 (804.672)3:52:55128.801report1995-01-019999-06-11terry labontehendrick motorsportschevrolet200500 (804.672)3:37:50137.72report1996-01-019999-06-16jeff gordonhendrick motorsportschevrolet200500 (804.672)3:35:40139.104report1997-01-019999-06-08jeff gordonhendrick motorsportschevrolet200500 (804.672)3:34:33139.828report1998-01-019999-06-21jeremy mayfieldpenske racingford200500 (804.672)4:14:39117.809report1999-01-019999-06-20bobby labontejoe gibbs racingpontiac200500 (804.672)4:12:19118.898report2000-01-019999-06-19jeremy mayfieldpenske racingford200500 (804.672)3:34:41139.741report2001-01-019999-06-17ricky ruddrobert yates racingford200500 (804.672)3:43:14134.389report2002-01-019999-06-09dale jarrettrobert yates racingford200500 (804.672)3:29:10143.426report2003-01-019999-06-08tony stewartjoe gibbs racingchevrolet200500 (804.672)3:42:24134.892report2004-01-019999-06-13jimmie johnsonhendrick motorsportschevrolet200500 (804.672)4:27:33112.129report2005-01-019999-06-12carl edwardsroush racingford201502.5 (808.695)3:53:24129.177report2006-01-019999-06-11denny hamlinjoe gibbs racingchevrolet200500 (804.672)3:47:52131.656report2007-01-019999-06-10jeff gordonhendrick motorsportschevrolet106265 (426.476)1:57:15135.608report2008-01-019999-06-08kasey kahnegillett evernham motorsportsdodge200500 (804.672)3:59:36125.209report2009-01-019999-06-07tony stewartstewart - haas racingchevrolet200500 (804.672)3:36:35138.515report2010-01-019999-06-06denny hamlinjoe gibbs racingtoyota204510 (820.765)3:44:30136.303report2011-01-019999-06-12jeff gordonhendrick motorsportschevrolet200500 (804.672)3:26:21145.384report2012-01-019999-06-10joey loganojoe gibbs racingtoyota160400 (643.737)3:03:12131.004report\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE date = '1996-06-16' \nAND driver = 'jeff gordon' \nAND team = 'hendrick motorsports';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-43.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: steve stricker of united states has the lowest score among all the players\nInput Table: 2006 u.s. open (golf)\n\n\nplaceplayercountryscoreto_par1steve strickerunited states70 + 69 = 139- 12colin montgomeriescotland69 + 71 = 140et3kenneth ferrieengland71 + 70 = 141+ 1t3geoff ogilvyaustralia71 + 70 = 141+ 1t5jim furykunited states70 + 72 = 142+ 2t5p\u00e1draig harringtonireland70 + 72 = 142+ 2t7jason dufnerunited states72 + 71 = 143+ 3t7graeme mcdowellnorthern ireland71 + 72 = 143+ 3t7phil mickelsonunited states70 + 73 = 143+ 3t7arron oberholserunited states75 + 68 = 143+ 3\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MIN(score) FROM table_sql) = (SELECT score FROM table_sql WHERE player = 'steve stricker' AND country = 'united states') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1231.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the packers scored the least amount of points (6) in a game versus the lions\nInput Table: 1976 detroit lions season\n\n\nweekdateopponentresultattendance11976-09-12chicago bearsl 10 - 35412521976-09-19atlanta falconsw 24 - 105084031976-09-26minnesota vikingsl 10 - 97729241976-10-03green bay packersl 24 - 145504151976-10-10new england patriotsw 30 - 106017461976-10-17washington redskinsl 20 - 74590871976-10-24seattle seahawksw 41 - 146128081976-10-31green bay packersw 27 - 67499291976-11-07minnesota vikingsl 31 - 2346735101976-11-14new orleans saintsl 17 - 1642048111976-11-21chicago bearsw 14 - 1078042121976-11-25buffalo billsw 27 - 1466875131976-12-05new york giantsl 24 - 1066069141976-12-11los angeles ramsl 20 - 1773470\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MIN(SUBSTR(result, INSTR(result, ' ') + 1, INSTR(result, ' - ') - INSTR(result, ' ') - 1)) \n              FROM table_sql \n              WHERE opponent = 'green bay packers') = 6 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1206.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: with a tie no 2 , sheffield wednesday is home team\nInput Table: 1983 - 84 fa cup\n\n\ntie_nohome_teamscoreaway_teamdate1notts county1 - 2everton1984-03-102sheffield wednesday0 - 0southampton1984-03-11replaysouthampton5 - 1sheffield wednesday1984-03-203plymouth argyle0 - 0derby county1984-03-10replayderby county0 - 1plymouth argyle1984-03-144birmingham city1 - 3watford1984-03-10\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN home_team = 'sheffield wednesday' AND tie_no = 2 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1894.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the 2005 drama desk award for outstanding choreography did not go to william ivey long\nInput Table: la cage aux folles (musical)\n\n\nyearawardcategorynomineeresult2005tony awardbest revival of a musicalbest revival of a musicalwon2005tony awardbest performance by a leading actor in a musicalgary beachnominated2005tony awardbest choreographyjerry mitchellwon2005tony awardbest costume designwilliam ivey longnominated2005drama desk awardoutstanding revival of a musicaloutstanding revival of a musicalwon2005drama desk awardoutstanding choreographyjerry mitchellwon2005drama desk awardoutstanding costume designwilliam ivey longnominated\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT result FROM table_sql WHERE year = 2005 AND award = 'drama desk award' AND category = 'outstanding choreography') != 'won' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1295.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: one athlete received a medal for pommel horse\nInput Table: list of multiple olympic medalists\n\n\nmedal_countdateathletenationsportrecord_medal_event11896-04-06james connollyunited statesathleticstriple jump g11896-04-06alexandre tuff\u00e8refranceathleticstriple jump s11896-04-06ioannis persakisgreeceathleticstriple jump b11896-04-06robert garrettunited statesathleticsdiscus g11896-04-06panagiotis paraskevopoulosgreeceathleticsdiscus s11896-04-06sotirios versisgreeceathleticsdiscus b21896-04-07robert garrettunited statesathleticslong jump s21896-04-07james connollyunited statesathleticslong jump b31896-04-07robert garrettunited statesathleticsshot put g31896-04-09carl schuhmanngermanygymnasticsvault g31896-04-09hermann weing\u00e4rtnergermanygymnasticsvault b41896-04-09hermann weing\u00e4rtnergermanygymnasticspommel horse s51896-04-09hermann weing\u00e4rtnergermanygymnasticsrings s61896-04-09hermann weing\u00e4rtnergermanygymnasticshorizontal bar g61900-07-16robert garrettunited statesathleticsstanding triple jump b61904-09-03ray ewryunited statesathleticsstanding triple jump g71908-07-20ray ewryunited statesathleticsstanding long jump g81908-07-23ray ewryunited statesathleticsstanding high jump g81920-07-29carl osburnunited statesshootingteam 300 m / 600 m military rifle , prone g91920-07-30carl osburnunited statesshooting300 m military rifle , standing g101920-07-31carl osburnunited statesshootingteam free rifle g111924-06-27carl osburnunited statesshooting600 m free rifle s111928-08-03paavo nurmifinlandathletics5000 m s121928-08-04paavo nurmifinlandathletics3000 m steeplechase s121960-09-02edoardo mangiarottiitalyfencingteam foil s131960-09-09edoardo mangiarottiitalyfencingteam \u00e9p\u00e9e g131964-10-21larisa latyninasoviet uniongymnasticsteam g141964-10-21larisa latyninasoviet uniongymnasticsall - around s151964-10-22larisa latyninasoviet uniongymnasticsvault s161964-10-22larisa latyninasoviet uniongymnasticsuneven bars b171964-10-23larisa latyninasoviet uniongymnasticsbalance beam b181964-10-23larisa latyninasoviet uniongymnasticsfloor exercise g182012-07-31michael phelpsunited statesswimming200 m butterfly s192012-07-31michael phelpsunited statesswimming4 x 200 m freestyle g202012-08-02michael phelpsunited statesswimming200 m individual medley g212012-08-03michael phelpsunited statesswimming100 m butterfly g222012-08-04michael phelpsunited statesswimming4 100 m medley relay g\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) > 0 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE record_medal_event = 'pommel horse';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1775.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: from 1990 - 1995 , the cbr was 22.6 and the number of deaths per year was 1058000\nInput Table: none\n\n\nperiodlive_births_per_yeardeaths_per_yearnatural_change_per_yearcbrcdrnctfrimrlife_expectancy_totallife_expectancy_maleslife_expectancy_females1950-01-01 - 1955-01-012 572 000900 0001 672 00044.115.528.66.1513550.949.252.61955-01-01 - 1960-01-012 918 000947 0001 971 00043.214.029.16.1512253.351.555.21960-01-01 - 1965-01-013 303 000986 0002 317 00042.212.629.66.1510955.753.857.69999-01-01 - 1970-01-013 330 000998 0002 332 00037.011.125.95.3810057.655.759.61970-01-01 - 1975-01-013 441 0001 014 0002 427 00033.79.923.84.729159.557.361.81975-01-01 - 1980-01-013 741 0001 043 0002 698 00032.59.023.54.317961.559.263.91980-01-01 - 1985-01-013 974 0001 064 0002 910 00030.88.222.63.86363.460.466.81985-01-01 - 1990-01-013 757 0001 055 0002 702 00026.37.418.93.15265.361.969.11990-01-01 - 1995-01-013 519 0001 058 0002 461 00022.66.815.82.64367.363.671.21995-01-01 - 2000-01-013 624 0001 086 0002 538 00021.56.515.12.453469.365.573.32000-01-01 - 2005-01-013 572 0001 147 0002 425 00019.86.413.42.252770.967.274.8\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN cbr = 22.6 AND deaths_per_year = 1058000 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE period = '1990-01-01 - 1995-01-01';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1341.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the game between footscray and carlton was played at princess park\nInput Table: 1962 vfl season\n\n\nhome_teamhome_team_scoreaway_teamaway_team_scorevenuecrowddatemelbourne11.18 (84)st kilda11.6 (72)mcg489521962-06-23essendon15.17 (107)geelong10.7 (67)windy hill350001962-06-23collingwood10.14 (74)fitzroy9.11 (65)victoria park264881962-06-23carlton12.9 (81)footscray9.10 (64)princes park324001962-06-23south melbourne10.13 (73)richmond11.13 (79)lake oval170001962-06-23north melbourne10.8 (68)hawthorn10.7 (67)arden street oval84701962-06-23\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE home_team = 'footscray' \nAND away_team = 'carlton' \nAND venue = 'princes park';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1685.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: on september 12 , the attendance was 34028 against the opponent chattanooga\nInput Table: east carolina pirates football , 1990 - 99\n\n\ndateopponentsiteresultattendance9999-09-05virginia techlane stadium blacksburg , val3 - 38481349999-09-12chattanoogadowdy - ficklen stadium greenville , ncw31 - 0340289999-09-19ohiopeden stadium athens , ohw21 - 14191869999-10-03armydowdy - ficklen stadium greenville , ncw30 - 25406079999-10-10uabdowdy - ficklen stadium greenville , ncw26 - 7310029999-10-17alabamalegion field birmingham , all22 - 23800799999-10-24southern missmm roberts stadium hattiesburg , msl7 - 41240209999-10-31houstondowdy - ficklen stadium greenville , ncl31 - 34268219999-11-05cincinnatinippert stadium cincinnati , ohw24 - 21190989999-11-14louisvilledowdy - ficklen stadium greenville , ncl45 - 63262589999-11-21memphisliberty bowl memorial stadium memphis , tnw34 - 31160529999-01-01all times are in easternall times are in easternall times are in easternall times are in eastern\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN attendance = 34028 AND opponent = 'chattanooga' AND date = '9999-09-12' THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-215.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the highest number of discs released for any of the volumes is only 1\nInput Table: none\n\n\nvolumediscsepisodesregion_1region_2region_41142006-01-312007-02-192007-03-152142006-03-282007-06-042007-07-053142006-05-302007-09-032008-03-134142006-07-182008-02-182008-06-195142006-09-192008-05-262009-03-05\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN MAX(discs) = 1 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1822.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: charlotte improved to 40 - 36 with a win of 97 - 92 in ot\nInput Table: 2008 - 09 miami heat season\n\n\ngamedateteamscorehigh_pointshigh_reboundshigh_assistslocation_attendancerecord759999-04-01dallasl 96 - 98 (ot)dwyane wade (23)jermaine o'neal , udonis haslem (7)dwyane wade (6)american airlines center 2002139 - 36769999-04-03charlottew 97 - 92 (ot)dwyane wade (27)daequan cook (7)dwyane wade (10)time warner cable arena 1956840 - 36779999-04-04washingtonw 118 - 104 (ot)dwyane wade (33)jermaine o'neal , jamaal magloire (6)dwyane wade (8)verizon center 2017341 - 3678'9999-04-07'new orleansl 87 - 93 (ot)dwyane wade (32)jamaal magloire (10)dwyane wade (6)american airlines arena 1960041 - 3779'9999-04-10'bostonl 98 - 105 (ot)dwyane wade (31)michael beasley (13)dwyane wade (9)td banknorth garden 1862441 - 3880'9999-04-12'new yorkw 122 - 105 (ot)dwyane wade (55)michael beasley (16)mario chalmers (9)american airlines arena 1960042 - 38819999-04-14atlantal 79 - 81 (ot)michael beasley (23)michael beasley (13)chris quinn (7)philips arena42 - 3982'9999-04-15'detroitw 102 - 96 (ot)chris quinn (26)dorell wright (10)mario chalmers (10)american airlines arena43 - 39\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT record FROM table_sql WHERE team = 'charlotte') = '40 - 36' \n             AND (SELECT score FROM table_sql WHERE team = 'charlotte') = '97 - 92 (ot)' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-252.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: sweden and canada were the only countries on the table that did not receive a medal in two of the categories\nInput Table: 1988 winter olympics\n\n\nranknationgoldsilverbronzetotal1soviet union (urs)1199292east germany (gdr)9106253switzerland (sui)555154finland (fin)41275sweden (swe)40266austria (aut)352107netherlands (ned)32278west germany (frg)24289united states (usa)213610italy (ita)212513canada (can)0235\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE nation = 'sweden' AND (gold = 0 OR silver = 0 OR bronze = 0)) > 0 \n             AND (SELECT COUNT(*) FROM table_sql WHERE nation = 'canada' AND (gold = 0 OR silver = 0 OR bronze = 0)) > 0 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-967.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the settlement of lok is a village\nInput Table: list of cities , towns and villages in vojvodina\n\n\nsettlementcyrillic_nametypepopulation_(2011)largest_ethnic_group_(2002)dominant_religion_(2002)titel\u0442\u0438\u0442\u0435\u043btown5294serbsorthodox christianitygardinovci\u0433\u0430\u0440\u0434\u0438\u043d\u043e\u0432\u0446\u0438village1297serbsorthodox christianitylok\u043b\u043e\u043avillage1114serbsorthodox christianitymo\u0161orin\u043c\u043e\u0448\u043e\u0440\u0438\u043dvillage2569serbsorthodox christianity\u0161ajka\u0161\u0448\u0430\u0458\u043a\u0430\u0448village4374serbsorthodox christianity\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN settlement = 'lok' AND type = 'village' THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-693.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the browns record after they played the game at the paul brown stadium was 3 - 8\nInput Table: 2004 cleveland browns season\n\n\nweekdateopponentresultstadiumrecordattendance12004-09-12baltimore ravensw 20 - 3cleveland browns stadium1 - 073068.022004-09-19dallas cowboysl 12 - 19texas stadium1 - 163119.032004-09-26new york giantsl 10 - 27giants stadium1 - 278521.042004-10-03washington redskinsw 17 - 13cleveland browns stadium2 - 273348.052004-10-10pittsburgh steelersl 23 - 34heinz field2 - 363609.062004-10-17cincinnati bengalsw 34 - 17cleveland browns stadium3 - 373263.072004-10-24philadelphia eaglesl 31 - 34cleveland browns stadium3 - 473394.089999-01-01----nan92004-11-07baltimore ravensl 13 - 27m&t bank stadium3 - 569781.0102004-11-14pittsburgh steelersl 10 - 24cleveland browns stadium3 - 673703.0112004-11-21new york jetsl 7 - 10cleveland browns stadium3 - 772547.0122004-11-28cincinnati bengalsl 48 - 58paul brown stadium3 - 865677.0132004-12-05new england patriotsl 15 - 42cleveland browns stadium3 - 973028.0142004-12-12buffalo billsl 7 - 37ralph wilson stadium3 - 1072330.0152004-12-19san diego chargersl 0 - 21cleveland browns stadium3 - 1172489.0162004-12-26miami dolphinsl 7 - 10pro player stadium3 - 1273169.0172005-01-02houston texansw 22 - 14reliant stadium4 - 1270724.0\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN record = '3 - 8' AND stadium = 'paul brown stadium' THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE week > 12;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1130.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the player with the highest number of league goals is ian robins\nInput Table: 1979 - 80 huddersfield town f.c. season\n\n\nnamepositionleague_appsleague_goalsfa_cup_appsfa_cup_goalsleague_cup_appsleague_cup_goalstotal_appstotal_goalsjim branagandf00000 (1)00 (1)0malcolm browndf4622041523david cowlingmf39 (1)10104044 (1)10peter fletcherfw30 (8)17203135 (8)18keith hanveydf3320040392peter hartmf4641140515ian holmesmf6 (4)3004110 (4)4steve kindonfw22 (1)14000022 (1)14mick laverickmf4542040514bernard purdiedf18 (4)0200020 (4)0andy rankingk2400000240ian robinsfw452520425127fred robinsondf3012040361tommy smithfw00001010brian stantonmf4192000439alan starlinggk2202040280dave suttondf4662041527chris toppingdf1302000150\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT MAX(league_goals) FROM table_sql) = (SELECT league_goals FROM table_sql WHERE name = 'ian robins') \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-970.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: in stanley the bridge is of the concrete deck girder style\nInput Table: list of bridges on the national register of historic places in north dakota\n\n\nnamelistedlocationcountytypebeaver creek bridge1997-02-27finleysteelepratt through trusscaledonia bridge1997-02-27caledoniatraillpratt through trusscedar creek bridge1997-02-27haynesadamspratt through trusscolton 's crossing bridge1997-02-27lisbonransompratt through trusscrystal bridge1997-05-30crystalpembinaconcrete t - beam bridgeeastwood park bridge1975-04-21minotwardcantilever typeelliott bridge1997-02-27townermchenrypratt through trussfairview lift bridge1997-03-14cartwrightmckenzierailroad lift bridgegrace city bridge1997-02-27grace cityfosterpratt through trussgreat northern railway underpass1997-02-27stanleymountrailconcrete deck girder bridgeknife river bridge near stanton2001-04-25stantonmercerpratt through trusslisbon bridge1997-02-27lisbonransomsteel cantilever bean bridgemidland continental overpass1997-02-27jamestownstutsmansteel cantilever beam bridgemidway bridge1997-02-27johnstowngrand forkswarren bedstead bridgenesheim bridge1997-02-27mcvillenelsonpratt through trussnew rockford bridge1997-03-13new rockford closed to trafficeddywarren through truss bridgenorthwood bridge1997-02-27northwoodgrand forkspratt pony trussnorway bridge1997-02-27mayvilletraillpratt pony trussost valle bridge1997-02-27thompsongrand forkspratt through trussromness bridge1997-02-27cooperstowngriggspratt through trusssorlie memorial bridge1999-07-19grand forksgrand forksparker through truss bridgeviking bridge1997-02-27portlandtraillpratt through trusswest antelope bridge1997-02-27florabensonpratt pony truss bridgewest park bridge1997-02-27valley citybarnesconcrete false arch bridgewestgaard bridge1997-02-27voltairemchenrypratt pony through trussblanchard bridge1997-02-27blanchardtraillpratt through trussgoose river bridge1997-02-27hillsborotraillpratt through trussliberty memorial bridge1997-03-11 removed 2009-03-25bismarckburleighwarren - turner through trussporter elliott bridge1997-02-27hillsborotraillwarren through trussportland park bridge2004-09-23portlandtraillsteel through girderrainbow arch bridge2004-09-23valley citybarnesmarsh rainbow arch\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT type FROM table_sql WHERE location = 'stanley') = 'concrete deck girder' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-897.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: none of the england players took as many wickets as bill johnston\nInput Table: 1948 ashes series\n\n\nplayerteammatcheswicketsaveragebest_bowlingray lindwallaustralia52719.626 / 20bill johnstonaustralia52723.335 / 36alec bedserengland51838.224 / 81keith milleraustralia51323.154 / 125ernie toshackaustralia41133.095 / 40norman yardleyengland5922.662 / 32jim lakerengland3952.444 / 138\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT wickets FROM table_sql WHERE team = 'england') < \n             (SELECT wickets FROM table_sql WHERE player = 'bill johnston') \n        THEN 'FALSE' \n        ELSE 'TRUE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-378.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: lgplv2 is the license for rygel\nInput Table: comparison of upnp av media servers\n\n\nnamelicenseos_xunix_-_likewindowsweb_interface360 media servergplnoyesyesyesavia media playerpropnonononobrisamitpartialpartialnoyescoherencemitpartialpartialpartialyesdivxpropyesnoyesnoelgato eyeconnectpropyesnononofoobar2000propnonoyesnofuppesgplyesyesyesyesgeexbox usharegplnoyesnoyesgmediaservergplnoyesnonohome media centergplv2nonoyesyesisedora media serverpropyesnoyesyesjriver media centerpropnonoyesyeskooraroo mediapropyesyesyesyeslximediagplyesyesyesnomajestic media serverpropyesnononomediatombgplpartialyesnoyesminidlnagpl / bsdpartialyesyespartialmezzmopropnonoyesnomyihomepropyesyesyesnomythtv with upnpgplyesyesnoyesnullriver medialinkpropyesnononoplayonpropnonoyesyesplexpropyesyesyesyesps3 media servergplyesyesyesyespymedsmitpartialpartialnonorygellgplv2noyesnonorivetpropyesnononoserviiopropyesyesyesyessimplecenter premiumpropnonoyesyesskiftapropyesyesyesnosongbirdgplv2yesnoyesnotvblepropnonoyesnotversitypropnonoyesyestvmobilipropyesyesyesyestvsharepropnonoyesnotwonkyserverpropyesyesyesyesuniversal media servergplyesyesyesyeswindows media connectpropnonoyesnowild media serverpropyesyesyesyesxbmc media centergplyesyesyesyesxupnpdgplv2noyesnoyesyazsoft playbackpropyesnonononamelicenseos xunix - likewindowsweb interface\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN license = 'lgplv2' AND name = 'rygel' THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-830.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: in the 1981 open championship no one player achieved their position alone , in other words there was a tie at every position\nInput Table: 1981 open championship\n\n\nplaceplayercountryscoreto_part1vicente fern\u00e3\u00a1ndezargentina70et1nick jobengland70et3isao aokijapan71+ 1t3david grahamaustralia71+ 1t3tony jacklinengland71+ 1t3johnny millerunited states71+ 1t3simon owennew zealand71+ 1t3hal sutton (a)united states71+ 1t9howard clarkengland72+ 2t9ben crenshawunited states72+ 2t9david jaggerengland72+ 2t9mark jamesengland72+ 2t9greg normanaustralia72+ 2t9arnold palmerunited states72+ 2t9bill rogersunited states72+ 2t9sam torrancescotland72+ 2\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(DISTINCT place) = COUNT(*) THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1774.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: in the period 1995 - 2000 , the imr is 34.0 and the life expectancy is 69.3\nInput Table: none\n\n\nperiodlive_births_per_yeardeaths_per_yearnatural_change_per_yearcbrcdrnctfrimrlife_expectancy_totallife_expectancy_maleslife_expectancy_females1950-01-01 - 1955-01-012 572 000900 0001 672 00044.115.528.66.1513550.949.252.61955-01-01 - 1960-01-012 918 000947 0001 971 00043.214.029.16.1512253.351.555.21960-01-01 - 1965-01-013 303 000986 0002 317 00042.212.629.66.1510955.753.857.69999-01-01 - 1970-01-013 330 000998 0002 332 00037.011.125.95.3810057.655.759.61970-01-01 - 1975-01-013 441 0001 014 0002 427 00033.79.923.84.729159.557.361.81975-01-01 - 1980-01-013 741 0001 043 0002 698 00032.59.023.54.317961.559.263.91980-01-01 - 1985-01-013 974 0001 064 0002 910 00030.88.222.63.86363.460.466.81985-01-01 - 1990-01-013 757 0001 055 0002 702 00026.37.418.93.15265.361.969.11990-01-01 - 1995-01-013 519 0001 058 0002 461 00022.66.815.82.64367.363.671.21995-01-01 - 2000-01-013 624 0001 086 0002 538 00021.56.515.12.453469.365.573.32000-01-01 - 2005-01-013 572 0001 147 0002 425 00019.86.413.42.252770.967.274.8\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN imr = 34.0 AND life_expectancy_total = 69.3 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE period = '1995-01-01 - 2000-01-01';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-699.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: chinatrust whales played against kao lung - wei\nInput Table: 2007 uni - president lions season\n\n\ndateopponentscorelosssave9999-03-17la new bears4 - 5pan wei - lunhuang chun - chung9999-03-18la new bears4 - 1horacio estradatseng yi - cheng9999-03-22chinatrust whales7 - 9kao lung - weini fu - deh9999-03-23chinatrust whales4 - 5pan wei - lunmiguel saladin9999-03-24la new bears1 - 5jeriome robertson||30089999-03-25la new bears1 - 6rob cordemanshuang chun - chung9999-03-27brother elephantspostponed rescheduled for june 19postponed rescheduled for june 19postponed rescheduled for june 199999-03-28brother elephants0 - 4tsao chun - yangchuang wei - chuan9999-03-31macoto cobras11 - 5diegomar markwell||2275\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 0 THEN 'FALSE' \n        ELSE 'TRUE' \n    END \nFROM table_sql \nWHERE opponent = 'chinatrust whales' \nAND save = 'kao lung - wei';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1400.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: lleyton hewitt has won the master series finals two times , in 2002 and 2003\nInput Table: lleyton hewitt\n\n\noutcomeyearchampionshipsurfaceopponentscorerunner - up2000-01-01stuttgarthard (i)wayne ferreira6 - 7 (6 - 8) , 6 - 3 , 7 - 6 (7 - 5) , 6 - 7 (2 - 7) , 2 - 6winner2002-01-01indian wellshardtim henman6 - 1 , 6 - 2runner - up2002-01-01cincinnatihardcarlos moy\u00e15 - 7 , 6 - 7 (5 - 7)runner - up2002-01-01pariscarpet (i)marat safin6 - 7 (4 - 7) , 0 - 6 , 4 - 6winner2003-01-01indian wells (2)hardgustavo kuerten6 - 1 , 6 - 1runner - up2004-01-01cincinnati (2)hardandre agassi3 - 6 , 6 - 3 , 2 - 6runner - up2005-01-01indian wellshardroger federer2 - 6 , 4 - 6 , 4 - 6\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 2 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE championship = 'master series finals' \nAND outcome = 'winner' \nAND year IN ('2002-01-01', '2003-01-01');\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1465.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: emi watanabe was ranked one place higher than dagmar lurz in the 1979 world figure skating championships\nInput Table: 1979 world figure skating championships\n\n\nranknamenationsp_+_fspointsplaces1linda fratianneunited states1186.92112anett p\u00f6tzscheast germany3184.36183emi watanabejapan4180.52314dagmar lurzwest germany6179.96335denise biellmannswitzerland2177.28496lisa - marie allenunited states5176.68547claudia kristofics - binderaustria7175.44638susanna drianoitaly9173.46709carola wei\u00dfenbergeast germany11170.548810kristiina wegeliusfinland15169.269811carrie rughunited states10169.349712sanda dubrav\u010di\u0107yugoslavia8166.9611513natalia strelkovasoviet union16164.9413414deborah cottrillunited kingdom20164.813615karin riedigerwest germany17164.514216renata baierovaczechoslovakia13164.014417petra ernertwest germany14163.2414918kira ivanovasoviet union12164.0214719janet morrisseycanada18162.0416220reiko kobayashijapan21161.317021jeanne chapmannorway19161.816622anita siegfriedswitzerland26150.3420723astrid jansen in de walnetherlands25149.1821624franca bianconiitaly22149.0421825bodil olssonsweden23147.0222526corine wyrschswitzerland27146.7623327kim myo silnorth korea24145.4823728belinda coulthardaustralia28145.9223829katie symmondsnew zealand29134.5826130shin hae sooksouth korea30120.4427031gloria masspain31112.28279\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT rank FROM table_sql WHERE name = 'emi watanabe') = \n             (SELECT rank FROM table_sql WHERE name = 'dagmar lurz') + 1 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-454.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the dolphins' defense recorded two shutouts during the season\nInput Table: 1983 miami dolphins season\n\n\nweekdateopponentresultattendance11983-09-04buffalo billsw 12 - 07871521983-09-11new england patriotsw 34 - 245934331983-09-19los angeles raidersl 27 - 145779641983-09-25kansas city chiefsw 14 - 65078551983-10-02new orleans saintsl 17 - 76648961983-10-09buffalo billsl 38 - 355994871983-10-16new york jetsw 32 - 145861581983-10-23baltimore coltsw 21 - 73234391983-10-30los angeles ramsw 30 - 1472175101983-11-06san francisco 49ersw 20 - 1757832111983-11-13new england patriotsl 17 - 660771121983-11-20baltimore coltsw 37 - 054482131983-11-28cincinnati bengalsw 38 - 1474506141983-12-04houston oilersw 24 - 1739434151983-12-10atlanta falconsw 31 - 2456725161983-12-16new york jetsw 34 - 1459975\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 2 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE result LIKE 'w%' \nAND attendance = 0;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-544.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: christian de la fuente 's duration is 02x03 - 03x05\nInput Table: list of csi : miami characters\n\n\ncharacterpositionactorfirst_episodefinal_episodedurationfinal_episode_countdr tom lomanmedical examinerchristian clemenson9999-01-019999-01-0108x03 - 10x1952maxine valeradna technicianboti bliss9999-01-019999-01-0102x01 - 08x1176dan cooperav technicianbrendan fehr9999-01-019999-01-0104x01 - 06x1635tyler jensonav technicianbrian pothYYYY-MM-DD9999-10-0701x19 - 03x2429aaron peterstrace technicianarmando kennedy9999-01-019999-01-0103x07 - 04x2516cynthia wellsqd technicianbrooke bloom9999-01-012023-09-2002x16 - 05x1814jake berkeleydetectivejohnny whitworth9999-01-012022-01-0105x02 - 08x2112john hagendetectiveholt mccallany9999-01-019999-10-0701x17 - 03x2411adelle sevilladetectivewanda de jesus9999-01-019999-01-0101x03 - 01x1710rebecca nevinsasachristina chang9999-01-019999-01-0103x06 - 08x2310joseph kaylefingerprints technicianleslie odom , jr9999-01-019999-01-0102x05 - 03x20 , 04x22 - 04x249aaron jessopofficerjoel west9999-01-019999-01-0102x20 - 04x258sam belmontestrace technicianchristian de la fuente9999-01-012022-01-0102x03 - 03x057peter elliottsecret service agentmichael b silver9999-01-019999-01-0102x17 - 05x037monica westasabellamy young9999-01-019999-01-0104x10 - 04x256glen colefbi agentmark rolston9999-01-019999-01-0104x25 - 06x123bob keatondea agentmax martini9999-01-019999-01-0102x08 , 03x20 - 03x223mac taylornypd csigary sinise9999-01-019999-01-0102x23 , 04x072stella bonaseranypd csimelina kanakaredes9999-01-019999-01-0102x231aiden burnnypd csivanessa ferlito9999-01-019999-01-0102x231danny messernypd csicarmine giovinazzo9999-01-019999-01-0102x231sheldon hawkesnypd medical examinerhill harper9999-01-019999-01-0102x231\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN duration = '02x03 - 03x05' AND actor = 'christian de la fuente' THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1229.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the minnesota vikings defeated the lions in both games they played\nInput Table: 1976 detroit lions season\n\n\nweekdateopponentresultattendance11976-09-12chicago bearsl 10 - 35412521976-09-19atlanta falconsw 24 - 105084031976-09-26minnesota vikingsl 10 - 97729241976-10-03green bay packersl 24 - 145504151976-10-10new england patriotsw 30 - 106017461976-10-17washington redskinsl 20 - 74590871976-10-24seattle seahawksw 41 - 146128081976-10-31green bay packersw 27 - 67499291976-11-07minnesota vikingsl 31 - 2346735101976-11-14new orleans saintsl 17 - 1642048111976-11-21chicago bearsw 14 - 1078042121976-11-25buffalo billsw 27 - 1466875131976-12-05new york giantsl 24 - 1066069141976-12-11los angeles ramsl 20 - 1773470\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 2 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE opponent = 'minnesota vikings' \nAND result LIKE 'w%';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-102.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: t7 is the place of peter oosterhuis , who won 7500\nInput Table: 1975 u.s. open (golf)\n\n\nplaceplayercountryscoreto_parmoneyt1lou grahamunited states74 + 72 + 68 + 73 = 287+ 3playofft1john mahaffeyunited states73 + 71 + 72 + 71 = 287+ 3playofft3frank beardunited states74 + 69 + 67 + 78 = 288+ 410875t3ben crenshawunited states70 + 68 + 76 + 74 = 288+ 410875t3hale irwinunited states74 + 71 + 73 + 70 = 288+ 410875t3bob murphyunited states74 + 73 + 72 + 69 = 288+ 410875t7jack nicklausunited states72 + 70 + 75 + 72 = 289+ 57500t7peter oosterhuisengland69 + 73 + 72 + 75 = 289+ 57500t9pat fitzsimonsunited states67 + 73 + 73 + 77 = 290+ 65000t9arnold palmerunited states69 + 75 + 73 + 73 = 290+ 65000t9tom watsonunited states67 + 68 + 78 + 77 = 290+ 65000\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN place = 't7' AND player = 'peter oosterhuis' AND money = 7500 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-342.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the highest attendance was at the american airlines center\nInput Table: 2008 - 09 phoenix suns season\n\n\ngamedateteamlocation_attendancerecord759999-04-01houstonus airways center 1842241 - 34769999-04-03sacramentous airways center 1842242 - 3477'9999-04-05'dallasamerican airlines center 2030142 - 35789999-04-08new orleansnew orleans arena 1778143 - 3579'9999-04-10'memphisfedexforum 1590843 - 36809999-04-11minnesotatarget center 1847844 - 36819999-04-13memphisus airways center 1842245 - 3682'9999-04-15'golden stateus airways center46 - 36\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN MAX(location_attendance) = (SELECT MAX(location_attendance) FROM table_sql) \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE location_attendance = 'american airlines center';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1613.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: on may 31st david lelay (fra) was the series leader\nInput Table: 2008 french road cycling cup\n\n\ndateeventwinnerteamseries_leader9999-02-24tour du haut vardavide rebellin ( ita )gerolsteinerrinaldo nocentini ( ita )9999-03-23cholet - pays de loirejanek tombak ( est )mitsubishi - jartazirinaldo nocentini ( ita )9999-04-06grand prix de rennesmikhaylo khalilov ( ukr )ceramica flaminia - bossini doccejimmy casper ( fra )'9999-04-15'paris - camembertalejandro valverde ( esp )caisse d'epargnej\u00e9r\u00f4me pineau ( fra )0000-04-17grand prix de denainedvald boasson hagen ( nor )team high roadjimmy casper ( fra )9999-04-19tour du finist\u00e8redavid lelay ( fra )bretagne - armor luxjimmy casper ( fra )9999-04-20tro - bro l\u00e9onfr\u00e9d\u00e9ric guesdon ( fra )fran\u00e7aise des jeuxjimmy casper ( fra )9999-05-04troph\u00e9e des grimpeursdavid lelay ( fra )bretagne - armor luxdavid lelay ( fra )9999-05-31grand prix de plumelec - morbihanthomas voeckler ( fra )bouygues t\u00e9l\u00e9comdavid lelay ( fra )9999-08-03polynormandearnaud g\u00e9rard ( fra )fran\u00e7aise des jeuxj\u00e9r\u00f4me pineau ( fra )9999-08-31chteauroux classicanthony ravard ( fra )agritubelj\u00e9r\u00f4me pineau ( fra )9999-09-21grand prix d'isbergueswilliam bonnet ( fra )cr\u00e9dit agricolej\u00e9r\u00f4me pineau ( fra )9999-10-05tour de vend\u00e9ekoldo fern\u00e1ndez ( esp )euskaltel - euskadij\u00e9r\u00f4me pineau ( fra )9999-10-09paris - bourgesbernhard eisel ( aut )team columbiaj\u00e9r\u00f4me pineau ( fra )\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT series_leader FROM table_sql WHERE date = '9999-05-31' AND winner = 'david lelay ( fra )') = 'david lelay ( fra )' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-266.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the new zealand breakers lost two games more than the melbourne tigers\nInput Table: 2008 - 09 nbl season\n\n\nteamlostlast_5streakhomeaway%_pts%_wonsouth dragons84 - 1won 213 - 29 - 6110.2573.33melbourne tigers103 - 2lost 111 - 49 - 6106.4766.67new zealand breakers122 - 3won 210 - 58 - 7106.0860.0perth wildcats134 - 1won 211 - 46 - 9102.0656.67townsville crocodiles134 - 1lost 112 - 35 - 1099.2656.67adelaide 36ers153 - 2lost 112 - 33 - 12100.9250.0wollongong hawks192 - 3lost 19 - 62 - 1395.0336.67sydney spirit190 - 5lost 89 - 62 - 1394.5136.67cairns taipans191 - 4lost 35 - 106 - 993.5736.67gold coast blaze223 - 2won 36 - 92 - 1393.4526.67\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT lost FROM table_sql WHERE team = 'new zealand breakers') > \n             (SELECT lost FROM table_sql WHERE team = 'melbourne tigers') + 2 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1481.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: 25 - 26 january 2003 and 12 - 13 july 2003 were the only games played in 2003\nInput Table: tsuyoshi fujita\n\n\nseasonevent_typelocationformatdaterank1997 - 98nationalstokyospecial1998-07-0441998 - 99grand prixkyotolimited1999-01-1641998 - 99apac region championshipsingaporespecial1999-03-2731999 - 00grand prixtaipeiextended2000-02-1222000 - 01grand prixkyotoextended2000-11-1212000 - 01grand prixhiroshimalimited2001-01-2762000 - 01pro tourtokyoblock constructed2001-03-1622001 - 02grand prixhong konglimited2001-11-1732001 - 02masterssan diegostandard2002-01-1172001 - 02grand prixfukuokalimited2002-02-1662001 - 02grand prixnagoyateam limited2002-05-1142002 - 03grand prixutsunomiyalimited2002-10-1232002 - 03grand prixhiroshimaextended2003-01-2572002 - 03grand prixbangkokstandard2003-07-1212003 - 04nationalsosakaspecial2004-06-1112003 - 04grand prixkuala lumpurstandard2004-07-2442005grand prixseattleextended2005-03-0572005invitationallos angelesspecial2005-05-1722005pro tourlondonbooster draft2005-07-0822005pro tourlos angelesextended2005-10-2852011pro tournagoyablock constructed and booster draft2011-06-105\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 2 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE (date BETWEEN '2003-01-25' AND '2003-01-26' OR date BETWEEN '2003-07-12' AND '2003-07-13') \nAND season LIKE '%2003%';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-312.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the jazz had two players with the last name dawkins but their time on the team did not overlap\nInput Table: utah jazz all - time roster\n\n\nplayernationalitypositionyears_for_jazzschool_/_club_teamadrian dantleyunited statesguard - forward1979-01-01notre damebrad davisunited statesguard1979-01-01marylanddarryl dawkinsunited statescenter1987-01-01maynard evans hspaul dawkinsunited statesguard1979-01-01northern illinoisgreg deaneunited statesguard1979-01-01utahjames donaldsonunited statescenter1993-01-01, 1994-01-01, 1995-01-01washington statejohn drewunited statesguard - forward1982-01-01gardner - webbjohn durenunited statesguard1980-01-01georgetown\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE player LIKE '%dawkins%') = 2 \n             AND (SELECT COUNT(*) FROM table_sql WHERE player LIKE '%dawkins%' AND years_for_jazz LIKE '%1993%' OR years_for_jazz LIKE '%1994%' OR years_for_jazz LIKE '%1995%') = 0 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-155.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: after 2000 england , the united states , brazil , and and puerto rico each contributed one player\nInput Table: utah jazz all - time roster\n\n\nplayernationalitypositionyears_for_jazzschool_/_club_teamrick adelmanunited statesguard1974-01-01loyola (ca)john amaechienglandcenter / forward2001-03-01penn statelouis amundsonunited statesforward2007-01-01unlvj j andersonunited statesforward1982-01-01bradleyshandon andersonunited statesguard / forward9999-01-01georgiarafael ara\u00e3jobrazilcenter2006-01-01byucarlos arroyopuerto ricoguard2002-05-01florida internationalisaac austinunited statescenter1991-01-01arizona stateanthony aventunited statesforward1998-01-01seton hall\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(*) = 4 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE years_for_jazz > '2000-01-01' \nAND nationality IN ('england', 'united states', 'brazil', 'puerto rico');\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-49.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: university of dublin is the only group of origin made up entirely of members from one party\nInput Table: members of the 5th seanad\n\n\npartyadministrative_panelagricultural_panelcultural_and_educational_panelindustrial_and_commercial_panellabour_panelnational_university_of_irelanduniversity_of_dublinnominated_by_the_taoiseachtotalfianna f\u00e1il4423010721fine gael132201009labour party000150028clann na talmhan020010003independent010101339total7115911331160\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT COUNT(*) FROM table_sql WHERE university_of_dublin > 0 AND party != 'university of dublin') = 0 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1506.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: fukusy\u016b no purop\u014dzu had 2.2% higher ratings than the title with the most recent broadcast date\nInput Table: tsuki no koibito\n\n\nUnnamed:_0episode_titleromanized_titletranslation_of_titlebroadcast_dateratingsep 1\u304a\u307e\u3048\u304c\u6b32\u3057\u3044omae ga hosiii want you2010-05-1022.4%ep 2\u3042\u308a\u3048\u306a\u3044\u30ad\u30b9arienai kisuthe unthinkable kiss2010-05-1719.2%ep 3\u5fa9\u8b90\u306e\u30d7\u30ed\u30dd\u30fc\u30bafukusy\u016b no purop\u014dzuthe proposal out of revenge2010-05-2415.6%ep 4\u3053\u3093\u306a\u306b\u597d\u304d\u3060\u3063\u305f\u3093\u3060\u2026konna ni suki dattanda\u2026that 's how much i liked you2010-05-3115.5%ep 5\u597d\u304d\u3068\u8a00\u3048\u305f\u3089\u3044\u3044\u306e\u306bsuki to ietara iinoniif only i could say , i like you2010-06-0717.4%ep 6\u6700\u7d42\u7ae0\u5e8f\u5e55\u30fb\u5225\u308csaish\u016bsh\u014djomakuwakarea prologue of final chapter , farewell2010-06-1413.4%\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT ratings FROM table_sql WHERE broadcast_date = (SELECT MAX(broadcast_date) FROM table_sql)) - \n             (SELECT ratings FROM table_sql WHERE romanized_title = 'fukusy\u016b no purop\u014dzu') > 2.2 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-341.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: three of the games at the us airways center had the same attendance\nInput Table: 2008 - 09 phoenix suns season\n\n\ngamedateteamlocation_attendancerecord759999-04-01houstonus airways center 1842241 - 34769999-04-03sacramentous airways center 1842242 - 3477'9999-04-05'dallasamerican airlines center 2030142 - 35789999-04-08new orleansnew orleans arena 1778143 - 3579'9999-04-10'memphisfedexforum 1590843 - 36809999-04-11minnesotatarget center 1847844 - 36819999-04-13memphisus airways center 1842245 - 3682'9999-04-15'golden stateus airways center46 - 36\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN COUNT(DISTINCT location_attendance) = 1 THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE location_attendance LIKE '%us airways center%';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1484.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: the last 2 games in season 5 were held in los angeles and london\nInput Table: tsuyoshi fujita\n\n\nseasonevent_typelocationformatdaterank1997 - 98nationalstokyospecial1998-07-0441998 - 99grand prixkyotolimited1999-01-1641998 - 99apac region championshipsingaporespecial1999-03-2731999 - 00grand prixtaipeiextended2000-02-1222000 - 01grand prixkyotoextended2000-11-1212000 - 01grand prixhiroshimalimited2001-01-2762000 - 01pro tourtokyoblock constructed2001-03-1622001 - 02grand prixhong konglimited2001-11-1732001 - 02masterssan diegostandard2002-01-1172001 - 02grand prixfukuokalimited2002-02-1662001 - 02grand prixnagoyateam limited2002-05-1142002 - 03grand prixutsunomiyalimited2002-10-1232002 - 03grand prixhiroshimaextended2003-01-2572002 - 03grand prixbangkokstandard2003-07-1212003 - 04nationalsosakaspecial2004-06-1112003 - 04grand prixkuala lumpurstandard2004-07-2442005grand prixseattleextended2005-03-0572005invitationallos angelesspecial2005-05-1722005pro tourlondonbooster draft2005-07-0822005pro tourlos angelesextended2005-10-2852011pro tournagoyablock constructed and booster draft2011-06-105\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (SELECT location FROM table_sql WHERE season = '2011' AND rank = 5) = 'los angeles' \n             AND (SELECT location FROM table_sql WHERE season = '2005' AND rank = 5) = 'london' \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END;\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    },
    "FN/test-1038.html": {
        "method": "Text2SQL",
        "subfolder": "FN",
        "LLM_analysis": "No",
        "Actual_Correctness": "No",
        "Model_Prediction": "False",
        "Actual_Answer": "True",
        "prompt_to_LLM": "\n        The Table Question Answering model is working on Table Fact Verification task (TabFact dataset), verifying if a given Statement is TRUE or FALSE on a given input Table.\n        You are given an explanation that describes the reasoning process of the Table Question Answering model in HTML format. This explanation is based on the 'Text2SQL' method. Please carefully analyze the explanation and determine whether the prediction is correct or wrong.\n\n        Text2SQL Explanation:\n        \n\n\n\n\nStatement: takamiyama had the longest time range between his first and last record , 13 years\nInput Table: list of sumo record holders\n\n\nnametotalfirstlasthighest_rankkotonishiki341990-09-011999-09-01sekiwakekai\u014d321994-05-012000-07-01\u014dzekimus\u014dyama311994-03-012000-09-01\u014dzekihasegawa301965-11-011974-09-01sekiwakekotomitsuki302001-01-012007-07-01\u014dzekiakinoshima271988-11-012000-09-01sekiwaketakamiyama271969-11-011982-09-01sekiwaketakat\u014driki261991-05-012000-05-01sekiwakewakanosato262000-11-012005-09-01sekiwakedaikirin221966-11-011970-09-01\u014dzekitochiazuma ii221997-07-012005-01-01\u014dzekikisenosato222006-07-012011-09-01\u014dzeki\n\n\nSQL Command:\nSELECT \n    CASE \n        WHEN (julianday(last) - julianday(first)) >= 4745 \n        THEN 'TRUE' \n        ELSE 'FALSE' \n    END \nFROM table_sql \nWHERE name = 'takamiyama';\nPrediction: False\n\n\n\n        Is the prediction shown in the Explanation correct? Answer with 'Yes' or 'No':\n        "
    }
}